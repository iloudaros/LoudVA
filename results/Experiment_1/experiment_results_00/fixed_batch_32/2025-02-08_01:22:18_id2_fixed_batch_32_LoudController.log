2025-02-08 01:21:19,013 - LoudVA - INFO - [LoudController] - Starting LoudController...
2025-02-08 01:21:19,013 - LoudVA - INFO - [LoudController] - Press CTRL+C to stop the controller.
2025-02-08 01:21:19,013 - LoudVA - INFO - [LoudController] - Debug mode: False
2025-02-08 01:21:19,039 - LoudVA - INFO - [LoudController] - Selected scheduler: fixed_batch
2025-02-08 01:21:19,047 - LoudVA - INFO - [LoudServer] - Starting LoudVA server...
 * Serving Flask app 'LoudServer'
 * Debug mode: off
WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:5000
Press CTRL+C to quit
2025-02-08 01:21:20,427 - LoudVA - INFO - [DeviceData] - Using profiling data for decision making.
2025-02-08 01:21:20,427 - LoudVA - INFO - [DeviceData] - Filling missing profile data with predictions.
2025-02-08 01:21:20,440 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/iloudaros/Desktop/LoudVA/LoudController/../measurements/archive/Representative/Profiling.csv
2025-02-08 01:21:20,440 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/iloudaros/Desktop/LoudVA/LoudController/../measurements/archive/Representative/xavier-nx-00/measurements/xavier-nx-00_filtered_freqs.csv
2025-02-08 01:21:20,441 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/iloudaros/Desktop/LoudVA/LoudController/../measurements/archive/Representative/LoudJetson0/measurements/LoudJetson0_filtered_freqs.csv
2025-02-08 01:21:20,441 - LoudVA - INFO - [DeviceData] - Loaded GPU specs from /home/iloudaros/Desktop/LoudVA/LoudController/../data/devices/gpu_specs.csv
2025-02-08 01:21:20,471 - LoudVA - INFO - [DeviceData] - Initial frequency on agx-xavier-00: 114750000
2025-02-08 01:21:20,471 - LoudVA - INFO - [DeviceData] - agx-xavier-00 : Filling missing profile data...
2025-02-08 01:21:20,471 - LoudVA - INFO - [DeviceData] - agx-xavier-00 : Missing profile data filled with predictions.
2025-02-08 01:21:20,471 - LoudVA - INFO - [DeviceData] - Devices initialized successfully
2025-02-08 01:21:20,471 - LoudVA - INFO - [LoudController] - Using fixed batch size 32
127.0.0.1 - - [08/Feb/2025 01:22:21] "GET / HTTP/1.1" 200 -
2025-02-08 01:22:22,356 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:22:27,127 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 61dcaf1f-e26b-42aa-8227-4e7155e22b7d
127.0.0.1 - - [08/Feb/2025 01:22:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:22:27,247 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 01:22:32,407 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 01:22:36,370 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8ef5933e-5726-4310-853e-a7310138ae1a
127.0.0.1 - - [08/Feb/2025 01:22:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:22:37,322 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 01:22:41,841 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 39c5103e-7747-495d-bf6e-bafbb3650bb7
127.0.0.1 - - [08/Feb/2025 01:22:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:22:42,305 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 01:22:46,238 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bf198544-2958-4117-9ab1-5fb9f6e53170
127.0.0.1 - - [08/Feb/2025 01:22:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:22:47,275 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 01:22:52,412 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 01:22:57,401 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 01:23:00,374 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 01:23:00,888 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cabc4bbb-6492-4dc9-9ee2-a49e55a08562
127.0.0.1 - - [08/Feb/2025 01:23:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:00,901 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a8af0a8c-65c1-4e5a-bb85-a0792780bf76
127.0.0.1 - - [08/Feb/2025 01:23:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:02,352 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 01:23:05,332 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 01:23:06,143 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a3595eb9-5a64-450d-b0ff-2def8d748002
127.0.0.1 - - [08/Feb/2025 01:23:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:07,336 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 01:23:08,454 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b5228ac2-14fc-4174-9b84-532d76470f0a
127.0.0.1 - - [08/Feb/2025 01:23:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:08,466 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 24683385-fa4e-414c-ba80-9821ec1f1eee
127.0.0.1 - - [08/Feb/2025 01:23:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:10,330 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 01:23:12,403 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.0
2025-02-08 01:23:12,921 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d67bcc80-0eac-4de9-9593-dd25a42d2b6a
127.0.0.1 - - [08/Feb/2025 01:23:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:12,939 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 18d5641b-aaa1-4ba7-a6a8-d1c1994ae124
127.0.0.1 - - [08/Feb/2025 01:23:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:15,444 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:23:17,278 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 01:23:20,459 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 01:23:21,204 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9c30bf80-46aa-485a-a139-a3595e1bd476
127.0.0.1 - - [08/Feb/2025 01:23:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:21,220 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 12125106-5502-4af7-acb0-8d04c02a5d48
127.0.0.1 - - [08/Feb/2025 01:23:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:22,298 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 01:23:25,361 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 01:23:27,292 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 01:23:28,356 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 60c64ab8-ee55-4ed5-a13b-1ee15ebb7884
127.0.0.1 - - [08/Feb/2025 01:23:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:30,466 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.0
2025-02-08 01:23:31,021 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0726793c-d0ed-4536-8fdd-22bf94c5c9e8
127.0.0.1 - - [08/Feb/2025 01:23:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:31,762 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4e26b77a-74e0-417d-9f72-ceac7e8430ca
127.0.0.1 - - [08/Feb/2025 01:23:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:32,318 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 01:23:33,282 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c00f6417-a91d-4c30-8268-8a6b13a9eca9
127.0.0.1 - - [08/Feb/2025 01:23:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:35,339 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 01:23:37,308 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 01:23:40,502 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 01:23:41,680 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 297fa7f9-90ac-4a42-83b4-70ba76287237
127.0.0.1 - - [08/Feb/2025 01:23:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:41,684 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2b6964c2-7d94-4ac3-b0d6-6843a3d45ac4
127.0.0.1 - - [08/Feb/2025 01:23:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:41,708 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 99af3781-d6d7-483a-a098-454093c309d5
127.0.0.1 - - [08/Feb/2025 01:23:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:42,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 01:23:43,178 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 36fd619a-2065-4396-b9f2-aa164e66d1ba
127.0.0.1 - - [08/Feb/2025 01:23:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:45,321 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:23:47,318 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 01:23:47,749 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 600dbec6-f20a-4a1b-b104-15961011a1b6
127.0.0.1 - - [08/Feb/2025 01:23:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:48,719 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bdfe5c7f-c785-4c82-832e-d1249f14c441
127.0.0.1 - - [08/Feb/2025 01:23:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:48,726 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b89cb6c3-c84c-4fb0-93f0-c68be0edc0a9
127.0.0.1 - - [08/Feb/2025 01:23:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:50,053 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ffaa41ce-bfe5-43f6-91e4-f8a797d49343
127.0.0.1 - - [08/Feb/2025 01:23:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:50,422 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 01:23:52,244 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 01:23:55,438 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 01:23:57,492 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 01:23:57,495 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d07bdd48-a4e2-40da-8eb9-b5cb7a8d2d9c
127.0.0.1 - - [08/Feb/2025 01:23:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:57,499 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 773ec466-fe98-4722-bd80-aafd89134adb
127.0.0.1 - - [08/Feb/2025 01:23:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:23:57,531 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 77deec99-7c36-4222-ac5e-b2dbdf37566e
127.0.0.1 - - [08/Feb/2025 01:23:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:24:00,527 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 01:24:02,034 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3e070e89-bef2-486f-b871-f5deb59211b5
127.0.0.1 - - [08/Feb/2025 01:24:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:24:02,046 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 030b50cc-d91d-4058-a960-8cadbd01718a
127.0.0.1 - - [08/Feb/2025 01:24:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:24:02,270 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 01:24:05,463 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 01:24:07,382 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 01:24:09,822 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4324d36f-e737-4aa9-9e8a-d56065e1be19
127.0.0.1 - - [08/Feb/2025 01:24:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:24:10,473 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 01:24:12,352 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 01:24:14,343 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:24:15,364 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:24:16,428 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 50be0fc7-000c-4ee3-bf5c-9ae4fe29513d
127.0.0.1 - - [08/Feb/2025 01:24:16] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:24:17,294 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 01:24:17,945 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 01:24:19,499 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.0
2025-02-08 01:24:20,405 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:24:22,378 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 01:24:22,994 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 01:24:23,905 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c8c4eda1-6747-42c2-a1a4-473b7d83043c
127.0.0.1 - - [08/Feb/2025 01:24:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:24:24,332 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:24:25,324 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 01:24:27,396 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.0
2025-02-08 01:24:29,508 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 01:24:30,452 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 01:24:32,357 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.0
2025-02-08 01:24:33,447 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3d20d982-99a1-4e79-bfba-c6cf8ae264a6
127.0.0.1 - - [08/Feb/2025 01:24:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:24:34,447 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 01:24:35,305 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 01:24:35,474 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3c554ec7-a875-4f70-98ad-1f2359792fb9
127.0.0.1 - - [08/Feb/2025 01:24:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:24:37,345 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 01:24:39,387 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 01:24:40,360 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:24:41,148 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 01:24:42,483 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:24:44,405 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 01:24:45,572 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 01:24:46,136 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:24:47,350 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 01:24:49,505 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.0
2025-02-08 01:24:50,498 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.0
2025-02-08 01:24:51,242 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 01:24:52,353 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:24:54,440 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 01:24:55,481 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 01:24:55,891 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bcd9f678-9c54-4a94-ae17-edc28199be98
127.0.0.1 - - [08/Feb/2025 01:24:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:24:56,138 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 01:24:56,685 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e13c3e54-73db-4c5a-a33a-b456bec0650a
127.0.0.1 - - [08/Feb/2025 01:24:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:24:57,305 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 01:24:59,518 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 01:25:00,442 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 01:25:01,300 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 01:25:02,126 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f5d39aae-2990-4861-a868-e985c1e96950
127.0.0.1 - - [08/Feb/2025 01:25:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:25:02,165 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6fb98613-d49a-4414-9962-8211770264da
127.0.0.1 - - [08/Feb/2025 01:25:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:25:04,555 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 01:25:05,708 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 01:25:05,896 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 01:25:06,209 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 01:25:06,818 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 01:25:07,801 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 01:25:08,871 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 01:25:09,568 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 01:25:09,839 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 01:25:10,524 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 01:25:10,844 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 01:25:11,263 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 01:25:11,900 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 01:25:12,801 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:25:13,810 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 01:25:14,599 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 01:25:14,803 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 01:25:15,772 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 01:25:15,836 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 01:25:16,237 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:25:16,646 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 49fe5483-4e9a-476c-9864-96a90f165d0f
127.0.0.1 - - [08/Feb/2025 01:25:16] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:25:19,302 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 01:25:20,452 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
Exception in thread Thread-38:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:21,200 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-39:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-40:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:24,292 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-41:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-42:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:25,318 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 01:25:26,498 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.0
Exception in thread Thread-43:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:29,546 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 01:25:30,352 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
Exception in thread Thread-44:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-45:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:31,435 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-46:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-47:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-48:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:34,770 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 01:25:35,851 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-49:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:36,144 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-51:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-50:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:39,736 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.0
2025-02-08 01:25:40,744 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 01:25:41,313 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-52:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-53:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:44,719 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.0
Exception in thread Thread-54:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-55:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:45,649 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.0
2025-02-08 01:25:46,407 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-56:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-57:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-58:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:49,670 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
Exception in thread Thread-59:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:50,912 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
Exception in thread Thread-60:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:51,240 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-62:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-61:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-64:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-63:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:54,628 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:25:55,621 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 01:25:56,232 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
Exception in thread Thread-66:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-65:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-67:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:25:59,844 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-68:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:00,805 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 01:26:01,155 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-69:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-70:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:04,772 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-71:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:05,672 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.0
Exception in thread Thread-72:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:06,321 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-73:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-74:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:09,468 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
Exception in thread Thread-75:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:11,642 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
Exception in thread Thread-76:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-77:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-78:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:14,752 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
Exception in thread Thread-79:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:16,253 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-80:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-81:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-82:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:19,354 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 01:26:21,220 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-83:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-84:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:24,778 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 01:26:26,871 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
Exception in thread Thread-85:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-86:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:29,673 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 01:26:31,176 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
Exception in thread Thread-87:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-88:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:34,566 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 01:26:36,545 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
Exception in thread Thread-89:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-90:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-91:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:39,607 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 01:26:41,120 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
Exception in thread Thread-92:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-93:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-94:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-95:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-96:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:46,582 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
Exception in thread Thread-97:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-98:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-99:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:51,543 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-100:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-102:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-101:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:26:56,892 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
Exception in thread Thread-103:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-104:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-106:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:27:01,246 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-105:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-107:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-108:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-109:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-110:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:27:06,680 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.0
Exception in thread Thread-111:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-112:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:27:11,525 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-113:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-114:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:27:16,305 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
Exception in thread Thread-115:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-116:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-117:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-119:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-118:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/iloudaros/Desktop/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/iloudaros/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/iloudaros/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 01:27:35,351 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 55f56dc5-a69a-4b2b-a6ee-f4ee3c165b20
127.0.0.1 - - [08/Feb/2025 01:27:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:27:35,504 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9f817a5a-ef0e-495d-8a95-52df6097443e
127.0.0.1 - - [08/Feb/2025 01:27:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:27:36,086 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2682ad0b-a7ae-4713-85e9-ccbaf5f54bb6
127.0.0.1 - - [08/Feb/2025 01:27:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:27:36,733 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 193398c6-6a28-420a-9a65-55cc8d7624e0
127.0.0.1 - - [08/Feb/2025 01:27:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:27:40,997 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 468890cd-3614-447a-b04c-3da4ec6fb1a3
127.0.0.1 - - [08/Feb/2025 01:27:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:27:41,269 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3daaded5-94c4-4969-a604-156cc36c2893
127.0.0.1 - - [08/Feb/2025 01:27:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:27:41,535 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9c8866db-e864-4ee7-ab14-20b2d9716210
127.0.0.1 - - [08/Feb/2025 01:27:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:27:41,987 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 02213fce-bd31-444a-955a-9f8a988ae63b
127.0.0.1 - - [08/Feb/2025 01:27:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:27:42,392 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 35215ff2-c5b2-49c2-9de4-113ed41bf170
127.0.0.1 - - [08/Feb/2025 01:27:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:27:42,995 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cf6a6725-6042-4a8e-a729-5e0705730695
127.0.0.1 - - [08/Feb/2025 01:27:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:27:43,746 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3714e966-d7d9-4c31-bcab-1005adce1d80
127.0.0.1 - - [08/Feb/2025 01:27:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:27:44,198 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b78432a3-2dd4-4379-8a39-acba23c1a464
127.0.0.1 - - [08/Feb/2025 01:27:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:27:44,286 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 265d6785-c3d0-44d2-bcc8-e303dc8688d1
127.0.0.1 - - [08/Feb/2025 01:27:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:17,344 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7abce338-4e21-4d81-9236-6ddbe4c3bbf9
2025-02-08 01:29:17,359 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7abce338-4e21-4d81-9236-6ddbe4c3bbf9
127.0.0.1 - - [08/Feb/2025 01:29:17] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:17,959 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 64238831-d632-41da-a396-ad22c95d32a6
2025-02-08 01:29:17,998 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 64238831-d632-41da-a396-ad22c95d32a6
127.0.0.1 - - [08/Feb/2025 01:29:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:19,539 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eb1b14a6-b6b0-4854-909f-c8c72a6008ca
2025-02-08 01:29:19,741 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eb1b14a6-b6b0-4854-909f-c8c72a6008ca
127.0.0.1 - - [08/Feb/2025 01:29:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:20,492 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 169452a4-561f-49ee-afcf-e074c0501612
2025-02-08 01:29:20,650 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 169452a4-561f-49ee-afcf-e074c0501612
127.0.0.1 - - [08/Feb/2025 01:29:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:22,550 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c11c77ab-0719-4782-8e9e-a5c9f911cc86
2025-02-08 01:29:22,761 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c11c77ab-0719-4782-8e9e-a5c9f911cc86
127.0.0.1 - - [08/Feb/2025 01:29:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:23,016 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5487b8cb-66df-4cc6-845e-94eb11c469ec
2025-02-08 01:29:23,058 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5487b8cb-66df-4cc6-845e-94eb11c469ec
127.0.0.1 - - [08/Feb/2025 01:29:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:24,378 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4524133c-9fa6-4017-8af7-4cc694d4b8a6
2025-02-08 01:29:24,431 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4524133c-9fa6-4017-8af7-4cc694d4b8a6
127.0.0.1 - - [08/Feb/2025 01:29:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:25,355 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d8c7cea2-bac8-4596-98bd-d88921ddf62f
2025-02-08 01:29:25,368 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d8c7cea2-bac8-4596-98bd-d88921ddf62f
127.0.0.1 - - [08/Feb/2025 01:29:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:27,460 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ee97e523-9039-4d71-8bf1-49b27c77974e
2025-02-08 01:29:27,578 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ee97e523-9039-4d71-8bf1-49b27c77974e
127.0.0.1 - - [08/Feb/2025 01:29:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:29,691 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a48eee70-32a7-4df1-bfc3-c280e1067a76
2025-02-08 01:29:29,839 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a48eee70-32a7-4df1-bfc3-c280e1067a76
127.0.0.1 - - [08/Feb/2025 01:29:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:30,508 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 73ef1820-b31e-4fdc-9704-4b122ae01d5b
2025-02-08 01:29:30,686 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 73ef1820-b31e-4fdc-9704-4b122ae01d5b
127.0.0.1 - - [08/Feb/2025 01:29:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:32,423 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 80b88ead-086a-42b7-bcec-e26216416c5c
2025-02-08 01:29:32,548 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 80b88ead-086a-42b7-bcec-e26216416c5c
127.0.0.1 - - [08/Feb/2025 01:29:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:34,605 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0d231e35-24fa-4928-a2af-770aac4fa383
2025-02-08 01:29:34,780 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0d231e35-24fa-4928-a2af-770aac4fa383
127.0.0.1 - - [08/Feb/2025 01:29:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:35,325 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 38ce3c74-94ba-4118-8da4-b10705d76f97
2025-02-08 01:29:35,358 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 38ce3c74-94ba-4118-8da4-b10705d76f97
127.0.0.1 - - [08/Feb/2025 01:29:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:37,484 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f4698d70-5b80-4831-ae0e-dee514afce3c
2025-02-08 01:29:37,647 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f4698d70-5b80-4831-ae0e-dee514afce3c
127.0.0.1 - - [08/Feb/2025 01:29:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:39,422 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f7b37344-0653-421a-8345-b5fb4f491ccf
2025-02-08 01:29:39,472 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f7b37344-0653-421a-8345-b5fb4f491ccf
127.0.0.1 - - [08/Feb/2025 01:29:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:40,371 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4e940c1c-9572-44fc-99db-fb935f3cc641
2025-02-08 01:29:40,421 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4e940c1c-9572-44fc-99db-fb935f3cc641
127.0.0.1 - - [08/Feb/2025 01:29:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:41,155 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2cdf0105-4c97-4176-b47c-f46674e0b51c
2025-02-08 01:29:41,303 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2cdf0105-4c97-4176-b47c-f46674e0b51c
127.0.0.1 - - [08/Feb/2025 01:29:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:42,521 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5cb11ff0-6244-42f2-8073-37f71d1d741a
2025-02-08 01:29:42,822 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5cb11ff0-6244-42f2-8073-37f71d1d741a
127.0.0.1 - - [08/Feb/2025 01:29:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:44,529 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f06e5532-266a-4714-8e01-eb3373c5097f
2025-02-08 01:29:44,703 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f06e5532-266a-4714-8e01-eb3373c5097f
127.0.0.1 - - [08/Feb/2025 01:29:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:45,703 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e1ff3e8c-4ed9-4aae-adc5-ecf3dfedfbbd
2025-02-08 01:29:45,858 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e1ff3e8c-4ed9-4aae-adc5-ecf3dfedfbbd
127.0.0.1 - - [08/Feb/2025 01:29:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:46,147 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ee8dd0c5-c4bb-45a3-9729-c83582822101
2025-02-08 01:29:46,186 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ee8dd0c5-c4bb-45a3-9729-c83582822101
127.0.0.1 - - [08/Feb/2025 01:29:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:47,392 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f1fa2b95-c073-429f-83c4-e174cb865c62
2025-02-08 01:29:47,557 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f1fa2b95-c073-429f-83c4-e174cb865c62
127.0.0.1 - - [08/Feb/2025 01:29:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:49,554 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a2140ddb-6015-4ff9-bb25-1b1b21d55402
2025-02-08 01:29:49,733 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a2140ddb-6015-4ff9-bb25-1b1b21d55402
127.0.0.1 - - [08/Feb/2025 01:29:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:50,550 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0239f09d-958e-408b-9c6f-0f815abb709b
2025-02-08 01:29:50,685 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0239f09d-958e-408b-9c6f-0f815abb709b
127.0.0.1 - - [08/Feb/2025 01:29:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:51,291 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cb47f81d-c948-42ee-b11b-308361396154
2025-02-08 01:29:51,351 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cb47f81d-c948-42ee-b11b-308361396154
127.0.0.1 - - [08/Feb/2025 01:29:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:52,427 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9d990a01-67f0-481f-aee8-78d26cf57722
2025-02-08 01:29:52,534 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9d990a01-67f0-481f-aee8-78d26cf57722
127.0.0.1 - - [08/Feb/2025 01:29:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:54,458 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b7155581-a017-4632-aa43-9ab67fd56da3
2025-02-08 01:29:54,511 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b7155581-a017-4632-aa43-9ab67fd56da3
127.0.0.1 - - [08/Feb/2025 01:29:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:55,513 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9bfdf309-75cf-46ca-9ee5-2db2092dfeb9
2025-02-08 01:29:55,583 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9bfdf309-75cf-46ca-9ee5-2db2092dfeb9
127.0.0.1 - - [08/Feb/2025 01:29:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:56,196 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 29be73a7-6f53-41f1-9bd4-d7fadd8c70df
2025-02-08 01:29:56,268 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 29be73a7-6f53-41f1-9bd4-d7fadd8c70df
127.0.0.1 - - [08/Feb/2025 01:29:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:57,316 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b28fc2cd-dbe8-4b81-9d9b-ca2a2cf0c2c3
2025-02-08 01:29:57,370 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b28fc2cd-dbe8-4b81-9d9b-ca2a2cf0c2c3
127.0.0.1 - - [08/Feb/2025 01:29:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:29:59,575 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 64224c97-b493-4249-b133-55c54aa9207f
2025-02-08 01:29:59,709 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 64224c97-b493-4249-b133-55c54aa9207f
127.0.0.1 - - [08/Feb/2025 01:29:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:00,491 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a9af71aa-b512-41d5-9d46-36a0321de795
2025-02-08 01:30:00,587 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a9af71aa-b512-41d5-9d46-36a0321de795
127.0.0.1 - - [08/Feb/2025 01:30:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:01,357 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9bb25b76-9f25-4725-bc48-23f338e20b49
2025-02-08 01:30:01,390 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9bb25b76-9f25-4725-bc48-23f338e20b49
127.0.0.1 - - [08/Feb/2025 01:30:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:04,654 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 54fce495-99b0-4007-9f0b-d7b160c09a16
2025-02-08 01:30:04,770 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 54fce495-99b0-4007-9f0b-d7b160c09a16
127.0.0.1 - - [08/Feb/2025 01:30:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:05,809 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 49fb1286-f541-4032-8bbe-62dfe31361d6
2025-02-08 01:30:05,907 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8130d024-bca5-46f4-a9f3-66b0b5543032
2025-02-08 01:30:05,909 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8130d024-bca5-46f4-a9f3-66b0b5543032
127.0.0.1 - - [08/Feb/2025 01:30:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:05,919 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 49fb1286-f541-4032-8bbe-62dfe31361d6
127.0.0.1 - - [08/Feb/2025 01:30:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:06,222 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3a87deac-8279-449f-bfe0-574ce946afda
2025-02-08 01:30:06,261 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3a87deac-8279-449f-bfe0-574ce946afda
127.0.0.1 - - [08/Feb/2025 01:30:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:06,831 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 02f945ff-1db5-41fa-8326-61cff838ab9d
2025-02-08 01:30:06,836 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 02f945ff-1db5-41fa-8326-61cff838ab9d
127.0.0.1 - - [08/Feb/2025 01:30:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:07,805 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a61c46c4-a703-4232-99e9-1edd06ae2c0b
2025-02-08 01:30:07,807 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a61c46c4-a703-4232-99e9-1edd06ae2c0b
127.0.0.1 - - [08/Feb/2025 01:30:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:08,897 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b6947f68-b5af-4aea-b8cb-e669cb33c226
2025-02-08 01:30:08,913 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b6947f68-b5af-4aea-b8cb-e669cb33c226
127.0.0.1 - - [08/Feb/2025 01:30:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:09,671 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 52fc0d41-2e50-4b57-af24-79cabae4635c
2025-02-08 01:30:09,779 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 52fc0d41-2e50-4b57-af24-79cabae4635c
127.0.0.1 - - [08/Feb/2025 01:30:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:09,845 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8c8c864d-3eab-4dc8-bfbc-c9d575011bfa
2025-02-08 01:30:09,849 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8c8c864d-3eab-4dc8-bfbc-c9d575011bfa
127.0.0.1 - - [08/Feb/2025 01:30:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:10,569 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0234d474-2b2a-47cf-a750-6b83ca8e3c87
2025-02-08 01:30:10,665 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0234d474-2b2a-47cf-a750-6b83ca8e3c87
127.0.0.1 - - [08/Feb/2025 01:30:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:10,852 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 240cf0e2-3a67-4cb1-afdf-7deb88b5445b
2025-02-08 01:30:10,861 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 240cf0e2-3a67-4cb1-afdf-7deb88b5445b
127.0.0.1 - - [08/Feb/2025 01:30:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:11,303 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 529ff645-e0da-496f-9e82-74a489859c17
2025-02-08 01:30:11,347 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 529ff645-e0da-496f-9e82-74a489859c17
127.0.0.1 - - [08/Feb/2025 01:30:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:11,908 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7ffbef45-e36b-4072-87f3-fc1cf0e5ba2c
2025-02-08 01:30:11,913 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7ffbef45-e36b-4072-87f3-fc1cf0e5ba2c
127.0.0.1 - - [08/Feb/2025 01:30:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:12,822 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d9772a33-b087-47c8-af2e-38f67f809793
2025-02-08 01:30:12,829 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d9772a33-b087-47c8-af2e-38f67f809793
127.0.0.1 - - [08/Feb/2025 01:30:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:13,812 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4c25ca5c-34cc-42da-bfb4-1de0ccce1320
2025-02-08 01:30:13,823 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4c25ca5c-34cc-42da-bfb4-1de0ccce1320
127.0.0.1 - - [08/Feb/2025 01:30:13] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:14,658 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e1571927-44dc-453c-8542-f7b38c81f216
2025-02-08 01:30:14,735 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e1571927-44dc-453c-8542-f7b38c81f216
127.0.0.1 - - [08/Feb/2025 01:30:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:14,806 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 35fd7f11-fca9-40f6-a0f1-4023e43b13c3
2025-02-08 01:30:14,811 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 35fd7f11-fca9-40f6-a0f1-4023e43b13c3
127.0.0.1 - - [08/Feb/2025 01:30:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:15,821 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 07195400-34ff-482b-967d-630ac36987ae
2025-02-08 01:30:15,846 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ed89a0a0-78ff-43df-9b10-137c4fc7f820
2025-02-08 01:30:15,859 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ed89a0a0-78ff-43df-9b10-137c4fc7f820
127.0.0.1 - - [08/Feb/2025 01:30:15] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:15,902 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 07195400-34ff-482b-967d-630ac36987ae
127.0.0.1 - - [08/Feb/2025 01:30:15] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:16,260 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 810f2007-3f9d-4f20-8196-1e05c5090fc3
2025-02-08 01:30:16,293 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 810f2007-3f9d-4f20-8196-1e05c5090fc3
127.0.0.1 - - [08/Feb/2025 01:30:16] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:19,324 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 072531da-34ae-4a48-9292-acaf495c0e8b
2025-02-08 01:30:19,332 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 072531da-34ae-4a48-9292-acaf495c0e8b
127.0.0.1 - - [08/Feb/2025 01:30:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:20,464 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 276b41f8-4980-4649-8019-e6210e41321f
2025-02-08 01:30:20,506 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 276b41f8-4980-4649-8019-e6210e41321f
127.0.0.1 - - [08/Feb/2025 01:30:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:21,238 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bf7d871d-67b5-4b6e-a246-8d7f49eef5cd
2025-02-08 01:30:21,275 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bf7d871d-67b5-4b6e-a246-8d7f49eef5cd
127.0.0.1 - - [08/Feb/2025 01:30:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:24,304 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cfb39eef-35de-49d2-813c-f35bd591b5c8
2025-02-08 01:30:24,308 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cfb39eef-35de-49d2-813c-f35bd591b5c8
127.0.0.1 - - [08/Feb/2025 01:30:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:25,335 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 444c7861-825c-4641-bd30-eab438b75b9d
2025-02-08 01:30:25,339 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 444c7861-825c-4641-bd30-eab438b75b9d
127.0.0.1 - - [08/Feb/2025 01:30:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:26,564 - LoudVA - WARNING - [LoudServer] - Timeout reached for request db44cf08-2fdf-4468-be08-8717defe02f7
2025-02-08 01:30:26,620 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: db44cf08-2fdf-4468-be08-8717defe02f7
127.0.0.1 - - [08/Feb/2025 01:30:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:29,594 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 54eaa64b-faa0-437b-9b2b-ede14c7a2507
2025-02-08 01:30:29,615 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 54eaa64b-faa0-437b-9b2b-ede14c7a2507
127.0.0.1 - - [08/Feb/2025 01:30:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:30,357 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c635df9b-1174-495a-b7ee-9425ec2e7b04
2025-02-08 01:30:30,361 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c635df9b-1174-495a-b7ee-9425ec2e7b04
127.0.0.1 - - [08/Feb/2025 01:30:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:31,503 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0a1ae634-f2a8-46a6-bab1-e53b0b0bbaf3
2025-02-08 01:30:31,544 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0a1ae634-f2a8-46a6-bab1-e53b0b0bbaf3
127.0.0.1 - - [08/Feb/2025 01:30:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:34,822 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 629cb6cb-ecfc-40c9-85fb-5842ad8ff905
2025-02-08 01:30:34,829 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 629cb6cb-ecfc-40c9-85fb-5842ad8ff905
127.0.0.1 - - [08/Feb/2025 01:30:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:35,990 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a73216e9-3380-4f0a-9d09-7eea74fd3482
2025-02-08 01:30:36,074 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a73216e9-3380-4f0a-9d09-7eea74fd3482
127.0.0.1 - - [08/Feb/2025 01:30:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:36,160 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1152c0b6-3714-470e-b5b3-c0661b7379f5
2025-02-08 01:30:36,182 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1152c0b6-3714-470e-b5b3-c0661b7379f5
127.0.0.1 - - [08/Feb/2025 01:30:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:39,777 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 16e023e4-471d-4d51-8b71-953858afa7f1
2025-02-08 01:30:39,819 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 16e023e4-471d-4d51-8b71-953858afa7f1
127.0.0.1 - - [08/Feb/2025 01:30:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:40,804 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 85e2082a-def9-4248-8658-a859f95bd8bf
2025-02-08 01:30:40,831 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 85e2082a-def9-4248-8658-a859f95bd8bf
127.0.0.1 - - [08/Feb/2025 01:30:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:41,325 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 13b5a235-a378-424d-90e4-d0ea67ca4f73
2025-02-08 01:30:41,335 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 13b5a235-a378-424d-90e4-d0ea67ca4f73
127.0.0.1 - - [08/Feb/2025 01:30:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:44,777 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fa800fbc-af0a-433c-bcdd-c41816139488
2025-02-08 01:30:44,804 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fa800fbc-af0a-433c-bcdd-c41816139488
127.0.0.1 - - [08/Feb/2025 01:30:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:45,692 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a0ab30ad-b4bd-426a-9440-ad00427841a5
2025-02-08 01:30:45,728 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a0ab30ad-b4bd-426a-9440-ad00427841a5
127.0.0.1 - - [08/Feb/2025 01:30:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:46,430 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 96ab94d8-8dfc-48f6-8652-4657fd7f06fd
2025-02-08 01:30:46,448 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 96ab94d8-8dfc-48f6-8652-4657fd7f06fd
127.0.0.1 - - [08/Feb/2025 01:30:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:49,735 - LoudVA - WARNING - [LoudServer] - Timeout reached for request abb9fef1-dd6f-4969-92a2-a82d59b43562
2025-02-08 01:30:49,779 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: abb9fef1-dd6f-4969-92a2-a82d59b43562
127.0.0.1 - - [08/Feb/2025 01:30:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:50,953 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 73f9661a-7770-46ba-93a9-f02b7677ccf8
2025-02-08 01:30:50,977 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 73f9661a-7770-46ba-93a9-f02b7677ccf8
127.0.0.1 - - [08/Feb/2025 01:30:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:51,259 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f29f99bf-b6de-442d-b4d8-57dc89233f58
2025-02-08 01:30:51,266 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f29f99bf-b6de-442d-b4d8-57dc89233f58
127.0.0.1 - - [08/Feb/2025 01:30:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:54,659 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 881ae1ec-bd2d-4b7b-8e85-0fc6f4d02f47
2025-02-08 01:30:54,668 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 881ae1ec-bd2d-4b7b-8e85-0fc6f4d02f47
127.0.0.1 - - [08/Feb/2025 01:30:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:55,644 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 350c9be1-e2ab-462a-84a7-07670c333f9c
2025-02-08 01:30:55,655 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 350c9be1-e2ab-462a-84a7-07670c333f9c
127.0.0.1 - - [08/Feb/2025 01:30:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:56,250 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 23fc4cbd-7560-42af-a365-5b16a37453cd
2025-02-08 01:30:56,255 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 23fc4cbd-7560-42af-a365-5b16a37453cd
127.0.0.1 - - [08/Feb/2025 01:30:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:30:59,890 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 364476a3-9a04-4620-ade8-daccf8e179eb
2025-02-08 01:30:59,920 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 364476a3-9a04-4620-ade8-daccf8e179eb
127.0.0.1 - - [08/Feb/2025 01:30:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:31:00,876 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c341a57f-ec82-4804-b2f0-988a07c8f2e9
2025-02-08 01:31:00,943 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c341a57f-ec82-4804-b2f0-988a07c8f2e9
127.0.0.1 - - [08/Feb/2025 01:31:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:31:01,174 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d1164c20-fb4d-478a-91d5-1d92a0798dcd
2025-02-08 01:31:01,202 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d1164c20-fb4d-478a-91d5-1d92a0798dcd
127.0.0.1 - - [08/Feb/2025 01:31:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:31:04,874 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ec073b4b-f6f8-4344-b7da-44e7d65edf84
2025-02-08 01:31:04,938 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ec073b4b-f6f8-4344-b7da-44e7d65edf84
127.0.0.1 - - [08/Feb/2025 01:31:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:31:05,715 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a1b82453-917c-4f5c-b6f9-7c58b7320e13
2025-02-08 01:31:05,780 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a1b82453-917c-4f5c-b6f9-7c58b7320e13
127.0.0.1 - - [08/Feb/2025 01:31:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:31:06,368 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c67beba3-3550-4d3a-8b75-590ce7bb2164
2025-02-08 01:31:06,386 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c67beba3-3550-4d3a-8b75-590ce7bb2164
127.0.0.1 - - [08/Feb/2025 01:31:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:31:09,502 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aefee96a-d515-43d9-a013-717808124d77
2025-02-08 01:31:09,509 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: aefee96a-d515-43d9-a013-717808124d77
127.0.0.1 - - [08/Feb/2025 01:31:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:31:11,699 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1a69f6a8-220f-4d08-87b0-b8bfdc2e656b
2025-02-08 01:31:11,710 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1a69f6a8-220f-4d08-87b0-b8bfdc2e656b
127.0.0.1 - - [08/Feb/2025 01:31:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:31:14,797 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e4cd0dac-af2c-44cf-97ca-37970eea432c
2025-02-08 01:31:14,800 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e4cd0dac-af2c-44cf-97ca-37970eea432c
127.0.0.1 - - [08/Feb/2025 01:31:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:31:16,277 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7464acc4-56c6-4ae7-97c8-1aa4493ae4e1
2025-02-08 01:31:16,290 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7464acc4-56c6-4ae7-97c8-1aa4493ae4e1
127.0.0.1 - - [08/Feb/2025 01:31:16] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:31:19,367 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2baf92d0-3431-468b-8e8e-fbfd47463559
2025-02-08 01:31:19,370 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2baf92d0-3431-468b-8e8e-fbfd47463559
127.0.0.1 - - [08/Feb/2025 01:31:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:31:21,223 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8be0ad77-19dd-400b-85a2-eb80ffc4bc63
2025-02-08 01:31:21,229 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8be0ad77-19dd-400b-85a2-eb80ffc4bc63
127.0.0.1 - - [08/Feb/2025 01:31:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:31:24,825 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7ee0f976-6548-4194-9bbc-44e1da57572e
2025-02-08 01:31:24,833 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7ee0f976-6548-4194-9bbc-44e1da57572e
127.0.0.1 - - [08/Feb/2025 01:31:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 01:31:26,927 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d9e9ecdb-2af8-49b8-96df-68e90c08c627
2025-02-08 01:31:26,935 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d9e9ecdb-2af8-49b8-96df-68e90c08c627
127.0.0.1 - - [08/Feb/2025 01:31:26] "POST /inference HTTP/1.1" 200 -
