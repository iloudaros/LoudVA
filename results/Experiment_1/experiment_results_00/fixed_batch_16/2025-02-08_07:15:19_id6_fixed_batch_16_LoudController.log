2025-02-08 07:14:20,123 - LoudVA - INFO - [LoudController] - Starting LoudController...
2025-02-08 07:14:20,123 - LoudVA - INFO - [LoudController] - Press CTRL+C to stop the controller.
2025-02-08 07:14:20,123 - LoudVA - INFO - [LoudController] - Debug mode: False
2025-02-08 07:14:20,145 - LoudVA - INFO - [LoudController] - Selected scheduler: fixed_batch
2025-02-08 07:14:20,153 - LoudVA - INFO - [LoudServer] - Starting LoudVA server...
 * Serving Flask app 'LoudServer'
 * Debug mode: off
WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:5000
Press CTRL+C to quit
2025-02-08 07:14:22,538 - LoudVA - INFO - [DeviceData] - Using profiling data for decision making.
2025-02-08 07:14:22,543 - LoudVA - INFO - [DeviceData] - Filling missing profile data with predictions.
2025-02-08 07:14:22,560 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/Profiling.csv
2025-02-08 07:14:22,560 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/xavier-nx-00/measurements/xavier-nx-00_filtered_freqs.csv
2025-02-08 07:14:22,560 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/LoudJetson0/measurements/LoudJetson0_filtered_freqs.csv
2025-02-08 07:14:22,561 - LoudVA - INFO - [DeviceData] - Loaded GPU specs from /home/louduser/LoudVA/LoudController/../data/devices/gpu_specs.csv
2025-02-08 07:14:22,592 - LoudVA - INFO - [DeviceData] - Initial frequency on agx-xavier-00: 114750000
2025-02-08 07:14:22,592 - LoudVA - INFO - [DeviceData] - agx-xavier-00 : Filling missing profile data...
2025-02-08 07:14:22,593 - LoudVA - INFO - [DeviceData] - agx-xavier-00 : Missing profile data filled with predictions.
2025-02-08 07:14:22,593 - LoudVA - INFO - [DeviceData] - Devices initialized successfully
2025-02-08 07:14:22,593 - LoudVA - INFO - [LoudController] - Using fixed batch size 16
127.0.0.1 - - [08/Feb/2025 07:15:22] "GET / HTTP/1.1" 200 -
2025-02-08 07:15:22,634 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:15:26,985 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:15:30,678 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1e525082-e39f-4c82-bbe7-14614b6cb892
127.0.0.1 - - [08/Feb/2025 07:15:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:15:32,661 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.0
2025-02-08 07:15:35,332 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: aaacff9d-8b46-4276-8c66-6e9d96c432e6
127.0.0.1 - - [08/Feb/2025 07:15:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:15:36,925 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:15:37,685 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d509aa61-858d-4ff1-b8b0-087605b505bb
127.0.0.1 - - [08/Feb/2025 07:15:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:15:42,690 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:15:46,988 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:15:48,083 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b2502486-4a6f-4fd1-a04c-a7203dd7fc9b
127.0.0.1 - - [08/Feb/2025 07:15:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:15:52,639 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:15:52,878 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f580d4fa-3c25-49d5-a0a3-bbcdffe2f712
127.0.0.1 - - [08/Feb/2025 07:15:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:15:57,051 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:15:59,895 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d4c2fcb4-20d0-4baa-bd54-5dfed8275faa
127.0.0.1 - - [08/Feb/2025 07:15:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:01,054 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ef689725-8212-4b26-aa55-a8dd5c8f9be8
127.0.0.1 - - [08/Feb/2025 07:16:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:02,610 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.0
2025-02-08 07:16:06,802 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:16:07,199 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 745c3f80-b0a7-437c-8fb8-5fec45ea3d6b
127.0.0.1 - - [08/Feb/2025 07:16:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:12,541 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:16:14,647 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a724d98f-1cf3-44c9-8713-8f5a6d0509ac
2025-02-08 07:16:14,650 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 70872bda-cc89-4686-b824-097a79273dd2
127.0.0.1 - - [08/Feb/2025 07:16:14] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 07:16:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:16,879 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:16:20,376 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d72a7ca9-86ea-4c96-ac60-4ce37a4c0c87
127.0.0.1 - - [08/Feb/2025 07:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:22,611 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:16:25,807 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 07:16:26,083 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0396ffef-78c8-4d7c-b844-2d085e654799
127.0.0.1 - - [08/Feb/2025 07:16:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:29,037 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1b6e930c-754c-4341-8deb-ab35c6d55571
127.0.0.1 - - [08/Feb/2025 07:16:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:30,774 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:16:32,601 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 07:16:32,731 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8c8ccaaf-340d-4068-979b-b6aa82f6deb1
127.0.0.1 - - [08/Feb/2025 07:16:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:35,740 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 07:16:36,581 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8b32c942-3413-44c2-b92f-17a97d375a90
127.0.0.1 - - [08/Feb/2025 07:16:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:39,674 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f2d81db9-9a7d-4d1d-b0de-cc3652aeaa7c
127.0.0.1 - - [08/Feb/2025 07:16:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:40,764 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:16:42,651 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:16:43,029 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3ed4b3f4-e915-4140-803f-591722c6d3d3
127.0.0.1 - - [08/Feb/2025 07:16:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:45,072 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7a217eea-be1d-4153-95e8-7114acec62e3
127.0.0.1 - - [08/Feb/2025 07:16:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:45,798 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:16:50,176 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7a4d5934-f871-48fa-bd80-99346d3c4d62
127.0.0.1 - - [08/Feb/2025 07:16:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:50,841 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:16:52,603 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:16:55,508 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9b7b206f-6c09-42bb-8fe8-7bf81c9114e4
127.0.0.1 - - [08/Feb/2025 07:16:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:16:55,747 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:17:00,862 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:17:02,144 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cd2de94a-1f2f-41f9-a884-c7ca75fe5168
127.0.0.1 - - [08/Feb/2025 07:17:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:17:02,601 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:17:02,628 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1c189f1b-5f1a-409d-8d65-ef4138750b22
127.0.0.1 - - [08/Feb/2025 07:17:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:17:02,725 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9533378f-0558-4137-aff2-d1b6edc17200
127.0.0.1 - - [08/Feb/2025 07:17:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:17:05,734 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:17:10,375 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 167c6ab4-98a9-4e66-9847-27b5fa28987d
127.0.0.1 - - [08/Feb/2025 07:17:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:17:10,831 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:17:12,634 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:17:13,453 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 091dce26-6f78-4dfc-af91-d3db07cdf495
127.0.0.1 - - [08/Feb/2025 07:17:13] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:17:13,468 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 560ace8c-97c6-469d-a03e-46a6e86c19b9
127.0.0.1 - - [08/Feb/2025 07:17:13] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:17:15,767 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:17:20,882 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:17:22,634 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:17:23,407 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ac020217-d850-41a6-b84b-b7432ed079bf
127.0.0.1 - - [08/Feb/2025 07:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:17:24,968 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6f771382-c99f-41ce-8c87-127a22fdcbc1
127.0.0.1 - - [08/Feb/2025 07:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:17:25,786 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:17:30,767 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:17:32,597 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:17:33,809 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 47fcc2db-3440-4f1f-9320-e40e20b1614a
127.0.0.1 - - [08/Feb/2025 07:17:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:17:35,837 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:17:35,943 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:17:37,491 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a04db021-f9db-470f-aa09-8e761ca8d14e
127.0.0.1 - - [08/Feb/2025 07:17:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:17:39,720 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f4a81113-ad92-4f7b-8140-1d10be1ce00e
127.0.0.1 - - [08/Feb/2025 07:17:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:17:40,866 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:17:42,093 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3eeb2b94-1186-4289-b8f8-dcdccefe7bc1
127.0.0.1 - - [08/Feb/2025 07:17:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:17:42,622 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:17:45,990 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 07:17:46,121 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:17:50,809 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 07:17:51,818 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f1d9474f-23e2-4140-a7c3-d936ed372a35
127.0.0.1 - - [08/Feb/2025 07:17:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:17:52,625 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:17:55,832 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:17:55,890 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:17:59,771 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4bf1bf86-9c38-461c-b16e-5de2c9442dcb
127.0.0.1 - - [08/Feb/2025 07:17:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:18:00,898 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:18:01,310 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c6478333-01e6-4578-96e8-5bfc9301338b
127.0.0.1 - - [08/Feb/2025 07:18:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:18:02,577 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:18:05,916 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:18:06,057 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.0
2025-02-08 07:18:08,479 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4b494dce-e650-43de-8bac-54e95278c8ec
127.0.0.1 - - [08/Feb/2025 07:18:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:18:10,351 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d1e1df8d-e3a9-4146-b3c8-cc6dbc96fa25
127.0.0.1 - - [08/Feb/2025 07:18:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:18:10,775 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:18:12,569 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:18:15,938 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:18:17,893 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:18:18,950 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.0
2025-02-08 07:18:20,530 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 18de525f-9dd6-4df1-9e71-96d5e488b4db
127.0.0.1 - - [08/Feb/2025 07:18:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:18:20,809 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:18:22,776 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:18:22,910 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:18:23,824 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:18:24,887 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e3423bd5-01c1-46a9-8666-b6faa1628f5c
127.0.0.1 - - [08/Feb/2025 07:18:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:18:25,731 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 07:18:27,860 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 07:18:28,758 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:18:29,226 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7c9a6228-e5b8-4a7d-b16f-9199e6cc0ff7
127.0.0.1 - - [08/Feb/2025 07:18:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:18:30,936 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:18:31,718 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5683cf66-3acb-4ddb-aaca-c44b945a041e
127.0.0.1 - - [08/Feb/2025 07:18:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:18:32,953 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:18:33,812 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:18:36,148 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:18:38,121 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 07:18:38,829 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:18:42,336 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: da12300a-d1e6-48e9-a79e-7a93b5ccd860
2025-02-08 07:18:42,337 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f0f1496e-ae7a-48a6-9ad0-b4e94b748ab0
127.0.0.1 - - [08/Feb/2025 07:18:42] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 07:18:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:18:42,576 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d84c5229-d43a-45a5-946a-d6796c335af9
127.0.0.1 - - [08/Feb/2025 07:18:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:18:43,076 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 07:18:43,790 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 07:18:47,889 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:18:48,932 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 07:18:52,296 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0bdc86a2-cfc0-432f-b9eb-5b82097e7cc1
127.0.0.1 - - [08/Feb/2025 07:18:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:18:53,048 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.0
2025-02-08 07:18:53,912 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:18:57,987 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:18:58,908 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.0
2025-02-08 07:18:59,607 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: df883fdf-290a-4dac-b8ab-a16a7ff62c87
127.0.0.1 - - [08/Feb/2025 07:18:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:18:59,686 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 357e665a-af1f-4d59-a1cb-806c5b5fadad
127.0.0.1 - - [08/Feb/2025 07:18:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:19:03,189 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:19:03,805 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 07:19:06,065 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 56f5cbda-c9af-4234-a428-643012e1c66f
127.0.0.1 - - [08/Feb/2025 07:19:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:19:06,305 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4134e6c0-4b4a-4c82-b14e-0bc77d17e478
127.0.0.1 - - [08/Feb/2025 07:19:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:19:08,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:19:08,957 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:19:13,018 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:19:14,054 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-118:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-120:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:18,209 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-121:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:19,015 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-122:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-123:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-124:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-126:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:23,100 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
Exception in thread Thread-127:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-128:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-129:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:24,254 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
Exception in thread Thread-130:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-131:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-132:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:27,770 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a9940de3-f433-474e-98cd-5458c427f8c0
127.0.0.1 - - [08/Feb/2025 07:19:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:19:28,274 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:19:29,117 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
Exception in thread Thread-135:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-136:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
Exception in thread Thread-134:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    raise timeout('timed out')
socket.timeout: timed out
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:33,700 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:19:33,990 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-137:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-138:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-139:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-140:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-141:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:38,415 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
Exception in thread Thread-143:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:39,110 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
Exception in thread Thread-145:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-142:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-146:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-144:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:43,208 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
Exception in thread Thread-147:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:44,041 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
Exception in thread Thread-148:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-149:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:48,048 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-150:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:49,204 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
Exception in thread Thread-151:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-152:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:53,410 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.0
Exception in thread Thread-153:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-154:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:54,123 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-155:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-156:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:58,106 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-157:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:19:59,135 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
Exception in thread Thread-158:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-159:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:20:03,616 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:20:03,867 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-161:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-160:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-162:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-163:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-164:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-166:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-165:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-167:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-168:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-169:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-170:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-171:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-172:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-173:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-174:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-175:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-176:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-178:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-177:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-180:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-179:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-181:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-182:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-183:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-184:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-187:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:20:39,237 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7b346028-ac70-442c-8b34-bc3bcf82d8ca
127.0.0.1 - - [08/Feb/2025 07:20:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:20:39,524 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e221b1a1-adaf-4826-9d35-a8898751b848
127.0.0.1 - - [08/Feb/2025 07:20:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:20:41,490 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4c73958d-2f05-4931-8f48-0b59e61c1500
127.0.0.1 - - [08/Feb/2025 07:20:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:20:42,303 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 61d8c693-9272-406a-bac6-684fa831b8cb
127.0.0.1 - - [08/Feb/2025 07:20:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:20:43,694 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c868c677-d94f-4021-acce-2f3d87da586c
127.0.0.1 - - [08/Feb/2025 07:20:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:20:44,162 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 17daf0f0-2855-4fb4-9c14-c7c78d88fc19
127.0.0.1 - - [08/Feb/2025 07:20:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:20:44,770 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7fa55bcf-d62e-4c79-bb54-f173631218c0
127.0.0.1 - - [08/Feb/2025 07:20:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:20:44,894 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 07de5e3f-2de0-4b49-883d-79feedc888db
127.0.0.1 - - [08/Feb/2025 07:20:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:20:45,037 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7ffe04ce-9ddc-4ee0-b7ea-044cc4535e8d
127.0.0.1 - - [08/Feb/2025 07:20:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:20:45,402 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ca8e22d7-ff72-4152-8448-258167d8d554
127.0.0.1 - - [08/Feb/2025 07:20:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:20:45,408 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 30a3ae89-2506-4d73-b331-cdccdc1980a1
127.0.0.1 - - [08/Feb/2025 07:20:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:20:46,178 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ca534a05-2eec-4388-9372-ea7dbdc42c6c
127.0.0.1 - - [08/Feb/2025 07:20:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:12,621 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2b6c2d43-229f-4aad-8957-cb5b74fb22ee
2025-02-08 07:23:12,690 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2b6c2d43-229f-4aad-8957-cb5b74fb22ee
127.0.0.1 - - [08/Feb/2025 07:23:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:16,002 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9e765535-f63f-439f-b9ff-8f0088441cb9
2025-02-08 07:23:16,155 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9e765535-f63f-439f-b9ff-8f0088441cb9
127.0.0.1 - - [08/Feb/2025 07:23:16] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:17,919 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 95bb7fce-1c69-45b1-a6a9-86df92f9fb4d
2025-02-08 07:23:18,046 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 95bb7fce-1c69-45b1-a6a9-86df92f9fb4d
127.0.0.1 - - [08/Feb/2025 07:23:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:18,980 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c6c925f7-7ab3-480a-b0f6-703e356422c5
2025-02-08 07:23:19,118 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c6c925f7-7ab3-480a-b0f6-703e356422c5
127.0.0.1 - - [08/Feb/2025 07:23:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:20,850 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 82c9b05b-adbe-42ea-8f52-6d672053e299
2025-02-08 07:23:20,942 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 82c9b05b-adbe-42ea-8f52-6d672053e299
127.0.0.1 - - [08/Feb/2025 07:23:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:22,811 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 463ea6c4-2fc0-4148-a63b-9b13c90b9c51
2025-02-08 07:23:22,922 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5e3eafbe-1d93-402c-b4cd-7965c3f03580
2025-02-08 07:23:22,996 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5e3eafbe-1d93-402c-b4cd-7965c3f03580
127.0.0.1 - - [08/Feb/2025 07:23:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:23,022 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 463ea6c4-2fc0-4148-a63b-9b13c90b9c51
127.0.0.1 - - [08/Feb/2025 07:23:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:23,868 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5ba93e15-e52d-4777-8f27-67b020bbe0e9
2025-02-08 07:23:23,914 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5ba93e15-e52d-4777-8f27-67b020bbe0e9
127.0.0.1 - - [08/Feb/2025 07:23:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:27,886 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8ba1e421-4413-4bd1-93a0-db15dc0ccfd9
2025-02-08 07:23:27,905 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8ba1e421-4413-4bd1-93a0-db15dc0ccfd9
127.0.0.1 - - [08/Feb/2025 07:23:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:28,768 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 88a7652a-6b8c-40d5-9b8c-fd4b1712e827
2025-02-08 07:23:28,774 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 88a7652a-6b8c-40d5-9b8c-fd4b1712e827
127.0.0.1 - - [08/Feb/2025 07:23:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:30,969 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 41e817e7-022e-4da3-9128-39984e3f3560
2025-02-08 07:23:31,051 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 41e817e7-022e-4da3-9128-39984e3f3560
127.0.0.1 - - [08/Feb/2025 07:23:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:32,993 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7b5ad48f-086b-4c62-94ba-c96f37f12e11
2025-02-08 07:23:33,024 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7b5ad48f-086b-4c62-94ba-c96f37f12e11
127.0.0.1 - - [08/Feb/2025 07:23:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:33,853 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9802fd55-b065-49e0-b6f3-754d1ff12a5e
2025-02-08 07:23:33,884 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9802fd55-b065-49e0-b6f3-754d1ff12a5e
127.0.0.1 - - [08/Feb/2025 07:23:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:36,222 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 08ee5b10-cbbd-4224-a0e2-df9e56d6f3b3
2025-02-08 07:23:36,320 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 08ee5b10-cbbd-4224-a0e2-df9e56d6f3b3
127.0.0.1 - - [08/Feb/2025 07:23:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:38,184 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 79bced2a-44ce-49bd-a511-c04049a36b6a
2025-02-08 07:23:38,286 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 79bced2a-44ce-49bd-a511-c04049a36b6a
127.0.0.1 - - [08/Feb/2025 07:23:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:38,847 - LoudVA - WARNING - [LoudServer] - Timeout reached for request da8187ee-a5d7-4d80-b7b3-a7671ad7a24a
2025-02-08 07:23:38,873 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: da8187ee-a5d7-4d80-b7b3-a7671ad7a24a
127.0.0.1 - - [08/Feb/2025 07:23:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:43,098 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2b16668a-78b9-43b2-b7e8-9dde2d94fe26
2025-02-08 07:23:43,197 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2b16668a-78b9-43b2-b7e8-9dde2d94fe26
127.0.0.1 - - [08/Feb/2025 07:23:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:43,814 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8a31d8a0-0e23-44a5-8a43-70eabde87fd7
2025-02-08 07:23:43,825 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8a31d8a0-0e23-44a5-8a43-70eabde87fd7
127.0.0.1 - - [08/Feb/2025 07:23:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:47,916 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a9942ca0-760d-4f6b-a561-497129ed2fc1
2025-02-08 07:23:47,935 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a9942ca0-760d-4f6b-a561-497129ed2fc1
127.0.0.1 - - [08/Feb/2025 07:23:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:48,964 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 95b86cd3-47b8-4798-9a92-c024498b2714
2025-02-08 07:23:48,966 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 95b86cd3-47b8-4798-9a92-c024498b2714
127.0.0.1 - - [08/Feb/2025 07:23:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:53,092 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9b9f2eb0-9625-49d7-9208-38291748fd55
2025-02-08 07:23:53,133 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9b9f2eb0-9625-49d7-9208-38291748fd55
127.0.0.1 - - [08/Feb/2025 07:23:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:53,938 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fb8dc572-b939-4637-bee7-3b10c144f1ae
2025-02-08 07:23:53,948 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fb8dc572-b939-4637-bee7-3b10c144f1ae
127.0.0.1 - - [08/Feb/2025 07:23:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:58,021 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4ea6fa16-9ff3-42dd-983b-8f6044097cc8
2025-02-08 07:23:58,037 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4ea6fa16-9ff3-42dd-983b-8f6044097cc8
127.0.0.1 - - [08/Feb/2025 07:23:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:23:58,935 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d3b54761-7b14-424f-b58b-0b69476386eb
2025-02-08 07:23:58,945 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d3b54761-7b14-424f-b58b-0b69476386eb
127.0.0.1 - - [08/Feb/2025 07:23:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:03,259 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 75a10d9e-ba69-4f3a-90e6-a8dee3ca7c6d
2025-02-08 07:24:03,289 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 75a10d9e-ba69-4f3a-90e6-a8dee3ca7c6d
127.0.0.1 - - [08/Feb/2025 07:24:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:03,814 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9bababd3-1afc-4444-8d83-8a2a595c55d8
2025-02-08 07:24:03,815 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9bababd3-1afc-4444-8d83-8a2a595c55d8
127.0.0.1 - - [08/Feb/2025 07:24:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:08,311 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 74551155-271a-451c-920a-9c1fe232f544
2025-02-08 07:24:08,325 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 74551155-271a-451c-920a-9c1fe232f544
127.0.0.1 - - [08/Feb/2025 07:24:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:08,996 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 430f6bf8-62f4-49f2-9f65-c889c7f5b694
2025-02-08 07:24:09,002 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 430f6bf8-62f4-49f2-9f65-c889c7f5b694
127.0.0.1 - - [08/Feb/2025 07:24:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:13,045 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f9ac4427-e8c4-4532-9de6-f78c87399b79
2025-02-08 07:24:13,056 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f9ac4427-e8c4-4532-9de6-f78c87399b79
127.0.0.1 - - [08/Feb/2025 07:24:13] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:14,087 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 053960c3-ad85-446e-b3f8-77cac8806eae
2025-02-08 07:24:14,102 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 053960c3-ad85-446e-b3f8-77cac8806eae
127.0.0.1 - - [08/Feb/2025 07:24:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:18,254 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 93a6bf89-1e53-4cc2-8476-5cb4500582ac
2025-02-08 07:24:18,258 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 93a6bf89-1e53-4cc2-8476-5cb4500582ac
127.0.0.1 - - [08/Feb/2025 07:24:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:19,067 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 296e0bc6-da4f-4e66-b3f3-027fab971005
2025-02-08 07:24:19,077 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 296e0bc6-da4f-4e66-b3f3-027fab971005
127.0.0.1 - - [08/Feb/2025 07:24:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:23,124 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 49008452-cd02-46fb-a7b1-1b834c1f8151
2025-02-08 07:24:23,125 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 49008452-cd02-46fb-a7b1-1b834c1f8151
127.0.0.1 - - [08/Feb/2025 07:24:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:24,303 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 915cc1b9-789c-4cdc-8cbf-a44ad2c1c0b8
2025-02-08 07:24:24,314 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 915cc1b9-789c-4cdc-8cbf-a44ad2c1c0b8
127.0.0.1 - - [08/Feb/2025 07:24:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:28,311 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 92adcb84-9850-44e0-a35a-f19bc6bacbfc
2025-02-08 07:24:28,313 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 92adcb84-9850-44e0-a35a-f19bc6bacbfc
127.0.0.1 - - [08/Feb/2025 07:24:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:29,141 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8116e7af-48d0-4675-b90c-a73a96f6b9c3
2025-02-08 07:24:29,145 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8116e7af-48d0-4675-b90c-a73a96f6b9c3
127.0.0.1 - - [08/Feb/2025 07:24:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:33,804 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4576774c-e292-4e8d-9bdc-caabb13cb74e
2025-02-08 07:24:33,809 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4576774c-e292-4e8d-9bdc-caabb13cb74e
127.0.0.1 - - [08/Feb/2025 07:24:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:24:34,018 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 62d4fdd8-b2c9-4b26-ac18-4cc2cbb16d0e
2025-02-08 07:24:34,019 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 62d4fdd8-b2c9-4b26-ac18-4cc2cbb16d0e
127.0.0.1 - - [08/Feb/2025 07:24:34] "POST /inference HTTP/1.1" 200 -
