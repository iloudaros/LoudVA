2025-02-15 11:51:39,454 - LoudVA - INFO - [LoudController] - Starting LoudController...
2025-02-15 11:51:39,454 - LoudVA - INFO - [LoudController] - Press CTRL+C to stop the controller.
2025-02-15 11:51:39,454 - LoudVA - INFO - [LoudController] - Debug mode: False
2025-02-15 11:51:39,486 - LoudVA - INFO - [LoudController] - Selected scheduler: fixed_batch
2025-02-15 11:51:39,494 - LoudVA - INFO - [LoudServer] - Starting LoudVA server...
 * Serving Flask app 'LoudServer'
 * Debug mode: off
WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:5000
Press CTRL+C to quit
2025-02-15 11:51:40,744 - LoudVA - INFO - [DeviceData] - Using profiling data for decision making.
2025-02-15 11:51:40,744 - LoudVA - INFO - [DeviceData] - Filling missing profile data with predictions.
2025-02-15 11:51:40,745 - LoudVA - INFO - [DeviceData] - Loaded network costs from /home/louduser/LoudVA/LoudController/../measurements/network/network_cost.csv
2025-02-15 11:51:40,753 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/Profiling.csv
2025-02-15 11:51:40,753 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/xavier-nx-00/measurements/xavier-nx-00_filtered_freqs.csv
2025-02-15 11:51:40,753 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/LoudJetson0/measurements/LoudJetson0_filtered_freqs.csv
2025-02-15 11:51:40,753 - LoudVA - INFO - [DeviceData] - Loaded GPU specs from /home/louduser/LoudVA/LoudController/../data/devices/gpu_specs.csv
2025-02-15 11:51:40,782 - LoudVA - INFO - [DeviceData] - Initial frequency on agx-xavier-00: 114750000
2025-02-15 11:51:40,782 - LoudVA - INFO - [DeviceData] - agx-xavier-00 : Filling missing profile data...
2025-02-15 11:51:40,782 - LoudVA - INFO - [DeviceData] - agx-xavier-00 : Missing profile data filled with predictions.
2025-02-15 11:51:40,782 - LoudVA - INFO - [DeviceData] - Devices initialized successfully
2025-02-15 11:51:40,783 - LoudVA - INFO - [LoudController] - Using fixed batch size 8
127.0.0.1 - - [15/Feb/2025 11:52:42] "GET / HTTP/1.1" 200 -
2025-02-15 11:53:02,510 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.190029
2025-02-15 11:53:03,056 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.559861
2025-02-15 11:53:03,489 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.190029
2025-02-15 11:53:04,022 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.465794
2025-02-15 11:53:04,521 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
2025-02-15 11:53:04,896 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 213ef1e6-d77d-4b1d-a7ad-59880c820d35
2025-02-15 11:53:04,899 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 80815bc6-57f2-4bb0-8482-ad0e65de9af9
127.0.0.1 - - [15/Feb/2025 11:53:04] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [15/Feb/2025 11:53:04] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:04,992 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.374043
2025-02-15 11:53:05,482 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.098841
2025-02-15 11:53:05,990 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.190029
2025-02-15 11:53:06,507 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.465794
2025-02-15 11:53:06,627 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9fa965ca-41d3-43ff-8031-e60d48194d8e
127.0.0.1 - - [15/Feb/2025 11:53:06] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:06,849 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7e353ea0-e8a3-48a2-94a5-8388b8dd4c28
127.0.0.1 - - [15/Feb/2025 11:53:06] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:06,857 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 65a2fc3e-24a0-4bb1-8746-537f16f1cc3b
127.0.0.1 - - [15/Feb/2025 11:53:06] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:06,866 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d81f1a91-67b2-434d-98e1-5680dbde606e
127.0.0.1 - - [15/Feb/2025 11:53:06] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:06,982 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-15 11:53:07,486 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-15 11:53:07,685 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4e72bb94-e2b3-48d8-8971-43e254868711
127.0.0.1 - - [15/Feb/2025 11:53:07] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:07,687 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 32c8d908-0b96-4e44-81ef-8432c8f5e72b
127.0.0.1 - - [15/Feb/2025 11:53:07] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:07,693 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 295f605f-84ed-4294-bdd4-d6a6947b9258
127.0.0.1 - - [15/Feb/2025 11:53:07] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:08,023 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.465794
2025-02-15 11:53:08,520 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.559861
2025-02-15 11:53:08,780 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.190029
2025-02-15 11:53:08,988 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.190029
2025-02-15 11:53:09,263 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.281418
2025-02-15 11:53:09,416 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bd8c0aa0-e2ad-4c5d-9286-8e498f7d5d02
127.0.0.1 - - [15/Feb/2025 11:53:09] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:09,425 - LoudVA - INFO - [LoudServer] - Completed. Request ID: aab75017-10d7-4ec5-8ebb-3823b0a04e0b
127.0.0.1 - - [15/Feb/2025 11:53:09] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:09,435 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 561ed6bc-5e31-49df-9a48-9d9d8762607d
127.0.0.1 - - [15/Feb/2025 11:53:09] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:09,482 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.190029
2025-02-15 11:53:09,753 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-15 11:53:10,012 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-15 11:53:10,273 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
2025-02-15 11:53:10,492 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-15 11:53:10,704 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7373b3b6-4f6c-4419-89c9-933a41740cf6
127.0.0.1 - - [15/Feb/2025 11:53:10] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:10,708 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6f2ff94d-c225-424c-8f54-aaacf23d32d1
127.0.0.1 - - [15/Feb/2025 11:53:10] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:10,771 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.559861
2025-02-15 11:53:10,983 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-15 11:53:11,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-15 11:53:11,487 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-15 11:53:11,537 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5458c26f-6506-4a65-b452-c12fbd565c6c
127.0.0.1 - - [15/Feb/2025 11:53:11] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:11,539 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b39fcf69-6bef-4198-a8b2-dacc55fd3c61
127.0.0.1 - - [15/Feb/2025 11:53:11] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:11,542 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b5b246b4-8e03-4645-803d-4710fe6f4325
127.0.0.1 - - [15/Feb/2025 11:53:11] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:11,753 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.465794
2025-02-15 11:53:12,004 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
2025-02-15 11:53:12,124 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 51f4fbaa-07c7-4929-943f-99a2c075453a
127.0.0.1 - - [15/Feb/2025 11:53:12] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:12,133 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8d8f9987-a3b1-44d8-959e-1529bd973446
127.0.0.1 - - [15/Feb/2025 11:53:12] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:12,274 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-15 11:53:12,489 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.559861
2025-02-15 11:53:12,757 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-15 11:53:12,989 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.190029
2025-02-15 11:53:13,272 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.374043
2025-02-15 11:53:13,352 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8f0efaa6-32e1-4bb7-a52d-f104c9bf06fb
127.0.0.1 - - [15/Feb/2025 11:53:13] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:13,358 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c1e21725-7eb3-411b-a950-a01e17b35a87
127.0.0.1 - - [15/Feb/2025 11:53:13] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:13,498 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.281418
2025-02-15 11:53:13,770 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
2025-02-15 11:53:13,778 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e5815fff-2930-49a5-adb1-5eff3020f97a
127.0.0.1 - - [15/Feb/2025 11:53:13] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:13,779 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8c360678-fe2c-4258-b0f5-86641395f710
127.0.0.1 - - [15/Feb/2025 11:53:13] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:13,785 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 909adb73-3e17-4b18-92ed-6e6c922973d9
127.0.0.1 - - [15/Feb/2025 11:53:13] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:13,791 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d6f36971-8622-4842-9ad5-9059835b2836
127.0.0.1 - - [15/Feb/2025 11:53:13] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:13,983 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.374043
2025-02-15 11:53:14,262 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-15 11:53:14,541 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.374043
2025-02-15 11:53:14,767 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
2025-02-15 11:53:14,987 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-15 11:53:15,262 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.190029
2025-02-15 11:53:15,425 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e2d3134d-14b9-425a-8e19-b3357f554004
127.0.0.1 - - [15/Feb/2025 11:53:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:15,434 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 282a7566-9b55-49c8-945c-6d6d60e4ff96
127.0.0.1 - - [15/Feb/2025 11:53:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:15,481 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.465794
2025-02-15 11:53:15,749 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
2025-02-15 11:53:15,984 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-15 11:53:16,280 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.281418
2025-02-15 11:53:16,408 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a203df62-b300-457c-9820-3f0d7c046688
127.0.0.1 - - [15/Feb/2025 11:53:16] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:16,485 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-15 11:53:16,760 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-15 11:53:16,983 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-15 11:53:17,001 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 910cd57c-62d5-4eb7-a9cc-af0b6969f150
127.0.0.1 - - [15/Feb/2025 11:53:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:17,004 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6b415868-caaf-4f93-807e-4e99ef4e6741
127.0.0.1 - - [15/Feb/2025 11:53:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:17,016 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1f415a21-708a-42e2-9e44-5956e5ae502e
127.0.0.1 - - [15/Feb/2025 11:53:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:17,256 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-15 11:53:17,484 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-15 11:53:17,750 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-15 11:53:17,806 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 65ffb9d0-dd48-4255-a355-9f646078f85d
127.0.0.1 - - [15/Feb/2025 11:53:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:17,811 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d3d67632-703d-4f3c-b42f-778f43437d0e
127.0.0.1 - - [15/Feb/2025 11:53:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:17,984 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.190029
2025-02-15 11:53:18,090 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 15702d1f-8245-4f1a-8349-e7258ee22801
127.0.0.1 - - [15/Feb/2025 11:53:18] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:18,103 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 31e2d9d5-48f4-40a3-b887-63d82c8502e3
127.0.0.1 - - [15/Feb/2025 11:53:18] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:18,262 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.190029
2025-02-15 11:53:18,507 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.465794
2025-02-15 11:53:18,771 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.374043
2025-02-15 11:53:19,024 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-15 11:53:19,275 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.374043
2025-02-15 11:53:19,478 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ccb233e8-c531-4e51-a07e-69687dee9545
127.0.0.1 - - [15/Feb/2025 11:53:19] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:19,503 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.374043
2025-02-15 11:53:19,760 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.281418
2025-02-15 11:53:19,774 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3dae19bc-0bbf-43b5-acaa-50a104d6970f
127.0.0.1 - - [15/Feb/2025 11:53:19] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:19,778 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 810d7d6a-1e57-461e-9f37-e1f04b1de149
127.0.0.1 - - [15/Feb/2025 11:53:19] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:19,794 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6f3bb17a-c59b-4d64-9beb-e5abb8fb9d00
127.0.0.1 - - [15/Feb/2025 11:53:19] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:19,797 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 80483b0f-43f2-41a2-9cf3-6facb5fda082
127.0.0.1 - - [15/Feb/2025 11:53:19] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:19,982 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-15 11:53:20,198 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 64e469df-588b-4d0e-981a-2acf8e74e527
127.0.0.1 - - [15/Feb/2025 11:53:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:20,200 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e2b23cc9-0bbb-4c1f-8492-c759aa43b2a1
127.0.0.1 - - [15/Feb/2025 11:53:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:20,201 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1d964b67-3bd2-4437-ac9d-4e3f67a34e94
127.0.0.1 - - [15/Feb/2025 11:53:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:20,203 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 71ed8afc-ed54-481f-a6b9-292265b6a35d
127.0.0.1 - - [15/Feb/2025 11:53:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:20,204 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 423d176b-8d2d-43f3-b8ed-d941c384b2bd
127.0.0.1 - - [15/Feb/2025 11:53:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:20,206 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8d4ac21f-e302-489b-aaf6-e8203d277fb3
127.0.0.1 - - [15/Feb/2025 11:53:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:20,254 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-15 11:53:20,402 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9623df05-c469-422a-a732-6ca1428ff729
127.0.0.1 - - [15/Feb/2025 11:53:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:20,408 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f6d407a2-ec09-4e6e-86b3-28ff92136069
127.0.0.1 - - [15/Feb/2025 11:53:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:20,422 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 521eb5d4-4d65-4638-a666-d784082dc45d
127.0.0.1 - - [15/Feb/2025 11:53:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:20,431 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d256ffe3-1e0a-4faf-a83f-00b729df2a8d
127.0.0.1 - - [15/Feb/2025 11:53:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:20,513 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.559861
2025-02-15 11:53:20,768 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.465794
2025-02-15 11:53:20,983 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-15 11:53:21,252 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-15 11:53:21,492 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.190029
2025-02-15 11:53:21,766 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.374043
2025-02-15 11:53:21,951 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5d021d87-36d9-4e28-8973-4bb70498dec4
127.0.0.1 - - [15/Feb/2025 11:53:21] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:21,962 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5cd16c0d-b550-4376-a97d-b545219c3562
127.0.0.1 - - [15/Feb/2025 11:53:21] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:21,996 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.374043
2025-02-15 11:53:22,004 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9ef9a9e7-7a6d-497c-a8ca-14745af55a80
127.0.0.1 - - [15/Feb/2025 11:53:22] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:22,256 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.190029
2025-02-15 11:53:22,487 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.190029
2025-02-15 11:53:22,791 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.374043
2025-02-15 11:53:23,004 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0e59ee14-5147-4c53-9990-087433e3b4f4
127.0.0.1 - - [15/Feb/2025 11:53:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:23,047 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
2025-02-15 11:53:23,063 - LoudVA - INFO - [LoudServer] - Completed. Request ID: dedfbf1c-8043-4cd8-9ecb-75de0bc75b75
127.0.0.1 - - [15/Feb/2025 11:53:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:23,074 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 18c0c1c8-9499-4c89-9d2c-f98f2b696bbf
127.0.0.1 - - [15/Feb/2025 11:53:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:23,286 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.559861
2025-02-15 11:53:23,498 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.281418
2025-02-15 11:53:23,700 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b89ec3a2-a17f-4ee7-867d-487a01042c19
127.0.0.1 - - [15/Feb/2025 11:53:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:23,705 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 09c31de6-19f2-4b9e-8fbd-bccd7bc4edba
127.0.0.1 - - [15/Feb/2025 11:53:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:23,708 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a9d2652c-9cd4-4987-91cc-ef54cb6ac4a0
127.0.0.1 - - [15/Feb/2025 11:53:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:23,724 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8b1b0219-414e-4254-9b08-15ca5a0b109b
127.0.0.1 - - [15/Feb/2025 11:53:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:23,747 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-15 11:53:24,022 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.559861
2025-02-15 11:53:24,261 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
2025-02-15 11:53:24,549 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.559861
2025-02-15 11:53:24,772 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
2025-02-15 11:53:25,033 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-15 11:53:25,176 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0f31fff7-ef67-4aa3-a4a0-7bad3b6a4b40
127.0.0.1 - - [15/Feb/2025 11:53:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:25,289 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.559861
2025-02-15 11:53:25,503 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.190029
2025-02-15 11:53:25,700 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 37bec027-c91e-4b77-9f11-da4c983b023f
127.0.0.1 - - [15/Feb/2025 11:53:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:25,704 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bcdd7888-3300-46db-8515-92dd9ff96d4a
127.0.0.1 - - [15/Feb/2025 11:53:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:25,771 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-15 11:53:25,776 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 461e9f2d-827e-41a1-8be7-269a8c4d36ed
127.0.0.1 - - [15/Feb/2025 11:53:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:25,786 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c865fafe-41e8-447d-87dc-2443f3226515
127.0.0.1 - - [15/Feb/2025 11:53:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:25,790 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 00ed7e40-5b38-40fe-a16d-4dff6f0c6e9a
127.0.0.1 - - [15/Feb/2025 11:53:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:25,797 - LoudVA - INFO - [LoudServer] - Completed. Request ID: da8b5642-7995-4616-ab29-df8b41a042b8
127.0.0.1 - - [15/Feb/2025 11:53:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:25,808 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 456a0327-15aa-483b-af32-2ee9e996e5dc
127.0.0.1 - - [15/Feb/2025 11:53:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:25,982 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-15 11:53:26,306 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.64948
2025-02-15 11:53:26,500 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.64948
2025-02-15 11:53:26,768 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.374043
2025-02-15 11:53:26,994 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-15 11:53:27,159 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cc70c874-bfce-474f-8dd7-dbccbfe8ccf6
127.0.0.1 - - [15/Feb/2025 11:53:27] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:27,190 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0de445b4-2c4d-42c3-9c80-80a15e488bd7
127.0.0.1 - - [15/Feb/2025 11:53:27] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:27,256 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
2025-02-15 11:53:27,479 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-15 11:53:27,765 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.374043
2025-02-15 11:53:28,004 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.281418
2025-02-15 11:53:28,044 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.583353
2025-02-15 11:53:28,270 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.374043
2025-02-15 11:53:28,561 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-15 11:53:28,746 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-15 11:53:28,991 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.559861
2025-02-15 11:53:29,109 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5a7e9db8-4ba7-4301-981e-079e379b7e89
127.0.0.1 - - [15/Feb/2025 11:53:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:29,248 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-15 11:53:29,483 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-15 11:53:29,769 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.190029
2025-02-15 11:53:29,789 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7dc2bcc7-862a-4fb6-bc2b-cfa4b538cb85
127.0.0.1 - - [15/Feb/2025 11:53:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:29,802 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e31e5166-e87c-430d-bef9-9ca0dfda53e6
127.0.0.1 - - [15/Feb/2025 11:53:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:29,815 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2997663c-b662-4d5d-ae77-0eec6714d06d
127.0.0.1 - - [15/Feb/2025 11:53:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:29,980 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-15 11:53:30,114 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 41945b63-dfce-4261-aeea-ecd17a4508f6
127.0.0.1 - - [15/Feb/2025 11:53:30] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:30,123 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 011e6816-81d7-465a-8123-2f2119a92bba
127.0.0.1 - - [15/Feb/2025 11:53:30] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:30,290 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.559861
2025-02-15 11:53:30,494 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
2025-02-15 11:53:30,771 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.374043
2025-02-15 11:53:31,012 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
2025-02-15 11:53:31,270 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.465794
2025-02-15 11:53:31,544 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.374043
2025-02-15 11:53:31,749 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-15 11:53:32,015 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.190029
2025-02-15 11:53:32,276 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-15 11:53:32,505 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.281418
2025-02-15 11:53:32,773 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-15 11:53:32,998 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.559861
2025-02-15 11:53:33,298 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.559861
2025-02-15 11:53:33,517 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.559861
2025-02-15 11:53:33,770 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.374043
2025-02-15 11:53:34,002 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-15 11:53:34,301 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.559861
2025-02-15 11:53:34,502 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-15 11:53:34,646 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e79b29de-8175-4f81-9091-c30c5f3a1367
127.0.0.1 - - [15/Feb/2025 11:53:34] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:34,654 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d0705f44-11c2-4c8a-8b30-3dc931836ebc
127.0.0.1 - - [15/Feb/2025 11:53:34] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:34,753 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-15 11:53:35,024 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.465794
2025-02-15 11:53:35,278 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.190029
2025-02-15 11:53:35,482 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.64948
2025-02-15 11:53:35,756 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-15 11:53:36,032 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.64948
2025-02-15 11:53:36,368 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.465794
2025-02-15 11:53:36,550 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.190029
2025-02-15 11:53:36,762 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-15 11:53:36,948 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c427899a-fd56-4171-b047-b05d5f2d537d
127.0.0.1 - - [15/Feb/2025 11:53:36] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:36,963 - LoudVA - INFO - [LoudServer] - Completed. Request ID: adcde74e-e4f3-455c-988d-2c1198e4f42c
2025-02-15 11:53:36,964 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9116279c-fdc9-4e0c-ac9a-b86d9a3655f2
127.0.0.1 - - [15/Feb/2025 11:53:36] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [15/Feb/2025 11:53:36] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:36,979 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.190029
2025-02-15 11:53:36,986 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7a953b33-357a-479e-85d7-39da7c1bd443
127.0.0.1 - - [15/Feb/2025 11:53:36] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:37,307 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.559861
2025-02-15 11:53:37,497 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.281418
2025-02-15 11:53:37,747 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-15 11:53:37,790 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.741029
2025-02-15 11:53:37,811 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ee4a7cd4-694a-420d-bdee-04c9ffc83082
127.0.0.1 - - [15/Feb/2025 11:53:37] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:37,943 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 92313cd3-9908-4225-956f-676018843472
127.0.0.1 - - [15/Feb/2025 11:53:37] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:37,957 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 896c9000-541b-4b68-8a79-47f1e89bce4b
127.0.0.1 - - [15/Feb/2025 11:53:37] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:37,985 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.374043
2025-02-15 11:53:38,266 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.64948
2025-02-15 11:53:38,476 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-15 11:53:38,767 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.465794
2025-02-15 11:53:38,988 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.374043
2025-02-15 11:53:39,272 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.559861
2025-02-15 11:53:39,505 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-15 11:53:39,758 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.374043
2025-02-15 11:53:39,908 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 934fa590-85a9-4a69-ade5-13dd16019640
127.0.0.1 - - [15/Feb/2025 11:53:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:39,925 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e45ded84-858f-4e2d-84af-ee846948ae37
127.0.0.1 - - [15/Feb/2025 11:53:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:39,979 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
2025-02-15 11:53:40,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.374043
2025-02-15 11:53:40,475 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-15 11:53:40,755 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.281418
2025-02-15 11:53:40,977 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-15 11:53:41,264 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-15 11:53:41,476 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-15 11:53:41,681 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7636c5dc-7934-4544-be56-9743a223af07
127.0.0.1 - - [15/Feb/2025 11:53:41] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:41,687 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a5f4210b-9c82-46a3-88f4-85f182888c14
127.0.0.1 - - [15/Feb/2025 11:53:41] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:41,762 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.465794
2025-02-15 11:53:41,992 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-15 11:53:42,267 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.465794
2025-02-15 11:53:42,333 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
2025-02-15 11:53:42,507 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-15 11:53:42,763 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.190029
2025-02-15 11:53:42,973 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-15 11:53:43,251 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.281418
2025-02-15 11:53:43,498 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
2025-02-15 11:53:43,758 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.465794
2025-02-15 11:53:43,953 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a816adb8-39c3-4c45-9a31-6d91c023eba8
127.0.0.1 - - [15/Feb/2025 11:53:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:43,986 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b448d43b-86fc-4298-9a31-e35c34c102ec
127.0.0.1 - - [15/Feb/2025 11:53:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:43,998 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.281418
2025-02-15 11:53:44,265 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.559861
2025-02-15 11:53:44,514 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.559861
2025-02-15 11:53:44,747 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-15 11:53:44,995 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
2025-02-15 11:53:45,257 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-15 11:53:45,481 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-15 11:53:45,792 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-15 11:53:45,887 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f8bf2f9b-c0c1-4af4-a6cf-3a0c4eda37cd
127.0.0.1 - - [15/Feb/2025 11:53:45] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:45,997 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.374043
2025-02-15 11:53:46,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.098841
2025-02-15 11:53:46,487 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.374043
2025-02-15 11:53:46,759 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-15 11:53:46,760 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ea8a60e9-d959-4fee-a4fe-dc3777922f0e
127.0.0.1 - - [15/Feb/2025 11:53:46] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:46,975 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-15 11:53:47,250 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
2025-02-15 11:53:47,495 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
2025-02-15 11:53:47,768 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.64948
2025-02-15 11:53:47,895 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.583353
2025-02-15 11:53:48,002 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
2025-02-15 11:53:48,292 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.465794
2025-02-15 11:53:48,304 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6da23657-0454-4d68-b51c-2c87001f37b3
127.0.0.1 - - [15/Feb/2025 11:53:48] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:48,311 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6e30429f-5512-42de-a1b8-f023e30ff5a1
127.0.0.1 - - [15/Feb/2025 11:53:48] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:48,347 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f4c00205-eee1-4d74-9743-13183bfaa4e9
127.0.0.1 - - [15/Feb/2025 11:53:48] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:48,478 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.190029
2025-02-15 11:53:48,747 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-15 11:53:48,982 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-15 11:53:49,256 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.281418
2025-02-15 11:53:49,489 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-15 11:53:49,766 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-15 11:53:49,927 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a4a0a123-ae18-4987-875c-a78f067da67c
127.0.0.1 - - [15/Feb/2025 11:53:49] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:50,021 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0cd4b8fd-273d-490b-8312-36ce796e4b46
127.0.0.1 - - [15/Feb/2025 11:53:50] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:50,026 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2c16b350-23f4-473f-b434-9ffbb2d6c04b
127.0.0.1 - - [15/Feb/2025 11:53:50] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:50,029 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-15 11:53:50,036 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ec32ad95-c1de-4b40-ad8e-9e21a1e3aa3c
127.0.0.1 - - [15/Feb/2025 11:53:50] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:50,040 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f1f95e55-5c56-4b3f-a3da-54426475d17b
127.0.0.1 - - [15/Feb/2025 11:53:50] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:50,060 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 18022723-15a4-4854-97af-91d638c2a63b
127.0.0.1 - - [15/Feb/2025 11:53:50] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:50,248 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-15 11:53:50,477 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-15 11:53:50,645 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 82e84a68-ac13-42ce-bfa8-77089f7e2486
127.0.0.1 - - [15/Feb/2025 11:53:50] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:50,666 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7109e73a-24a6-4286-a3ed-6d4f3f62f239
127.0.0.1 - - [15/Feb/2025 11:53:50] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:50,784 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.64948
2025-02-15 11:53:50,994 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.559861
2025-02-15 11:53:51,245 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-15 11:53:51,326 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ac46a29b-f530-4ca5-a247-5ecf55fde012
127.0.0.1 - - [15/Feb/2025 11:53:51] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:51,350 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 98c057a4-91c8-4fca-8576-8acef038f155
127.0.0.1 - - [15/Feb/2025 11:53:51] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:51,477 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-15 11:53:51,768 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.281418
2025-02-15 11:53:51,982 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-15 11:53:52,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-15 11:53:52,483 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
2025-02-15 11:53:52,487 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.059384
2025-02-15 11:53:52,754 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-15 11:53:52,979 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-15 11:53:53,182 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ca846927-8346-4c46-aab1-b85d155ba6a7
127.0.0.1 - - [15/Feb/2025 11:53:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:53,245 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 875e4abd-fd27-47e5-b063-c4b2c264691d
127.0.0.1 - - [15/Feb/2025 11:53:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:53,256 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-15 11:53:53,291 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a3d7c81c-cb04-48db-961e-3cdc47cf1bc1
127.0.0.1 - - [15/Feb/2025 11:53:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:53,293 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1ba13218-9429-408d-8415-b62743307d79
127.0.0.1 - - [15/Feb/2025 11:53:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:53,499 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.559861
2025-02-15 11:53:53,745 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
2025-02-15 11:53:53,997 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-15 11:53:54,061 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8dc05060-dbeb-4cd1-9cc2-f9e1c54b5903
127.0.0.1 - - [15/Feb/2025 11:53:54] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:54,081 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 575930dd-530a-4ab7-a96f-495d18c29828
127.0.0.1 - - [15/Feb/2025 11:53:54] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:54,092 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0981aa7d-12a6-4d97-9250-0e0b2b69f63b
127.0.0.1 - - [15/Feb/2025 11:53:54] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:54,325 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.281418
2025-02-15 11:53:54,480 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.281418
2025-02-15 11:53:54,764 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.281418
2025-02-15 11:53:54,998 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-15 11:53:55,272 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
2025-02-15 11:53:55,504 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.559861
2025-02-15 11:53:55,757 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-15 11:53:56,007 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.559861
2025-02-15 11:53:56,262 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.465794
2025-02-15 11:53:56,486 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.190029
2025-02-15 11:53:56,758 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-15 11:53:56,982 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.190029
2025-02-15 11:53:57,300 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
2025-02-15 11:53:57,600 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.374043
2025-02-15 11:53:57,749 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.281418
2025-02-15 11:53:57,935 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e5324f8b-bf61-42d0-b7d3-134337b1a0f6
127.0.0.1 - - [15/Feb/2025 11:53:57] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:57,989 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-15 11:53:57,991 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.424948
2025-02-15 11:53:58,280 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-15 11:53:58,500 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-15 11:53:58,754 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-15 11:53:59,024 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-15 11:53:59,267 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.374043
2025-02-15 11:53:59,511 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.374043
2025-02-15 11:53:59,696 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bd6f8d87-985c-4a48-b886-1f6a03e6a8b2
127.0.0.1 - - [15/Feb/2025 11:53:59] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:53:59,770 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.64948
2025-02-15 11:54:00,001 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.374043
2025-02-15 11:54:00,303 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.374043
2025-02-15 11:54:00,494 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.281418
2025-02-15 11:54:00,766 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-15 11:54:01,013 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.465794
2025-02-15 11:54:01,266 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.559861
2025-02-15 11:54:01,562 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-15 11:54:01,757 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-15 11:54:01,998 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-15 11:54:02,264 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.465794
2025-02-15 11:54:02,581 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.583353
2025-02-15 11:54:02,617 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.374043
2025-02-15 11:54:02,785 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.374043
2025-02-15 11:54:02,994 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-15 11:54:03,263 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
2025-02-15 11:54:03,340 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bc72d4cd-0dc8-4b5c-9bf4-c0de639640df
127.0.0.1 - - [15/Feb/2025 11:54:03] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:03,609 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.64948
2025-02-15 11:54:03,811 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7e7b1ef3-1a61-4cc8-848b-aafafd5d06d0
127.0.0.1 - - [15/Feb/2025 11:54:03] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:03,829 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f5d7a6cb-d4e1-4709-8fe6-494939a4037a
127.0.0.1 - - [15/Feb/2025 11:54:03] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:03,878 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ae853276-d47e-44b9-bf68-a93b7e268891
127.0.0.1 - - [15/Feb/2025 11:54:03] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:03,906 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.559861
2025-02-15 11:54:03,991 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-15 11:54:04,254 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-15 11:54:04,510 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.64948
2025-02-15 11:54:04,608 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 423865e6-ee56-43e9-b267-a43d690d3228
127.0.0.1 - - [15/Feb/2025 11:54:04] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:04,657 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1f4b382b-baf5-4ecb-9d35-b054029ba279
127.0.0.1 - - [15/Feb/2025 11:54:04] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:04,757 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-15 11:54:05,154 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
2025-02-15 11:54:05,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-15 11:54:05,495 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.281418
2025-02-15 11:54:05,535 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 14c196cf-d701-4e77-b1a2-25bc8c10171f
127.0.0.1 - - [15/Feb/2025 11:54:05] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:05,600 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 180a0846-d96c-4dda-bdba-cb0fd8b19385
127.0.0.1 - - [15/Feb/2025 11:54:05] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:05,761 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.190029
2025-02-15 11:54:06,060 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-15 11:54:06,275 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.465794
2025-02-15 11:54:06,488 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-15 11:54:06,776 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.559861
2025-02-15 11:54:06,981 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
2025-02-15 11:54:07,237 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d7081f77-6799-4775-9e52-87147ad14260
2025-02-15 11:54:07,241 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 44961eb2-016c-4c5a-9b2e-fbd0a2712141
127.0.0.1 - - [15/Feb/2025 11:54:07] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [15/Feb/2025 11:54:07] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:07,273 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c74e7639-32e7-427e-b88f-2bbcc6476c68
127.0.0.1 - - [15/Feb/2025 11:54:07] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:07,278 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.190029
2025-02-15 11:54:07,478 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-15 11:54:07,783 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-15 11:54:07,986 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.190029
2025-02-15 11:54:08,055 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.752793
2025-02-15 11:54:08,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.190029
2025-02-15 11:54:08,499 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-15 11:54:08,754 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-15 11:54:09,002 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.281418
2025-02-15 11:54:09,218 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7c3f1b62-9951-4003-a323-0f7e7c4cc9cc
127.0.0.1 - - [15/Feb/2025 11:54:09] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:09,238 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7df47688-6628-4fcf-9092-dce0a2619872
127.0.0.1 - - [15/Feb/2025 11:54:09] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:09,326 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0a7576e1-82a9-4fa1-a5bc-b09c24c453e6
127.0.0.1 - - [15/Feb/2025 11:54:09] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:09,329 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.559861
2025-02-15 11:54:09,364 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e1b3c760-6e77-4ed7-b52d-39abd0180a4d
127.0.0.1 - - [15/Feb/2025 11:54:09] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:09,391 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d68cd679-45ea-4383-ad26-770f2c6fccb3
127.0.0.1 - - [15/Feb/2025 11:54:09] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:09,508 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.281418
2025-02-15 11:54:09,947 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.465794
2025-02-15 11:54:10,030 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.374043
2025-02-15 11:54:10,354 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.465794
2025-02-15 11:54:10,491 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-15 11:54:10,749 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-15 11:54:11,079 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.465794
2025-02-15 11:54:11,285 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.281418
2025-02-15 11:54:11,505 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-15 11:54:11,617 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4e96d771-7ae6-48a6-8f16-0a62f7df9ac5
127.0.0.1 - - [15/Feb/2025 11:54:11] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:11,834 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-15 11:54:12,000 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.190029
2025-02-15 11:54:12,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-15 11:54:12,414 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.29484
2025-02-15 11:54:12,494 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.190029
2025-02-15 11:54:12,796 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-15 11:54:12,989 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-15 11:54:13,308 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.64948
2025-02-15 11:54:13,525 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.281418
2025-02-15 11:54:13,748 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-15 11:54:13,981 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-15 11:54:14,260 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.281418
2025-02-15 11:54:14,517 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-15 11:54:14,814 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
2025-02-15 11:54:15,000 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.281418
2025-02-15 11:54:15,019 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a0193f22-0b68-4d51-b0b6-e0a9b2e7d1b7
127.0.0.1 - - [15/Feb/2025 11:54:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:15,028 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3b1fa955-ea59-432a-b187-3b53a66b4b7f
127.0.0.1 - - [15/Feb/2025 11:54:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:15,124 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 222b44a1-820f-4d28-9b0e-7240bf677f5b
127.0.0.1 - - [15/Feb/2025 11:54:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:15,271 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.559861
2025-02-15 11:54:15,479 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-15 11:54:15,622 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 51a83c06-9fb6-4880-8fe1-f01f054b9519
127.0.0.1 - - [15/Feb/2025 11:54:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:15,733 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b6ccd1fc-e21a-4e25-9812-d3672a37e973
127.0.0.1 - - [15/Feb/2025 11:54:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:15,764 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d734c582-588a-4800-a34a-2f03fac45eaf
127.0.0.1 - - [15/Feb/2025 11:54:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:15,785 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e3b5f93c-aaf1-46ec-b61b-b5659c810af8
127.0.0.1 - - [15/Feb/2025 11:54:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:15,831 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
2025-02-15 11:54:15,845 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 19f90bb9-0f60-41e9-abdc-5c33aea2d91a
127.0.0.1 - - [15/Feb/2025 11:54:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:15,979 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-15 11:54:16,273 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.559861
2025-02-15 11:54:16,470 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 86f740a4-6aae-4431-8f79-d5c37bda80c5
127.0.0.1 - - [15/Feb/2025 11:54:16] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:16,488 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 55a19b85-ab67-4522-ad17-e6b460b9aa51
127.0.0.1 - - [15/Feb/2025 11:54:16] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:16,512 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.374043
2025-02-15 11:54:16,538 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e171244b-6276-4585-9d75-cd6919c61bfb
127.0.0.1 - - [15/Feb/2025 11:54:16] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:16,760 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-15 11:54:17,007 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
2025-02-15 11:54:17,249 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
2025-02-15 11:54:17,478 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 65a7fb38-20be-4325-9aea-df3da61e9012
127.0.0.1 - - [15/Feb/2025 11:54:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:17,481 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 921759a8-eec6-41cc-96cf-3b76b0e3b74f
127.0.0.1 - - [15/Feb/2025 11:54:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:17,491 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 11a79a9b-c23d-410e-a526-e99051a65665
127.0.0.1 - - [15/Feb/2025 11:54:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:17,509 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-15 11:54:17,537 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0dd7f520-a1c9-46d4-b59b-48ce6f71a98a
127.0.0.1 - - [15/Feb/2025 11:54:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:17,843 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.477553
2025-02-15 11:54:17,900 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.465794
2025-02-15 11:54:18,070 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.465794
2025-02-15 11:54:18,257 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.374043
2025-02-15 11:54:18,506 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.190029
2025-02-15 11:54:19,004 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.64948
2025-02-15 11:54:19,103 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.374043
2025-02-15 11:54:19,260 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-15 11:54:19,358 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.304701999999999
2025-02-15 11:54:19,494 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
2025-02-15 11:54:19,759 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.190029
2025-02-15 11:54:20,065 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-15 11:54:20,252 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.098841
2025-02-15 11:54:20,481 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 885c2791-c452-4860-aa5c-9e289f3e5024
127.0.0.1 - - [15/Feb/2025 11:54:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:20,525 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.374043
2025-02-15 11:54:20,915 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.64948
2025-02-15 11:54:21,055 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.281418
2025-02-15 11:54:21,203 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4ab7e8fb-7252-4a3b-8d83-52f61c86a956
127.0.0.1 - - [15/Feb/2025 11:54:21] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:21,271 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.374043
2025-02-15 11:54:21,507 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-15 11:54:21,770 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.190029
2025-02-15 11:54:22,021 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-15 11:54:22,262 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.098841
2025-02-15 11:54:22,558 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-15 11:54:22,666 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.059384
2025-02-15 11:54:22,762 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-15 11:54:22,997 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-15 11:54:23,058 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6d768459-ffa8-4392-977e-c253e84656b4
2025-02-15 11:54:23,063 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ba779e86-4bc3-48f9-b886-b4c07a593771
127.0.0.1 - - [15/Feb/2025 11:54:23] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [15/Feb/2025 11:54:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:23,112 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4eb379b1-6a88-4ea9-89b6-5e640a6792cb
127.0.0.1 - - [15/Feb/2025 11:54:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:23,172 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 13104740-b416-4898-9eeb-f8f4cd95a1f2
127.0.0.1 - - [15/Feb/2025 11:54:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:23,289 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.374043
2025-02-15 11:54:23,568 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.559861
2025-02-15 11:54:23,620 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3cac9e83-f8a2-4775-8420-a867a651df1d
127.0.0.1 - - [15/Feb/2025 11:54:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:23,810 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
2025-02-15 11:54:23,986 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.190029
2025-02-15 11:54:24,163 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e8d4d6af-f552-4f5f-89cf-555576e5468c
127.0.0.1 - - [15/Feb/2025 11:54:24] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:24,172 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 547483aa-a1a2-478e-bdbd-00660e46f734
127.0.0.1 - - [15/Feb/2025 11:54:24] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:24,269 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.281418
2025-02-15 11:54:24,543 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.190029
2025-02-15 11:54:24,792 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-15 11:54:24,982 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-15 11:54:25,290 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.559861
2025-02-15 11:54:25,483 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b61ccd95-50c3-42b1-b4ac-77ce948bd187
127.0.0.1 - - [15/Feb/2025 11:54:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:25,514 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.281418
2025-02-15 11:54:25,760 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-15 11:54:25,996 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.465794
2025-02-15 11:54:26,286 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.190029
2025-02-15 11:54:26,493 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-15 11:54:26,594 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1e49af4c-e47a-43ac-89b7-5a6e1bff5490
127.0.0.1 - - [15/Feb/2025 11:54:26] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:26,623 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ea125784-de13-49be-8daa-e8e6a5f705ac
127.0.0.1 - - [15/Feb/2025 11:54:26] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:26,668 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2d1c3c4a-88ed-4410-938f-f95500025ce7
127.0.0.1 - - [15/Feb/2025 11:54:26] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:27,005 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-15 11:54:27,752 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
2025-02-15 11:54:28,179 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.190029
2025-02-15 11:54:28,285 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.059384
2025-02-15 11:54:28,539 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.281418
2025-02-15 11:54:29,040 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.833391
2025-02-15 11:54:29,078 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.465794
2025-02-15 11:54:29,640 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.465794
2025-02-15 11:54:30,007 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.281418
2025-02-15 11:54:30,550 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.559861
2025-02-15 11:54:30,664 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e53df30c-3c8b-4dbe-b4d1-99df0e82862e
127.0.0.1 - - [15/Feb/2025 11:54:30] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:30,830 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4259b28f-9dcb-49bf-8bc6-c1a34eee4691
127.0.0.1 - - [15/Feb/2025 11:54:30] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:31,020 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-15 11:54:31,579 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-15 11:54:31,988 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1b212ef3-b673-4cc6-91a7-6a429ad91eaa
127.0.0.1 - - [15/Feb/2025 11:54:31] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:32,062 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c864dbed-a09d-4f1b-b240-1a035cc443d8
127.0.0.1 - - [15/Feb/2025 11:54:32] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:32,186 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-15 11:54:32,505 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
2025-02-15 11:54:32,891 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.853023
2025-02-15 11:54:32,998 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.190029
2025-02-15 11:54:33,026 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bb070b85-5899-4b7d-a972-96f9d0bf43d6
127.0.0.1 - - [15/Feb/2025 11:54:33] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:33,031 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 753c92f5-767b-4fa1-828d-e7e5762629d0
127.0.0.1 - - [15/Feb/2025 11:54:33] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:33,057 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 08dba872-5364-4b3b-935f-617a4e1f9066
127.0.0.1 - - [15/Feb/2025 11:54:33] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:33,085 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8871d85f-9c4e-42ed-b990-54e43ed3bfcc
127.0.0.1 - - [15/Feb/2025 11:54:33] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:33,500 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-15 11:54:34,023 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.374043
2025-02-15 11:54:34,616 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-15 11:54:35,000 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-15 11:54:35,280 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ed067d56-6458-4201-9251-3b695b5b2531
127.0.0.1 - - [15/Feb/2025 11:54:35] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:35,345 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 65a2ddfb-6c22-45cf-ac46-2a47adb0a810
127.0.0.1 - - [15/Feb/2025 11:54:35] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:35,373 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 444d41f6-3e78-4237-b1a2-a582a3eeae53
127.0.0.1 - - [15/Feb/2025 11:54:35] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:35,479 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-15 11:54:36,066 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.559861
2025-02-15 11:54:36,376 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 86940131-5c04-42ee-9b87-96a7961460eb
127.0.0.1 - - [15/Feb/2025 11:54:36] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:36,532 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.559861
2025-02-15 11:54:37,036 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-15 11:54:37,418 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 77494fc5-5e66-493e-a6f9-13379dc45941
127.0.0.1 - - [15/Feb/2025 11:54:37] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:37,458 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 34ad865d-1def-4a03-ba3e-b2d1b8fd68e9
127.0.0.1 - - [15/Feb/2025 11:54:37] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:37,488 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3196c887-e2be-47e9-862f-9849c95365b2
127.0.0.1 - - [15/Feb/2025 11:54:37] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:37,550 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-15 11:54:37,988 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.386889
2025-02-15 11:54:38,119 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
2025-02-15 11:54:38,551 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.465794
2025-02-15 11:54:39,016 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-15 11:54:39,413 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 90babf69-84a0-44bd-8df9-599a9e0b8861
127.0.0.1 - - [15/Feb/2025 11:54:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:39,560 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fc81cd51-59d7-4afe-8169-eb77919d58bc
127.0.0.1 - - [15/Feb/2025 11:54:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:39,638 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
2025-02-15 11:54:40,191 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.64948
2025-02-15 11:54:40,549 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.281418
2025-02-15 11:54:41,013 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-15 11:54:41,059 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.190029
2025-02-15 11:54:41,509 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-15 11:54:41,570 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.190029
2025-02-15 11:54:41,755 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9390a6c3-292c-4eb6-aa49-09a0ac1e2d4c
127.0.0.1 - - [15/Feb/2025 11:54:41] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:41,989 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e194e6a0-f395-4f69-b78a-1255cd57810f
127.0.0.1 - - [15/Feb/2025 11:54:41] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:42,000 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-15 11:54:42,004 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c2dfe041-6ac1-4493-b947-451ddc3aa4fa
127.0.0.1 - - [15/Feb/2025 11:54:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:42,020 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 66c914b3-4d73-478a-8c1c-d24f6c249da1
127.0.0.1 - - [15/Feb/2025 11:54:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:42,113 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.374043
2025-02-15 11:54:42,506 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.190029
2025-02-15 11:54:42,573 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.304702
2025-02-15 11:54:42,593 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.190029
2025-02-15 11:54:42,752 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 69df203e-1f02-4906-9510-ab48f4410066
127.0.0.1 - - [15/Feb/2025 11:54:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:43,078 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-15 11:54:43,224 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-15 11:54:43,558 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.190029
2025-02-15 11:54:43,710 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-15 11:54:43,977 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.098841
2025-02-15 11:54:44,122 - LoudVA - INFO - [LoudServer] - Completed. Request ID: edd9d0f0-0ea7-40c1-93e1-2b2cd0112bee
127.0.0.1 - - [15/Feb/2025 11:54:44] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:44,138 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e3c5b512-f27d-4e85-9ffe-2458122cab3b
127.0.0.1 - - [15/Feb/2025 11:54:44] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:44,197 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ab0bf10c-3da6-4eea-aabc-d6a215654386
127.0.0.1 - - [15/Feb/2025 11:54:44] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:44,222 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.64948
2025-02-15 11:54:44,401 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 52ffe0c6-0b7e-45ad-83ce-232257c6ed19
127.0.0.1 - - [15/Feb/2025 11:54:44] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:44,416 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 82a3fbd4-aadf-4cb7-8675-99477e891890
127.0.0.1 - - [15/Feb/2025 11:54:44] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:44,427 - LoudVA - INFO - [LoudServer] - Completed. Request ID: be1a6b0c-e9af-45be-84ac-3ab74d90e0c5
127.0.0.1 - - [15/Feb/2025 11:54:44] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:44,559 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-15 11:54:44,661 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
2025-02-15 11:54:44,998 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-15 11:54:45,050 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-15 11:54:45,605 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.465794
2025-02-15 11:54:45,723 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.374043
2025-02-15 11:54:46,174 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.374043
2025-02-15 11:54:46,229 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-15 11:54:46,588 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-15 11:54:46,630 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.374043
2025-02-15 11:54:46,995 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.281418
2025-02-15 11:54:47,077 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.281418
2025-02-15 11:54:47,586 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.374043
2025-02-15 11:54:47,789 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-15 11:54:48,033 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-15 11:54:48,134 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.465794
2025-02-15 11:54:48,277 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.853023
2025-02-15 11:54:48,555 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.281418
2025-02-15 11:54:48,570 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.190029
2025-02-15 11:54:49,067 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.281418
2025-02-15 11:54:49,200 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.559861
2025-02-15 11:54:49,557 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.190029
2025-02-15 11:54:49,570 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-15 11:54:50,083 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-15 11:54:50,098 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-15 11:54:50,504 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.190029
2025-02-15 11:54:50,547 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-15 11:54:51,175 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.281418
2025-02-15 11:54:51,220 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.465794
2025-02-15 11:54:51,497 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-15 11:54:51,578 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.281418
2025-02-15 11:54:52,032 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.190029
2025-02-15 11:54:52,111 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.190029
2025-02-15 11:54:52,504 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.281418
Exception in thread Thread-88:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:54:52,602 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-15 11:54:52,925 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a1a90378-43a6-4fc2-81ae-79e8174a0b90
127.0.0.1 - - [15/Feb/2025 11:54:52] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:52,994 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-15 11:54:53,038 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3e558fbe-4b4b-47ac-8ad9-7bae5516b1d6
127.0.0.1 - - [15/Feb/2025 11:54:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:53,083 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6aa8748c-a274-4313-b976-5e0b31091f8e
127.0.0.1 - - [15/Feb/2025 11:54:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:53,087 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-15 11:54:53,238 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f935191e-18bc-4a07-a5bc-4b7e6fa20cec
127.0.0.1 - - [15/Feb/2025 11:54:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:53,393 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.144352
2025-02-15 11:54:53,427 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3c23f8a1-fc72-485c-8f6b-79a2cdbc5ce4
127.0.0.1 - - [15/Feb/2025 11:54:53] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-92:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:54:53,602 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.465794
2025-02-15 11:54:53,650 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.465794
2025-02-15 11:54:54,069 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e55407e4-7599-4b51-b419-c9e747bb1302
127.0.0.1 - - [15/Feb/2025 11:54:54] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:54,089 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d89023ee-f66d-4d1f-912d-e1fdea66228c
127.0.0.1 - - [15/Feb/2025 11:54:54] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:54,094 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.465794
2025-02-15 11:54:54,166 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.281418
2025-02-15 11:54:54,647 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.64948
2025-02-15 11:54:54,744 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.374043
2025-02-15 11:54:55,018 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.281418
2025-02-15 11:54:55,192 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.559861
2025-02-15 11:54:55,373 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7ec13c48-df73-4dc0-8e0e-c3dab546c280
127.0.0.1 - - [15/Feb/2025 11:54:55] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:55,533 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.190029
2025-02-15 11:54:55,550 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-15 11:54:55,614 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d6352cf1-902e-493b-b34c-ec62e42817bf
2025-02-15 11:54:55,616 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0b2cb939-1c2e-45cf-a739-4c85dd73d0d7
127.0.0.1 - - [15/Feb/2025 11:54:55] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [15/Feb/2025 11:54:55] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:55,665 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 22954945-a932-4aab-9fcd-88c7300be139
127.0.0.1 - - [15/Feb/2025 11:54:55] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:55,689 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5985a586-2aa6-434a-9f7e-7bdea2887a9c
127.0.0.1 - - [15/Feb/2025 11:54:55] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:56,041 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.559861
2025-02-15 11:54:56,058 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-15 11:54:56,553 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.281418
2025-02-15 11:54:56,590 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.281418
Exception in thread Thread-98:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:54:57,171 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
2025-02-15 11:54:57,175 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-15 11:54:57,558 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-15 11:54:57,634 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.374043
Exception in thread Thread-100:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:54:57,927 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fa2a536d-31a6-406d-89e6-ab41cd04e124
127.0.0.1 - - [15/Feb/2025 11:54:57] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:58,026 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-15 11:54:58,035 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6e13cc9c-0f4b-49dd-a7ec-ddcef245a243
127.0.0.1 - - [15/Feb/2025 11:54:58] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:54:58,073 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.098841
2025-02-15 11:54:58,175 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.843875
2025-02-15 11:54:58,607 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.465794
2025-02-15 11:54:58,692 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.559861
Exception in thread Thread-101:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-104:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:54:59,169 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
2025-02-15 11:54:59,299 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.64948
Exception in thread Thread-105:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:54:59,600 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-15 11:54:59,625 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.190029
Exception in thread Thread-102:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:00,016 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.281418
2025-02-15 11:55:00,408 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 65343d14-749c-4a62-86dc-92b718f16d4a
127.0.0.1 - - [15/Feb/2025 11:55:00] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:55:00,424 - LoudVA - INFO - [LoudServer] - Completed. Request ID: dab0f190-9800-4585-a70d-0a59406535d1
127.0.0.1 - - [15/Feb/2025 11:55:00] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:55:00,480 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 55d74844-dfad-46da-a8f9-c791e712cc7d
127.0.0.1 - - [15/Feb/2025 11:55:00] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:55:00,588 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1495c49b-023d-476d-9b5e-6bcbf2dd557b
127.0.0.1 - - [15/Feb/2025 11:55:00] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:55:00,752 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.465794
2025-02-15 11:55:01,037 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.281418
2025-02-15 11:55:01,506 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
Exception in thread Thread-109:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-110:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:02,294 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.64948
Exception in thread Thread-108:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:02,599 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.374043
2025-02-15 11:55:02,950 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.119834
Exception in thread Thread-112:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:03,022 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
Exception in thread Thread-103:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-113:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:03,636 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.098841
Exception in thread Thread-116:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-115:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:04,192 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.559861
Exception in thread Thread-118:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-117:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:04,592 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
Exception in thread Thread-119:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:05,082 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.559861
2025-02-15 11:55:05,510 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.190029
Exception in thread Thread-121:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:06,161 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.559861
2025-02-15 11:55:06,514 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
Exception in thread Thread-122:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-120:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:07,261 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.64948
Exception in thread Thread-123:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:07,543 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-15 11:55:07,832 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
2025-02-15 11:55:08,003 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
Exception in thread Thread-124:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-125:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:08,566 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.465794
Exception in thread Thread-127:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:09,136 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.559861
2025-02-15 11:55:09,506 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
Exception in thread Thread-128:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:10,002 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
Exception in thread Thread-129:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:10,600 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.465794
Exception in thread Thread-126:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:11,029 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.190029
Exception in thread Thread-130:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:11,848 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
2025-02-15 11:55:12,011 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
Exception in thread Thread-132:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:12,611 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
Exception in thread Thread-131:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-133:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:13,045 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.281418
2025-02-15 11:55:13,263 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.231161
Exception in thread Thread-135:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:13,362 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.741029
2025-02-15 11:55:13,483 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.190029
Exception in thread Thread-136:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-134:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:14,013 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
2025-02-15 11:55:14,611 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
2025-02-15 11:55:15,024 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.465794
2025-02-15 11:55:15,614 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.465794
Exception in thread Thread-138:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:16,129 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.281418
2025-02-15 11:55:16,637 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
Exception in thread Thread-139:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:16,991 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
Exception in thread Thread-140:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-141:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:17,503 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
Exception in thread Thread-143:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:18,356 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-15 11:55:18,551 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-15 11:55:18,581 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.49637
Exception in thread Thread-146:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:18,987 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
Exception in thread Thread-144:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-145:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:19,580 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
Exception in thread Thread-147:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-149:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:20,026 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
Exception in thread Thread-148:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-150:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:20,625 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.374043
Exception in thread Thread-137:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-142:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:21,046 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.190029
Exception in thread Thread-151:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-152:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:21,720 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.465794
Exception in thread Thread-154:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-153:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:22,190 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.64948
2025-02-15 11:55:22,766 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.281418
2025-02-15 11:55:23,015 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
Exception in thread Thread-156:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-155:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-157:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-159:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:23,679 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.281418
Exception in thread Thread-161:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:24,104 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-15 11:55:24,128 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.119834
2025-02-15 11:55:24,513 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
Exception in thread Thread-158:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-160:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-111:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:25,045 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
Exception in thread Thread-163:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:25,867 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-15 11:55:26,242 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.465794
Exception in thread Thread-162:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-164:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:26,599 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.281418
Exception in thread Thread-165:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:27,047 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-15 11:55:27,585 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-15 11:55:28,096 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-15 11:55:28,487 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.752793
2025-02-15 11:55:28,554 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.190029
Exception in thread Thread-166:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:29,073 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.374043
Exception in thread Thread-167:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-171:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-169:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:29,588 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.559861
2025-02-15 11:55:30,075 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
Exception in thread Thread-172:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-168:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-170:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
Exception in thread Thread-173:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    raise timeout('timed out')
socket.timeout: timed out
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:30,768 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.281418
2025-02-15 11:55:31,026 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.465794
Exception in thread Thread-174:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:31,820 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.374043
2025-02-15 11:55:32,521 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.465794
2025-02-15 11:55:32,752 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.465794
2025-02-15 11:55:33,282 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.465794
Exception in thread Thread-175:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-178:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:33,933 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.119834
Exception in thread Thread-180:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:34,027 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.374043
2025-02-15 11:55:34,299 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.374043
Exception in thread Thread-176:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-177:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:34,556 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
Exception in thread Thread-179:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:35,095 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.465794
Exception in thread Thread-181:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:35,671 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-15 11:55:36,192 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.281418
Exception in thread Thread-182:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:36,687 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.465794
Exception in thread Thread-183:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:37,059 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-15 11:55:37,678 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.559861
2025-02-15 11:55:37,800 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.281418
Exception in thread Thread-184:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:38,435 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.465794
2025-02-15 11:55:38,585 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.281418
Exception in thread Thread-185:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-186:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:39,177 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-15 11:55:39,526 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.190029
Exception in thread Thread-187:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:40,232 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.465794
Exception in thread Thread-188:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:40,573 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
Exception in thread Thread-189:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:41,041 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.190029
2025-02-15 11:55:41,946 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.465794
2025-02-15 11:55:42,233 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
Exception in thread Thread-190:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:42,545 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
Exception in thread Thread-191:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-194:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:43,314 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
Exception in thread Thread-192:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-195:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-193:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:43,530 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.027485
2025-02-15 11:55:44,033 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
2025-02-15 11:55:44,124 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
Exception in thread Thread-196:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-197:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:44,693 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
Exception in thread Thread-198:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:45,171 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
Exception in thread Thread-199:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:45,591 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.281418
Exception in thread Thread-200:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:46,246 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.190029
2025-02-15 11:55:46,523 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-15 11:55:47,097 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
Exception in thread Thread-202:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:47,817 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.281418
Exception in thread Thread-203:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:48,195 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.281418
2025-02-15 11:55:48,539 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
Exception in thread Thread-201:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-205:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-204:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-207:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-206:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:49,206 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
Exception in thread Thread-209:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:49,634 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.190029
2025-02-15 11:55:50,043 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
Exception in thread Thread-208:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-210:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-211:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:50,625 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.465794
2025-02-15 11:55:51,024 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-15 11:55:51,606 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.465794
Exception in thread Thread-213:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-212:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:52,406 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.465794
2025-02-15 11:55:52,578 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.374043
Exception in thread Thread-214:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:53,332 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.833391
2025-02-15 11:55:53,501 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.64948
2025-02-15 11:55:53,577 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.465794
Exception in thread Thread-216:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:53,982 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
Exception in thread Thread-217:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-215:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:54,575 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.374043
Exception in thread Thread-219:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-218:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:55,231 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.374043
Exception in thread Thread-220:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-221:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:55,577 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
Exception in thread Thread-223:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-222:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:56,074 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-15 11:55:56,585 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
Exception in thread Thread-224:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-225:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:57,376 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
Exception in thread Thread-226:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:58,069 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.190029
2025-02-15 11:55:58,239 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.559861
2025-02-15 11:55:58,543 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
Exception in thread Thread-227:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-228:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-229:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-230:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:55:59,386 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.465794
Exception in thread Thread-232:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-231:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:00,171 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.559861
Exception in thread Thread-233:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:00,534 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
Exception in thread Thread-234:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:00,698 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.559861
2025-02-15 11:56:00,801 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.583353
2025-02-15 11:56:01,030 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
Exception in thread Thread-235:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:01,610 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.465794
2025-02-15 11:56:02,164 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.465794
2025-02-15 11:56:02,894 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.559861
2025-02-15 11:56:03,096 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.281418
Exception in thread Thread-236:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-237:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:03,536 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
Exception in thread Thread-238:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-239:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:04,039 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.098841
2025-02-15 11:56:04,520 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.956077
2025-02-15 11:56:04,814 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
Exception in thread Thread-240:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:05,106 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.374043
Exception in thread Thread-241:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:06,053 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.559861
2025-02-15 11:56:06,140 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.281418
Exception in thread Thread-242:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-243:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-244:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-245:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:10,136 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
Exception in thread Thread-246:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-247:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:13,422 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
Exception in thread Thread-248:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-250:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-249:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-252:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-251:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-253:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-254:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-255:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-256:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-257:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-259:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-258:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-260:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-261:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-262:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-263:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:21,005 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.677423
Exception in thread Thread-264:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-265:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:23,459 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.934937
2025-02-15 11:56:23,590 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1e7b57bc-176a-4052-80d5-a2d833bb0b65
127.0.0.1 - - [15/Feb/2025 11:56:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:23,976 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c289d6ad-fb7c-45c0-9d4a-381a17be14a9
127.0.0.1 - - [15/Feb/2025 11:56:24] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-267:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-269:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-270:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:25,511 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d8af53bb-4891-45f3-8a8d-11d15cbdc778
127.0.0.1 - - [15/Feb/2025 11:56:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:25,555 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7907f1c5-6c5e-4678-bfda-d69f99b46914
127.0.0.1 - - [15/Feb/2025 11:56:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:25,641 - LoudVA - INFO - [LoudServer] - Completed. Request ID: dddf8304-a805-4d77-9f46-2c0e84385dff
127.0.0.1 - - [15/Feb/2025 11:56:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:27,001 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 17b94548-eac7-4fa5-8198-e2e108a84bbc
127.0.0.1 - - [15/Feb/2025 11:56:27] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:27,430 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 688d59d9-03bb-4c15-b4c0-cd355d04bd04
127.0.0.1 - - [15/Feb/2025 11:56:27] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:27,476 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d7f0e898-6da4-437b-a9d6-800c53bc2aec
127.0.0.1 - - [15/Feb/2025 11:56:27] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:27,611 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c23253e1-efcf-4fdd-b901-b37acb4761dd
127.0.0.1 - - [15/Feb/2025 11:56:27] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:28,993 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 43d2b832-1611-4200-aeed-29afd7b2b5e3
2025-02-15 11:56:28,994 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7713a27e-e572-4f8b-b538-77bc47c54b02
127.0.0.1 - - [15/Feb/2025 11:56:28] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [15/Feb/2025 11:56:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:29,055 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 273b1a3a-3d30-4e2a-9330-bde42bb27732
127.0.0.1 - - [15/Feb/2025 11:56:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:29,229 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 23e4d68e-fe46-41ad-86e9-e1de272a23a5
127.0.0.1 - - [15/Feb/2025 11:56:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:29,298 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3954b7c9-6af5-4ad1-8d24-0324026939ea
127.0.0.1 - - [15/Feb/2025 11:56:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:29,357 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b80d0190-8238-4098-8986-957e96f86f85
127.0.0.1 - - [15/Feb/2025 11:56:29] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-276:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:29,647 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a34373ed-55f4-4e7e-bd3a-8634deadfdf9
127.0.0.1 - - [15/Feb/2025 11:56:29] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-277:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:30,088 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.213975
Exception in thread Thread-278:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-15 11:56:32,548 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6409c1c9-6adb-407c-af7d-f20163875acf
127.0.0.1 - - [15/Feb/2025 11:56:32] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:32,671 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 678dcbcc-8981-41f0-867d-9c56bbe45d4a
127.0.0.1 - - [15/Feb/2025 11:56:32] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:32,758 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 228d6069-987e-4976-ab63-36bb439f0bda
127.0.0.1 - - [15/Feb/2025 11:56:32] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:32,805 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1ea2b5b5-9f06-448a-abb6-410e7a133dc9
127.0.0.1 - - [15/Feb/2025 11:56:32] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:32,849 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4a1e8bce-abff-4c34-b6c3-93150e602b8a
127.0.0.1 - - [15/Feb/2025 11:56:32] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:32,969 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2db2ee75-45df-48cc-a062-da648a72dcbb
127.0.0.1 - - [15/Feb/2025 11:56:32] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:33,030 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e731e687-02a1-46a3-9701-3e555beeac04
127.0.0.1 - - [15/Feb/2025 11:56:33] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:33,051 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 778a2b40-7bd3-4aa8-9d76-49165da02955
127.0.0.1 - - [15/Feb/2025 11:56:33] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:33,167 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0ba308d4-cf41-4884-a8e0-a783351b85e7
127.0.0.1 - - [15/Feb/2025 11:56:33] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:33,236 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f5d29818-542e-4c2d-99be-fd451268f2d3
127.0.0.1 - - [15/Feb/2025 11:56:33] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:33,240 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 941ccc89-d1da-4d0b-b457-0dff0a1cc17a
127.0.0.1 - - [15/Feb/2025 11:56:33] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:34,138 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.477553
2025-02-15 11:56:34,390 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3224d651-563a-4534-8ba9-2b9363764870
2025-02-15 11:56:34,407 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c00c8095-246a-4443-8e93-992472984244
127.0.0.1 - - [15/Feb/2025 11:56:34] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [15/Feb/2025 11:56:34] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:35,143 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8bbf35f4-7757-427e-95ae-93b6c9dfb981
127.0.0.1 - - [15/Feb/2025 11:56:35] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:35,257 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6747ff6c-a47f-4af7-b2b7-36f9e23661e7
127.0.0.1 - - [15/Feb/2025 11:56:35] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:35,470 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5d4d3f38-fe7d-4f70-921b-6f672231b80c
127.0.0.1 - - [15/Feb/2025 11:56:35] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:35,547 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c1bb4779-e371-4511-ae99-69262bda9245
127.0.0.1 - - [15/Feb/2025 11:56:35] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:35,604 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fcc4a9ff-49b0-492c-8408-3203deb669ac
127.0.0.1 - - [15/Feb/2025 11:56:35] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:35,793 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ea32c61e-f581-4a98-bc9d-a269399e9f65
127.0.0.1 - - [15/Feb/2025 11:56:35] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:35,855 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c02832b4-d321-4453-878c-ca8f120c97db
127.0.0.1 - - [15/Feb/2025 11:56:35] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:35,997 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0d17ff40-401d-43af-b302-a5036df7db29
127.0.0.1 - - [15/Feb/2025 11:56:36] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:36,214 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f0228143-aecd-4e9c-b348-26df1c293faa
127.0.0.1 - - [15/Feb/2025 11:56:36] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:36,330 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f99ca87d-2cb7-4b9a-a3bf-0d41f75defa0
127.0.0.1 - - [15/Feb/2025 11:56:36] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:37,946 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8aec599a-682b-4c21-ad54-ac3dc1a267ed
127.0.0.1 - - [15/Feb/2025 11:56:37] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:38,398 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 02aac7c3-aeeb-4146-bc0c-fd45d315622c
127.0.0.1 - - [15/Feb/2025 11:56:38] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:38,563 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7c7e924a-fba4-4fc6-89a0-115940e54f14
127.0.0.1 - - [15/Feb/2025 11:56:38] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,235 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d46559af-8a1e-4725-b59c-b3ddfef43642
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,281 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1e046f32-198a-4d3a-8405-dac9d497c915
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,295 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5c763879-93a1-45a3-81e1-bb987a93cc6f
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,365 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 30ff5bca-743b-41fc-be90-5df6d69b4f1a
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,384 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2976510b-2d76-4e77-b3dc-7cdd5b8e1328
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,427 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 319f834f-f5c6-4a8f-a4d2-d6d1f25649c0
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,441 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 618bd2a4-4782-41bc-a711-425a9d44e34b
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,546 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 742fe74a-e876-414a-a2d8-bdfd91d6f8e9
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,583 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2fe11dff-92a6-48b2-b56e-102f650035d2
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,625 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b2a5eeb0-5ef3-46b6-97ad-10b542f55df0
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,705 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2f34e5fe-f6a2-40e4-ae94-4fa1c4fa389a
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,913 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 54ce6efe-7eb7-4c27-a3e6-fa8b19c21a97
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,914 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9fe3c5e9-0285-44f5-8c84-3e6301a47a48
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:39,953 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 35bd5de0-6203-4595-84ad-09c55f0e64d1
127.0.0.1 - - [15/Feb/2025 11:56:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:40,063 - LoudVA - INFO - [LoudServer] - Completed. Request ID: aa467b95-df2a-4c37-bf1a-a9c3a5b5ee9d
127.0.0.1 - - [15/Feb/2025 11:56:40] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:40,079 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e592b9c4-ca82-40e9-b389-4af7419c9521
127.0.0.1 - - [15/Feb/2025 11:56:40] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:40,147 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8af3af3e-1085-4f25-9f2c-04819a67dea0
127.0.0.1 - - [15/Feb/2025 11:56:40] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:40,186 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e1c3fabe-ca97-43fd-8bb9-95f2e2c0f4b1
127.0.0.1 - - [15/Feb/2025 11:56:40] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:40,204 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 68772290-866c-4224-ad9e-878f46fe28d0
127.0.0.1 - - [15/Feb/2025 11:56:40] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:40,274 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 23.403595
2025-02-15 11:56:40,298 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 314cee2a-5ae3-4871-b99d-f2e30133fd8e
127.0.0.1 - - [15/Feb/2025 11:56:40] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:40,339 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fad7d506-86ff-4515-b16e-623387a42562
127.0.0.1 - - [15/Feb/2025 11:56:40] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:40,372 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2b3f98f4-a1df-4c04-89da-6e878f666e67
127.0.0.1 - - [15/Feb/2025 11:56:40] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:42,220 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8e93cab6-6594-449c-bc88-0eade847d875
127.0.0.1 - - [15/Feb/2025 11:56:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:42,315 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4d57292c-ef07-491e-b286-e393d7e021ac
127.0.0.1 - - [15/Feb/2025 11:56:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:42,559 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3f8ef64d-c5bc-408b-92b0-a4591097cb93
127.0.0.1 - - [15/Feb/2025 11:56:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:42,701 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ef54722b-0fb2-4004-9e44-3ad4dd489f0e
127.0.0.1 - - [15/Feb/2025 11:56:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:42,776 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 48ce4129-11e8-4d7b-8176-abdea89ba805
127.0.0.1 - - [15/Feb/2025 11:56:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:42,915 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a16637c7-6d5b-43fa-8288-6d87ebfccca4
127.0.0.1 - - [15/Feb/2025 11:56:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:43,051 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9d0db44a-0d49-4681-b427-6a5f18950b37
127.0.0.1 - - [15/Feb/2025 11:56:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:43,200 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2c508f20-00ae-4635-9a6a-855ed836ccd3
127.0.0.1 - - [15/Feb/2025 11:56:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:43,308 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 94f2aa55-6562-48f2-817e-4945ff47180f
127.0.0.1 - - [15/Feb/2025 11:56:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:43,383 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2fabd829-4a09-4c80-9196-86e28f9717fb
127.0.0.1 - - [15/Feb/2025 11:56:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:43,445 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a204447e-cf2e-4421-ba1e-042149902b60
2025-02-15 11:56:43,460 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 988423bf-53bf-4cbd-b138-9a05b10d4939
127.0.0.1 - - [15/Feb/2025 11:56:43] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [15/Feb/2025 11:56:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:43,509 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 98cb9008-9652-4e5e-ae5b-507107cc1551
127.0.0.1 - - [15/Feb/2025 11:56:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:43,530 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 953912ad-4d91-4612-a0af-f4829fee45a6
127.0.0.1 - - [15/Feb/2025 11:56:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:43,730 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8711cfc2-63fb-4138-8b67-c7ac1e7b87a9
127.0.0.1 - - [15/Feb/2025 11:56:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:43,815 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b1629ceb-eccb-4c87-948d-fb72d45e03c7
127.0.0.1 - - [15/Feb/2025 11:56:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:44,152 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 48467fca-78f3-4ce7-b488-d6f5d60ea367
127.0.0.1 - - [15/Feb/2025 11:56:44] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:44,600 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bfe50689-0323-44db-b10f-957bf23dd90a
127.0.0.1 - - [15/Feb/2025 11:56:44] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:44,608 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 354a9b5b-f21b-4b52-afcf-9594d8b4342a
127.0.0.1 - - [15/Feb/2025 11:56:44] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:44,649 - LoudVA - INFO - [LoudServer] - Completed. Request ID: dfee803f-8419-4f7f-b367-3814ecaf218b
127.0.0.1 - - [15/Feb/2025 11:56:44] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:44,712 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.424948
2025-02-15 11:56:45,007 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4416d0e6-6e10-47a5-982c-5fe28538ae2a
127.0.0.1 - - [15/Feb/2025 11:56:45] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:46,143 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f2cd9cad-7745-4b11-9f80-94191e50aa19
127.0.0.1 - - [15/Feb/2025 11:56:46] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:47,491 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3ab15224-168e-4efa-b72c-0a79aba7e0c4
2025-02-15 11:56:47,493 - LoudVA - INFO - [LoudServer] - Completed. Request ID: dec91df7-19f4-4873-b9d2-49672fd3e975
127.0.0.1 - - [15/Feb/2025 11:56:47] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [15/Feb/2025 11:56:47] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:48,462 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 236afa44-2378-4d10-b595-d01ef8a74b45
127.0.0.1 - - [15/Feb/2025 11:56:48] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:49,811 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.934937
2025-02-15 11:56:49,850 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fa29c20a-d0a6-42d0-8bef-af46cea7fea5
127.0.0.1 - - [15/Feb/2025 11:56:49] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:50,028 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 902f9c82-2b24-4c78-9423-691150cc5f7e
127.0.0.1 - - [15/Feb/2025 11:56:50] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:51,229 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f9d32cd2-d6c2-4656-8c78-22327c2db67a
127.0.0.1 - - [15/Feb/2025 11:56:51] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:53,190 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 537fe01a-173f-4b4e-b9a7-d74f1a72122c
127.0.0.1 - - [15/Feb/2025 11:56:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:54,011 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.49637
2025-02-15 11:56:54,192 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f99e320f-aae5-4ee4-8a34-32d7429bdff4
127.0.0.1 - - [15/Feb/2025 11:56:54] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:54,547 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d624a459-c182-4b2a-a3eb-273614c54258
127.0.0.1 - - [15/Feb/2025 11:56:54] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:56,313 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0c5a9e17-c270-407e-9fa6-61dad2e7fab2
127.0.0.1 - - [15/Feb/2025 11:56:56] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:56:59,640 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.943081
2025-02-15 11:57:02,149 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 588c7554-bc91-4c52-b58e-08714cb0dd48
127.0.0.1 - - [15/Feb/2025 11:57:02] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:57:02,700 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0270c5fa-34ca-4b65-bb56-62fe35d44de1
127.0.0.1 - - [15/Feb/2025 11:57:02] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:57:04,852 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.677423
2025-02-15 11:57:09,320 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-15 11:57:10,591 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b7dfc993-a66b-4157-91b8-5b01b8e18433
127.0.0.1 - - [15/Feb/2025 11:57:10] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:57:15,553 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.677423
2025-02-15 11:57:17,562 - LoudVA - INFO - [LoudServer] - Completed. Request ID: da965e83-6141-484b-8fd8-1fba574bfe2a
127.0.0.1 - - [15/Feb/2025 11:57:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:57:20,322 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.677423
2025-02-15 11:57:24,145 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 23.853023
2025-02-15 11:57:26,282 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 11a0ed5e-269b-46b7-8074-c8eb99a06937
127.0.0.1 - - [15/Feb/2025 11:57:26] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:57:29,001 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1eabd073-4fad-4e11-a297-a4bd4f8f2163
127.0.0.1 - - [15/Feb/2025 11:57:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:57:29,492 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.741029
2025-02-15 11:57:31,762 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a9bde318-b54f-4b7e-8099-9258c10cdd3b
127.0.0.1 - - [15/Feb/2025 11:57:31] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:57:34,256 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.583352999999999
2025-02-15 11:57:37,534 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 63395882-5f86-43d5-a502-5f969827ec79
127.0.0.1 - - [15/Feb/2025 11:57:37] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:57:39,196 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 346a8daa-b735-44c6-a29a-6feec3566e51
127.0.0.1 - - [15/Feb/2025 11:57:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:57:39,655 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.29484
2025-02-15 11:57:56,473 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 02223c81-318f-49c1-94d9-659536acf611
127.0.0.1 - - [15/Feb/2025 11:57:56] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:50,999 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f74e022f-e622-40bd-8717-68307d61b005
2025-02-15 11:58:51,061 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f74e022f-e622-40bd-8717-68307d61b005
127.0.0.1 - - [15/Feb/2025 11:58:51] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:51,266 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 675af99d-0b63-4337-9b09-51b8aa424909
2025-02-15 11:58:51,288 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 675af99d-0b63-4337-9b09-51b8aa424909
127.0.0.1 - - [15/Feb/2025 11:58:51] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:51,488 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a80e8d19-0b0b-46bb-8bd1-1c26ce73b466
2025-02-15 11:58:51,511 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a80e8d19-0b0b-46bb-8bd1-1c26ce73b466
127.0.0.1 - - [15/Feb/2025 11:58:51] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:51,779 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a200eacc-2fbd-4d66-9018-84c72e1c6a30
2025-02-15 11:58:51,833 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a200eacc-2fbd-4d66-9018-84c72e1c6a30
127.0.0.1 - - [15/Feb/2025 11:58:51] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:52,653 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8647a1df-8648-49fd-9f77-28df7c19ed45
2025-02-15 11:58:53,383 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8647a1df-8648-49fd-9f77-28df7c19ed45
127.0.0.1 - - [15/Feb/2025 11:58:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:55,552 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 66c099ce-04e4-4855-8bfa-c9f443ac9883
2025-02-15 11:58:55,709 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 66c099ce-04e4-4855-8bfa-c9f443ac9883
127.0.0.1 - - [15/Feb/2025 11:58:55] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:55,771 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1f4effea-3519-43b7-855d-3706498521a8
2025-02-15 11:58:55,793 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1f4effea-3519-43b7-855d-3706498521a8
127.0.0.1 - - [15/Feb/2025 11:58:55] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:56,062 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 86ff82e3-59d1-4407-b55a-b8e47a19fddb
2025-02-15 11:58:56,163 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 86ff82e3-59d1-4407-b55a-b8e47a19fddb
127.0.0.1 - - [15/Feb/2025 11:58:56] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:56,778 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5d858013-1675-4ed2-8af8-6b0408476e9c
2025-02-15 11:58:56,822 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5d858013-1675-4ed2-8af8-6b0408476e9c
127.0.0.1 - - [15/Feb/2025 11:58:56] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:57,042 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ab898c02-d5b7-4958-8bbf-01810e53ff0c
2025-02-15 11:58:57,080 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ab898c02-d5b7-4958-8bbf-01810e53ff0c
127.0.0.1 - - [15/Feb/2025 11:58:57] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:57,359 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5f148cf6-db03-4fef-b797-892faeb4db26
2025-02-15 11:58:57,468 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5f148cf6-db03-4fef-b797-892faeb4db26
127.0.0.1 - - [15/Feb/2025 11:58:57] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:57,663 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5d066900-2c78-4b0d-8bf6-44fc556c70a0
2025-02-15 11:58:57,757 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5d066900-2c78-4b0d-8bf6-44fc556c70a0
127.0.0.1 - - [15/Feb/2025 11:58:57] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:57,776 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0e87d9ff-ee63-4dd6-97d3-ff3d636e6212
2025-02-15 11:58:57,841 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0e87d9ff-ee63-4dd6-97d3-ff3d636e6212
127.0.0.1 - - [15/Feb/2025 11:58:57] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:57,999 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c77e86e2-175b-4551-83f9-09effd635a34
2025-02-15 11:58:58,054 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c77e86e2-175b-4551-83f9-09effd635a34
127.0.0.1 - - [15/Feb/2025 11:58:58] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:58,114 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 99921fa4-078e-410c-940d-1f8168b2fd73
2025-02-15 11:58:58,308 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b615ec51-6d34-4233-bee1-79dd3252a372
2025-02-15 11:58:58,336 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b615ec51-6d34-4233-bee1-79dd3252a372
127.0.0.1 - - [15/Feb/2025 11:58:58] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:58,504 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ae7884c7-8e3c-4ff5-8404-61d6eb5dbc2e
2025-02-15 11:58:58,615 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ae7884c7-8e3c-4ff5-8404-61d6eb5dbc2e
127.0.0.1 - - [15/Feb/2025 11:58:58] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:58,720 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 99921fa4-078e-410c-940d-1f8168b2fd73
127.0.0.1 - - [15/Feb/2025 11:58:58] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:58:59,790 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5dfb87bb-c3a4-4a44-95d1-94eab8160a20
2025-02-15 11:58:59,918 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5dfb87bb-c3a4-4a44-95d1-94eab8160a20
127.0.0.1 - - [15/Feb/2025 11:58:59] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:00,006 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 42268e47-1544-41a3-a296-46e3f311b111
2025-02-15 11:59:00,078 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 42268e47-1544-41a3-a296-46e3f311b111
127.0.0.1 - - [15/Feb/2025 11:59:00] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:00,328 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f022f807-c59b-467a-a00c-19bfd5c2ca1d
2025-02-15 11:59:00,346 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f022f807-c59b-467a-a00c-19bfd5c2ca1d
127.0.0.1 - - [15/Feb/2025 11:59:00] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:00,500 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 854957d2-1576-4ba9-8cb0-87430c0db21c
2025-02-15 11:59:00,591 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 854957d2-1576-4ba9-8cb0-87430c0db21c
127.0.0.1 - - [15/Feb/2025 11:59:00] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:00,774 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5c4a6fcd-f45a-4bc1-9ac5-549774d88dfc
2025-02-15 11:59:00,811 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5c4a6fcd-f45a-4bc1-9ac5-549774d88dfc
127.0.0.1 - - [15/Feb/2025 11:59:00] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:01,043 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ca6c3044-5a07-471c-b1de-acd6384a8e78
2025-02-15 11:59:01,107 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ca6c3044-5a07-471c-b1de-acd6384a8e78
127.0.0.1 - - [15/Feb/2025 11:59:01] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:01,347 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 11cc7a2c-d4a3-4b1e-ae60-30ea3ea46e42
2025-02-15 11:59:01,474 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 11cc7a2c-d4a3-4b1e-ae60-30ea3ea46e42
127.0.0.1 - - [15/Feb/2025 11:59:01] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:01,585 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 17939011-e3b7-4bc8-8bd7-264de9637aae
2025-02-15 11:59:01,601 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 17939011-e3b7-4bc8-8bd7-264de9637aae
127.0.0.1 - - [15/Feb/2025 11:59:01] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:01,778 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b5783b5c-597d-4d5d-b8ce-fc7bc2be29c2
2025-02-15 11:59:01,813 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b5783b5c-597d-4d5d-b8ce-fc7bc2be29c2
127.0.0.1 - - [15/Feb/2025 11:59:01] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:02,081 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6c469ab8-4666-4f7a-b3a5-71777dc3c554
2025-02-15 11:59:02,288 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6c469ab8-4666-4f7a-b3a5-71777dc3c554
127.0.0.1 - - [15/Feb/2025 11:59:02] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:02,364 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b9627226-c18b-4461-98d9-0a305c53bb8b
2025-02-15 11:59:02,503 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b9627226-c18b-4461-98d9-0a305c53bb8b
127.0.0.1 - - [15/Feb/2025 11:59:02] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:02,635 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 63479c37-21c0-4bc9-a9c4-587fdd5dd4b3
2025-02-15 11:59:02,712 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9008f85f-a0c4-45b8-a6e7-836361dff45a
2025-02-15 11:59:02,787 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 63479c37-21c0-4bc9-a9c4-587fdd5dd4b3
127.0.0.1 - - [15/Feb/2025 11:59:02] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:02,800 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0642eb22-e9e9-4dec-afbc-bc5ac0732a7e
2025-02-15 11:59:02,966 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0642eb22-e9e9-4dec-afbc-bc5ac0732a7e
127.0.0.1 - - [15/Feb/2025 11:59:02] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:03,029 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8580cc8f-3031-4949-b5c2-17d58a6c5bd5
2025-02-15 11:59:03,058 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8580cc8f-3031-4949-b5c2-17d58a6c5bd5
127.0.0.1 - - [15/Feb/2025 11:59:03] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:03,303 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1378f6c3-2ccb-4d91-a4ea-cb8e7440bac7
2025-02-15 11:59:03,402 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9008f85f-a0c4-45b8-a6e7-836361dff45a
127.0.0.1 - - [15/Feb/2025 11:59:03] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:03,431 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1378f6c3-2ccb-4d91-a4ea-cb8e7440bac7
127.0.0.1 - - [15/Feb/2025 11:59:03] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:03,657 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 04da5322-1acc-4405-8dd6-3c3e8b3fcd78
2025-02-15 11:59:03,890 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 04da5322-1acc-4405-8dd6-3c3e8b3fcd78
127.0.0.1 - - [15/Feb/2025 11:59:03] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:03,946 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 72f72a5e-2f9e-4a70-8ea3-f2ec3d6d995c
2025-02-15 11:59:04,017 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 947d3b83-5b96-45f1-adbb-639c12b45376
2025-02-15 11:59:04,078 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 72f72a5e-2f9e-4a70-8ea3-f2ec3d6d995c
127.0.0.1 - - [15/Feb/2025 11:59:04] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:04,156 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 947d3b83-5b96-45f1-adbb-639c12b45376
127.0.0.1 - - [15/Feb/2025 11:59:04] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:04,278 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c880a1eb-46e7-480b-bde5-678bedeb9a73
2025-02-15 11:59:04,304 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c880a1eb-46e7-480b-bde5-678bedeb9a73
127.0.0.1 - - [15/Feb/2025 11:59:04] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:04,636 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 704950d1-0073-49a0-8bfc-96e0f9896967
2025-02-15 11:59:04,775 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7c36002c-ff2f-4d15-a386-aa0abe600498
2025-02-15 11:59:04,833 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7c36002c-ff2f-4d15-a386-aa0abe600498
127.0.0.1 - - [15/Feb/2025 11:59:04] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:04,873 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 704950d1-0073-49a0-8bfc-96e0f9896967
127.0.0.1 - - [15/Feb/2025 11:59:04] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:05,174 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0398dedc-fe1d-4ffd-be8a-70dd9d4991c1
2025-02-15 11:59:05,276 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bfce0dd7-39c4-4e3a-935c-328dec9181bc
2025-02-15 11:59:05,356 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bfce0dd7-39c4-4e3a-935c-328dec9181bc
127.0.0.1 - - [15/Feb/2025 11:59:05] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:05,438 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0398dedc-fe1d-4ffd-be8a-70dd9d4991c1
127.0.0.1 - - [15/Feb/2025 11:59:05] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:05,530 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3f14b9f3-a4af-4b20-b71c-d3da29c69c54
2025-02-15 11:59:05,627 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3f14b9f3-a4af-4b20-b71c-d3da29c69c54
127.0.0.1 - - [15/Feb/2025 11:59:05] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:05,808 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 07f90143-4ab4-4c32-8064-87fcdf932469
2025-02-15 11:59:05,888 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 07f90143-4ab4-4c32-8064-87fcdf932469
127.0.0.1 - - [15/Feb/2025 11:59:05] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:06,092 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1bebcbad-4a82-49bc-8db4-2585fadf9334
2025-02-15 11:59:06,112 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1bebcbad-4a82-49bc-8db4-2585fadf9334
127.0.0.1 - - [15/Feb/2025 11:59:06] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:06,328 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8509fab7-8d3c-4a74-8103-71d8150b1d32
2025-02-15 11:59:06,485 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8509fab7-8d3c-4a74-8103-71d8150b1d32
127.0.0.1 - - [15/Feb/2025 11:59:06] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:06,512 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 580b564e-2363-4fa8-a908-a434edcf5ba5
2025-02-15 11:59:06,583 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 580b564e-2363-4fa8-a908-a434edcf5ba5
127.0.0.1 - - [15/Feb/2025 11:59:06] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:06,852 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 85292cc8-dc0d-488c-a53b-901646c63094
2025-02-15 11:59:07,004 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 49cd48ac-82f4-46d4-a814-61ba0ef72e25
2025-02-15 11:59:07,074 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 49cd48ac-82f4-46d4-a814-61ba0ef72e25
127.0.0.1 - - [15/Feb/2025 11:59:07] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:07,220 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 85292cc8-dc0d-488c-a53b-901646c63094
127.0.0.1 - - [15/Feb/2025 11:59:07] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:07,304 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ae41783d-c22f-428d-b6f9-8625d3576e93
2025-02-15 11:59:07,374 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ae41783d-c22f-428d-b6f9-8625d3576e93
127.0.0.1 - - [15/Feb/2025 11:59:07] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:07,482 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e45dcac4-3113-42dd-9e50-4d4bfd7d5a03
2025-02-15 11:59:07,532 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e45dcac4-3113-42dd-9e50-4d4bfd7d5a03
127.0.0.1 - - [15/Feb/2025 11:59:07] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:07,842 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8bfbe17e-a859-45c6-9e9c-533823ee36b8
2025-02-15 11:59:07,950 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8bfbe17e-a859-45c6-9e9c-533823ee36b8
127.0.0.1 - - [15/Feb/2025 11:59:07] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:07,994 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 66057dc0-2a45-4d94-8761-9d4a9ad4562e
2025-02-15 11:59:08,029 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 66057dc0-2a45-4d94-8761-9d4a9ad4562e
127.0.0.1 - - [15/Feb/2025 11:59:08] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:08,115 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e73497ef-5a9e-4b25-b4bd-7079f0c7a08a
2025-02-15 11:59:08,264 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2239ec7f-d19f-438b-ade8-6d40ab6ddf7a
2025-02-15 11:59:08,327 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2239ec7f-d19f-438b-ade8-6d40ab6ddf7a
127.0.0.1 - - [15/Feb/2025 11:59:08] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:08,503 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e73497ef-5a9e-4b25-b4bd-7079f0c7a08a
2025-02-15 11:59:08,512 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b5d45cb4-11d8-405c-988b-d11dd6fd9ae1
2025-02-15 11:59:08,519 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b5d45cb4-11d8-405c-988b-d11dd6fd9ae1
127.0.0.1 - - [15/Feb/2025 11:59:08] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [15/Feb/2025 11:59:08] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:08,770 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 931901a4-046f-48b1-be08-adcb370c874e
2025-02-15 11:59:08,770 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 931901a4-046f-48b1-be08-adcb370c874e
127.0.0.1 - - [15/Feb/2025 11:59:08] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:09,039 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e563ccd0-429c-4acd-b908-e5cab20245ae
2025-02-15 11:59:09,106 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e563ccd0-429c-4acd-b908-e5cab20245ae
127.0.0.1 - - [15/Feb/2025 11:59:09] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:09,403 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1dd2ee44-8d7d-4480-95b0-712431cffd36
2025-02-15 11:59:09,422 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1dd2ee44-8d7d-4480-95b0-712431cffd36
127.0.0.1 - - [15/Feb/2025 11:59:09] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:09,525 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6c451b9f-910b-4ad0-81bc-472694f8cf07
2025-02-15 11:59:09,567 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6c451b9f-910b-4ad0-81bc-472694f8cf07
127.0.0.1 - - [15/Feb/2025 11:59:09] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:09,993 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0524311a-d492-4459-be5e-faf971640bf4
2025-02-15 11:59:10,048 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f3d1a797-656f-4331-b52a-0419b055c23c
2025-02-15 11:59:10,059 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0524311a-d492-4459-be5e-faf971640bf4
127.0.0.1 - - [15/Feb/2025 11:59:10] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:10,127 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f3d1a797-656f-4331-b52a-0419b055c23c
127.0.0.1 - - [15/Feb/2025 11:59:10] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:10,378 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6f755915-f236-418f-a23c-42ecf43849c2
2025-02-15 11:59:10,433 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6f755915-f236-418f-a23c-42ecf43849c2
127.0.0.1 - - [15/Feb/2025 11:59:10] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:10,497 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eeb95f92-db3f-40eb-b721-3565932719e2
2025-02-15 11:59:10,502 - LoudVA - INFO - [LoudServer] - Completed. Request ID: eeb95f92-db3f-40eb-b721-3565932719e2
127.0.0.1 - - [15/Feb/2025 11:59:10] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:10,757 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a830dee8-02c3-4b91-a14c-7864c0ed45f0
2025-02-15 11:59:10,770 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a830dee8-02c3-4b91-a14c-7864c0ed45f0
127.0.0.1 - - [15/Feb/2025 11:59:10] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:11,103 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 05b3ffb1-3263-4df5-9181-eed1859e8f9c
2025-02-15 11:59:11,130 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 05b3ffb1-3263-4df5-9181-eed1859e8f9c
127.0.0.1 - - [15/Feb/2025 11:59:11] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:11,357 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a0a281be-07a7-48d5-9560-5fa52a65f640
2025-02-15 11:59:11,473 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a0a281be-07a7-48d5-9560-5fa52a65f640
127.0.0.1 - - [15/Feb/2025 11:59:11] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:11,518 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 23d4dc63-0774-4351-a7eb-db37d9223b30
2025-02-15 11:59:11,542 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 23d4dc63-0774-4351-a7eb-db37d9223b30
127.0.0.1 - - [15/Feb/2025 11:59:11] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:11,848 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 370d783b-e0c4-4f19-98cf-93452ab90665
2025-02-15 11:59:11,909 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 370d783b-e0c4-4f19-98cf-93452ab90665
127.0.0.1 - - [15/Feb/2025 11:59:11] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:12,028 - LoudVA - WARNING - [LoudServer] - Timeout reached for request afe495ff-755a-4d96-bc85-f5002a3d2bc6
2025-02-15 11:59:12,035 - LoudVA - INFO - [LoudServer] - Completed. Request ID: afe495ff-755a-4d96-bc85-f5002a3d2bc6
127.0.0.1 - - [15/Feb/2025 11:59:12] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:12,271 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7a31d1be-90c7-4c3f-b909-c60b83b223f2
2025-02-15 11:59:12,284 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7a31d1be-90c7-4c3f-b909-c60b83b223f2
127.0.0.1 - - [15/Feb/2025 11:59:12] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:12,505 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8d142761-ed92-4f6d-ae15-c0699746c1a7
2025-02-15 11:59:12,506 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3de785c9-e208-4b16-8593-30cd9105026d
2025-02-15 11:59:12,540 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3de785c9-e208-4b16-8593-30cd9105026d
127.0.0.1 - - [15/Feb/2025 11:59:12] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:12,649 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8d142761-ed92-4f6d-ae15-c0699746c1a7
127.0.0.1 - - [15/Feb/2025 11:59:12] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:12,804 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ebeaf96f-015c-48e7-a585-d4ffbf110fe2
2025-02-15 11:59:12,819 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ebeaf96f-015c-48e7-a585-d4ffbf110fe2
127.0.0.1 - - [15/Feb/2025 11:59:12] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:13,015 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d9434904-a13d-488f-a6f3-ce60e3a37cb4
2025-02-15 11:59:13,039 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d9434904-a13d-488f-a6f3-ce60e3a37cb4
127.0.0.1 - - [15/Feb/2025 11:59:13] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:13,348 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6d295da2-6492-4683-aba1-c9f262fe86f6
2025-02-15 11:59:13,418 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6d295da2-6492-4683-aba1-c9f262fe86f6
127.0.0.1 - - [15/Feb/2025 11:59:13] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:13,532 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f589595c-0f4e-4ea3-978b-0cd813e5f791
2025-02-15 11:59:13,564 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f589595c-0f4e-4ea3-978b-0cd813e5f791
127.0.0.1 - - [15/Feb/2025 11:59:13] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:13,754 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3108c81b-996b-4900-b206-63df219d8044
2025-02-15 11:59:13,762 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3108c81b-996b-4900-b206-63df219d8044
127.0.0.1 - - [15/Feb/2025 11:59:13] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:13,984 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3b55d504-7067-43ac-abe4-8ea50e1eb598
2025-02-15 11:59:14,003 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3b55d504-7067-43ac-abe4-8ea50e1eb598
127.0.0.1 - - [15/Feb/2025 11:59:14] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:14,296 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 84b0ba4f-bb99-4fb3-99b4-db346dfd4c29
2025-02-15 11:59:14,331 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 84b0ba4f-bb99-4fb3-99b4-db346dfd4c29
127.0.0.1 - - [15/Feb/2025 11:59:14] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:14,541 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0a4c1f2a-1cbd-4210-9b52-f10ba031f5db
2025-02-15 11:59:14,601 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0a4c1f2a-1cbd-4210-9b52-f10ba031f5db
127.0.0.1 - - [15/Feb/2025 11:59:14] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:14,838 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5aa0bd8f-c360-4f1a-a90e-582e90504c22
2025-02-15 11:59:14,852 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5aa0bd8f-c360-4f1a-a90e-582e90504c22
127.0.0.1 - - [15/Feb/2025 11:59:14] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:15,029 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b55626cd-26f4-47a5-af98-4eec0c28d520
2025-02-15 11:59:15,062 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b55626cd-26f4-47a5-af98-4eec0c28d520
127.0.0.1 - - [15/Feb/2025 11:59:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:15,274 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9d26d751-4c82-4eb8-9e4b-d1c7ea702f5b
2025-02-15 11:59:15,336 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9d26d751-4c82-4eb8-9e4b-d1c7ea702f5b
127.0.0.1 - - [15/Feb/2025 11:59:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:15,489 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ffe9f461-ba37-4956-8ea1-3043cd6da3f9
2025-02-15 11:59:15,496 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ffe9f461-ba37-4956-8ea1-3043cd6da3f9
127.0.0.1 - - [15/Feb/2025 11:59:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:15,863 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 22a6ffcc-21a4-4353-93f5-38e790911617
2025-02-15 11:59:15,922 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 22a6ffcc-21a4-4353-93f5-38e790911617
127.0.0.1 - - [15/Feb/2025 11:59:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:15,985 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a49cad1b-1bfd-4f87-baa0-425b332d2741
2025-02-15 11:59:15,996 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a49cad1b-1bfd-4f87-baa0-425b332d2741
127.0.0.1 - - [15/Feb/2025 11:59:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:16,288 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bf047e92-9e48-447f-95d3-aeecec7958bf
2025-02-15 11:59:16,357 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bf047e92-9e48-447f-95d3-aeecec7958bf
127.0.0.1 - - [15/Feb/2025 11:59:16] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:16,536 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b927dcde-29ff-4a45-a567-c88c35e34ef1
2025-02-15 11:59:16,579 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b927dcde-29ff-4a45-a567-c88c35e34ef1
127.0.0.1 - - [15/Feb/2025 11:59:16] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:16,765 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 502b6076-9485-4635-b498-8e4229d7b1ec
2025-02-15 11:59:16,810 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 502b6076-9485-4635-b498-8e4229d7b1ec
127.0.0.1 - - [15/Feb/2025 11:59:16] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:17,011 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bf8f3888-4f90-412b-8609-e9b47b2157da
2025-02-15 11:59:17,099 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bf8f3888-4f90-412b-8609-e9b47b2157da
127.0.0.1 - - [15/Feb/2025 11:59:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:17,260 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 004ab52c-b062-4000-9509-cdf80f0d4d64
2025-02-15 11:59:17,272 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 004ab52c-b062-4000-9509-cdf80f0d4d64
127.0.0.1 - - [15/Feb/2025 11:59:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:17,542 - LoudVA - WARNING - [LoudServer] - Timeout reached for request da09f2cd-8307-4aed-bfe9-90c5bcd9bbcf
2025-02-15 11:59:17,583 - LoudVA - INFO - [LoudServer] - Completed. Request ID: da09f2cd-8307-4aed-bfe9-90c5bcd9bbcf
127.0.0.1 - - [15/Feb/2025 11:59:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:17,921 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fca1ae49-ad6e-4efc-aab2-0096fca4b436
2025-02-15 11:59:17,925 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d84ef741-7a42-494f-bccb-fb6c917eab99
2025-02-15 11:59:17,976 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fca1ae49-ad6e-4efc-aab2-0096fca4b436
127.0.0.1 - - [15/Feb/2025 11:59:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:18,102 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d84ef741-7a42-494f-bccb-fb6c917eab99
127.0.0.1 - - [15/Feb/2025 11:59:18] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:18,111 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 12f7c540-bea3-4ddf-944e-07491aeb1ecc
2025-02-15 11:59:18,182 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 12f7c540-bea3-4ddf-944e-07491aeb1ecc
127.0.0.1 - - [15/Feb/2025 11:59:18] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:18,266 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d43f598f-27a6-4747-96be-be28e225515c
2025-02-15 11:59:18,302 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d43f598f-27a6-4747-96be-be28e225515c
127.0.0.1 - - [15/Feb/2025 11:59:18] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:18,516 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 187aaf04-728e-4614-b5ee-f2fa6918908e
2025-02-15 11:59:18,557 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 187aaf04-728e-4614-b5ee-f2fa6918908e
127.0.0.1 - - [15/Feb/2025 11:59:18] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:19,052 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8ee24cef-3171-4227-b375-f903e8d9b10b
2025-02-15 11:59:19,137 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8ee24cef-3171-4227-b375-f903e8d9b10b
127.0.0.1 - - [15/Feb/2025 11:59:19] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:19,174 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7eeaf258-1e74-4d2e-8be2-d65da82d57a3
2025-02-15 11:59:19,253 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7eeaf258-1e74-4d2e-8be2-d65da82d57a3
2025-02-15 11:59:19,267 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 288d299b-5d28-466f-b682-4aefc5158ccd
127.0.0.1 - - [15/Feb/2025 11:59:19] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:19,277 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 288d299b-5d28-466f-b682-4aefc5158ccd
127.0.0.1 - - [15/Feb/2025 11:59:19] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:19,498 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 836b09e9-423a-4172-9215-e90998f6774e
2025-02-15 11:59:19,501 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 836b09e9-423a-4172-9215-e90998f6774e
127.0.0.1 - - [15/Feb/2025 11:59:19] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:19,514 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3e6c7a1d-e423-4a2d-9f27-ead414a6f166
2025-02-15 11:59:19,771 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 46196615-d28e-4595-9649-95fe7d4c6a89
2025-02-15 11:59:19,799 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 46196615-d28e-4595-9649-95fe7d4c6a89
127.0.0.1 - - [15/Feb/2025 11:59:19] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:19,799 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3e6c7a1d-e423-4a2d-9f27-ead414a6f166
127.0.0.1 - - [15/Feb/2025 11:59:19] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:20,080 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d62e8a87-20ba-4e19-b031-42712c9f19bc
2025-02-15 11:59:20,093 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d62e8a87-20ba-4e19-b031-42712c9f19bc
127.0.0.1 - - [15/Feb/2025 11:59:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:20,262 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cca3c2ec-a862-4a9d-b447-c43711ca8117
2025-02-15 11:59:20,267 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cca3c2ec-a862-4a9d-b447-c43711ca8117
127.0.0.1 - - [15/Feb/2025 11:59:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:20,528 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 07afe1b0-d9df-42dc-ab70-6e5b139c3e95
2025-02-15 11:59:20,597 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 07afe1b0-d9df-42dc-ab70-6e5b139c3e95
127.0.0.1 - - [15/Feb/2025 11:59:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:20,962 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5a68a2b4-706d-4229-ac8d-6aadd249efcb
2025-02-15 11:59:21,013 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5a68a2b4-706d-4229-ac8d-6aadd249efcb
127.0.0.1 - - [15/Feb/2025 11:59:21] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:21,085 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f8c9b91b-96fd-4602-ae68-1241c97950d9
2025-02-15 11:59:21,107 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f8c9b91b-96fd-4602-ae68-1241c97950d9
127.0.0.1 - - [15/Feb/2025 11:59:21] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:21,292 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7b4e43c6-9f95-40d9-860e-c572204f8771
2025-02-15 11:59:21,324 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7b4e43c6-9f95-40d9-860e-c572204f8771
127.0.0.1 - - [15/Feb/2025 11:59:21] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:21,527 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 74a5ca90-065d-4e40-bcb4-a46fff80841e
2025-02-15 11:59:21,543 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 74a5ca90-065d-4e40-bcb4-a46fff80841e
127.0.0.1 - - [15/Feb/2025 11:59:21] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:21,800 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d3721f84-c34e-4b17-b3f4-2be3e8d74189
2025-02-15 11:59:21,834 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d3721f84-c34e-4b17-b3f4-2be3e8d74189
127.0.0.1 - - [15/Feb/2025 11:59:21] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:22,040 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a6600bec-1e3d-46e7-a621-bb0611ae9730
2025-02-15 11:59:22,102 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a6600bec-1e3d-46e7-a621-bb0611ae9730
127.0.0.1 - - [15/Feb/2025 11:59:22] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:22,275 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b2378c9d-e309-42ae-b123-496fd09ec8a4
2025-02-15 11:59:22,292 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b2378c9d-e309-42ae-b123-496fd09ec8a4
127.0.0.1 - - [15/Feb/2025 11:59:22] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:22,588 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a688b0cc-ed12-494e-91a8-04689793e30c
2025-02-15 11:59:22,632 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a688b0cc-ed12-494e-91a8-04689793e30c
127.0.0.1 - - [15/Feb/2025 11:59:22] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:22,711 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 384e39f0-945f-4907-8504-b3c389eca8aa
2025-02-15 11:59:22,763 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 15f2f4b9-d174-4222-a567-9663b9032094
2025-02-15 11:59:22,777 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 15f2f4b9-d174-4222-a567-9663b9032094
127.0.0.1 - - [15/Feb/2025 11:59:22] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:23,012 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0348253b-a034-463a-9837-e4750ca5f5a9
2025-02-15 11:59:23,028 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0348253b-a034-463a-9837-e4750ca5f5a9
127.0.0.1 - - [15/Feb/2025 11:59:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:23,069 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 384e39f0-945f-4907-8504-b3c389eca8aa
127.0.0.1 - - [15/Feb/2025 11:59:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:23,305 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aed27a62-ceda-47bb-8884-a36acb1037f3
2025-02-15 11:59:23,360 - LoudVA - INFO - [LoudServer] - Completed. Request ID: aed27a62-ceda-47bb-8884-a36acb1037f3
127.0.0.1 - - [15/Feb/2025 11:59:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:23,594 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 302c9cac-4618-4614-9dc2-dfae9a71bad2
2025-02-15 11:59:23,675 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 302c9cac-4618-4614-9dc2-dfae9a71bad2
127.0.0.1 - - [15/Feb/2025 11:59:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:23,815 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d52d940e-51cc-42c9-8fc4-241ffe742164
2025-02-15 11:59:23,821 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d52d940e-51cc-42c9-8fc4-241ffe742164
127.0.0.1 - - [15/Feb/2025 11:59:23] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:24,001 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 96b34972-b5a7-4338-8fa7-6f1d1b8797a8
2025-02-15 11:59:24,022 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 96b34972-b5a7-4338-8fa7-6f1d1b8797a8
127.0.0.1 - - [15/Feb/2025 11:59:24] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:24,280 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 47bdc909-0b27-43a1-855e-a924f865c58f
2025-02-15 11:59:24,325 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 47bdc909-0b27-43a1-855e-a924f865c58f
127.0.0.1 - - [15/Feb/2025 11:59:24] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:24,562 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1be8d02b-81e5-4426-b17d-489eced9f24c
2025-02-15 11:59:24,573 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1be8d02b-81e5-4426-b17d-489eced9f24c
127.0.0.1 - - [15/Feb/2025 11:59:24] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:24,813 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d00f60be-fd96-4fec-8f4b-db33c7612568
2025-02-15 11:59:24,879 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d00f60be-fd96-4fec-8f4b-db33c7612568
127.0.0.1 - - [15/Feb/2025 11:59:24] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:24,994 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 236e6fad-161c-4aa8-9129-f52b368f4ff0
2025-02-15 11:59:25,003 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 236e6fad-161c-4aa8-9129-f52b368f4ff0
127.0.0.1 - - [15/Feb/2025 11:59:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:25,338 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ed45660b-eef8-4c3e-9a4f-dbfc8604f24a
2025-02-15 11:59:25,397 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ed45660b-eef8-4c3e-9a4f-dbfc8604f24a
127.0.0.1 - - [15/Feb/2025 11:59:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:25,542 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aafd667f-035d-43f4-b3b5-cf59cb9e9192
2025-02-15 11:59:25,601 - LoudVA - INFO - [LoudServer] - Completed. Request ID: aafd667f-035d-43f4-b3b5-cf59cb9e9192
127.0.0.1 - - [15/Feb/2025 11:59:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:25,771 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e65c58ed-98e9-49bc-af23-416c151ffadc
2025-02-15 11:59:25,793 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e65c58ed-98e9-49bc-af23-416c151ffadc
127.0.0.1 - - [15/Feb/2025 11:59:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:26,045 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 783445c9-0b8f-42d1-b57a-5629c59f2d83
2025-02-15 11:59:26,087 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 783445c9-0b8f-42d1-b57a-5629c59f2d83
127.0.0.1 - - [15/Feb/2025 11:59:26] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:26,312 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e6a690c3-3bf9-425c-a93b-b57439041cd2
2025-02-15 11:59:26,335 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e6a690c3-3bf9-425c-a93b-b57439041cd2
127.0.0.1 - - [15/Feb/2025 11:59:26] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:26,504 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 541dfb79-fffb-4f9b-ac1d-e0be058652a3
2025-02-15 11:59:26,524 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 541dfb79-fffb-4f9b-ac1d-e0be058652a3
127.0.0.1 - - [15/Feb/2025 11:59:26] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:27,028 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 121141bd-b57f-4be7-ac78-c7fce19d7d56
2025-02-15 11:59:27,050 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 121141bd-b57f-4be7-ac78-c7fce19d7d56
127.0.0.1 - - [15/Feb/2025 11:59:27] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:27,804 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ee702750-02d5-4dff-8b8a-129737c59353
2025-02-15 11:59:27,862 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ee702750-02d5-4dff-8b8a-129737c59353
127.0.0.1 - - [15/Feb/2025 11:59:27] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:28,187 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8aaf9c0d-8ec7-4fd2-820c-721c7ac9c234
2025-02-15 11:59:28,210 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8aaf9c0d-8ec7-4fd2-820c-721c7ac9c234
127.0.0.1 - - [15/Feb/2025 11:59:28] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:28,321 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8410c6a6-c21e-4df4-92f2-17b23d20ce3e
2025-02-15 11:59:28,557 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 17d33166-e12f-4c33-b9ab-636cf5a2a267
2025-02-15 11:59:28,586 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 17d33166-e12f-4c33-b9ab-636cf5a2a267
127.0.0.1 - - [15/Feb/2025 11:59:28] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:28,626 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8410c6a6-c21e-4df4-92f2-17b23d20ce3e
127.0.0.1 - - [15/Feb/2025 11:59:28] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:29,085 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ef89e65b-5b19-4d77-97f4-f1dc83d7edf2
2025-02-15 11:59:29,123 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cf19be7a-45fa-4d7a-9dca-b24fb55d6653
2025-02-15 11:59:29,162 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cf19be7a-45fa-4d7a-9dca-b24fb55d6653
127.0.0.1 - - [15/Feb/2025 11:59:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:29,180 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ef89e65b-5b19-4d77-97f4-f1dc83d7edf2
127.0.0.1 - - [15/Feb/2025 11:59:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:29,684 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a709fbaf-653b-4d61-90b8-8d2fdf74ba28
2025-02-15 11:59:29,755 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a709fbaf-653b-4d61-90b8-8d2fdf74ba28
127.0.0.1 - - [15/Feb/2025 11:59:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:30,044 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7874d3b3-a588-43e4-94c3-f36c82cd574e
2025-02-15 11:59:30,074 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7874d3b3-a588-43e4-94c3-f36c82cd574e
127.0.0.1 - - [15/Feb/2025 11:59:30] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:30,577 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 63f4e548-4d66-40bc-bd5d-fdd1e856418d
2025-02-15 11:59:30,628 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 63f4e548-4d66-40bc-bd5d-fdd1e856418d
127.0.0.1 - - [15/Feb/2025 11:59:30] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:31,035 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fd16866f-c980-4e41-a6a0-38b6d9aca9e7
2025-02-15 11:59:31,054 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fd16866f-c980-4e41-a6a0-38b6d9aca9e7
127.0.0.1 - - [15/Feb/2025 11:59:31] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:31,587 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 65dd7657-5cbe-4e7e-b116-918ee75b38ff
2025-02-15 11:59:31,603 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 65dd7657-5cbe-4e7e-b116-918ee75b38ff
127.0.0.1 - - [15/Feb/2025 11:59:31] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:32,226 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6e9ae5d0-b05e-435b-8469-215e8ca22d5a
2025-02-15 11:59:32,287 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6e9ae5d0-b05e-435b-8469-215e8ca22d5a
127.0.0.1 - - [15/Feb/2025 11:59:32] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:32,526 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 84368e82-795a-4739-b982-59d4423ed202
2025-02-15 11:59:32,561 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 84368e82-795a-4739-b982-59d4423ed202
127.0.0.1 - - [15/Feb/2025 11:59:32] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:32,979 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5fc6bef2-24d7-4e34-b513-d6d4f2944956
2025-02-15 11:59:33,005 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 62eb00d6-7572-44b1-9bca-739ff31c4114
2025-02-15 11:59:33,027 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 62eb00d6-7572-44b1-9bca-739ff31c4114
127.0.0.1 - - [15/Feb/2025 11:59:33] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:33,221 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5fc6bef2-24d7-4e34-b513-d6d4f2944956
127.0.0.1 - - [15/Feb/2025 11:59:33] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:33,506 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c4c1d4c3-8abc-4e4a-a3b8-e452fa2bc399
2025-02-15 11:59:33,520 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c4c1d4c3-8abc-4e4a-a3b8-e452fa2bc399
127.0.0.1 - - [15/Feb/2025 11:59:33] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:34,036 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 42533e8d-e70e-446b-9e79-161f73988e11
2025-02-15 11:59:34,063 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 42533e8d-e70e-446b-9e79-161f73988e11
127.0.0.1 - - [15/Feb/2025 11:59:34] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:34,637 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cfc12470-56d7-48d6-8fa7-31a27f1d1aa8
2025-02-15 11:59:34,679 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cfc12470-56d7-48d6-8fa7-31a27f1d1aa8
127.0.0.1 - - [15/Feb/2025 11:59:34] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:35,009 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 85b61315-f40b-4d9e-9000-92eb0e83c8ed
2025-02-15 11:59:35,027 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 85b61315-f40b-4d9e-9000-92eb0e83c8ed
127.0.0.1 - - [15/Feb/2025 11:59:35] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:35,502 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e8578eaa-e8f7-4594-950e-7c8d519dc3e5
2025-02-15 11:59:35,529 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e8578eaa-e8f7-4594-950e-7c8d519dc3e5
127.0.0.1 - - [15/Feb/2025 11:59:35] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:36,079 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 76bcda58-0be4-409c-9fb3-114f3ec5a7a7
2025-02-15 11:59:36,190 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 76bcda58-0be4-409c-9fb3-114f3ec5a7a7
127.0.0.1 - - [15/Feb/2025 11:59:36] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:36,540 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2cbfc145-5300-4033-b8ee-d3f39e2e2eee
2025-02-15 11:59:36,576 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2cbfc145-5300-4033-b8ee-d3f39e2e2eee
127.0.0.1 - - [15/Feb/2025 11:59:36] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:37,072 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d9e5aa43-d8a0-47b6-b7cb-4d04ecc3b942
2025-02-15 11:59:37,095 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d9e5aa43-d8a0-47b6-b7cb-4d04ecc3b942
127.0.0.1 - - [15/Feb/2025 11:59:37] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:37,585 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9b15df6e-9409-4335-8e54-c77a80c4e59c
2025-02-15 11:59:37,599 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9b15df6e-9409-4335-8e54-c77a80c4e59c
127.0.0.1 - - [15/Feb/2025 11:59:37] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:38,051 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cee5f9b1-3e40-4262-ab51-b270793b97f8
2025-02-15 11:59:38,134 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 70b3a920-91bb-4f94-a853-5abde7f3d1a7
2025-02-15 11:59:38,181 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cee5f9b1-3e40-4262-ab51-b270793b97f8
2025-02-15 11:59:38,185 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 70b3a920-91bb-4f94-a853-5abde7f3d1a7
127.0.0.1 - - [15/Feb/2025 11:59:38] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [15/Feb/2025 11:59:38] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:38,579 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bae6071f-6fb8-4eb2-827f-b40f0b6b02de
2025-02-15 11:59:38,622 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bae6071f-6fb8-4eb2-827f-b40f0b6b02de
127.0.0.1 - - [15/Feb/2025 11:59:38] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:39,026 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e5515dba-b38f-48ca-a678-802122257360
2025-02-15 11:59:39,053 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e5515dba-b38f-48ca-a678-802122257360
127.0.0.1 - - [15/Feb/2025 11:59:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:39,680 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3c96773d-957d-4686-9ae8-074f1bb607d0
2025-02-15 11:59:39,712 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3c96773d-957d-4686-9ae8-074f1bb607d0
127.0.0.1 - - [15/Feb/2025 11:59:39] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:40,226 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ff68344e-501a-42f7-989b-57a0393ccda8
2025-02-15 11:59:40,273 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ff68344e-501a-42f7-989b-57a0393ccda8
127.0.0.1 - - [15/Feb/2025 11:59:40] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:40,567 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 640a27be-e42b-44c2-8bd2-966a93c22769
2025-02-15 11:59:40,582 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 640a27be-e42b-44c2-8bd2-966a93c22769
127.0.0.1 - - [15/Feb/2025 11:59:40] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:41,026 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 38633deb-216a-42fa-9f3a-c074060c1bda
2025-02-15 11:59:41,073 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 38633deb-216a-42fa-9f3a-c074060c1bda
127.0.0.1 - - [15/Feb/2025 11:59:41] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:41,073 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ea7a3364-5eed-4446-b552-f969badffe01
2025-02-15 11:59:41,101 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ea7a3364-5eed-4446-b552-f969badffe01
127.0.0.1 - - [15/Feb/2025 11:59:41] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:41,520 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6ed8b2ea-19a3-4d81-8a98-f35ed5effb71
2025-02-15 11:59:41,522 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6ed8b2ea-19a3-4d81-8a98-f35ed5effb71
127.0.0.1 - - [15/Feb/2025 11:59:41] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:41,574 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7cd90942-0f97-480f-85dc-82085dd9184f
2025-02-15 11:59:41,595 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7cd90942-0f97-480f-85dc-82085dd9184f
127.0.0.1 - - [15/Feb/2025 11:59:41] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:42,018 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0e650f05-52c6-49da-aecc-b2bafb81d6d9
2025-02-15 11:59:42,024 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0e650f05-52c6-49da-aecc-b2bafb81d6d9
127.0.0.1 - - [15/Feb/2025 11:59:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:42,122 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 50dbe60f-bd4a-48dc-9318-b75a0f39eb94
2025-02-15 11:59:42,147 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 50dbe60f-bd4a-48dc-9318-b75a0f39eb94
127.0.0.1 - - [15/Feb/2025 11:59:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:42,523 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fc7a2bc0-2b24-4fb6-8399-827fc5e9f2fb
2025-02-15 11:59:42,526 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fc7a2bc0-2b24-4fb6-8399-827fc5e9f2fb
127.0.0.1 - - [15/Feb/2025 11:59:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:42,584 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3d191aad-027b-467a-ad10-a8a297030d35
2025-02-15 11:59:42,606 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 296750cc-a6f6-47da-a14d-e60030e4463c
2025-02-15 11:59:42,619 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 296750cc-a6f6-47da-a14d-e60030e4463c
127.0.0.1 - - [15/Feb/2025 11:59:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:42,731 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3d191aad-027b-467a-ad10-a8a297030d35
127.0.0.1 - - [15/Feb/2025 11:59:42] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:43,120 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 61801abd-2253-4bcd-85c0-e4c1bd8a8ec6
2025-02-15 11:59:43,153 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 61801abd-2253-4bcd-85c0-e4c1bd8a8ec6
127.0.0.1 - - [15/Feb/2025 11:59:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:43,256 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a8e148b0-142a-4fdf-9ed2-bad5cb44977e
2025-02-15 11:59:43,313 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a8e148b0-142a-4fdf-9ed2-bad5cb44977e
127.0.0.1 - - [15/Feb/2025 11:59:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:43,566 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 510e495a-c55f-4761-84b7-0d46bd88e111
2025-02-15 11:59:43,586 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 510e495a-c55f-4761-84b7-0d46bd88e111
127.0.0.1 - - [15/Feb/2025 11:59:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:43,756 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 048011c6-bf72-4f66-a0ff-e58ef142cd4a
2025-02-15 11:59:43,788 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 048011c6-bf72-4f66-a0ff-e58ef142cd4a
127.0.0.1 - - [15/Feb/2025 11:59:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:43,985 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b85daeee-c233-4df3-bc2d-858112539283
2025-02-15 11:59:43,989 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b85daeee-c233-4df3-bc2d-858112539283
127.0.0.1 - - [15/Feb/2025 11:59:43] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:44,273 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f7b44f7f-92a6-4660-8885-5cb941ed86bd
2025-02-15 11:59:44,319 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f7b44f7f-92a6-4660-8885-5cb941ed86bd
127.0.0.1 - - [15/Feb/2025 11:59:44] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:44,596 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 51cd7158-b026-4cc6-9799-da5802376a9e
2025-02-15 11:59:44,602 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 51cd7158-b026-4cc6-9799-da5802376a9e
127.0.0.1 - - [15/Feb/2025 11:59:44] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:44,682 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1e0c7432-3363-43e3-9cb2-6a5f4787a1fe
2025-02-15 11:59:44,730 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1e0c7432-3363-43e3-9cb2-6a5f4787a1fe
127.0.0.1 - - [15/Feb/2025 11:59:44] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:45,008 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 91e0e6d5-e41e-4f89-b675-438ea16c0232
2025-02-15 11:59:45,022 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 91e0e6d5-e41e-4f89-b675-438ea16c0232
127.0.0.1 - - [15/Feb/2025 11:59:45] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:45,058 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a18fb9d4-bbc3-4ee7-a0c8-5364ba45c12a
2025-02-15 11:59:45,062 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a18fb9d4-bbc3-4ee7-a0c8-5364ba45c12a
127.0.0.1 - - [15/Feb/2025 11:59:45] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:45,619 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a468ac13-f821-4d76-87a4-143d3b2e3ba4
2025-02-15 11:59:45,651 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a468ac13-f821-4d76-87a4-143d3b2e3ba4
127.0.0.1 - - [15/Feb/2025 11:59:45] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:45,751 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e72b6acd-c7dc-4aa9-9de0-2e62aae40cff
2025-02-15 11:59:45,766 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e72b6acd-c7dc-4aa9-9de0-2e62aae40cff
127.0.0.1 - - [15/Feb/2025 11:59:45] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:46,215 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8a649fdf-c48f-4efc-bc49-6df7e9dc0b5d
2025-02-15 11:59:46,236 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8a649fdf-c48f-4efc-bc49-6df7e9dc0b5d
127.0.0.1 - - [15/Feb/2025 11:59:46] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:46,261 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 68941409-974f-4f94-8822-87a1bd50a27c
2025-02-15 11:59:46,276 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 68941409-974f-4f94-8822-87a1bd50a27c
127.0.0.1 - - [15/Feb/2025 11:59:46] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:46,613 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7dbe668b-4586-46b4-ab3f-e2fb3f98ff84
2025-02-15 11:59:46,616 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7dbe668b-4586-46b4-ab3f-e2fb3f98ff84
127.0.0.1 - - [15/Feb/2025 11:59:46] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:46,646 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4491174e-7c26-412b-99dc-3d30ad2ebf9d
2025-02-15 11:59:46,661 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4491174e-7c26-412b-99dc-3d30ad2ebf9d
127.0.0.1 - - [15/Feb/2025 11:59:46] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:47,014 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9b38a23c-5c50-42c0-8af1-d70ef260ac50
2025-02-15 11:59:47,036 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9b38a23c-5c50-42c0-8af1-d70ef260ac50
127.0.0.1 - - [15/Feb/2025 11:59:47] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:47,092 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 557d7098-6892-4c21-a8c9-9d1ab1559aaa
2025-02-15 11:59:47,114 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 557d7098-6892-4c21-a8c9-9d1ab1559aaa
127.0.0.1 - - [15/Feb/2025 11:59:47] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:47,605 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9f9b320f-9d86-4f46-841f-8a19859f0fd1
2025-02-15 11:59:47,627 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9f9b320f-9d86-4f46-841f-8a19859f0fd1
127.0.0.1 - - [15/Feb/2025 11:59:47] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:47,818 - LoudVA - WARNING - [LoudServer] - Timeout reached for request af91a64c-cc61-490a-8b01-52b8e6789358
2025-02-15 11:59:47,820 - LoudVA - INFO - [LoudServer] - Completed. Request ID: af91a64c-cc61-490a-8b01-52b8e6789358
127.0.0.1 - - [15/Feb/2025 11:59:47] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:48,044 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aaf8897f-7586-4d90-8117-369352275b2f
2025-02-15 11:59:48,055 - LoudVA - INFO - [LoudServer] - Completed. Request ID: aaf8897f-7586-4d90-8117-369352275b2f
127.0.0.1 - - [15/Feb/2025 11:59:48] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:48,169 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3ae99611-febe-4235-831e-a8b023144abe
2025-02-15 11:59:48,213 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3ae99611-febe-4235-831e-a8b023144abe
127.0.0.1 - - [15/Feb/2025 11:59:48] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:48,404 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3b51b162-0e3d-4e40-aea0-73bd3552d21d
2025-02-15 11:59:48,568 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3b51b162-0e3d-4e40-aea0-73bd3552d21d
2025-02-15 11:59:48,568 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 55cc6288-0326-4dc7-8723-7a6870db2710
127.0.0.1 - - [15/Feb/2025 11:59:48] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:48,580 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5d659d2d-313d-4b74-bbcc-6b9b20a734d0
2025-02-15 11:59:48,587 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 55cc6288-0326-4dc7-8723-7a6870db2710
127.0.0.1 - - [15/Feb/2025 11:59:48] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:48,596 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5d659d2d-313d-4b74-bbcc-6b9b20a734d0
127.0.0.1 - - [15/Feb/2025 11:59:48] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:49,077 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 28823013-5799-41cb-ac15-eaa91925d589
2025-02-15 11:59:49,089 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 28823013-5799-41cb-ac15-eaa91925d589
127.0.0.1 - - [15/Feb/2025 11:59:49] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:49,239 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 56b7364c-70f9-4156-b410-e3e3ed41023b
2025-02-15 11:59:49,273 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 56b7364c-70f9-4156-b410-e3e3ed41023b
127.0.0.1 - - [15/Feb/2025 11:59:49] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:49,575 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ea0e0791-7bf6-429f-b23e-5903395bc8f2
2025-02-15 11:59:49,585 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ea0e0791-7bf6-429f-b23e-5903395bc8f2
127.0.0.1 - - [15/Feb/2025 11:59:49] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:49,593 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3b56df5c-669d-4ca7-9f8e-693364694749
2025-02-15 11:59:49,635 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3b56df5c-669d-4ca7-9f8e-693364694749
127.0.0.1 - - [15/Feb/2025 11:59:49] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:50,096 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 28378129-51f1-4886-b54f-fe1977d497d5
2025-02-15 11:59:50,105 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 28378129-51f1-4886-b54f-fe1977d497d5
127.0.0.1 - - [15/Feb/2025 11:59:50] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:50,145 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 39514d66-6209-4cc7-90a9-5480a70c1b13
2025-02-15 11:59:50,162 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 39514d66-6209-4cc7-90a9-5480a70c1b13
127.0.0.1 - - [15/Feb/2025 11:59:50] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:50,507 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b7985e4c-5a61-42ce-a107-c7d7d12853e9
2025-02-15 11:59:50,521 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b7985e4c-5a61-42ce-a107-c7d7d12853e9
127.0.0.1 - - [15/Feb/2025 11:59:50] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:50,558 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 02c599f1-92e4-485a-ab87-f1c4dad00745
2025-02-15 11:59:50,564 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 02c599f1-92e4-485a-ab87-f1c4dad00745
127.0.0.1 - - [15/Feb/2025 11:59:50] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:51,185 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1c895980-7f1c-4ecc-a5bf-8a40a4826f2e
2025-02-15 11:59:51,193 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1c895980-7f1c-4ecc-a5bf-8a40a4826f2e
127.0.0.1 - - [15/Feb/2025 11:59:51] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:51,296 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d336f808-d9ab-4d44-81cd-76eaaca0597c
2025-02-15 11:59:51,313 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d336f808-d9ab-4d44-81cd-76eaaca0597c
127.0.0.1 - - [15/Feb/2025 11:59:51] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:51,510 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 415c22c5-c2ef-4dc1-bfc7-8777c60261fe
2025-02-15 11:59:51,516 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 415c22c5-c2ef-4dc1-bfc7-8777c60261fe
127.0.0.1 - - [15/Feb/2025 11:59:51] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:51,589 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a2afe701-a87b-415f-9a28-810e7918b877
2025-02-15 11:59:51,602 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a2afe701-a87b-415f-9a28-810e7918b877
127.0.0.1 - - [15/Feb/2025 11:59:51] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:52,047 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5100b39d-2963-4676-8fc5-929f8f70b8dc
2025-02-15 11:59:52,061 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5100b39d-2963-4676-8fc5-929f8f70b8dc
127.0.0.1 - - [15/Feb/2025 11:59:52] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:52,162 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 79161272-1a0f-4306-b3cb-922a1a1390df
2025-02-15 11:59:52,172 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 79161272-1a0f-4306-b3cb-922a1a1390df
127.0.0.1 - - [15/Feb/2025 11:59:52] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:52,510 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 47a9f176-1949-4108-9540-9b1771abd14c
2025-02-15 11:59:52,522 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 47a9f176-1949-4108-9540-9b1771abd14c
127.0.0.1 - - [15/Feb/2025 11:59:52] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:52,627 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 68b80900-edf5-4193-bb04-e0a8001937be
2025-02-15 11:59:52,634 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 68b80900-edf5-4193-bb04-e0a8001937be
127.0.0.1 - - [15/Feb/2025 11:59:52] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:53,020 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9997b9bc-5dda-4887-b6a0-6a0e73405699
2025-02-15 11:59:53,023 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9997b9bc-5dda-4887-b6a0-6a0e73405699
127.0.0.1 - - [15/Feb/2025 11:59:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:53,091 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c9cced49-947e-4fc5-a15c-c47c3b4d1b30
2025-02-15 11:59:53,094 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c9cced49-947e-4fc5-a15c-c47c3b4d1b30
127.0.0.1 - - [15/Feb/2025 11:59:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:53,470 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 58dc5b65-f842-45f1-bbb8-b894ea36a886
2025-02-15 11:59:53,575 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 58dc5b65-f842-45f1-bbb8-b894ea36a886
127.0.0.1 - - [15/Feb/2025 11:59:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:53,618 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6aeec9e6-a5b2-4b7c-b405-b905584be029
2025-02-15 11:59:53,635 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6aeec9e6-a5b2-4b7c-b405-b905584be029
127.0.0.1 - - [15/Feb/2025 11:59:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:53,668 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a265340c-ac63-4895-ab6e-0de31117f7c4
2025-02-15 11:59:53,694 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a265340c-ac63-4895-ab6e-0de31117f7c4
127.0.0.1 - - [15/Feb/2025 11:59:53] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:54,132 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a4923888-a849-402e-8070-e39bdaee0eef
2025-02-15 11:59:54,146 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a4923888-a849-402e-8070-e39bdaee0eef
127.0.0.1 - - [15/Feb/2025 11:59:54] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:54,194 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6799adda-6a15-4710-b82e-ebd2d2f7e7cf
2025-02-15 11:59:54,211 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6799adda-6a15-4710-b82e-ebd2d2f7e7cf
127.0.0.1 - - [15/Feb/2025 11:59:54] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:54,657 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bd381d46-dd28-4053-b370-c37a1f633124
2025-02-15 11:59:54,669 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bd381d46-dd28-4053-b370-c37a1f633124
127.0.0.1 - - [15/Feb/2025 11:59:54] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:54,767 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f3f75814-1b9a-42cd-803d-ed0725951b3b
2025-02-15 11:59:54,786 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f3f75814-1b9a-42cd-803d-ed0725951b3b
127.0.0.1 - - [15/Feb/2025 11:59:54] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:55,034 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a917917f-03b6-4e23-9049-b23fb78d4fd4
2025-02-15 11:59:55,043 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a917917f-03b6-4e23-9049-b23fb78d4fd4
127.0.0.1 - - [15/Feb/2025 11:59:55] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:55,220 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ca673541-1f0e-4050-893e-f263d986501e
2025-02-15 11:59:55,236 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ca673541-1f0e-4050-893e-f263d986501e
127.0.0.1 - - [15/Feb/2025 11:59:55] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:55,545 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2bb4a3f5-61c5-4bcf-abf1-6e4cbe12ec03
2025-02-15 11:59:55,549 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2bb4a3f5-61c5-4bcf-abf1-6e4cbe12ec03
127.0.0.1 - - [15/Feb/2025 11:59:55] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:55,561 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 30c1d5d0-8875-4554-a594-016dac1893ae
2025-02-15 11:59:55,563 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 30c1d5d0-8875-4554-a594-016dac1893ae
127.0.0.1 - - [15/Feb/2025 11:59:55] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:56,057 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c7b4d92d-20ed-4bd8-b204-07404c6cab17
2025-02-15 11:59:56,066 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c7b4d92d-20ed-4bd8-b204-07404c6cab17
127.0.0.1 - - [15/Feb/2025 11:59:56] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:56,066 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 20a74d59-0d4a-41ac-b589-860043fa2631
2025-02-15 11:59:56,086 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 20a74d59-0d4a-41ac-b589-860043fa2631
127.0.0.1 - - [15/Feb/2025 11:59:56] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:56,562 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 412d416e-0147-4b97-81b3-55680e730ed5
2025-02-15 11:59:56,566 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 412d416e-0147-4b97-81b3-55680e730ed5
127.0.0.1 - - [15/Feb/2025 11:59:56] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:56,599 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b0e9cea7-bde1-4096-84d7-25c9f82e5cbf
2025-02-15 11:59:56,603 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b0e9cea7-bde1-4096-84d7-25c9f82e5cbf
127.0.0.1 - - [15/Feb/2025 11:59:56] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:57,188 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0381cdfb-590f-4d6b-a85b-04e90e9cd19f
2025-02-15 11:59:57,190 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0381cdfb-590f-4d6b-a85b-04e90e9cd19f
127.0.0.1 - - [15/Feb/2025 11:59:57] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:57,208 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0708a6f5-1993-4949-b12f-9daea33daa94
2025-02-15 11:59:57,209 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0708a6f5-1993-4949-b12f-9daea33daa94
127.0.0.1 - - [15/Feb/2025 11:59:57] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:57,562 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d90ec549-ccde-4de9-95f6-13b860d32f1b
2025-02-15 11:59:57,566 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d90ec549-ccde-4de9-95f6-13b860d32f1b
127.0.0.1 - - [15/Feb/2025 11:59:57] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:57,653 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3011df2c-785f-475c-a8d9-0fd70f916948
2025-02-15 11:59:57,657 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3011df2c-785f-475c-a8d9-0fd70f916948
127.0.0.1 - - [15/Feb/2025 11:59:57] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:58,031 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2ef78ac5-53ca-46ee-8bbb-cd6adda9e6b7
2025-02-15 11:59:58,032 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2ef78ac5-53ca-46ee-8bbb-cd6adda9e6b7
127.0.0.1 - - [15/Feb/2025 11:59:58] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:58,078 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7dd0de71-f6c4-488b-b39d-791063081a62
2025-02-15 11:59:58,080 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7dd0de71-f6c4-488b-b39d-791063081a62
127.0.0.1 - - [15/Feb/2025 11:59:58] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:58,227 - LoudVA - WARNING - [LoudServer] - Timeout reached for request da43d7fc-663d-4834-aba0-0fafdb06dde5
2025-02-15 11:59:58,242 - LoudVA - INFO - [LoudServer] - Completed. Request ID: da43d7fc-663d-4834-aba0-0fafdb06dde5
127.0.0.1 - - [15/Feb/2025 11:59:58] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:58,624 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a0a1c710-9bcf-4ae9-9f00-ce024f4f3304
2025-02-15 11:59:58,635 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a0a1c710-9bcf-4ae9-9f00-ce024f4f3304
127.0.0.1 - - [15/Feb/2025 11:59:58] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:58,722 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 33260c3b-b440-46eb-923a-66e43ff59229
2025-02-15 11:59:58,728 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 33260c3b-b440-46eb-923a-66e43ff59229
127.0.0.1 - - [15/Feb/2025 11:59:58] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:59,194 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e9be47c7-e35f-422c-a24c-0ffb4b9c97f6
2025-02-15 11:59:59,197 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e9be47c7-e35f-422c-a24c-0ffb4b9c97f6
127.0.0.1 - - [15/Feb/2025 11:59:59] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:59,338 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8531b0c0-2076-476b-89bd-c2d9d712e812
2025-02-15 11:59:59,342 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8531b0c0-2076-476b-89bd-c2d9d712e812
127.0.0.1 - - [15/Feb/2025 11:59:59] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:59,622 - LoudVA - WARNING - [LoudServer] - Timeout reached for request feeb45b7-bb39-4a5f-93e6-912d10a706c0
2025-02-15 11:59:59,624 - LoudVA - INFO - [LoudServer] - Completed. Request ID: feeb45b7-bb39-4a5f-93e6-912d10a706c0
127.0.0.1 - - [15/Feb/2025 11:59:59] "POST /inference HTTP/1.1" 200 -
2025-02-15 11:59:59,631 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8979e7fc-635c-4613-bc82-21b8890df195
2025-02-15 11:59:59,636 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8979e7fc-635c-4613-bc82-21b8890df195
127.0.0.1 - - [15/Feb/2025 11:59:59] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:00,031 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 106791ae-c848-4741-9f01-f7a1504ace42
2025-02-15 12:00:00,034 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 106791ae-c848-4741-9f01-f7a1504ace42
127.0.0.1 - - [15/Feb/2025 12:00:00] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:00,788 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 34e205b1-9210-43e4-8b46-387a1cec3c9d
2025-02-15 12:00:00,793 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 34e205b1-9210-43e4-8b46-387a1cec3c9d
127.0.0.1 - - [15/Feb/2025 12:00:00] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:01,054 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fb9e96e4-3a84-4155-82ce-e8652c513978
2025-02-15 12:00:01,056 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fb9e96e4-3a84-4155-82ce-e8652c513978
127.0.0.1 - - [15/Feb/2025 12:00:01] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:01,510 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2bf06a10-b5cd-4277-8f60-058bc45f3b9a
2025-02-15 12:00:01,512 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2bf06a10-b5cd-4277-8f60-058bc45f3b9a
127.0.0.1 - - [15/Feb/2025 12:00:01] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:02,319 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d750401f-9270-4f14-a2b8-8f27347fc515
2025-02-15 12:00:02,320 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d750401f-9270-4f14-a2b8-8f27347fc515
127.0.0.1 - - [15/Feb/2025 12:00:02] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:02,611 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5b324a48-75e4-4616-b142-d84817bfc5c6
2025-02-15 12:00:02,614 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5b324a48-75e4-4616-b142-d84817bfc5c6
127.0.0.1 - - [15/Feb/2025 12:00:02] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:02,985 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8f15e430-e73e-436d-aafc-87090516425b
2025-02-15 12:00:03,000 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8f15e430-e73e-436d-aafc-87090516425b
127.0.0.1 - - [15/Feb/2025 12:00:03] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:03,040 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 468a4c83-2ee7-4f3d-aee4-4435ab8729a7
2025-02-15 12:00:03,042 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 468a4c83-2ee7-4f3d-aee4-4435ab8729a7
127.0.0.1 - - [15/Feb/2025 12:00:03] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:03,657 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 59d62274-06bf-4401-b731-9f232c8cca0e
2025-02-15 12:00:03,658 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 59d62274-06bf-4401-b731-9f232c8cca0e
127.0.0.1 - - [15/Feb/2025 12:00:03] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:04,219 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d2e1c53b-12c9-4447-9c27-74e37ec7bfc2
2025-02-15 12:00:04,223 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d2e1c53b-12c9-4447-9c27-74e37ec7bfc2
127.0.0.1 - - [15/Feb/2025 12:00:04] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:04,603 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ffd7c963-6b8e-43e6-b92e-4a1f644766ee
2025-02-15 12:00:04,603 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ffd7c963-6b8e-43e6-b92e-4a1f644766ee
127.0.0.1 - - [15/Feb/2025 12:00:04] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:05,094 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 82d3851b-b86d-41b1-a94f-4f25d91ddde9
2025-02-15 12:00:05,105 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 82d3851b-b86d-41b1-a94f-4f25d91ddde9
127.0.0.1 - - [15/Feb/2025 12:00:05] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:05,527 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e46b4cdd-79f0-49d6-93bc-4bcce15f6d3b
2025-02-15 12:00:05,528 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e46b4cdd-79f0-49d6-93bc-4bcce15f6d3b
127.0.0.1 - - [15/Feb/2025 12:00:05] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:06,172 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a0cef85a-67be-4111-9bce-dc5a6c8bf167
2025-02-15 12:00:06,175 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a0cef85a-67be-4111-9bce-dc5a6c8bf167
127.0.0.1 - - [15/Feb/2025 12:00:06] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:06,522 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b7946f3c-dc40-47b4-8796-72ee61024168
2025-02-15 12:00:06,524 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b7946f3c-dc40-47b4-8796-72ee61024168
127.0.0.1 - - [15/Feb/2025 12:00:06] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:07,281 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a7b16bfc-371d-48fb-8879-87550d1013cd
2025-02-15 12:00:07,285 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a7b16bfc-371d-48fb-8879-87550d1013cd
127.0.0.1 - - [15/Feb/2025 12:00:07] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:07,551 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 93305d6c-5c3d-4dfc-a776-bfa8c5f84a0e
2025-02-15 12:00:07,552 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 93305d6c-5c3d-4dfc-a776-bfa8c5f84a0e
127.0.0.1 - - [15/Feb/2025 12:00:07] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:07,839 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 11b1d021-7a35-4e67-bfde-cf2493493908
2025-02-15 12:00:07,842 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 11b1d021-7a35-4e67-bfde-cf2493493908
127.0.0.1 - - [15/Feb/2025 12:00:07] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:08,008 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 969bce76-d0e7-4f66-b23d-771d54d9c6e7
2025-02-15 12:00:08,011 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 969bce76-d0e7-4f66-b23d-771d54d9c6e7
127.0.0.1 - - [15/Feb/2025 12:00:08] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:08,576 - LoudVA - WARNING - [LoudServer] - Timeout reached for request de15a186-81a6-490a-8587-0f87defc8cf8
2025-02-15 12:00:08,579 - LoudVA - INFO - [LoudServer] - Completed. Request ID: de15a186-81a6-490a-8587-0f87defc8cf8
127.0.0.1 - - [15/Feb/2025 12:00:08] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:09,155 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 94cf31c5-280a-4552-add7-4ad9b1c524bc
2025-02-15 12:00:09,157 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 94cf31c5-280a-4552-add7-4ad9b1c524bc
127.0.0.1 - - [15/Feb/2025 12:00:09] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:09,516 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e350a50e-90df-45b2-a1f6-001f4482bcaa
2025-02-15 12:00:09,517 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e350a50e-90df-45b2-a1f6-001f4482bcaa
127.0.0.1 - - [15/Feb/2025 12:00:09] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:10,012 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 730767b1-f4e7-4815-93af-1f2b571bd001
2025-02-15 12:00:10,013 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 730767b1-f4e7-4815-93af-1f2b571bd001
127.0.0.1 - - [15/Feb/2025 12:00:10] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:10,609 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 748e2675-e2e6-473a-8b0c-6d48c21a3734
2025-02-15 12:00:10,613 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 748e2675-e2e6-473a-8b0c-6d48c21a3734
127.0.0.1 - - [15/Feb/2025 12:00:10] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:11,039 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fb3f7e8b-b220-4829-91f3-c4d058041cb9
2025-02-15 12:00:11,041 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fb3f7e8b-b220-4829-91f3-c4d058041cb9
127.0.0.1 - - [15/Feb/2025 12:00:11] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:11,870 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 43e49355-8d48-49c6-ab52-72284011c34c
2025-02-15 12:00:11,875 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 43e49355-8d48-49c6-ab52-72284011c34c
127.0.0.1 - - [15/Feb/2025 12:00:11] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:12,037 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 62bf8537-5ff7-4712-9989-593fd20a42c1
2025-02-15 12:00:12,038 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 62bf8537-5ff7-4712-9989-593fd20a42c1
127.0.0.1 - - [15/Feb/2025 12:00:12] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:12,626 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2353c2db-741d-4320-acec-05071bd8f5af
2025-02-15 12:00:12,633 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2353c2db-741d-4320-acec-05071bd8f5af
127.0.0.1 - - [15/Feb/2025 12:00:12] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:13,051 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4f10ded0-98d1-4d9c-ba34-4c7d9acfac1b
2025-02-15 12:00:13,059 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4f10ded0-98d1-4d9c-ba34-4c7d9acfac1b
127.0.0.1 - - [15/Feb/2025 12:00:13] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:13,361 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c96c5357-de5e-4257-8b5a-f4504a0050bf
2025-02-15 12:00:13,398 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 753daa42-a4a1-48a3-88d0-bfae5335a734
2025-02-15 12:00:13,424 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 753daa42-a4a1-48a3-88d0-bfae5335a734
2025-02-15 12:00:13,427 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c96c5357-de5e-4257-8b5a-f4504a0050bf
127.0.0.1 - - [15/Feb/2025 12:00:13] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [15/Feb/2025 12:00:13] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:13,500 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 541b64d2-1f9f-4e18-a327-8be9dbcdedf6
2025-02-15 12:00:13,509 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 541b64d2-1f9f-4e18-a327-8be9dbcdedf6
127.0.0.1 - - [15/Feb/2025 12:00:13] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:14,023 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 34d81c96-b369-437a-baa5-d0a69015f4b0
2025-02-15 12:00:14,034 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 34d81c96-b369-437a-baa5-d0a69015f4b0
127.0.0.1 - - [15/Feb/2025 12:00:14] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:14,634 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ae683d57-c0c7-418b-a67e-dd7a8d6c31c9
2025-02-15 12:00:14,643 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ae683d57-c0c7-418b-a67e-dd7a8d6c31c9
127.0.0.1 - - [15/Feb/2025 12:00:14] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:15,039 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8690c400-4dba-499e-8431-0cfe1d1c2649
2025-02-15 12:00:15,049 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8690c400-4dba-499e-8431-0cfe1d1c2649
127.0.0.1 - - [15/Feb/2025 12:00:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:15,653 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0e371621-8542-47db-a13d-ce1265557537
2025-02-15 12:00:15,671 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0e371621-8542-47db-a13d-ce1265557537
127.0.0.1 - - [15/Feb/2025 12:00:15] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:16,149 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ab022dd6-fddc-40d5-a81c-173222900193
2025-02-15 12:00:16,156 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ab022dd6-fddc-40d5-a81c-173222900193
127.0.0.1 - - [15/Feb/2025 12:00:16] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:16,663 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 85066c23-7e0c-4e45-8616-d135ab8aee7d
2025-02-15 12:00:16,672 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 85066c23-7e0c-4e45-8616-d135ab8aee7d
127.0.0.1 - - [15/Feb/2025 12:00:16] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:17,002 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b1a1cc1c-09e1-4c23-8ea6-a3fe7bc36c23
2025-02-15 12:00:17,009 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b1a1cc1c-09e1-4c23-8ea6-a3fe7bc36c23
127.0.0.1 - - [15/Feb/2025 12:00:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:17,507 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 318c36d7-7112-4638-93a7-a04a8efad37b
2025-02-15 12:00:17,507 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 318c36d7-7112-4638-93a7-a04a8efad37b
127.0.0.1 - - [15/Feb/2025 12:00:17] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:18,374 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 633f4c26-c455-4a45-babb-ae36b3607286
2025-02-15 12:00:18,376 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 633f4c26-c455-4a45-babb-ae36b3607286
127.0.0.1 - - [15/Feb/2025 12:00:18] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:18,552 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3508cf6d-7ae7-4c2b-a1ee-f60b61ab9849
2025-02-15 12:00:18,554 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3508cf6d-7ae7-4c2b-a1ee-f60b61ab9849
127.0.0.1 - - [15/Feb/2025 12:00:18] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:18,633 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 793a62e0-79cf-4cf2-9ab2-fb3c3d8e9acc
2025-02-15 12:00:18,653 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 793a62e0-79cf-4cf2-9ab2-fb3c3d8e9acc
127.0.0.1 - - [15/Feb/2025 12:00:18] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:19,022 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 46bc6537-10fb-422f-8954-3ed3e08ec8ad
2025-02-15 12:00:19,023 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 46bc6537-10fb-422f-8954-3ed3e08ec8ad
127.0.0.1 - - [15/Feb/2025 12:00:19] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:19,604 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b361aa6f-6fd4-49c0-94af-c4d985b8221a
2025-02-15 12:00:19,606 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b361aa6f-6fd4-49c0-94af-c4d985b8221a
127.0.0.1 - - [15/Feb/2025 12:00:19] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:20,027 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4f9b4a5c-9b33-4ff6-995a-2efefde52a22
2025-02-15 12:00:20,031 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4f9b4a5c-9b33-4ff6-995a-2efefde52a22
127.0.0.1 - - [15/Feb/2025 12:00:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:20,631 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8f7a60ef-8d70-40a0-a0c0-b7c9ddb8303b
2025-02-15 12:00:20,636 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8f7a60ef-8d70-40a0-a0c0-b7c9ddb8303b
127.0.0.1 - - [15/Feb/2025 12:00:20] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:21,051 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 553199ed-007e-4cbb-903c-b79741bafe28
2025-02-15 12:00:21,053 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 553199ed-007e-4cbb-903c-b79741bafe28
127.0.0.1 - - [15/Feb/2025 12:00:21] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:21,753 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 47eec8c2-f883-4b49-a33d-e53453a0a71b
2025-02-15 12:00:21,755 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 47eec8c2-f883-4b49-a33d-e53453a0a71b
127.0.0.1 - - [15/Feb/2025 12:00:21] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:22,203 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e9b6709f-9de2-49bf-9446-17596f0fec3e
2025-02-15 12:00:22,205 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e9b6709f-9de2-49bf-9446-17596f0fec3e
127.0.0.1 - - [15/Feb/2025 12:00:22] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:24,130 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 184925ad-f5c5-4b66-9c1c-55bdd59f9e43
2025-02-15 12:00:24,132 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 184925ad-f5c5-4b66-9c1c-55bdd59f9e43
127.0.0.1 - - [15/Feb/2025 12:00:24] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:24,225 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8a1b79fd-00a4-4036-8f74-98f5b4864b03
2025-02-15 12:00:24,234 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8a1b79fd-00a4-4036-8f74-98f5b4864b03
127.0.0.1 - - [15/Feb/2025 12:00:24] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:24,526 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 58e7515b-efac-4a8f-b260-4e89ab5909a0
2025-02-15 12:00:24,527 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 58e7515b-efac-4a8f-b260-4e89ab5909a0
127.0.0.1 - - [15/Feb/2025 12:00:24] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:25,065 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f9acaf7f-489f-480c-9729-6855dc2918a2
2025-02-15 12:00:25,066 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f9acaf7f-489f-480c-9729-6855dc2918a2
127.0.0.1 - - [15/Feb/2025 12:00:25] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:28,578 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 80f72973-f6df-49ab-8ffa-1867d2d34692
2025-02-15 12:00:28,586 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 80f72973-f6df-49ab-8ffa-1867d2d34692
127.0.0.1 - - [15/Feb/2025 12:00:28] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:29,082 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3146c0c7-1559-4a21-92b4-584f4cbb5336
2025-02-15 12:00:29,087 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3146c0c7-1559-4a21-92b4-584f4cbb5336
127.0.0.1 - - [15/Feb/2025 12:00:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:29,604 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4d517296-713e-4c21-8392-aaad9b22af8f
2025-02-15 12:00:29,605 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4d517296-713e-4c21-8392-aaad9b22af8f
127.0.0.1 - - [15/Feb/2025 12:00:29] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:30,082 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 07c9d2e9-0370-42cb-a49b-04cea583e4e0
2025-02-15 12:00:30,084 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 07c9d2e9-0370-42cb-a49b-04cea583e4e0
127.0.0.1 - - [15/Feb/2025 12:00:30] "POST /inference HTTP/1.1" 200 -
2025-02-15 12:00:30,799 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 777cdf84-ae9a-43db-b36c-3eed46564fe6
2025-02-15 12:00:30,800 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 777cdf84-ae9a-43db-b36c-3eed46564fe6
127.0.0.1 - - [15/Feb/2025 12:00:30] "POST /inference HTTP/1.1" 200 -
