Returning to the default values
---Setting GPU frequency to 153600000---
Returning to the default values
Model: NVIDIA Jetson Nano Developer Kit
GPU frequency set to 153600000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 49
    Throughput: 1.0886 infer/sec
    Avg latency: 905204 usec (standard deviation 8274 usec)
    p50 latency: 902619 usec
    p90 latency: 917539 usec
    p95 latency: 920487 usec
    p99 latency: 922184 usec
    Avg HTTP time: 905036 usec (send/recv 1937 usec + response wait 903099 usec)
  Server: 
    Inference count: 50
    Execution count: 50
    Successful request count: 50
    Avg request latency: 892483 usec (overhead 329 usec + queue 264 usec + compute input 464 usec + compute infer 891246 usec + compute output 180 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 1.0886 infer/sec, latency 905204 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2265.38
Median: 2229
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 49
    Throughput: 1.25615 infer/sec
    Avg latency: 1586447 usec (standard deviation 2671 usec)
    p50 latency: 1586157 usec
    p90 latency: 1589948 usec
    p95 latency: 1592315 usec
    p99 latency: 1593943 usec
    Avg HTTP time: 1586397 usec (send/recv 2379 usec + response wait 1584018 usec)
  Server: 
    Inference count: 50
    Execution count: 50
    Successful request count: 50
    Avg request latency: 1573880 usec (overhead 382 usec + queue 780952 usec + compute input 1866 usec + compute infer 790509 usec + compute output 171 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 1.25615 infer/sec, latency 1586447 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2689.18
Median: 2670
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 49
    Throughput: 1.39972 infer/sec
    Avg latency: 2055726 usec (standard deviation 2116 usec)
    p50 latency: 2056088 usec
    p90 latency: 2058212 usec
    p95 latency: 2059056 usec
    p99 latency: 2059859 usec
    Avg HTTP time: 2055637 usec (send/recv 2909 usec + response wait 2052728 usec)
  Server: 
    Inference count: 51
    Execution count: 34
    Successful request count: 51
    Avg request latency: 2040773 usec (overhead 497 usec + queue 935028 usec + compute input 3548 usec + compute infer 1101468 usec + compute output 232 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 1.39972 infer/sec, latency 2055726 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2621.21
Median: 2629
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 48
    Throughput: 1.45428 infer/sec
    Avg latency: 2581651 usec (standard deviation 3597 usec)
    p50 latency: 2582942 usec
    p90 latency: 2585182 usec
    p95 latency: 2586004 usec
    p99 latency: 2589578 usec
    Avg HTTP time: 2581552 usec (send/recv 2400 usec + response wait 2579152 usec)
  Server: 
    Inference count: 51
    Execution count: 25
    Successful request count: 51
    Avg request latency: 2565764 usec (overhead 522 usec + queue 1012030 usec + compute input 4801 usec + compute infer 1548229 usec + compute output 182 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 1.45428 infer/sec, latency 2581651 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2637.19
Median: 2633
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 46
    Throughput: 1.48349 infer/sec
    Avg latency: 3064563 usec (standard deviation 5381 usec)
    p50 latency: 3063851 usec
    p90 latency: 3071277 usec
    p95 latency: 3072455 usec
    p99 latency: 3075811 usec
    Avg HTTP time: 3064606 usec (send/recv 2592 usec + response wait 3062014 usec)
  Server: 
    Inference count: 51
    Execution count: 21
    Successful request count: 51
    Avg request latency: 3045745 usec (overhead 719 usec + queue 1094489 usec + compute input 6143 usec + compute infer 1944093 usec + compute output 301 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 1.48349 infer/sec, latency 3064563 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2694.58
Median: 2633.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 49
    Throughput: 1.48453 infer/sec
    Avg latency: 3581891 usec (standard deviation 3992 usec)
    p50 latency: 3581356 usec
    p90 latency: 3587131 usec
    p95 latency: 3588102 usec
    p99 latency: 3590591 usec
    Avg HTTP time: 3581522 usec (send/recv 3027 usec + response wait 3578495 usec)
  Server: 
    Inference count: 55
    Execution count: 19
    Successful request count: 55
    Avg request latency: 3563035 usec (overhead 1054 usec + queue 1139022 usec + compute input 6435 usec + compute infer 2416239 usec + compute output 285 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 1.48453 infer/sec, latency 3581891 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2642.82
Median: 2670.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 44
    Throughput: 1.51693 infer/sec
    Avg latency: 4046391 usec (standard deviation 6242 usec)
    p50 latency: 4047059 usec
    p90 latency: 4054365 usec
    p95 latency: 4054583 usec
    p99 latency: 4061190 usec
    Avg HTTP time: 4047177 usec (send/recv 2635 usec + response wait 4044542 usec)
  Server: 
    Inference count: 51
    Execution count: 15
    Successful request count: 51
    Avg request latency: 4030876 usec (overhead 636 usec + queue 1723433 usec + compute input 6704 usec + compute infer 2299864 usec + compute output 239 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 1.51693 infer/sec, latency 4046391 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2657.67
Median: 2633
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 48
    Throughput: 1.59952 infer/sec
    Avg latency: 4576840 usec (standard deviation 3944 usec)
    p50 latency: 4576816 usec
    p90 latency: 4581724 usec
    p95 latency: 4583957 usec
    p99 latency: 4586729 usec
    Avg HTTP time: 4576933 usec (send/recv 2947 usec + response wait 4573986 usec)
  Server: 
    Inference count: 51
    Execution count: 13
    Successful request count: 51
    Avg request latency: 4555699 usec (overhead 858 usec + queue 2179618 usec + compute input 7607 usec + compute infer 2367318 usec + compute output 298 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 1.59952 infer/sec, latency 4576840 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2648.22
Median: 2633.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 49
    Throughput: 1.58029 infer/sec
    Avg latency: 5060098 usec (standard deviation 4845 usec)
    p50 latency: 5060069 usec
    p90 latency: 5066461 usec
    p95 latency: 5068604 usec
    p99 latency: 5069557 usec
    Avg HTTP time: 5060355 usec (send/recv 2401 usec + response wait 5057954 usec)
  Server: 
    Inference count: 54
    Execution count: 12
    Successful request count: 54
    Avg request latency: 5042565 usec (overhead 933 usec + queue 2484266 usec + compute input 8103 usec + compute infer 2548930 usec + compute output 333 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 1.58029 infer/sec, latency 5060098 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2609.73
Median: 2592
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 45
    Throughput: 1.6068 infer/sec
    Avg latency: 5573766 usec (standard deviation 4394 usec)
    p50 latency: 5573169 usec
    p90 latency: 5581022 usec
    p95 latency: 5581984 usec
    p99 latency: 5583086 usec
    Avg HTTP time: 5574645 usec (send/recv 2867 usec + response wait 5571778 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 5557602 usec (overhead 1087 usec + queue 2770530 usec + compute input 8613 usec + compute infer 2777040 usec + compute output 332 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 1.6068 infer/sec, latency 5573766 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2616.40
Median: 2592
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 45
    Throughput: 1.60674 infer/sec
    Avg latency: 6136122 usec (standard deviation 3508311 usec)
    p50 latency: 5580572 usec
    p90 latency: 8362678 usec
    p95 latency: 8364168 usec
    p99 latency: 8372710 usec
    Avg HTTP time: 6136725 usec (send/recv 2959 usec + response wait 6133766 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 6118576 usec (overhead 1158 usec + queue 3329771 usec + compute input 9569 usec + compute infer 2777727 usec + compute output 351 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 1.60674 infer/sec, latency 6136122 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2629.62
Median: 2629
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 45
    Throughput: 1.60674 infer/sec
    Avg latency: 6693379 usec (standard deviation 2355937 usec)
    p50 latency: 5585968 usec
    p90 latency: 8367384 usec
    p95 latency: 8369518 usec
    p99 latency: 8374466 usec
    Avg HTTP time: 6693227 usec (send/recv 2652 usec + response wait 6690575 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 6674998 usec (overhead 772 usec + queue 3886726 usec + compute input 9108 usec + compute infer 2778092 usec + compute output 300 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 1.60674 infer/sec, latency 6693379 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2634.07
Median: 2592.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 45
    Throughput: 1.60674 infer/sec
    Avg latency: 7258362 usec (standard deviation 0 usec)
    p50 latency: 8365993 usec
    p90 latency: 8382253 usec
    p95 latency: 8386658 usec
    p99 latency: 8391281 usec
    Avg HTTP time: 7258092 usec (send/recv 2767 usec + response wait 7255325 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 7241043 usec (overhead 2008 usec + queue 4451842 usec + compute input 8344 usec + compute infer 2778552 usec + compute output 297 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 1.60674 infer/sec, latency 7258362 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2639.43
Median: 2633
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_153600000.csv
Combined CSV file created: power_measurement_stats_freq_153600000.csv
---Setting GPU frequency to 230400000---
Returning to the default values
Model: NVIDIA Jetson Nano Developer Kit
GPU frequency set to 230400000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 49
    Throughput: 1.81448 infer/sec
    Avg latency: 546033 usec (standard deviation 1801 usec)
    p50 latency: 546050 usec
    p90 latency: 548094 usec
    p95 latency: 549164 usec
    p99 latency: 549446 usec
    Avg HTTP time: 546048 usec (send/recv 1878 usec + response wait 544170 usec)
  Server: 
    Inference count: 50
    Execution count: 50
    Successful request count: 50
    Avg request latency: 533335 usec (overhead 323 usec + queue 270 usec + compute input 484 usec + compute infer 532093 usec + compute output 165 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 1.81448 infer/sec, latency 546033 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2981.30
Median: 2990.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 49
    Throughput: 1.81448 infer/sec
    Avg latency: 1074365 usec (standard deviation 2336 usec)
    p50 latency: 1074165 usec
    p90 latency: 1077133 usec
    p95 latency: 1078579 usec
    p99 latency: 1079111 usec
    Avg HTTP time: 1074329 usec (send/recv 2224 usec + response wait 1072105 usec)
  Server: 
    Inference count: 50
    Execution count: 50
    Successful request count: 50
    Avg request latency: 1062488 usec (overhead 350 usec + queue 525605 usec + compute input 1943 usec + compute infer 534424 usec + compute output 166 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 1.81448 infer/sec, latency 1074365 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2999.07
Median: 2990
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 48
    Throughput: 2.0865 infer/sec
    Avg latency: 1390581 usec (standard deviation 2941 usec)
    p50 latency: 1390262 usec
    p90 latency: 1394096 usec
    p95 latency: 1395454 usec
    p99 latency: 1396370 usec
    Avg HTTP time: 1390322 usec (send/recv 2663 usec + response wait 1387659 usec)
  Server: 
    Inference count: 50
    Execution count: 33
    Successful request count: 50
    Avg request latency: 1377650 usec (overhead 448 usec + queue 626108 usec + compute input 3420 usec + compute infer 747488 usec + compute output 186 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 2.0865 infer/sec, latency 1390581 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2978.05
Median: 2990
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 48
    Throughput: 2.18132 infer/sec
    Avg latency: 1743182 usec (standard deviation 2429 usec)
    p50 latency: 1743097 usec
    p90 latency: 1745868 usec
    p95 latency: 1746471 usec
    p99 latency: 1751776 usec
    Avg HTTP time: 1743069 usec (send/recv 2734 usec + response wait 1740335 usec)
  Server: 
    Inference count: 51
    Execution count: 25
    Successful request count: 51
    Avg request latency: 1726811 usec (overhead 574 usec + queue 679320 usec + compute input 4619 usec + compute infer 1042083 usec + compute output 215 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 2.18132 infer/sec, latency 1743182 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2986.53
Median: 2953.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 49
    Throughput: 2.33278 infer/sec
    Avg latency: 2072490 usec (standard deviation 2716 usec)
    p50 latency: 2072756 usec
    p90 latency: 2076118 usec
    p95 latency: 2077079 usec
    p99 latency: 2078031 usec
    Avg HTTP time: 2072365 usec (send/recv 2333 usec + response wait 2070032 usec)
  Server: 
    Inference count: 50
    Execution count: 20
    Successful request count: 50
    Avg request latency: 2053984 usec (overhead 677 usec + queue 720207 usec + compute input 5762 usec + compute infer 1327039 usec + compute output 299 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 2.33278 infer/sec, latency 2072490 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2946.32
Median: 2912.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 53
    Throughput: 2.40865 infer/sec
    Avg latency: 2414834 usec (standard deviation 3630 usec)
    p50 latency: 2414792 usec
    p90 latency: 2418592 usec
    p95 latency: 2419534 usec
    p99 latency: 2421012 usec
    Avg HTTP time: 2414664 usec (send/recv 2283 usec + response wait 2412381 usec)
  Server: 
    Inference count: 54
    Execution count: 18
    Successful request count: 54
    Avg request latency: 2394213 usec (overhead 800 usec + queue 741132 usec + compute input 6840 usec + compute infer 1645219 usec + compute output 222 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 2.40865 infer/sec, latency 2414834 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2979.20
Median: 2953
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 44
    Throughput: 2.19956 infer/sec
    Avg latency: 2731643 usec (standard deviation 4829 usec)
    p50 latency: 2731610 usec
    p90 latency: 2737318 usec
    p95 latency: 2739692 usec
    p99 latency: 2742395 usec
    Avg HTTP time: 2731177 usec (send/recv 2649 usec + response wait 2728528 usec)
  Server: 
    Inference count: 51
    Execution count: 15
    Successful request count: 51
    Avg request latency: 2716381 usec (overhead 983 usec + queue 1160712 usec + compute input 6732 usec + compute infer 1547670 usec + compute output 284 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 2.19956 infer/sec, latency 2731643 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2947.65
Median: 2912
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 48
    Throughput: 2.39928 infer/sec
    Avg latency: 3081787 usec (standard deviation 7883 usec)
    p50 latency: 3079911 usec
    p90 latency: 3095345 usec
    p95 latency: 3097908 usec
    p99 latency: 3098453 usec
    Avg HTTP time: 3081745 usec (send/recv 2096 usec + response wait 3079649 usec)
  Server: 
    Inference count: 53
    Execution count: 13
    Successful request count: 53
    Avg request latency: 3066214 usec (overhead 1093 usec + queue 1417803 usec + compute input 7236 usec + compute infer 1639841 usec + compute output 241 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 2.39928 infer/sec, latency 3081787 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2986.79
Median: 2990
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 49
    Throughput: 2.333 infer/sec
    Avg latency: 3413835 usec (standard deviation 4219 usec)
    p50 latency: 3413667 usec
    p90 latency: 3419461 usec
    p95 latency: 3421044 usec
    p99 latency: 3422977 usec
    Avg HTTP time: 3413888 usec (send/recv 3330 usec + response wait 3410558 usec)
  Server: 
    Inference count: 54
    Execution count: 12
    Successful request count: 54
    Avg request latency: 3397906 usec (overhead 1081 usec + queue 1672321 usec + compute input 7675 usec + compute infer 1716483 usec + compute output 346 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 2.333 infer/sec, latency 3413835 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2930.60
Median: 2912.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 45
    Throughput: 2.49958 infer/sec
    Avg latency: 3757483 usec (standard deviation 5202 usec)
    p50 latency: 3755904 usec
    p90 latency: 3764532 usec
    p95 latency: 3764951 usec
    p99 latency: 3771467 usec
    Avg HTTP time: 3756886 usec (send/recv 2972 usec + response wait 3753914 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 3736186 usec (overhead 1064 usec + queue 1858231 usec + compute input 8608 usec + compute infer 1867910 usec + compute output 373 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 2.49958 infer/sec, latency 3757483 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2917.24
Median: 2912.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 40
    Throughput: 2.22173 infer/sec
    Avg latency: 4131981 usec (standard deviation 0 usec)
    p50 latency: 3759772 usec
    p90 latency: 5629020 usec
    p95 latency: 5629472 usec
    p99 latency: 5639923 usec
    Avg HTTP time: 4131194 usec (send/recv 2334 usec + response wait 4128860 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 4111186 usec (overhead 942 usec + queue 2233607 usec + compute input 8225 usec + compute infer 1868092 usec + compute output 320 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 2.22173 infer/sec, latency 4131981 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2918.53
Median: 2912
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 40
    Throughput: 2.22111 infer/sec
    Avg latency: 4511977 usec (standard deviation 3451168 usec)
    p50 latency: 3766639 usec
    p90 latency: 5638201 usec
    p95 latency: 5641558 usec
    p99 latency: 5644009 usec
    Avg HTTP time: 4510663 usec (send/recv 2622 usec + response wait 4508041 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 4491701 usec (overhead 1138 usec + queue 2613482 usec + compute input 8190 usec + compute infer 1868603 usec + compute output 288 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 2.22111 infer/sec, latency 4511977 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2918.09
Median: 2912.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 40
    Throughput: 2.22185 infer/sec
    Avg latency: 4884556 usec (standard deviation 2867493 usec)
    p50 latency: 5630358 usec
    p90 latency: 5637294 usec
    p95 latency: 5641866 usec
    p99 latency: 5646225 usec
    Avg HTTP time: 4883937 usec (send/recv 3294 usec + response wait 4880643 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 4863811 usec (overhead 978 usec + queue 2985788 usec + compute input 7877 usec + compute infer 1868877 usec + compute output 291 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 2.22185 infer/sec, latency 4884556 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 2955.12
Median: 2912
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_230400000.csv
Combined CSV file created: power_measurement_stats_freq_230400000.csv
---Setting GPU frequency to 307200000---
Returning to the default values
Model: NVIDIA Jetson Nano Developer Kit
GPU frequency set to 307200000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 50
    Throughput: 2.38073 infer/sec
    Avg latency: 419416 usec (standard deviation 1665 usec)
    p50 latency: 419258 usec
    p90 latency: 421468 usec
    p95 latency: 422584 usec
    p99 latency: 423828 usec
    Avg HTTP time: 419354 usec (send/recv 1770 usec + response wait 417584 usec)
  Server: 
    Inference count: 50
    Execution count: 50
    Successful request count: 50
    Avg request latency: 407499 usec (overhead 296 usec + queue 257 usec + compute input 492 usec + compute infer 406306 usec + compute output 148 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 2.38073 infer/sec, latency 419416 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3299.21
Median: 3307.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 51
    Throughput: 2.42799 infer/sec
    Avg latency: 823498 usec (standard deviation 1864 usec)
    p50 latency: 823610 usec
    p90 latency: 825732 usec
    p95 latency: 826457 usec
    p99 latency: 826989 usec
    Avg HTTP time: 823445 usec (send/recv 2283 usec + response wait 821162 usec)
  Server: 
    Inference count: 52
    Execution count: 52
    Successful request count: 52
    Avg request latency: 811854 usec (overhead 362 usec + queue 400340 usec + compute input 1836 usec + compute infer 409162 usec + compute output 154 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 2.42799 infer/sec, latency 823498 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3323.91
Median: 3330.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 49
    Throughput: 2.72162 infer/sec
    Avg latency: 1063400 usec (standard deviation 67570 usec)
    p50 latency: 1059254 usec
    p90 latency: 1065619 usec
    p95 latency: 1066590 usec
    p99 latency: 1469867 usec
    Avg HTTP time: 1063271 usec (send/recv 2344 usec + response wait 1060927 usec)
  Server: 
    Inference count: 51
    Execution count: 34
    Successful request count: 51
    Avg request latency: 1049185 usec (overhead 438 usec + queue 480243 usec + compute input 3068 usec + compute infer 565252 usec + compute output 184 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 2.72162 infer/sec, latency 1063400 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3252.56
Median: 3230
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 48
    Throughput: 2.99962 infer/sec
    Avg latency: 1297554 usec (standard deviation 3287 usec)
    p50 latency: 1297575 usec
    p90 latency: 1301882 usec
    p95 latency: 1304114 usec
    p99 latency: 1304414 usec
    Avg HTTP time: 1297402 usec (send/recv 2869 usec + response wait 1294533 usec)
  Server: 
    Inference count: 50
    Execution count: 25
    Successful request count: 50
    Avg request latency: 1283444 usec (overhead 527 usec + queue 635027 usec + compute input 3930 usec + compute infer 643757 usec + compute output 203 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 2.99962 infer/sec, latency 1297554 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3276.24
Median: 3230.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 48
    Throughput: 2.99925 infer/sec
    Avg latency: 1564097 usec (standard deviation 2896 usec)
    p50 latency: 1564373 usec
    p90 latency: 1567579 usec
    p95 latency: 1568500 usec
    p99 latency: 1568968 usec
    Avg HTTP time: 1564110 usec (send/recv 3147 usec + response wait 1560963 usec)
  Server: 
    Inference count: 50
    Execution count: 20
    Successful request count: 50
    Avg request latency: 1549356 usec (overhead 579 usec + queue 741172 usec + compute input 5268 usec + compute infer 802113 usec + compute output 224 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 2.99925 infer/sec, latency 1564097 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3237.07
Median: 3189
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 44
    Throughput: 2.93275 infer/sec
    Avg latency: 1815241 usec (standard deviation 4268 usec)
    p50 latency: 1815489 usec
    p90 latency: 1820333 usec
    p95 latency: 1821993 usec
    p99 latency: 1822617 usec
    Avg HTTP time: 1815189 usec (send/recv 2712 usec + response wait 1812477 usec)
  Server: 
    Inference count: 48
    Execution count: 16
    Successful request count: 48
    Avg request latency: 1800745 usec (overhead 728 usec + queue 806827 usec + compute input 5732 usec + compute infer 987124 usec + compute output 334 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 2.93275 infer/sec, latency 1815241 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3232.91
Median: 3189.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 49
    Throughput: 3.06193 infer/sec
    Avg latency: 2081415 usec (standard deviation 4484 usec)
    p50 latency: 2082023 usec
    p90 latency: 2087018 usec
    p95 latency: 2087644 usec
    p99 latency: 2089209 usec
    Avg HTTP time: 2081421 usec (send/recv 2907 usec + response wait 2078514 usec)
  Server: 
    Inference count: 52
    Execution count: 15
    Successful request count: 52
    Avg request latency: 2062637 usec (overhead 734 usec + queue 1012593 usec + compute input 6583 usec + compute infer 1042404 usec + compute output 323 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 3.06193 infer/sec, latency 2081415 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3235.65
Median: 3230.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 48
    Throughput: 2.99944 infer/sec
    Avg latency: 2337697 usec (standard deviation 3653 usec)
    p50 latency: 2337807 usec
    p90 latency: 2341853 usec
    p95 latency: 2344443 usec
    p99 latency: 2345536 usec
    Avg HTTP time: 2337996 usec (send/recv 2438 usec + response wait 2335558 usec)
  Server: 
    Inference count: 53
    Execution count: 13
    Successful request count: 53
    Avg request latency: 2318421 usec (overhead 734 usec + queue 1067764 usec + compute input 7294 usec + compute infer 1242330 usec + compute output 299 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 2.99944 infer/sec, latency 2337697 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3220.02
Median: 3189
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 49
    Throughput: 3.26601 infer/sec
    Avg latency: 2592546 usec (standard deviation 4237 usec)
    p50 latency: 2593343 usec
    p90 latency: 2598762 usec
    p95 latency: 2599667 usec
    p99 latency: 2601283 usec
    Avg HTTP time: 2592458 usec (send/recv 2444 usec + response wait 2590014 usec)
  Server: 
    Inference count: 54
    Execution count: 12
    Successful request count: 54
    Avg request latency: 2572784 usec (overhead 1003 usec + queue 1262765 usec + compute input 7999 usec + compute infer 1300712 usec + compute output 305 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 3.26601 infer/sec, latency 2592546 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3220.75
Median: 3189.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 45
    Throughput: 2.9994 infer/sec
    Avg latency: 2851180 usec (standard deviation 3396 usec)
    p50 latency: 2850928 usec
    p90 latency: 2855667 usec
    p95 latency: 2856613 usec
    p99 latency: 2857649 usec
    Avg HTTP time: 2850823 usec (send/recv 2470 usec + response wait 2848353 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 2828661 usec (overhead 948 usec + queue 1403730 usec + compute input 8847 usec + compute infer 1414800 usec + compute output 336 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 2.9994 infer/sec, latency 2851180 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3228.26
Median: 3230
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 40
    Throughput: 2.85673 infer/sec
    Avg latency: 3137121 usec (standard deviation 569467 usec)
    p50 latency: 2853641 usec
    p90 latency: 4273800 usec
    p95 latency: 4279150 usec
    p99 latency: 4285549 usec
    Avg HTTP time: 3136103 usec (send/recv 2952 usec + response wait 3133151 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 3117671 usec (overhead 1052 usec + queue 1692758 usec + compute input 8642 usec + compute infer 1414881 usec + compute output 338 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 2.85673 infer/sec, latency 3137121 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3245.12
Median: 3230
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 40
    Throughput: 2.85653 infer/sec
    Avg latency: 3421604 usec (standard deviation 695805 usec)
    p50 latency: 2859180 usec
    p90 latency: 4277182 usec
    p95 latency: 4281786 usec
    p99 latency: 4292303 usec
    Avg HTTP time: 3422185 usec (send/recv 2408 usec + response wait 3419777 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 3405508 usec (overhead 2147 usec + queue 1979868 usec + compute input 8374 usec + compute infer 1414792 usec + compute output 327 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 2.85653 infer/sec, latency 3421604 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3257.00
Median: 3230
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 40
    Throughput: 2.85633 infer/sec
    Avg latency: 3702892 usec (standard deviation 693647 usec)
    p50 latency: 4265412 usec
    p90 latency: 4274818 usec
    p95 latency: 4275573 usec
    p99 latency: 4279403 usec
    Avg HTTP time: 3702391 usec (send/recv 2857 usec + response wait 3699534 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 3679668 usec (overhead 854 usec + queue 2256214 usec + compute input 7516 usec + compute infer 1414809 usec + compute output 275 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 2.85633 infer/sec, latency 3702892 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3262.34
Median: 3230
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_307200000.csv
Combined CSV file created: power_measurement_stats_freq_307200000.csv
---Setting GPU frequency to 384000000---
Returning to the default values
Model: NVIDIA Jetson Nano Developer Kit
GPU frequency set to 384000000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 51
    Throughput: 2.83286 infer/sec
    Avg latency: 348082 usec (standard deviation 1585 usec)
    p50 latency: 347822 usec
    p90 latency: 350346 usec
    p95 latency: 350867 usec
    p99 latency: 351813 usec
    Avg HTTP time: 347997 usec (send/recv 1864 usec + response wait 346133 usec)
  Server: 
    Inference count: 52
    Execution count: 52
    Successful request count: 52
    Avg request latency: 336040 usec (overhead 311 usec + queue 271 usec + compute input 468 usec + compute infer 334818 usec + compute output 172 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 2.83286 infer/sec, latency 348082 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3554.58
Median: 3546.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 50
    Throughput: 2.94066 infer/sec
    Avg latency: 678211 usec (standard deviation 1873 usec)
    p50 latency: 678049 usec
    p90 latency: 680735 usec
    p95 latency: 681867 usec
    p99 latency: 682640 usec
    Avg HTTP time: 678172 usec (send/recv 2154 usec + response wait 676018 usec)
  Server: 
    Inference count: 50
    Execution count: 50
    Successful request count: 50
    Avg request latency: 666695 usec (overhead 309 usec + queue 327840 usec + compute input 1911 usec + compute infer 336480 usec + compute output 155 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 2.94066 infer/sec, latency 678211 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3559.95
Median: 3546
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 50
    Throughput: 3.33289 infer/sec
    Avg latency: 876513 usec (standard deviation 77639 usec)
    p50 latency: 870176 usec
    p90 latency: 873860 usec
    p95 latency: 875614 usec
    p99 latency: 1211504 usec
    Avg HTTP time: 876364 usec (send/recv 2484 usec + response wait 873880 usec)
  Server: 
    Inference count: 51
    Execution count: 35
    Successful request count: 51
    Avg request latency: 862954 usec (overhead 471 usec + queue 403764 usec + compute input 2895 usec + compute infer 455653 usec + compute output 171 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 3.33289 infer/sec, latency 876513 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3563.62
Median: 3587
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 48
    Throughput: 3.69174 infer/sec
    Avg latency: 1061353 usec (standard deviation 2436 usec)
    p50 latency: 1061283 usec
    p90 latency: 1064101 usec
    p95 latency: 1065463 usec
    p99 latency: 1068952 usec
    Avg HTTP time: 1061148 usec (send/recv 2808 usec + response wait 1058340 usec)
  Server: 
    Inference count: 50
    Execution count: 25
    Successful request count: 50
    Avg request latency: 1047619 usec (overhead 518 usec + queue 517315 usec + compute input 3935 usec + compute infer 525643 usec + compute output 208 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 3.69174 infer/sec, latency 1061353 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3550.92
Median: 3587.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 48
    Throughput: 3.69174 infer/sec
    Avg latency: 1277037 usec (standard deviation 3161 usec)
    p50 latency: 1278089 usec
    p90 latency: 1280063 usec
    p95 latency: 1280624 usec
    p99 latency: 1283592 usec
    Avg HTTP time: 1276892 usec (send/recv 2907 usec + response wait 1273985 usec)
  Server: 
    Inference count: 50
    Execution count: 20
    Successful request count: 50
    Avg request latency: 1262713 usec (overhead 641 usec + queue 603298 usec + compute input 5320 usec + compute infer 653237 usec + compute output 217 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 3.69174 infer/sec, latency 1277037 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3522.20
Median: 3506
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 48
    Throughput: 3.999 infer/sec
    Avg latency: 1490996 usec (standard deviation 4226 usec)
    p50 latency: 1490718 usec
    p90 latency: 1496721 usec
    p95 latency: 1498086 usec
    p99 latency: 1499138 usec
    Avg HTTP time: 1491136 usec (send/recv 2621 usec + response wait 1488515 usec)
  Server: 
    Inference count: 51
    Execution count: 17
    Successful request count: 51
    Avg request latency: 1477610 usec (overhead 687 usec + queue 732393 usec + compute input 5990 usec + compute infer 738318 usec + compute output 222 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 3.999 infer/sec, latency 1490996 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3501.00
Median: 3470
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 49
    Throughput: 3.76807 infer/sec
    Avg latency: 1689319 usec (standard deviation 4266 usec)
    p50 latency: 1689245 usec
    p90 latency: 1694346 usec
    p95 latency: 1696389 usec
    p99 latency: 1698664 usec
    Avg HTTP time: 1689606 usec (send/recv 2730 usec + response wait 1686876 usec)
  Server: 
    Inference count: 54
    Execution count: 15
    Successful request count: 54
    Avg request latency: 1668927 usec (overhead 856 usec + queue 674520 usec + compute input 7975 usec + compute infer 985189 usec + compute output 387 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 3.76807 infer/sec, latency 1689319 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3509.52
Median: 3470.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 48
    Throughput: 3.99933 infer/sec
    Avg latency: 1902411 usec (standard deviation 5598 usec)
    p50 latency: 1902041 usec
    p90 latency: 1909248 usec
    p95 latency: 1913473 usec
    p99 latency: 1916993 usec
    Avg HTTP time: 1902334 usec (send/recv 2437 usec + response wait 1899897 usec)
  Server: 
    Inference count: 53
    Execution count: 13
    Successful request count: 53
    Avg request latency: 1886810 usec (overhead 951 usec + queue 870154 usec + compute input 7481 usec + compute infer 1007941 usec + compute output 283 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 3.99933 infer/sec, latency 1902411 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3502.14
Median: 3470
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 49
    Throughput: 3.76836 infer/sec
    Avg latency: 2108042 usec (standard deviation 4624 usec)
    p50 latency: 2108036 usec
    p90 latency: 2113143 usec
    p95 latency: 2114284 usec
    p99 latency: 2117521 usec
    Avg HTTP time: 2107996 usec (send/recv 2785 usec + response wait 2105211 usec)
  Server: 
    Inference count: 54
    Execution count: 12
    Successful request count: 54
    Avg request latency: 2087355 usec (overhead 872 usec + queue 1022251 usec + compute input 7280 usec + compute infer 1056680 usec + compute output 272 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 3.76836 infer/sec, latency 2108042 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3480.41
Median: 3470
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 45
    Throughput: 3.74906 infer/sec
    Avg latency: 2312440 usec (standard deviation 5099 usec)
    p50 latency: 2312190 usec
    p90 latency: 2318638 usec
    p95 latency: 2319732 usec
    p99 latency: 2327173 usec
    Avg HTTP time: 2312826 usec (send/recv 2786 usec + response wait 2310040 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 2292769 usec (overhead 873 usec + queue 1136754 usec + compute input 8221 usec + compute infer 1146647 usec + compute output 274 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 3.74906 infer/sec, latency 2312440 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3481.04
Median: 3506
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 45
    Throughput: 3.74938 infer/sec
    Avg latency: 2549692 usec (standard deviation 461525 usec)
    p50 latency: 2320209 usec
    p90 latency: 3473952 usec
    p95 latency: 3476502 usec
    p99 latency: 3479407 usec
    Avg HTTP time: 2549519 usec (send/recv 3240 usec + response wait 2546279 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 2530799 usec (overhead 1133 usec + queue 1372318 usec + compute input 8484 usec + compute infer 1148505 usec + compute output 359 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 3.74938 infer/sec, latency 2549692 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3488.16
Median: 3470
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 45
    Throughput: 3.74938 infer/sec
    Avg latency: 2774313 usec (standard deviation 563294 usec)
    p50 latency: 2320922 usec
    p90 latency: 3467380 usec
    p95 latency: 3468744 usec
    p99 latency: 3475425 usec
    Avg HTTP time: 2774457 usec (send/recv 2321 usec + response wait 2772136 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 2755690 usec (overhead 863 usec + queue 1599990 usec + compute input 6637 usec + compute infer 1147930 usec + compute output 270 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 3.74938 infer/sec, latency 2774313 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3530.77
Median: 3506.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 45
    Throughput: 3.74938 infer/sec
    Avg latency: 3011359 usec (standard deviation 565557 usec)
    p50 latency: 3467197 usec
    p90 latency: 3479857 usec
    p95 latency: 3480911 usec
    p99 latency: 3482088 usec
    Avg HTTP time: 3010756 usec (send/recv 2464 usec + response wait 3008292 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 2991460 usec (overhead 904 usec + queue 1833832 usec + compute input 7912 usec + compute infer 1148507 usec + compute output 305 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 3.74938 infer/sec, latency 3011359 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3484.87
Median: 3546.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_384000000.csv
Combined CSV file created: power_measurement_stats_freq_384000000.csv
---Setting GPU frequency to 460800000---
Returning to the default values
Model: NVIDIA Jetson Nano Developer Kit
GPU frequency set to 460800000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 50
    Throughput: 3.33289 infer/sec
    Avg latency: 299077 usec (standard deviation 1735 usec)
    p50 latency: 299101 usec
    p90 latency: 301081 usec
    p95 latency: 301973 usec
    p99 latency: 303227 usec
    Avg HTTP time: 298979 usec (send/recv 1877 usec + response wait 297102 usec)
  Server: 
    Inference count: 50
    Execution count: 50
    Successful request count: 50
    Avg request latency: 287051 usec (overhead 308 usec + queue 255 usec + compute input 414 usec + compute infer 285922 usec + compute output 152 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 3.33289 infer/sec, latency 299077 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3778.27
Median: 3779.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 51
    Throughput: 3.39955 infer/sec
    Avg latency: 582285 usec (standard deviation 1935 usec)
    p50 latency: 582439 usec
    p90 latency: 584918 usec
    p95 latency: 585535 usec
    p99 latency: 588148 usec
    Avg HTTP time: 582222 usec (send/recv 2082 usec + response wait 580140 usec)
  Server: 
    Inference count: 52
    Execution count: 52
    Successful request count: 52
    Avg request latency: 570889 usec (overhead 326 usec + queue 280001 usec + compute input 1735 usec + compute infer 288664 usec + compute output 163 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 3.39955 infer/sec, latency 582285 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3815.29
Median: 3820
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 50
    Throughput: 3.84556 infer/sec
    Avg latency: 756429 usec (standard deviation 103984 usec)
    p50 latency: 743495 usec
    p90 latency: 748892 usec
    p95 latency: 1033047 usec
    p99 latency: 1037384 usec
    Avg HTTP time: 755906 usec (send/recv 2422 usec + response wait 753484 usec)
  Server: 
    Inference count: 52
    Execution count: 36
    Successful request count: 52
    Avg request latency: 743404 usec (overhead 450 usec + queue 353745 usec + compute input 3076 usec + compute infer 385974 usec + compute output 159 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 3.84556 infer/sec, latency 756429 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3826.36
Median: 3820
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 49
    Throughput: 4.08299 infer/sec
    Avg latency: 944719 usec (standard deviation 179736 usec)
    p50 latency: 923697 usec
    p90 latency: 1216458 usec
    p95 latency: 1223442 usec
    p99 latency: 1376210 usec
    Avg HTTP time: 942852 usec (send/recv 2475 usec + response wait 940377 usec)
  Server: 
    Inference count: 51
    Execution count: 28
    Successful request count: 51
    Avg request latency: 930139 usec (overhead 626 usec + queue 435088 usec + compute input 3539 usec + compute infer 490697 usec + compute output 189 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 4.08299 infer/sec, latency 944719 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3811.82
Median: 3802.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 47
    Throughput: 4.27234 infer/sec
    Avg latency: 1092497 usec (standard deviation 163527 usec)
    p50 latency: 1080718 usec
    p90 latency: 1345733 usec
    p95 latency: 1524609 usec
    p99 latency: 1533714 usec
    Avg HTTP time: 1091598 usec (send/recv 2442 usec + response wait 1089156 usec)
  Server: 
    Inference count: 50
    Execution count: 21
    Successful request count: 50
    Avg request latency: 1076445 usec (overhead 536 usec + queue 540150 usec + compute input 4182 usec + compute infer 531389 usec + compute output 188 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 4.27234 infer/sec, latency 1092497 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3792.50
Median: 3741.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 51
    Throughput: 4.6351 infer/sec
    Avg latency: 1262231 usec (standard deviation 3456 usec)
    p50 latency: 1262165 usec
    p90 latency: 1265571 usec
    p95 latency: 1268656 usec
    p99 latency: 1271287 usec
    Avg HTTP time: 1262328 usec (send/recv 2856 usec + response wait 1259472 usec)
  Server: 
    Inference count: 54
    Execution count: 18
    Successful request count: 54
    Avg request latency: 1248386 usec (overhead 705 usec + queue 617770 usec + compute input 5558 usec + compute infer 624110 usec + compute output 243 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 4.6351 infer/sec, latency 1262231 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3790.27
Median: 3802.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 49
    Throughput: 4.45374 infer/sec
    Avg latency: 1440168 usec (standard deviation 2866 usec)
    p50 latency: 1440113 usec
    p90 latency: 1443265 usec
    p95 latency: 1443739 usec
    p99 latency: 1447586 usec
    Avg HTTP time: 1440060 usec (send/recv 2976 usec + response wait 1437084 usec)
  Server: 
    Inference count: 52
    Execution count: 15
    Successful request count: 52
    Avg request latency: 1422001 usec (overhead 769 usec + queue 695505 usec + compute input 7820 usec + compute infer 717622 usec + compute output 285 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 4.45374 infer/sec, latency 1440168 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3782.97
Median: 3782.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 48
    Throughput: 4.79904 infer/sec
    Avg latency: 1609470 usec (standard deviation 2846 usec)
    p50 latency: 1609652 usec
    p90 latency: 1613315 usec
    p95 latency: 1613761 usec
    p99 latency: 1614285 usec
    Avg HTTP time: 1609499 usec (send/recv 2170 usec + response wait 1607329 usec)
  Server: 
    Inference count: 53
    Execution count: 13
    Successful request count: 53
    Avg request latency: 1589268 usec (overhead 1262 usec + queue 729413 usec + compute input 7369 usec + compute infer 850945 usec + compute output 279 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 4.79904 infer/sec, latency 1609470 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3781.04
Median: 3779
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 49
    Throughput: 4.45333 infer/sec
    Avg latency: 1786343 usec (standard deviation 5052 usec)
    p50 latency: 1786507 usec
    p90 latency: 1793385 usec
    p95 latency: 1795559 usec
    p99 latency: 1798422 usec
    Avg HTTP time: 1786877 usec (send/recv 2524 usec + response wait 1784353 usec)
  Server: 
    Inference count: 54
    Execution count: 12
    Successful request count: 54
    Avg request latency: 1769850 usec (overhead 982 usec + queue 867185 usec + compute input 8116 usec + compute infer 893232 usec + compute output 335 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 4.45333 infer/sec, latency 1786343 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3762.06
Median: 3779
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 45
    Throughput: 4.4991 infer/sec
    Avg latency: 1956021 usec (standard deviation 3577 usec)
    p50 latency: 1955740 usec
    p90 latency: 1961827 usec
    p95 latency: 1962293 usec
    p99 latency: 1964506 usec
    Avg HTTP time: 1955806 usec (send/recv 2577 usec + response wait 1953229 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1934084 usec (overhead 1000 usec + queue 956733 usec + compute input 7626 usec + compute infer 968419 usec + compute output 306 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 4.4991 infer/sec, latency 1956021 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3784.68
Median: 3785.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 45
    Throughput: 4.4991 infer/sec
    Avg latency: 2151158 usec (standard deviation 388371 usec)
    p50 latency: 1957892 usec
    p90 latency: 2926404 usec
    p95 latency: 2927901 usec
    p99 latency: 2935045 usec
    Avg HTTP time: 2150888 usec (send/recv 2547 usec + response wait 2148341 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 2129101 usec (overhead 919 usec + queue 1151690 usec + compute input 8313 usec + compute infer 967868 usec + compute output 311 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 4.4991 infer/sec, latency 2151158 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3789.14
Median: 3744.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 45
    Throughput: 4.4991 infer/sec
    Avg latency: 2344390 usec (standard deviation 476576 usec)
    p50 latency: 1961101 usec
    p90 latency: 2930622 usec
    p95 latency: 2932568 usec
    p99 latency: 2937636 usec
    Avg HTTP time: 2344648 usec (send/recv 2562 usec + response wait 2342086 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 2327372 usec (overhead 961 usec + queue 1350587 usec + compute input 7528 usec + compute infer 967979 usec + compute output 317 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 4.4991 infer/sec, latency 2344390 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3759.98
Median: 3744.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 45
    Throughput: 4.4991 infer/sec
    Avg latency: 2541969 usec (standard deviation 477169 usec)
    p50 latency: 2923484 usec
    p90 latency: 2936655 usec
    p95 latency: 2943373 usec
    p99 latency: 2948380 usec
    Avg HTTP time: 2542156 usec (send/recv 2336 usec + response wait 2539820 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 2525777 usec (overhead 2017 usec + queue 1548730 usec + compute input 6662 usec + compute infer 968045 usec + compute output 323 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 4.4991 infer/sec, latency 2541969 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3761.12
Median: 3785
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_460800000.csv
Combined CSV file created: power_measurement_stats_freq_460800000.csv
---Setting GPU frequency to 537600000---
Returning to the default values
Model: NVIDIA Jetson Nano Developer Kit
GPU frequency set to 537600000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 52
    Throughput: 3.71376 infer/sec
    Avg latency: 264996 usec (standard deviation 1484 usec)
    p50 latency: 265054 usec
    p90 latency: 266841 usec
    p95 latency: 267421 usec
    p99 latency: 268516 usec
    Avg HTTP time: 264902 usec (send/recv 1806 usec + response wait 263096 usec)
  Server: 
    Inference count: 53
    Execution count: 53
    Successful request count: 53
    Avg request latency: 253177 usec (overhead 297 usec + queue 256 usec + compute input 431 usec + compute infer 252041 usec + compute output 152 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 3.71376 infer/sec, latency 264996 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3997.07
Median: 4017.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 49
    Throughput: 3.76894 infer/sec
    Avg latency: 513728 usec (standard deviation 1603 usec)
    p50 latency: 513611 usec
    p90 latency: 515334 usec
    p95 latency: 516748 usec
    p99 latency: 518428 usec
    Avg HTTP time: 513622 usec (send/recv 2040 usec + response wait 511582 usec)
  Server: 
    Inference count: 50
    Execution count: 50
    Successful request count: 50
    Avg request latency: 502682 usec (overhead 306 usec + queue 246129 usec + compute input 1627 usec + compute infer 254461 usec + compute output 159 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 3.76894 infer/sec, latency 513728 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4106.25
Median: 4098
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 48
    Throughput: 4.36324 infer/sec
    Avg latency: 659106 usec (standard deviation 72466 usec)
    p50 latency: 651703 usec
    p90 latency: 654682 usec
    p95 latency: 907519 usec
    p99 latency: 908804 usec
    Avg HTTP time: 658740 usec (send/recv 2405 usec + response wait 656335 usec)
  Server: 
    Inference count: 50
    Execution count: 34
    Successful request count: 50
    Avg request latency: 645468 usec (overhead 444 usec + queue 300659 usec + compute input 2608 usec + compute infer 341568 usec + compute output 189 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 4.36324 infer/sec, latency 659106 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4060.75
Median: 4057
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 50
    Throughput: 4.54463 infer/sec
    Avg latency: 817096 usec (standard deviation 146534 usec)
    p50 latency: 807206 usec
    p90 latency: 1063975 usec
    p95 latency: 1069352 usec
    p99 latency: 1207574 usec
    Avg HTTP time: 823692 usec (send/recv 2618 usec + response wait 821074 usec)
  Server: 
    Inference count: 54
    Execution count: 30
    Successful request count: 54
    Avg request latency: 810752 usec (overhead 624 usec + queue 382468 usec + compute input 3617 usec + compute infer 423845 usec + compute output 198 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 4.54463 infer/sec, latency 817096 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4049.85
Median: 4037.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 47
    Throughput: 4.69953 infer/sec
    Avg latency: 988355 usec (standard deviation 213379 usec)
    p50 latency: 951802 usec
    p90 latency: 1224437 usec
    p95 latency: 1340007 usec
    p99 latency: 1368364 usec
    Avg HTTP time: 1001430 usec (send/recv 2512 usec + response wait 998918 usec)
  Server: 
    Inference count: 52
    Execution count: 24
    Successful request count: 52
    Avg request latency: 986882 usec (overhead 563 usec + queue 462031 usec + compute input 4450 usec + compute infer 519605 usec + compute output 233 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 4.69953 infer/sec, latency 988355 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4031.45
Median: 4074.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 51
    Throughput: 5.09898 infer/sec
    Avg latency: 1099896 usec (standard deviation 5418 usec)
    p50 latency: 1099598 usec
    p90 latency: 1105402 usec
    p95 latency: 1109507 usec
    p99 latency: 1111874 usec
    Avg HTTP time: 1100024 usec (send/recv 2486 usec + response wait 1097538 usec)
  Server: 
    Inference count: 54
    Execution count: 18
    Successful request count: 54
    Avg request latency: 1086397 usec (overhead 804 usec + queue 536696 usec + compute input 5612 usec + compute infer 543066 usec + compute output 219 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 5.09898 infer/sec, latency 1099896 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4043.76
Median: 4074.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 49
    Throughput: 4.89853 infer/sec
    Avg latency: 1261268 usec (standard deviation 2112 usec)
    p50 latency: 1261319 usec
    p90 latency: 1263304 usec
    p95 latency: 1265072 usec
    p99 latency: 1266365 usec
    Avg HTTP time: 1261031 usec (send/recv 2730 usec + response wait 1258301 usec)
  Server: 
    Inference count: 52
    Execution count: 15
    Successful request count: 52
    Avg request latency: 1242315 usec (overhead 798 usec + queue 606051 usec + compute input 6727 usec + compute infer 628460 usec + compute output 279 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 4.89853 infer/sec, latency 1261268 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3995.06
Median: 3959.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 48
    Throughput: 5.33215 infer/sec
    Avg latency: 1404806 usec (standard deviation 4790 usec)
    p50 latency: 1405851 usec
    p90 latency: 1411198 usec
    p95 latency: 1412917 usec
    p99 latency: 1415453 usec
    Avg HTTP time: 1405104 usec (send/recv 2474 usec + response wait 1402630 usec)
  Server: 
    Inference count: 53
    Execution count: 13
    Successful request count: 53
    Avg request latency: 1387078 usec (overhead 1305 usec + queue 636488 usec + compute input 7356 usec + compute infer 741663 usec + compute output 266 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 5.33215 infer/sec, latency 1404806 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4037.77
Median: 4017
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 45
    Throughput: 4.99889 infer/sec
    Avg latency: 1559297 usec (standard deviation 4452 usec)
    p50 latency: 1560210 usec
    p90 latency: 1564897 usec
    p95 latency: 1566851 usec
    p99 latency: 1569345 usec
    Avg HTTP time: 1559818 usec (send/recv 3096 usec + response wait 1556722 usec)
  Server: 
    Inference count: 50
    Execution count: 11
    Successful request count: 50
    Avg request latency: 1541775 usec (overhead 837 usec + queue 747999 usec + compute input 6943 usec + compute infer 785679 usec + compute output 317 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 4.99889 infer/sec, latency 1559297 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4024.12
Median: 4017
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 45
    Throughput: 5.62359 infer/sec
    Avg latency: 1702968 usec (standard deviation 3211 usec)
    p50 latency: 1702668 usec
    p90 latency: 1707216 usec
    p95 latency: 1709240 usec
    p99 latency: 1710000 usec
    Avg HTTP time: 1703124 usec (send/recv 2859 usec + response wait 1700265 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1683247 usec (overhead 1487 usec + queue 831977 usec + compute input 7350 usec + compute infer 842161 usec + compute output 272 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 5.62359 infer/sec, latency 1702968 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4029.16
Median: 4017
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 45
    Throughput: 4.99944 infer/sec
    Avg latency: 1877660 usec (standard deviation 338202 usec)
    p50 latency: 1710412 usec
    p90 latency: 2552641 usec
    p95 latency: 2554967 usec
    p99 latency: 2563191 usec
    Avg HTTP time: 1877648 usec (send/recv 2216 usec + response wait 1875432 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1858728 usec (overhead 1934 usec + queue 1005856 usec + compute input 7532 usec + compute infer 842992 usec + compute output 414 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 4.99944 infer/sec, latency 1877660 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4036.15
Median: 4091
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 45
    Throughput: 4.99944 infer/sec
    Avg latency: 2043492 usec (standard deviation 412909 usec)
    p50 latency: 1709334 usec
    p90 latency: 2551068 usec
    p95 latency: 2552582 usec
    p99 latency: 2554181 usec
    Avg HTTP time: 2043814 usec (send/recv 2268 usec + response wait 2041546 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 2020365 usec (overhead 990 usec + queue 1169169 usec + compute input 8023 usec + compute infer 841864 usec + compute output 319 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 4.99944 infer/sec, latency 2043492 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4060.60
Median: 4057
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 40
    Throughput: 4.99875 infer/sec
    Avg latency: 2212636 usec (standard deviation 415788 usec)
    p50 latency: 2548064 usec
    p90 latency: 2554949 usec
    p95 latency: 2557439 usec
    p99 latency: 2562219 usec
    Avg HTTP time: 2212079 usec (send/recv 2290 usec + response wait 2209789 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 2193230 usec (overhead 819 usec + queue 1342614 usec + compute input 7528 usec + compute infer 841978 usec + compute output 291 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 4.99875 infer/sec, latency 2212636 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4078.25
Median: 4098
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_537600000.csv
Combined CSV file created: power_measurement_stats_freq_537600000.csv
---Setting GPU frequency to 614400000---
Returning to the default values
Model: NVIDIA Jetson Nano Developer Kit
GPU frequency set to 614400000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 50
    Throughput: 4.16632 infer/sec
    Avg latency: 238438 usec (standard deviation 1905 usec)
    p50 latency: 238213 usec
    p90 latency: 241346 usec
    p95 latency: 242061 usec
    p99 latency: 242857 usec
    Avg HTTP time: 238379 usec (send/recv 1658 usec + response wait 236721 usec)
  Server: 
    Inference count: 50
    Execution count: 50
    Successful request count: 50
    Avg request latency: 227110 usec (overhead 272 usec + queue 252 usec + compute input 428 usec + compute infer 226020 usec + compute output 138 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 4.16632 infer/sec, latency 238438 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4445.40
Median: 4449.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 51
    Throughput: 4.24965 infer/sec
    Avg latency: 460943 usec (standard deviation 1746 usec)
    p50 latency: 460917 usec
    p90 latency: 463184 usec
    p95 latency: 463834 usec
    p99 latency: 465047 usec
    Avg HTTP time: 460889 usec (send/recv 1987 usec + response wait 458902 usec)
  Server: 
    Inference count: 52
    Execution count: 52
    Successful request count: 52
    Avg request latency: 450165 usec (overhead 312 usec + queue 219940 usec + compute input 1523 usec + compute infer 228255 usec + compute output 135 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 4.24965 infer/sec, latency 460943 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4525.91
Median: 4523
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 51
    Throughput: 5.09949 infer/sec
    Avg latency: 586056 usec (standard deviation 36232 usec)
    p50 latency: 583948 usec
    p90 latency: 586721 usec
    p95 latency: 588323 usec
    p99 latency: 812851 usec
    Avg HTTP time: 585954 usec (send/recv 2319 usec + response wait 583635 usec)
  Server: 
    Inference count: 52
    Execution count: 35
    Successful request count: 52
    Avg request latency: 572372 usec (overhead 425 usec + queue 262075 usec + compute input 2712 usec + compute infer 306982 usec + compute output 178 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 5.09949 infer/sec, latency 586056 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4527.95
Median: 4523
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 53
    Throughput: 5.29947 infer/sec
    Avg latency: 712067 usec (standard deviation 91116 usec)
    p50 latency: 706228 usec
    p90 latency: 720245 usec
    p95 latency: 723372 usec
    p99 latency: 1071052 usec
    Avg HTTP time: 720457 usec (send/recv 2643 usec + response wait 717814 usec)
  Server: 
    Inference count: 56
    Execution count: 29
    Successful request count: 56
    Avg request latency: 706371 usec (overhead 543 usec + queue 342695 usec + compute input 3876 usec + compute infer 359072 usec + compute output 185 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 5.29947 infer/sec, latency 712067 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4482.10
Median: 4502.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 54
    Throughput: 5.39892 infer/sec
    Avg latency: 871594 usec (standard deviation 135157 usec)
    p50 latency: 845601 usec
    p90 latency: 1081788 usec
    p95 latency: 1211139 usec
    p99 latency: 1213444 usec
    Avg HTTP time: 863782 usec (send/recv 2350 usec + response wait 861432 usec)
  Server: 
    Inference count: 57
    Execution count: 24
    Successful request count: 57
    Avg request latency: 847923 usec (overhead 631 usec + queue 394620 usec + compute input 5148 usec + compute infer 447308 usec + compute output 216 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 5.39892 infer/sec, latency 871594 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4488.51
Median: 4482.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 52
    Throughput: 5.77649 infer/sec
    Avg latency: 1000520 usec (standard deviation 188055 usec)
    p50 latency: 986857 usec
    p90 latency: 1339067 usec
    p95 latency: 1342598 usec
    p99 latency: 1479255 usec
    Avg HTTP time: 1004192 usec (send/recv 2710 usec + response wait 1001482 usec)
  Server: 
    Inference count: 54
    Execution count: 20
    Successful request count: 54
    Avg request latency: 988399 usec (overhead 938 usec + queue 456937 usec + compute input 6130 usec + compute infer 524130 usec + compute output 264 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 5.77649 infer/sec, latency 1000520 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4473.16
Median: 4408.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 45
    Throughput: 5.62359 infer/sec
    Avg latency: 1155398 usec (standard deviation 215437 usec)
    p50 latency: 1125330 usec
    p90 latency: 1480161 usec
    p95 latency: 1481845 usec
    p99 latency: 1595007 usec
    Avg HTTP time: 1141101 usec (send/recv 2399 usec + response wait 1138702 usec)
  Server: 
    Inference count: 50
    Execution count: 16
    Successful request count: 50
    Avg request latency: 1123952 usec (overhead 784 usec + queue 561788 usec + compute input 6767 usec + compute infer 554298 usec + compute output 315 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 5.62359 infer/sec, latency 1155398 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4475.80
Median: 4482.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 48
    Throughput: 5.99925 infer/sec
    Avg latency: 1267621 usec (standard deviation 4613 usec)
    p50 latency: 1268372 usec
    p90 latency: 1273248 usec
    p95 latency: 1274182 usec
    p99 latency: 1280049 usec
    Avg HTTP time: 1267473 usec (send/recv 2420 usec + response wait 1265053 usec)
  Server: 
    Inference count: 52
    Execution count: 13
    Successful request count: 52
    Avg request latency: 1246629 usec (overhead 886 usec + queue 613196 usec + compute input 7983 usec + compute infer 624265 usec + compute output 299 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 5.99925 infer/sec, latency 1267621 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4405.56
Median: 4401
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 45
    Throughput: 5.61938 infer/sec
    Avg latency: 1385806 usec (standard deviation 4731 usec)
    p50 latency: 1386211 usec
    p90 latency: 1392350 usec
    p95 latency: 1393029 usec
    p99 latency: 1393949 usec
    Avg HTTP time: 1386259 usec (send/recv 2392 usec + response wait 1383867 usec)
  Server: 
    Inference count: 50
    Execution count: 11
    Successful request count: 50
    Avg request latency: 1366311 usec (overhead 934 usec + queue 661292 usec + compute input 7561 usec + compute infer 696247 usec + compute output 277 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 5.61938 infer/sec, latency 1385806 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4437.30
Median: 4408.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 45
    Throughput: 6.42765 infer/sec
    Avg latency: 1508480 usec (standard deviation 3105 usec)
    p50 latency: 1508145 usec
    p90 latency: 1513588 usec
    p95 latency: 1514036 usec
    p99 latency: 1515867 usec
    Avg HTTP time: 1508535 usec (send/recv 2218 usec + response wait 1506317 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1485092 usec (overhead 1110 usec + queue 731127 usec + compute input 8045 usec + compute infer 744417 usec + compute output 393 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 6.42765 infer/sec, latency 1508480 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4481.57
Median: 4482
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 40
    Throughput: 5.71347 infer/sec
    Avg latency: 1657914 usec (standard deviation 298703 usec)
    p50 latency: 1510952 usec
    p90 latency: 2250001 usec
    p95 latency: 2260010 usec
    p99 latency: 2266966 usec
    Avg HTTP time: 1658045 usec (send/recv 2271 usec + response wait 1655774 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1641653 usec (overhead 956 usec + queue 888326 usec + compute input 7511 usec + compute infer 744501 usec + compute output 359 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 5.71347 infer/sec, latency 1657914 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4461.43
Median: 4442.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 40
    Throughput: 5.71265 infer/sec
    Avg latency: 1807335 usec (standard deviation 367027 usec)
    p50 latency: 1512387 usec
    p90 latency: 2259852 usec
    p95 latency: 2262750 usec
    p99 latency: 2266123 usec
    Avg HTTP time: 1808459 usec (send/recv 2237 usec + response wait 1806222 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1791201 usec (overhead 1486 usec + queue 1038338 usec + compute input 7295 usec + compute infer 743791 usec + compute output 291 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 5.71265 infer/sec, latency 1807335 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4454.52
Median: 4425.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 40
    Throughput: 5.71265 infer/sec
    Avg latency: 1965769 usec (standard deviation 368956 usec)
    p50 latency: 2262003 usec
    p90 latency: 2271866 usec
    p95 latency: 2275144 usec
    p99 latency: 2277540 usec
    Avg HTTP time: 1964408 usec (send/recv 2265 usec + response wait 1962143 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1945579 usec (overhead 1035 usec + queue 1190745 usec + compute input 9130 usec + compute infer 744382 usec + compute output 287 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 5.71265 infer/sec, latency 1965769 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4474.06
Median: 4449.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_614400000.csv
Combined CSV file created: power_measurement_stats_freq_614400000.csv
---Setting GPU frequency to 691200000---
Returning to the default values
Model: NVIDIA Jetson Nano Developer Kit
GPU frequency set to 691200000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 54
    Throughput: 4.49962 infer/sec
    Avg latency: 220684 usec (standard deviation 1737 usec)
    p50 latency: 220758 usec
    p90 latency: 222996 usec
    p95 latency: 223328 usec
    p99 latency: 223347 usec
    Avg HTTP time: 220629 usec (send/recv 1689 usec + response wait 218940 usec)
  Server: 
    Inference count: 54
    Execution count: 54
    Successful request count: 54
    Avg request latency: 209216 usec (overhead 292 usec + queue 251 usec + compute input 454 usec + compute infer 208068 usec + compute output 151 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 4.49962 infer/sec, latency 220684 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4727.01
Median: 4717
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 51
    Throughput: 4.63594 infer/sec
    Avg latency: 425166 usec (standard deviation 1467 usec)
    p50 latency: 425080 usec
    p90 latency: 426494 usec
    p95 latency: 428578 usec
    p99 latency: 429075 usec
    Avg HTTP time: 425088 usec (send/recv 2016 usec + response wait 423072 usec)
  Server: 
    Inference count: 52
    Execution count: 52
    Successful request count: 52
    Avg request latency: 414169 usec (overhead 299 usec + queue 201814 usec + compute input 1407 usec + compute infer 210492 usec + compute output 157 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 4.63594 infer/sec, latency 425166 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4826.10
Median: 4798
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 53
    Throughput: 5.29947 infer/sec
    Avg latency: 543589 usec (standard deviation 65179 usec)
    p50 latency: 535776 usec
    p90 latency: 539262 usec
    p95 latency: 745394 usec
    p99 latency: 748292 usec
    Avg HTTP time: 543266 usec (send/recv 2259 usec + response wait 541007 usec)
  Server: 
    Inference count: 55
    Execution count: 38
    Successful request count: 55
    Avg request latency: 530667 usec (overhead 393 usec + queue 250110 usec + compute input 2500 usec + compute infer 277495 usec + compute output 169 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 5.29947 infer/sec, latency 543589 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4823.73
Median: 4830
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 51
    Throughput: 5.66541 infer/sec
    Avg latency: 673702 usec (standard deviation 116889 usec)
    p50 latency: 648503 usec
    p90 latency: 860452 usec
    p95 latency: 980159 usec
    p99 latency: 985345 usec
    Avg HTTP time: 673291 usec (send/recv 2750 usec + response wait 670541 usec)
  Server: 
    Inference count: 52
    Execution count: 28
    Successful request count: 52
    Avg request latency: 659374 usec (overhead 521 usec + queue 320310 usec + compute input 3469 usec + compute infer 334883 usec + compute output 191 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 5.66541 infer/sec, latency 673702 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4869.24
Median: 4870
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 47
    Throughput: 5.87353 infer/sec
    Avg latency: 812793 usec (standard deviation 171604 usec)
    p50 latency: 777764 usec
    p90 latency: 1001346 usec
    p95 latency: 1111756 usec
    p99 latency: 1112900 usec
    Avg HTTP time: 803798 usec (send/recv 2483 usec + response wait 801315 usec)
  Server: 
    Inference count: 50
    Execution count: 23
    Successful request count: 50
    Avg request latency: 787611 usec (overhead 667 usec + queue 377274 usec + compute input 4820 usec + compute infer 404615 usec + compute output 235 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 5.87353 infer/sec, latency 812793 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4891.96
Median: 4886.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 45
    Throughput: 5.6243 infer/sec
    Avg latency: 939312 usec (standard deviation 220054 usec)
    p50 latency: 906628 usec
    p90 latency: 1219566 usec
    p95 latency: 1227144 usec
    p99 latency: 1227602 usec
    Avg HTTP time: 951597 usec (send/recv 2721 usec + response wait 948876 usec)
  Server: 
    Inference count: 51
    Execution count: 21
    Successful request count: 51
    Avg request latency: 936604 usec (overhead 814 usec + queue 402872 usec + compute input 5297 usec + compute infer 527353 usec + compute output 268 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 5.6243 infer/sec, latency 939312 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4858.91
Median: 4830.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 47
    Throughput: 5.87427 infer/sec
    Avg latency: 1036145 usec (standard deviation 204875 usec)
    p50 latency: 1022243 usec
    p90 latency: 1231362 usec
    p95 latency: 1332319 usec
    p99 latency: 1471097 usec
    Avg HTTP time: 1043357 usec (send/recv 2656 usec + response wait 1040701 usec)
  Server: 
    Inference count: 54
    Execution count: 18
    Successful request count: 54
    Avg request latency: 1024355 usec (overhead 677 usec + queue 513109 usec + compute input 5733 usec + compute infer 504554 usec + compute output 282 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 5.87427 infer/sec, latency 1036145 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4894.66
Median: 4890.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 52
    Throughput: 6.49756 infer/sec
    Avg latency: 1156631 usec (standard deviation 3677 usec)
    p50 latency: 1156987 usec
    p90 latency: 1161544 usec
    p95 latency: 1162016 usec
    p99 latency: 1163756 usec
    Avg HTTP time: 1156763 usec (send/recv 2676 usec + response wait 1154087 usec)
  Server: 
    Inference count: 56
    Execution count: 14
    Successful request count: 56
    Avg request latency: 1137856 usec (overhead 806 usec + queue 559751 usec + compute input 7157 usec + compute infer 569850 usec + compute output 292 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 6.49756 infer/sec, latency 1156631 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4832.63
Median: 4830
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 54
    Throughput: 6.74831 infer/sec
    Avg latency: 1265116 usec (standard deviation 3336 usec)
    p50 latency: 1265720 usec
    p90 latency: 1268698 usec
    p95 latency: 1268992 usec
    p99 latency: 1271821 usec
    Avg HTTP time: 1264832 usec (send/recv 2617 usec + response wait 1262215 usec)
  Server: 
    Inference count: 58
    Execution count: 13
    Successful request count: 58
    Avg request latency: 1242868 usec (overhead 785 usec + queue 608918 usec + compute input 7393 usec + compute infer 625501 usec + compute output 271 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 6.74831 infer/sec, latency 1265116 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4881.08
Median: 4830
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 45
    Throughput: 6.42765 infer/sec
    Avg latency: 1379003 usec (standard deviation 7179 usec)
    p50 latency: 1379047 usec
    p90 latency: 1386685 usec
    p95 latency: 1392532 usec
    p99 latency: 1394874 usec
    Avg HTTP time: 1379373 usec (send/recv 3040 usec + response wait 1376333 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1360223 usec (overhead 1131 usec + queue 670857 usec + compute input 8416 usec + compute infer 679467 usec + compute output 352 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 6.42765 infer/sec, latency 1379003 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4926.63
Median: 4903.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 45
    Throughput: 6.42765 infer/sec
    Avg latency: 1514293 usec (standard deviation 272097 usec)
    p50 latency: 1381269 usec
    p90 latency: 2060626 usec
    p95 latency: 2065824 usec
    p99 latency: 2068204 usec
    Avg HTTP time: 1514674 usec (send/recv 2386 usec + response wait 1512288 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1490696 usec (overhead 864 usec + queue 802419 usec + compute input 8805 usec + compute infer 678296 usec + compute output 312 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 6.42765 infer/sec, latency 1514293 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4932.04
Median: 4943
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 45
    Throughput: 6.42765 infer/sec
    Avg latency: 1647211 usec (standard deviation 332649 usec)
    p50 latency: 1380522 usec
    p90 latency: 2060226 usec
    p95 latency: 2062385 usec
    p99 latency: 2065674 usec
    Avg HTTP time: 1647943 usec (send/recv 2310 usec + response wait 1645633 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1627156 usec (overhead 985 usec + queue 940441 usec + compute input 7678 usec + compute infer 677648 usec + compute output 404 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 6.42765 infer/sec, latency 1647211 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4928.48
Median: 4943
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 45
    Throughput: 6.42765 infer/sec
    Avg latency: 1788464 usec (standard deviation 332981 usec)
    p50 latency: 2056868 usec
    p90 latency: 2063748 usec
    p95 latency: 2065869 usec
    p99 latency: 2070351 usec
    Avg HTTP time: 1788245 usec (send/recv 2099 usec + response wait 1786146 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1766882 usec (overhead 822 usec + queue 1079369 usec + compute input 7778 usec + compute infer 678613 usec + compute output 300 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 6.42765 infer/sec, latency 1788464 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4935.54
Median: 4923.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_691200000.csv
Combined CSV file created: power_measurement_stats_freq_691200000.csv
---Setting GPU frequency to 768000000---
Returning to the default values
Model: NVIDIA Jetson Nano Developer Kit
GPU frequency set to 768000000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 54
    Throughput: 4.90864 infer/sec
    Avg latency: 202581 usec (standard deviation 1884 usec)
    p50 latency: 202641 usec
    p90 latency: 204681 usec
    p95 latency: 205113 usec
    p99 latency: 205139 usec
    Avg HTTP time: 202529 usec (send/recv 1561 usec + response wait 200968 usec)
  Server: 
    Inference count: 54
    Execution count: 54
    Successful request count: 54
    Avg request latency: 191620 usec (overhead 272 usec + queue 258 usec + compute input 413 usec + compute infer 190539 usec + compute output 138 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 4.90864 infer/sec, latency 202581 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5273.20
Median: 5328
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 50
    Throughput: 4.9995 infer/sec
    Avg latency: 389905 usec (standard deviation 1085 usec)
    p50 latency: 389988 usec
    p90 latency: 391017 usec
    p95 latency: 391598 usec
    p99 latency: 392945 usec
    Avg HTTP time: 389803 usec (send/recv 1930 usec + response wait 387873 usec)
  Server: 
    Inference count: 51
    Execution count: 51
    Successful request count: 51
    Avg request latency: 378996 usec (overhead 259 usec + queue 184301 usec + compute input 1467 usec + compute infer 192851 usec + compute output 118 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 4.9995 infer/sec, latency 389905 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5421.71
Median: 5400
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 53
    Throughput: 5.88823 infer/sec
    Avg latency: 491760 usec (standard deviation 29708 usec)
    p50 latency: 490372 usec
    p90 latency: 492102 usec
    p95 latency: 492293 usec
    p99 latency: 492469 usec
    Avg HTTP time: 491558 usec (send/recv 2234 usec + response wait 489324 usec)
  Server: 
    Inference count: 55
    Execution count: 37
    Successful request count: 55
    Avg request latency: 478392 usec (overhead 415 usec + queue 218554 usec + compute input 2676 usec + compute infer 256588 usec + compute output 159 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 5.88823 infer/sec, latency 491760 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5421.28
Median: 5400
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 50
    Throughput: 6.24922 infer/sec
    Avg latency: 634191 usec (standard deviation 131130 usec)
    p50 latency: 602741 usec
    p90 latency: 796764 usec
    p95 latency: 799355 usec
    p99 latency: 802337 usec
    Avg HTTP time: 633557 usec (send/recv 2544 usec + response wait 631013 usec)
  Server: 
    Inference count: 51
    Execution count: 29
    Successful request count: 51
    Avg request latency: 621167 usec (overhead 572 usec + queue 290807 usec + compute input 3248 usec + compute infer 326336 usec + compute output 204 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 6.24922 infer/sec, latency 634191 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5459.77
Median: 5440.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 52
    Throughput: 6.49919 infer/sec
    Avg latency: 735423 usec (standard deviation 158296 usec)
    p50 latency: 720333 usec
    p90 latency: 916762 usec
    p95 latency: 920910 usec
    p99 latency: 1017155 usec
    Avg HTTP time: 729934 usec (send/recv 2259 usec + response wait 727675 usec)
  Server: 
    Inference count: 54
    Execution count: 25
    Successful request count: 54
    Avg request latency: 714876 usec (overhead 528 usec + queue 329437 usec + compute input 3996 usec + compute infer 380698 usec + compute output 217 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 6.49919 infer/sec, latency 735423 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5387.47
Median: 5368.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 47
    Throughput: 6.71429 infer/sec
    Avg latency: 841857 usec (standard deviation 153452 usec)
    p50 latency: 821252 usec
    p90 latency: 1106243 usec
    p95 latency: 1116855 usec
    p99 latency: 1225783 usec
    Avg HTTP time: 834608 usec (send/recv 2425 usec + response wait 832183 usec)
  Server: 
    Inference count: 52
    Execution count: 19
    Successful request count: 52
    Avg request latency: 817355 usec (overhead 603 usec + queue 413889 usec + compute input 5514 usec + compute infer 397088 usec + compute output 261 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 6.71429 infer/sec, latency 841857 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5414.13
Median: 5400.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 49
    Throughput: 6.998 infer/sec
    Avg latency: 952371 usec (standard deviation 174079 usec)
    p50 latency: 935696 usec
    p90 latency: 1208650 usec
    p95 latency: 1215523 usec
    p99 latency: 1340572 usec
    Avg HTTP time: 951316 usec (send/recv 2604 usec + response wait 948712 usec)
  Server: 
    Inference count: 52
    Execution count: 16
    Successful request count: 52
    Avg request latency: 934344 usec (overhead 717 usec + queue 459523 usec + compute input 6348 usec + compute infer 467494 usec + compute output 262 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 6.998 infer/sec, latency 952371 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5427.47
Median: 5380.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 52
    Throughput: 7.42645 infer/sec
    Avg latency: 1051040 usec (standard deviation 5338 usec)
    p50 latency: 1051674 usec
    p90 latency: 1057272 usec
    p95 latency: 1057668 usec
    p99 latency: 1062546 usec
    Avg HTTP time: 1051149 usec (send/recv 2313 usec + response wait 1048836 usec)
  Server: 
    Inference count: 56
    Execution count: 14
    Successful request count: 56
    Avg request latency: 1036198 usec (overhead 616 usec + queue 512226 usec + compute input 6207 usec + compute infer 516933 usec + compute output 216 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 7.42645 infer/sec, latency 1051040 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5395.09
Median: 5400
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 50
    Throughput: 7.14082 infer/sec
    Avg latency: 1149281 usec (standard deviation 5338 usec)
    p50 latency: 1148764 usec
    p90 latency: 1157763 usec
    p95 latency: 1158617 usec
    p99 latency: 1159516 usec
    Avg HTTP time: 1149247 usec (send/recv 2350 usec + response wait 1146897 usec)
  Server: 
    Inference count: 54
    Execution count: 12
    Successful request count: 54
    Avg request latency: 1133057 usec (overhead 726 usec + queue 554310 usec + compute input 6187 usec + compute infer 571594 usec + compute output 240 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 7.14082 infer/sec, latency 1149281 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5493.53
Median: 5480
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 45
    Throughput: 7.49875 infer/sec
    Avg latency: 1248633 usec (standard deviation 4384 usec)
    p50 latency: 1249181 usec
    p90 latency: 1255174 usec
    p95 latency: 1255917 usec
    p99 latency: 1258825 usec
    Avg HTTP time: 1248626 usec (send/recv 2675 usec + response wait 1245951 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1228234 usec (overhead 938 usec + queue 604274 usec + compute input 8072 usec + compute infer 614638 usec + compute output 312 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 7.49875 infer/sec, latency 1248633 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5511.66
Median: 5480
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 40
    Throughput: 6.66667 infer/sec
    Avg latency: 1371671 usec (standard deviation 247437 usec)
    p50 latency: 1250149 usec
    p90 latency: 1866695 usec
    p95 latency: 1867702 usec
    p99 latency: 1872549 usec
    Avg HTTP time: 1372779 usec (send/recv 2568 usec + response wait 1370211 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1356821 usec (overhead 2082 usec + queue 733341 usec + compute input 6998 usec + compute infer 614086 usec + compute output 314 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 6.66667 infer/sec, latency 1371671 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5499.72
Median: 5515.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 40
    Throughput: 6.66556 infer/sec
    Avg latency: 1503062 usec (standard deviation 304285 usec)
    p50 latency: 1259483 usec
    p90 latency: 1877868 usec
    p95 latency: 1879516 usec
    p99 latency: 1882374 usec
    Avg HTTP time: 1503268 usec (send/recv 2283 usec + response wait 1500985 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1487560 usec (overhead 2021 usec + queue 861818 usec + compute input 8817 usec + compute infer 614486 usec + compute output 418 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 6.66556 infer/sec, latency 1503062 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5483.02
Median: 5420.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 40
    Throughput: 6.66556 infer/sec
    Avg latency: 1623604 usec (standard deviation 304182 usec)
    p50 latency: 1867998 usec
    p90 latency: 1874624 usec
    p95 latency: 1877714 usec
    p99 latency: 1879889 usec
    Avg HTTP time: 1624421 usec (send/recv 2487 usec + response wait 1621934 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1607259 usec (overhead 1161 usec + queue 982555 usec + compute input 8227 usec + compute infer 614999 usec + compute output 317 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 6.66556 infer/sec, latency 1623604 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5509.70
Median: 5480.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_768000000.csv
Combined CSV file created: power_measurement_stats_freq_768000000.csv
---Setting GPU frequency to 844800000---
Returning to the default values
Model: NVIDIA Jetson Nano Developer Kit
GPU frequency set to 844800000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 52
    Throughput: 5.19948 infer/sec
    Avg latency: 191337 usec (standard deviation 1587 usec)
    p50 latency: 191448 usec
    p90 latency: 193319 usec
    p95 latency: 193734 usec
    p99 latency: 194366 usec
    Avg HTTP time: 191290 usec (send/recv 1453 usec + response wait 189837 usec)
  Server: 
    Inference count: 52
    Execution count: 52
    Successful request count: 52
    Avg request latency: 180183 usec (overhead 249 usec + queue 248 usec + compute input 443 usec + compute infer 179113 usec + compute output 130 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 5.19948 infer/sec, latency 191337 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5762.88
Median: 5811
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 54
    Throughput: 5.39946 infer/sec
    Avg latency: 367165 usec (standard deviation 1465 usec)
    p50 latency: 367182 usec
    p90 latency: 369087 usec
    p95 latency: 369494 usec
    p99 latency: 370219 usec
    Avg HTTP time: 367063 usec (send/recv 1908 usec + response wait 365155 usec)
  Server: 
    Inference count: 55
    Execution count: 55
    Successful request count: 55
    Avg request latency: 356653 usec (overhead 273 usec + queue 173327 usec + compute input 1432 usec + compute infer 181486 usec + compute output 135 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 5.39946 infer/sec, latency 367165 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5919.30
Median: 5931
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 50
    Throughput: 6.24922 infer/sec
    Avg latency: 463992 usec (standard deviation 50051 usec)
    p50 latency: 458513 usec
    p90 latency: 460162 usec
    p95 latency: 641725 usec
    p99 latency: 643240 usec
    Avg HTTP time: 463863 usec (send/recv 2089 usec + response wait 461774 usec)
  Server: 
    Inference count: 51
    Execution count: 35
    Successful request count: 51
    Avg request latency: 451158 usec (overhead 400 usec + queue 210656 usec + compute input 2413 usec + compute infer 237521 usec + compute output 168 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 6.24922 infer/sec, latency 463992 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5949.42
Median: 5961
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 49
    Throughput: 6.999 infer/sec
    Avg latency: 556159 usec (standard deviation 52035 usec)
    p50 latency: 551831 usec
    p90 latency: 559970 usec
    p95 latency: 564442 usec
    p99 latency: 826587 usec
    Avg HTTP time: 555923 usec (send/recv 2491 usec + response wait 553432 usec)
  Server: 
    Inference count: 51
    Execution count: 26
    Successful request count: 51
    Avg request latency: 541592 usec (overhead 458 usec + queue 259931 usec + compute input 3448 usec + compute infer 277543 usec + compute output 212 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 6.999 infer/sec, latency 556159 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5963.43
Median: 5961.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 47
    Throughput: 6.71045 infer/sec
    Avg latency: 713116 usec (standard deviation 156021 usec)
    p50 latency: 681341 usec
    p90 latency: 868970 usec
    p95 latency: 929699 usec
    p99 latency: 960472 usec
    Avg HTTP time: 702446 usec (send/recv 2406 usec + response wait 700040 usec)
  Server: 
    Inference count: 50
    Execution count: 24
    Successful request count: 50
    Avg request latency: 689791 usec (overhead 1033 usec + queue 336330 usec + compute input 3767 usec + compute infer 348460 usec + compute output 201 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 6.71045 infer/sec, latency 713116 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5863.19
Median: 5851.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 51
    Throughput: 7.28467 infer/sec
    Avg latency: 798167 usec (standard deviation 146697 usec)
    p50 latency: 774467 usec
    p90 latency: 1049203 usec
    p95 latency: 1052668 usec
    p99 latency: 1054556 usec
    Avg HTTP time: 789671 usec (send/recv 2557 usec + response wait 787114 usec)
  Server: 
    Inference count: 53
    Execution count: 21
    Successful request count: 53
    Avg request latency: 775017 usec (overhead 675 usec + queue 386318 usec + compute input 5338 usec + compute infer 382447 usec + compute output 239 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 7.28467 infer/sec, latency 798167 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5907.86
Median: 5916.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 45
    Throughput: 7.49875 infer/sec
    Avg latency: 884530 usec (standard deviation 156718 usec)
    p50 latency: 870203 usec
    p90 latency: 1147073 usec
    p95 latency: 1151353 usec
    p99 latency: 1262896 usec
    Avg HTTP time: 893507 usec (send/recv 2381 usec + response wait 891126 usec)
  Server: 
    Inference count: 50
    Execution count: 16
    Successful request count: 50
    Avg request latency: 876086 usec (overhead 802 usec + queue 421548 usec + compute input 6249 usec + compute infer 447234 usec + compute output 253 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 7.49875 infer/sec, latency 884530 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5871.82
Median: 5821
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 52
    Throughput: 7.42645 infer/sec
    Avg latency: 1017564 usec (standard deviation 217688 usec)
    p50 latency: 1147404 usec
    p90 latency: 1245386 usec
    p95 latency: 1247312 usec
    p99 latency: 1358393 usec
    Avg HTTP time: 1021834 usec (send/recv 2672 usec + response wait 1019162 usec)
  Server: 
    Inference count: 55
    Execution count: 17
    Successful request count: 55
    Avg request latency: 1005519 usec (overhead 1423 usec + queue 531033 usec + compute input 6141 usec + compute infer 466677 usec + compute output 245 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 7.42645 infer/sec, latency 1017564 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5975.21
Median: 5961.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 48
    Throughput: 6.85616 infer/sec
    Avg latency: 1115271 usec (standard deviation 208730 usec)
    p50 latency: 1069227 usec
    p90 latency: 1364495 usec
    p95 latency: 1465063 usec
    p99 latency: 1478705 usec
    Avg HTTP time: 1111392 usec (send/recv 2993 usec + response wait 1108399 usec)
  Server: 
    Inference count: 53
    Execution count: 15
    Successful request count: 53
    Avg request latency: 1092814 usec (overhead 702 usec + queue 600484 usec + compute input 6139 usec + compute infer 485165 usec + compute output 324 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 6.85616 infer/sec, latency 1115271 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6004.55
Median: 5931.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 45
    Throughput: 7.49875 infer/sec
    Avg latency: 1161638 usec (standard deviation 5292 usec)
    p50 latency: 1162137 usec
    p90 latency: 1168511 usec
    p95 latency: 1169164 usec
    p99 latency: 1172902 usec
    Avg HTTP time: 1161268 usec (send/recv 2079 usec + response wait 1159189 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1141386 usec (overhead 915 usec + queue 561888 usec + compute input 8256 usec + compute infer 570049 usec + compute output 278 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 7.49875 infer/sec, latency 1161638 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6087.22
Median: 6060.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 45
    Throughput: 7.4975 infer/sec
    Avg latency: 1276299 usec (standard deviation 229311 usec)
    p50 latency: 1161994 usec
    p90 latency: 1734298 usec
    p95 latency: 1737363 usec
    p99 latency: 1740317 usec
    Avg HTTP time: 1276680 usec (send/recv 2379 usec + response wait 1274301 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1253211 usec (overhead 793 usec + queue 673146 usec + compute input 7619 usec + compute infer 571399 usec + compute output 254 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 7.4975 infer/sec, latency 1276299 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6067.00
Median: 6080
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 45
    Throughput: 7.4975 infer/sec
    Avg latency: 1392951 usec (standard deviation 280985 usec)
    p50 latency: 1167801 usec
    p90 latency: 1739889 usec
    p95 latency: 1742109 usec
    p99 latency: 1745133 usec
    Avg HTTP time: 1393471 usec (send/recv 2033 usec + response wait 1391438 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1371925 usec (overhead 898 usec + queue 791233 usec + compute input 9154 usec + compute infer 570347 usec + compute output 293 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 7.4975 infer/sec, latency 1392951 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6043.78
Median: 6041
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 45
    Throughput: 7.49875 infer/sec
    Avg latency: 1508722 usec (standard deviation 280395 usec)
    p50 latency: 1731714 usec
    p90 latency: 1743671 usec
    p95 latency: 1744086 usec
    p99 latency: 1756133 usec
    Avg HTTP time: 1508391 usec (send/recv 2025 usec + response wait 1506366 usec)
  Server: 
    Inference count: 50
    Execution count: 10
    Successful request count: 50
    Avg request latency: 1487427 usec (overhead 994 usec + queue 907626 usec + compute input 7833 usec + compute infer 570649 usec + compute output 325 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 7.49875 infer/sec, latency 1508722 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6025.17
Median: 5971
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_844800000.csv
Combined CSV file created: power_measurement_stats_freq_844800000.csv
---Setting GPU frequency to 921600000---
Returning to the default values
Model: NVIDIA Jetson Nano Developer Kit
GPU frequency set to 921600000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 49
    Throughput: 5.44384 infer/sec
    Avg latency: 181294 usec (standard deviation 1439 usec)
    p50 latency: 181327 usec
    p90 latency: 182920 usec
    p95 latency: 183657 usec
    p99 latency: 186068 usec
    Avg HTTP time: 181190 usec (send/recv 1523 usec + response wait 179667 usec)
  Server: 
    Inference count: 50
    Execution count: 50
    Successful request count: 50
    Avg request latency: 170398 usec (overhead 269 usec + queue 252 usec + compute input 450 usec + compute infer 169297 usec + compute output 130 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 5.44384 infer/sec, latency 181294 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6215.03
Median: 6338
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 51
    Throughput: 5.66604 infer/sec
    Avg latency: 347068 usec (standard deviation 1942 usec)
    p50 latency: 347106 usec
    p90 latency: 349476 usec
    p95 latency: 350629 usec
    p99 latency: 351275 usec
    Avg HTTP time: 347014 usec (send/recv 1964 usec + response wait 345050 usec)
  Server: 
    Inference count: 52
    Execution count: 52
    Successful request count: 52
    Avg request latency: 336386 usec (overhead 266 usec + queue 163068 usec + compute input 1341 usec + compute infer 171586 usec + compute output 125 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 5.66604 infer/sec, latency 347068 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6434.15
Median: 6486
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 52
    Throughput: 6.49919 infer/sec
    Avg latency: 440444 usec (standard deviation 65858 usec)
    p50 latency: 432054 usec
    p90 latency: 600877 usec
    p95 latency: 604037 usec
    p99 latency: 606875 usec
    Avg HTTP time: 443253 usec (send/recv 2118 usec + response wait 441135 usec)
  Server: 
    Inference count: 54
    Execution count: 38
    Successful request count: 54
    Avg request latency: 430629 usec (overhead 367 usec + queue 207168 usec + compute input 2321 usec + compute infer 220633 usec + compute output 140 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 6.49919 infer/sec, latency 440444 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6457.34
Median: 6486
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 50
    Throughput: 7.14184 infer/sec
    Avg latency: 537124 usec (standard deviation 84151 usec)
    p50 latency: 526231 usec
    p90 latency: 689494 usec
    p95 latency: 699173 usec
    p99 latency: 790755 usec
    Avg HTTP time: 536631 usec (send/recv 2334 usec + response wait 534297 usec)
  Server: 
    Inference count: 53
    Execution count: 28
    Successful request count: 53
    Avg request latency: 522282 usec (overhead 462 usec + queue 242101 usec + compute input 3386 usec + compute infer 276151 usec + compute output 182 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 7.14184 infer/sec, latency 537124 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6432.07
Median: 6431.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 51
    Throughput: 7.28571 infer/sec
    Avg latency: 648527 usec (standard deviation 137285 usec)
    p50 latency: 635299 usec
    p90 latency: 811821 usec
    p95 latency: 812815 usec
    p99 latency: 815405 usec
    Avg HTTP time: 648473 usec (send/recv 2243 usec + response wait 646230 usec)
  Server: 
    Inference count: 51
    Execution count: 24
    Successful request count: 51
    Avg request latency: 634236 usec (overhead 640 usec + queue 276193 usec + compute input 4090 usec + compute infer 353073 usec + compute output 240 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 7.28571 infer/sec, latency 648527 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6479.78
Median: 6457.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 46
    Throughput: 7.66539 infer/sec
    Avg latency: 732461 usec (standard deviation 130082 usec)
    p50 latency: 721362 usec
    p90 latency: 972138 usec
    p95 latency: 976425 usec
    p99 latency: 1072991 usec
    Avg HTTP time: 743092 usec (send/recv 2527 usec + response wait 740565 usec)
  Server: 
    Inference count: 52
    Execution count: 19
    Successful request count: 52
    Avg request latency: 726892 usec (overhead 710 usec + queue 355531 usec + compute input 5338 usec + compute infer 365075 usec + compute output 238 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 7.66539 infer/sec, latency 732461 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6539.65
Median: 6526.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 54
    Throughput: 7.71318 infer/sec
    Avg latency: 831936 usec (standard deviation 173140 usec)
    p50 latency: 805784 usec
    p90 latency: 1065723 usec
    p95 latency: 1071463 usec
    p99 latency: 1177300 usec
    Avg HTTP time: 830589 usec (send/recv 2178 usec + response wait 828411 usec)
  Server: 
    Inference count: 58
    Execution count: 19
    Successful request count: 58
    Avg request latency: 816012 usec (overhead 806 usec + queue 388052 usec + compute input 5451 usec + compute infer 421476 usec + compute output 227 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 7.71318 infer/sec, latency 831936 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6513.45
Median: 6506.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 50
    Throughput: 8.33194 infer/sec
    Avg latency: 922421 usec (standard deviation 169759 usec)
    p50 latency: 899003 usec
    p90 latency: 1158014 usec
    p95 latency: 1247349 usec
    p99 latency: 1360934 usec
    Avg HTTP time: 921003 usec (send/recv 2432 usec + response wait 918571 usec)
  Server: 
    Inference count: 53
    Execution count: 15
    Successful request count: 53
    Avg request latency: 902095 usec (overhead 712 usec + queue 457433 usec + compute input 6330 usec + compute infer 437345 usec + compute output 275 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 8.33194 infer/sec, latency 922421 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6642.00
Median: 6673
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 51
    Throughput: 8.5 infer/sec
    Avg latency: 1018646 usec (standard deviation 190684 usec)
    p50 latency: 1000187 usec
    p90 latency: 1270397 usec
    p95 latency: 1358338 usec
    p99 latency: 1464723 usec
    Avg HTTP time: 1026814 usec (send/recv 2654 usec + response wait 1024160 usec)
  Server: 
    Inference count: 55
    Execution count: 14
    Successful request count: 55
    Avg request latency: 1005448 usec (overhead 711 usec + queue 535497 usec + compute input 7210 usec + compute infer 461768 usec + compute output 262 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 8.5 infer/sec, latency 1018646 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6502.45
Median: 6526
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 50
    Throughput: 8.33194 infer/sec
    Avg latency: 1089836 usec (standard deviation 4597 usec)
    p50 latency: 1090931 usec
    p90 latency: 1095153 usec
    p95 latency: 1097066 usec
    p99 latency: 1100180 usec
    Avg HTTP time: 1089500 usec (send/recv 2642 usec + response wait 1086858 usec)
  Server: 
    Inference count: 55
    Execution count: 11
    Successful request count: 55
    Avg request latency: 1068663 usec (overhead 854 usec + queue 524570 usec + compute input 7128 usec + compute infer 535806 usec + compute output 305 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 8.33194 infer/sec, latency 1089836 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6661.50
Median: 6633.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 45
    Throughput: 7.49875 infer/sec
    Avg latency: 1205521 usec (standard deviation 217111 usec)
    p50 latency: 1097511 usec
    p90 latency: 1637551 usec
    p95 latency: 1644860 usec
    p99 latency: 1646358 usec
    Avg HTTP time: 1205225 usec (send/recv 2053 usec + response wait 1203172 usec)
  Server: 
    Inference count: 55
    Execution count: 11
    Successful request count: 55
    Avg request latency: 1185342 usec (overhead 940 usec + queue 637622 usec + compute input 8384 usec + compute infer 538115 usec + compute output 281 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 7.49875 infer/sec, latency 1205521 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6635.43
Median: 6605
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 45
    Throughput: 7.49875 infer/sec
    Avg latency: 1312737 usec (standard deviation 263702 usec)
    p50 latency: 1101792 usec
    p90 latency: 1637706 usec
    p95 latency: 1638607 usec
    p99 latency: 1641697 usec
    Avg HTTP time: 1313286 usec (send/recv 2644 usec + response wait 1310642 usec)
  Server: 
    Inference count: 55
    Execution count: 11
    Successful request count: 55
    Avg request latency: 1293606 usec (overhead 945 usec + queue 746606 usec + compute input 7659 usec + compute infer 538125 usec + compute output 271 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 7.49875 infer/sec, latency 1312737 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6582.08
Median: 6594
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 45
    Throughput: 7.49875 infer/sec
    Avg latency: 1426032 usec (standard deviation 267160 usec)
    p50 latency: 1637648 usec
    p90 latency: 1649368 usec
    p95 latency: 1649568 usec
    p99 latency: 1657573 usec
    Avg HTTP time: 1425749 usec (send/recv 2685 usec + response wait 1423064 usec)
  Server: 
    Inference count: 55
    Execution count: 11
    Successful request count: 55
    Avg request latency: 1407200 usec (overhead 1268 usec + queue 859977 usec + compute input 7436 usec + compute infer 538227 usec + compute output 292 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 7.49875 infer/sec, latency 1426032 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6574.35
Median: 6605
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_921600000.csv
Combined CSV file created: power_measurement_stats_freq_921600000.csv
Returning to the default values
