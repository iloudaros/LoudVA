2025-02-14 22:23:29,722 - LoudVA - INFO - [LoudController] - Starting LoudController...
2025-02-14 22:23:29,722 - LoudVA - INFO - [LoudController] - Press CTRL+C to stop the controller.
2025-02-14 22:23:29,722 - LoudVA - INFO - [LoudController] - Debug mode: False
2025-02-14 22:23:29,752 - LoudVA - INFO - [LoudController] - Selected scheduler: fixed_batch
2025-02-14 22:23:29,761 - LoudVA - INFO - [LoudServer] - Starting LoudVA server...
 * Serving Flask app 'LoudServer'
 * Debug mode: off
WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:5000
Press CTRL+C to quit
2025-02-14 22:23:31,003 - LoudVA - INFO - [DeviceData] - Using profiling data for decision making.
2025-02-14 22:23:31,004 - LoudVA - INFO - [DeviceData] - Filling missing profile data with predictions.
2025-02-14 22:23:31,004 - LoudVA - INFO - [DeviceData] - Loaded network costs from /home/louduser/LoudVA/LoudController/../measurements/network/network_cost.csv
2025-02-14 22:23:31,013 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/Profiling.csv
2025-02-14 22:23:31,013 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/xavier-nx-00/measurements/xavier-nx-00_filtered_freqs.csv
2025-02-14 22:23:31,013 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/LoudJetson0/measurements/LoudJetson0_filtered_freqs.csv
2025-02-14 22:23:31,013 - LoudVA - INFO - [DeviceData] - Loaded GPU specs from /home/louduser/LoudVA/LoudController/../data/devices/gpu_specs.csv
2025-02-14 22:23:31,042 - LoudVA - INFO - [DeviceData] - Initial frequency on agx-xavier-00: 114750000
2025-02-14 22:23:31,042 - LoudVA - INFO - [DeviceData] - agx-xavier-00 : Filling missing profile data...
2025-02-14 22:23:31,042 - LoudVA - INFO - [DeviceData] - agx-xavier-00 : Missing profile data filled with predictions.
2025-02-14 22:23:31,042 - LoudVA - INFO - [DeviceData] - Devices initialized successfully
2025-02-14 22:23:31,042 - LoudVA - INFO - [LoudController] - Using fixed batch size 8
127.0.0.1 - - [14/Feb/2025 22:24:32] "GET / HTTP/1.1" 200 -
2025-02-14 22:24:32,738 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:24:33,274 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.374043
2025-02-14 22:24:33,759 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.559861
2025-02-14 22:24:34,257 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-14 22:24:34,762 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-14 22:24:35,265 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-14 22:24:35,601 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 30ed36c7-a13d-4449-90b3-58c77cb1afcf
127.0.0.1 - - [14/Feb/2025 22:24:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:35,604 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9d711219-5273-4566-b2d5-700f7d70bcbd
127.0.0.1 - - [14/Feb/2025 22:24:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:35,746 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.559861
2025-02-14 22:24:36,096 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4b3113fd-e19a-4d92-a568-a8cdf8ca311e
127.0.0.1 - - [14/Feb/2025 22:24:36] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:36,267 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.559861
2025-02-14 22:24:36,772 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
2025-02-14 22:24:37,252 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.190029
2025-02-14 22:24:37,743 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.190029
2025-02-14 22:24:38,031 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 46fae71f-1fff-4707-8517-c21a6288a418
127.0.0.1 - - [14/Feb/2025 22:24:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:38,041 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f8af1168-6428-4ff3-ae6a-41faa1e79be0
127.0.0.1 - - [14/Feb/2025 22:24:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:38,051 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4236fdf8-cebc-4b56-9600-9b3cdc2c3a38
127.0.0.1 - - [14/Feb/2025 22:24:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:38,238 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
2025-02-14 22:24:38,257 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a04b5265-d9f2-4171-a28d-8fc191ec465e
127.0.0.1 - - [14/Feb/2025 22:24:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:38,273 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b862e367-b665-4817-9df7-d23854f5b0a3
127.0.0.1 - - [14/Feb/2025 22:24:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:38,738 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-14 22:24:39,013 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f7970708-9835-4200-9b28-8fd3a70a2866
127.0.0.1 - - [14/Feb/2025 22:24:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:39,017 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bc8091fa-8fab-40bf-a16b-bb2ac15e4198
127.0.0.1 - - [14/Feb/2025 22:24:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:39,250 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.374043
2025-02-14 22:24:39,730 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-14 22:24:39,835 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9b1a9c9f-44c7-443d-97ff-00ce0b2094ed
127.0.0.1 - - [14/Feb/2025 22:24:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:39,839 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1d53231d-2093-481a-8241-10644e166c56
127.0.0.1 - - [14/Feb/2025 22:24:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:39,842 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7f96ec7a-c860-4a77-8e10-c1d881562959
127.0.0.1 - - [14/Feb/2025 22:24:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:40,243 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-14 22:24:40,740 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.374043
2025-02-14 22:24:41,259 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.374043
2025-02-14 22:24:41,752 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-14 22:24:41,853 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cfda1a53-5ae5-4565-a8aa-7da1067118df
127.0.0.1 - - [14/Feb/2025 22:24:41] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:41,856 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1d0854fd-8af5-4055-9d65-7285ee50a1a0
127.0.0.1 - - [14/Feb/2025 22:24:41] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:41,864 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 58a26cee-c428-4468-b55a-39fbea843408
127.0.0.1 - - [14/Feb/2025 22:24:41] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:42,240 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-14 22:24:42,748 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.559861
2025-02-14 22:24:43,236 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.190029
2025-02-14 22:24:43,304 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 199b98a6-a8eb-47d1-acbb-6b640c260ec5
2025-02-14 22:24:43,305 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ef54b2ba-ba0d-4f10-9850-1ea033edcabb
127.0.0.1 - - [14/Feb/2025 22:24:43] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:24:43] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:43,745 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.559861
2025-02-14 22:24:43,998 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a681fa40-832c-4b54-b5a5-58a5e0a94013
127.0.0.1 - - [14/Feb/2025 22:24:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:44,003 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7d1e262d-f0c5-495e-b3ea-a54a048f1340
127.0.0.1 - - [14/Feb/2025 22:24:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:44,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.374043
2025-02-14 22:24:44,734 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-14 22:24:44,941 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1c8b6d8a-05f7-40ad-a585-ec64545e5ea2
127.0.0.1 - - [14/Feb/2025 22:24:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:44,943 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f588a0a6-2a28-4082-b706-100b74bdf7e7
127.0.0.1 - - [14/Feb/2025 22:24:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:45,233 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
2025-02-14 22:24:45,755 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.374043
2025-02-14 22:24:46,236 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.281418
2025-02-14 22:24:46,324 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fc2e584e-ce6e-47f9-a020-236a956d1211
127.0.0.1 - - [14/Feb/2025 22:24:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:46,326 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 289b1962-0669-4fb0-89f8-dd8c9bd35c4c
127.0.0.1 - - [14/Feb/2025 22:24:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:46,331 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7dd6c44e-041f-41f3-a9e6-1d1203db3157
127.0.0.1 - - [14/Feb/2025 22:24:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:46,333 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7d1a403e-1622-4035-b0f2-e2f3b9064988
127.0.0.1 - - [14/Feb/2025 22:24:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:46,742 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-14 22:24:47,233 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-14 22:24:47,748 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.559861
2025-02-14 22:24:48,070 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1f3c044e-7549-4d8e-ba76-2e0e7597beb4
127.0.0.1 - - [14/Feb/2025 22:24:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:48,076 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c5d144a3-e7c3-4cef-b652-77aa19fb80ff
127.0.0.1 - - [14/Feb/2025 22:24:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:48,268 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.465794
2025-02-14 22:24:48,737 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
2025-02-14 22:24:49,240 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.374043
2025-02-14 22:24:49,259 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5c00c8c5-4370-4df7-bacd-5723ed889f64
127.0.0.1 - - [14/Feb/2025 22:24:49] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:49,264 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 920edb14-62a7-41eb-bfcd-781fe264409b
127.0.0.1 - - [14/Feb/2025 22:24:49] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:49,736 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
2025-02-14 22:24:50,239 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.374043
2025-02-14 22:24:50,346 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f5b23f34-317f-4569-974e-6109bc6d7167
127.0.0.1 - - [14/Feb/2025 22:24:50] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:50,351 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 17d639b2-7e81-4373-96bc-4b0037fb822c
127.0.0.1 - - [14/Feb/2025 22:24:50] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:50,744 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.374043
2025-02-14 22:24:51,237 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.190029
2025-02-14 22:24:51,351 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ad7c16b3-140e-492a-92bf-e9d1c9edbffc
127.0.0.1 - - [14/Feb/2025 22:24:51] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:51,355 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 19df9822-6f24-4575-8f1c-8af331a7f49f
127.0.0.1 - - [14/Feb/2025 22:24:51] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:51,359 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 08385c53-23ea-442b-ae82-1f37346f8edc
127.0.0.1 - - [14/Feb/2025 22:24:51] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:51,732 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
2025-02-14 22:24:52,254 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
2025-02-14 22:24:52,285 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 58d779ba-73a7-4734-90b8-3d60bfd58da5
127.0.0.1 - - [14/Feb/2025 22:24:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:52,288 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 366605e6-b272-48e9-86dc-39cb3c2c36ba
127.0.0.1 - - [14/Feb/2025 22:24:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:52,291 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2faf3f77-10c0-4733-b8e3-0d5cd4b31688
127.0.0.1 - - [14/Feb/2025 22:24:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:52,732 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.190029
2025-02-14 22:24:53,233 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-14 22:24:53,744 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.374043
2025-02-14 22:24:54,215 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f23afcc7-0c6a-4391-9c3d-67620f64e391
127.0.0.1 - - [14/Feb/2025 22:24:54] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:54,219 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 90f5caf5-6a97-49f9-8d8c-751f117a6737
127.0.0.1 - - [14/Feb/2025 22:24:54] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:54,235 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-14 22:24:54,727 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-14 22:24:55,232 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.098841
2025-02-14 22:24:55,394 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b60a839d-40e8-4cdb-a2cc-5dc056d84a08
127.0.0.1 - - [14/Feb/2025 22:24:55] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:55,396 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 382325d7-6548-4631-bf8d-cb22ac3e6000
127.0.0.1 - - [14/Feb/2025 22:24:55] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:55,400 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9a8461c5-25ef-4443-83ee-e799a5d32d6f
127.0.0.1 - - [14/Feb/2025 22:24:55] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:55,739 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.465794
2025-02-14 22:24:56,234 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.098841
2025-02-14 22:24:56,742 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.465794
2025-02-14 22:24:56,747 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0437b74e-d53f-4aeb-b092-be5ceec8f213
127.0.0.1 - - [14/Feb/2025 22:24:56] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:56,755 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ebb81d71-c8d2-4746-af9f-d83c65b6f7b7
127.0.0.1 - - [14/Feb/2025 22:24:56] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:56,758 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e09fe6fe-6b71-4aae-8bc3-a0ed1a5a10c9
127.0.0.1 - - [14/Feb/2025 22:24:56] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:57,233 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-14 22:24:57,737 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-14 22:24:58,231 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-14 22:24:58,279 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 73922faa-e905-48ed-96d5-106498f28c0f
127.0.0.1 - - [14/Feb/2025 22:24:58] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:58,282 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1d3c6955-41ab-4425-8152-6234a87c4035
127.0.0.1 - - [14/Feb/2025 22:24:58] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:58,284 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1003c967-2bbb-41b0-8596-7b3afcea308b
127.0.0.1 - - [14/Feb/2025 22:24:58] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:58,740 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.559861
2025-02-14 22:24:59,246 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.559861
2025-02-14 22:24:59,761 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.374043
2025-02-14 22:24:59,900 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 428abf16-0d06-47b9-823b-94eed0673c60
127.0.0.1 - - [14/Feb/2025 22:24:59] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:59,905 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 29ea28d3-42d3-4f43-98b2-969b074dcad4
127.0.0.1 - - [14/Feb/2025 22:24:59] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:24:59,908 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c69e0091-5a24-4490-aabe-db102bdea56c
127.0.0.1 - - [14/Feb/2025 22:24:59] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:00,241 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.281418
2025-02-14 22:25:00,551 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ec31d079-b1b3-4446-ad72-a3b17cd6a384
127.0.0.1 - - [14/Feb/2025 22:25:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:00,742 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.374043
2025-02-14 22:25:01,234 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-14 22:25:01,737 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.190029
2025-02-14 22:25:02,238 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
2025-02-14 22:25:02,734 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-14 22:25:02,928 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3193f4ee-a307-4399-86e5-a080a27960d3
127.0.0.1 - - [14/Feb/2025 22:25:02] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:02,937 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6e7f2ab5-1df3-4983-b345-14ad551f75cc
127.0.0.1 - - [14/Feb/2025 22:25:02] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:03,235 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-14 22:25:03,318 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c0a9aee7-c9d3-4669-b414-f3d352f4e247
127.0.0.1 - - [14/Feb/2025 22:25:03] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:03,321 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4d59bdd1-163e-4cbe-8b79-b610a751c76b
2025-02-14 22:25:03,323 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ec650189-e4e6-47a0-b414-edd578568803
127.0.0.1 - - [14/Feb/2025 22:25:03] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:25:03] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:03,750 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.465794
2025-02-14 22:25:04,215 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.64948
2025-02-14 22:25:04,234 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-14 22:25:04,695 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.465794
2025-02-14 22:25:04,734 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-14 22:25:04,850 - LoudVA - INFO - [LoudServer] - Completed. Request ID: af5c9730-c3f6-4448-935f-435eefb8e9a1
127.0.0.1 - - [14/Feb/2025 22:25:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:04,852 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5edb7854-12d3-4b93-9360-ad1e37ffcaaa
127.0.0.1 - - [14/Feb/2025 22:25:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:04,854 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b42711fb-7707-4639-8172-ca9818ecdeea
127.0.0.1 - - [14/Feb/2025 22:25:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:04,862 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0164f425-3d3f-4a41-9ca8-094dc79a3caa
127.0.0.1 - - [14/Feb/2025 22:25:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:05,217 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.281418
2025-02-14 22:25:05,242 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
2025-02-14 22:25:05,700 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.281418
2025-02-14 22:25:05,742 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.374043
2025-02-14 22:25:06,216 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.374043
2025-02-14 22:25:06,268 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.64948
2025-02-14 22:25:06,472 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bbbac8e1-b1cf-4808-9f3a-a4e2466e95e6
127.0.0.1 - - [14/Feb/2025 22:25:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:06,565 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 92816683-ce0b-4b00-94b7-cb5dfcf3bb64
127.0.0.1 - - [14/Feb/2025 22:25:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:06,574 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d78c90dd-068a-41f3-a87e-9ab33fc832b6
127.0.0.1 - - [14/Feb/2025 22:25:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:06,687 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
2025-02-14 22:25:06,741 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.281418
2025-02-14 22:25:07,212 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.559861
2025-02-14 22:25:07,236 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-14 22:25:07,712 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
2025-02-14 22:25:07,776 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
2025-02-14 22:25:08,222 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.465794
2025-02-14 22:25:08,267 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.465794
2025-02-14 22:25:08,691 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 89aa835e-9a5a-49ac-baa0-de4673167796
127.0.0.1 - - [14/Feb/2025 22:25:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:08,700 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 650dbc95-f575-47b8-b69b-b7266197dca9
127.0.0.1 - - [14/Feb/2025 22:25:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:08,723 - LoudVA - INFO - [LoudServer] - Completed. Request ID: eb54982c-798e-4c62-a302-b3d34fa8ead9
127.0.0.1 - - [14/Feb/2025 22:25:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:08,735 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:25:08,755 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.64948
2025-02-14 22:25:09,081 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 30f419a4-b742-4656-a87b-89df0248fe5f
127.0.0.1 - - [14/Feb/2025 22:25:09] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:09,089 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2c46890e-621f-4b41-beae-471eb509916d
127.0.0.1 - - [14/Feb/2025 22:25:09] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:09,202 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.281418
2025-02-14 22:25:09,249 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-14 22:25:09,528 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 28104f23-c52c-47e6-b1b0-9044da534f5b
127.0.0.1 - - [14/Feb/2025 22:25:09] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:09,541 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f82b73d8-865e-4575-929f-076caef0d151
127.0.0.1 - - [14/Feb/2025 22:25:09] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:09,716 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.559861
2025-02-14 22:25:09,738 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.281418
2025-02-14 22:25:10,212 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.374043
2025-02-14 22:25:10,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.281418
2025-02-14 22:25:10,709 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.281418
2025-02-14 22:25:10,769 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.374043
2025-02-14 22:25:10,957 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ad7a0b12-5579-4095-8fed-db6bb3f32b45
127.0.0.1 - - [14/Feb/2025 22:25:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:10,976 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bf86a70c-598e-4b60-a452-18f9d1b950f5
127.0.0.1 - - [14/Feb/2025 22:25:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:10,993 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 94368b6c-c692-4372-9da4-c87aef713b7d
127.0.0.1 - - [14/Feb/2025 22:25:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:11,204 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.281418
2025-02-14 22:25:11,235 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-14 22:25:11,521 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3684f12f-9e55-487f-b2cd-ac2e2ecc7927
127.0.0.1 - - [14/Feb/2025 22:25:11] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:11,526 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a8df645b-09a0-4026-8763-d9e59770a9d7
127.0.0.1 - - [14/Feb/2025 22:25:11] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:11,739 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.465794
2025-02-14 22:25:11,780 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.374043
2025-02-14 22:25:12,195 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.190029
2025-02-14 22:25:12,299 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.190029
2025-02-14 22:25:12,710 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
2025-02-14 22:25:12,760 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.374043
2025-02-14 22:25:13,129 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5fe5d5f5-1428-4e20-af22-ece8f08f6e90
127.0.0.1 - - [14/Feb/2025 22:25:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:13,142 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 16d25660-df1e-42ad-b034-57714d417605
127.0.0.1 - - [14/Feb/2025 22:25:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:13,204 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.465794
2025-02-14 22:25:13,250 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-14 22:25:13,706 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-14 22:25:13,775 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.64948
2025-02-14 22:25:13,793 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:25:14,310 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.281418
2025-02-14 22:25:14,359 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
2025-02-14 22:25:14,454 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.64948
2025-02-14 22:25:14,710 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:25:14,776 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-14 22:25:14,790 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.190029
2025-02-14 22:25:14,853 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 746152a3-8471-4725-a9c2-38139dd292eb
127.0.0.1 - - [14/Feb/2025 22:25:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:15,162 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7944bf97-ffda-4cc5-9729-12142e47eaf6
127.0.0.1 - - [14/Feb/2025 22:25:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:15,183 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7fa807da-47e3-4b03-846e-50fd4fa0f7d9
127.0.0.1 - - [14/Feb/2025 22:25:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:15,203 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 901ccfe2-ce90-43d6-8d85-2fa37de68911
127.0.0.1 - - [14/Feb/2025 22:25:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:15,239 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.465794
2025-02-14 22:25:15,283 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.281418
2025-02-14 22:25:15,309 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.281418
2025-02-14 22:25:15,733 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.559861
2025-02-14 22:25:15,777 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.190029
2025-02-14 22:25:15,793 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0dbd4166-cc28-48a0-b563-ca28f2da3227
127.0.0.1 - - [14/Feb/2025 22:25:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:15,808 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.190029
2025-02-14 22:25:16,243 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.281418
2025-02-14 22:25:16,270 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.281418
2025-02-14 22:25:16,296 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.559861
2025-02-14 22:25:16,565 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 22ca1e83-6f4e-4230-bd70-bf6aad0cd797
127.0.0.1 - - [14/Feb/2025 22:25:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:16,590 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 67a41076-1e57-4321-bc94-bafa156af4ba
127.0.0.1 - - [14/Feb/2025 22:25:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:16,600 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ac718082-6110-4d75-a0d7-44927bce25b1
127.0.0.1 - - [14/Feb/2025 22:25:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:16,714 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.465794
2025-02-14 22:25:16,777 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.190029
2025-02-14 22:25:16,786 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.64948
2025-02-14 22:25:17,289 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.374043
2025-02-14 22:25:17,334 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.281418
2025-02-14 22:25:17,339 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.465794
2025-02-14 22:25:17,600 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d9868585-65e5-4f10-ad18-59c069857bee
127.0.0.1 - - [14/Feb/2025 22:25:17] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:17,656 - LoudVA - INFO - [LoudServer] - Completed. Request ID: faadf10a-f6a1-47ca-b7fb-f15f9d1325c1
127.0.0.1 - - [14/Feb/2025 22:25:17] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:17,706 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-14 22:25:17,758 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.190029
2025-02-14 22:25:17,760 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
2025-02-14 22:25:18,219 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.281418
2025-02-14 22:25:18,298 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.190029
2025-02-14 22:25:18,315 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.64948
2025-02-14 22:25:18,596 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9e0a14cd-e43a-48ef-8681-1cec89ac1bf7
127.0.0.1 - - [14/Feb/2025 22:25:18] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:18,643 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 89ce5fd3-2ae5-4e86-a45c-4d1ee75ec0d9
127.0.0.1 - - [14/Feb/2025 22:25:18] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:18,792 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.190029
2025-02-14 22:25:18,853 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.374043
2025-02-14 22:25:18,923 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.465794
2025-02-14 22:25:19,258 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-14 22:25:19,293 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
2025-02-14 22:25:19,324 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-14 22:25:19,744 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.465794
2025-02-14 22:25:19,762 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.190029
2025-02-14 22:25:19,867 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
2025-02-14 22:25:20,207 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-14 22:25:20,265 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.281418
2025-02-14 22:25:20,274 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
2025-02-14 22:25:20,698 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.190029
2025-02-14 22:25:20,735 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-14 22:25:20,790 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.190029
2025-02-14 22:25:21,191 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-14 22:25:21,231 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
2025-02-14 22:25:21,303 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.374043
2025-02-14 22:25:21,700 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-14 22:25:21,758 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.190029
2025-02-14 22:25:21,767 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.281418
2025-02-14 22:25:22,215 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-14 22:25:22,253 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-14 22:25:22,314 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.559861
2025-02-14 22:25:22,710 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-14 22:25:22,788 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.374043
2025-02-14 22:25:22,808 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.465794
2025-02-14 22:25:23,198 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.190029
2025-02-14 22:25:23,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-14 22:25:23,313 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.64948
2025-02-14 22:25:23,710 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-14 22:25:23,735 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-14 22:25:23,756 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.374043
2025-02-14 22:25:24,194 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-14 22:25:24,269 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.559861
2025-02-14 22:25:24,276 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.281418
2025-02-14 22:25:24,391 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4dc4a496-21b1-4228-96ec-b98920ca0113
127.0.0.1 - - [14/Feb/2025 22:25:24] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:24,419 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fc62ea2e-2d29-4199-98dd-3eb508a1fcb2
127.0.0.1 - - [14/Feb/2025 22:25:24] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:24,426 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cdbd9ef4-d207-40a3-8df1-87d790ea6db3
127.0.0.1 - - [14/Feb/2025 22:25:24] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:24,697 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
2025-02-14 22:25:24,740 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.374043
2025-02-14 22:25:24,762 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.374043
2025-02-14 22:25:24,945 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 82cc9fe3-8e1f-4c2f-a346-2440f5a3c575
127.0.0.1 - - [14/Feb/2025 22:25:24] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:25,130 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1e975509-6a5c-4cb7-917e-78340956951b
127.0.0.1 - - [14/Feb/2025 22:25:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:25,139 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cfdcebc4-b285-4d74-9dd0-ef2eaa8f5c6c
127.0.0.1 - - [14/Feb/2025 22:25:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:25,149 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 074c707b-bb05-4f33-b82f-9d19da1fc8f4
127.0.0.1 - - [14/Feb/2025 22:25:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:25,188 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
2025-02-14 22:25:25,234 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.374043
2025-02-14 22:25:25,248 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-14 22:25:25,753 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-14 22:25:25,755 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-14 22:25:25,758 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.465794
2025-02-14 22:25:26,211 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-14 22:25:26,242 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.374043
2025-02-14 22:25:26,260 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.281418
2025-02-14 22:25:26,639 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5f587ddf-442c-4ead-9485-bfd025eee029
127.0.0.1 - - [14/Feb/2025 22:25:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:26,708 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.64948
2025-02-14 22:25:26,741 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.281418
2025-02-14 22:25:26,748 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.098841
2025-02-14 22:25:27,222 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-14 22:25:27,251 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-14 22:25:27,256 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.374043
2025-02-14 22:25:27,695 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.374043
2025-02-14 22:25:27,760 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.559861
2025-02-14 22:25:27,766 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-14 22:25:28,201 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.281418
2025-02-14 22:25:28,250 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.465794
2025-02-14 22:25:28,338 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.281418
2025-02-14 22:25:28,736 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.374043
2025-02-14 22:25:28,771 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.374043
2025-02-14 22:25:28,825 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.64948
2025-02-14 22:25:28,845 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5b56a16c-f449-4e15-98d7-3e6f96ca18c1
127.0.0.1 - - [14/Feb/2025 22:25:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:28,862 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2f7ae59e-2c7c-4674-9c92-4f9cdd14e6b1
127.0.0.1 - - [14/Feb/2025 22:25:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:28,869 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1b2918b8-c2a3-415a-8286-d6388d606bd2
127.0.0.1 - - [14/Feb/2025 22:25:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:29,192 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.190029
2025-02-14 22:25:29,264 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
2025-02-14 22:25:29,348 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
2025-02-14 22:25:29,731 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.190029
2025-02-14 22:25:29,763 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-14 22:25:29,862 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.465794
2025-02-14 22:25:30,197 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
2025-02-14 22:25:30,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.190029
2025-02-14 22:25:30,266 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.64948
2025-02-14 22:25:30,792 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-14 22:25:30,812 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.559861
2025-02-14 22:25:30,843 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-14 22:25:31,195 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-14 22:25:31,288 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
2025-02-14 22:25:31,312 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.465794
2025-02-14 22:25:31,710 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.281418
2025-02-14 22:25:31,740 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.281418
2025-02-14 22:25:31,803 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.374043
2025-02-14 22:25:31,966 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 365e22ff-0c00-4d69-8cfe-f1caf610b16b
127.0.0.1 - - [14/Feb/2025 22:25:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:31,988 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6805168f-66a5-4a62-b69e-5591873aeaac
127.0.0.1 - - [14/Feb/2025 22:25:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:32,008 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e51bfa2c-25f3-4841-abcf-9a7e74e33a7c
127.0.0.1 - - [14/Feb/2025 22:25:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:32,213 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
2025-02-14 22:25:32,256 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.465794
2025-02-14 22:25:32,297 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.374043
2025-02-14 22:25:32,710 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 73180160-8bb2-43af-bd08-115512a9a7ed
127.0.0.1 - - [14/Feb/2025 22:25:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:32,736 - LoudVA - INFO - [LoudServer] - Completed. Request ID: aa437a02-aeb6-4b97-bd42-96617e40d166
127.0.0.1 - - [14/Feb/2025 22:25:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:32,737 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-14 22:25:32,745 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7acddd81-4b93-4ccb-b9e2-b40db31daede
127.0.0.1 - - [14/Feb/2025 22:25:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:32,763 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.465794
2025-02-14 22:25:32,772 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.190029
2025-02-14 22:25:32,790 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 88f68bbe-a4d8-472d-ae61-a5214dd87aba
127.0.0.1 - - [14/Feb/2025 22:25:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:33,190 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
2025-02-14 22:25:33,282 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.281418
2025-02-14 22:25:33,290 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-14 22:25:33,707 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.465794
2025-02-14 22:25:33,738 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.281418
2025-02-14 22:25:33,757 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-14 22:25:34,216 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 86003c9e-0660-4b7e-8d52-2769212794b9
127.0.0.1 - - [14/Feb/2025 22:25:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:34,262 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-14 22:25:34,270 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 218ee334-8fdd-4789-b4b2-842788aa4325
127.0.0.1 - - [14/Feb/2025 22:25:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:34,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-14 22:25:34,312 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.374043
2025-02-14 22:25:34,693 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
2025-02-14 22:25:34,725 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-14 22:25:34,756 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.190029
2025-02-14 22:25:35,198 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.098841
2025-02-14 22:25:35,252 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-14 22:25:35,265 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.559861
2025-02-14 22:25:35,728 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
2025-02-14 22:25:35,772 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.281418
2025-02-14 22:25:35,790 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.281418
2025-02-14 22:25:36,229 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-14 22:25:36,296 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.465794
2025-02-14 22:25:36,308 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.281418
2025-02-14 22:25:36,698 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-14 22:25:36,753 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
2025-02-14 22:25:36,791 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.559861
2025-02-14 22:25:37,234 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.374043
2025-02-14 22:25:37,237 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:25:37,251 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-14 22:25:37,273 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3e793d1e-f0a7-4f7a-b571-06eff9b1064a
2025-02-14 22:25:37,273 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 14d0c049-da16-420a-b97d-d3c9f5c8cf1c
127.0.0.1 - - [14/Feb/2025 22:25:37] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:25:37] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:37,728 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.64948
2025-02-14 22:25:37,785 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-14 22:25:37,786 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.559861
2025-02-14 22:25:38,221 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-14 22:25:38,258 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:25:38,260 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.190029
2025-02-14 22:25:38,432 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a923bbf0-4c7d-49b9-bed7-5d0e83f0612f
127.0.0.1 - - [14/Feb/2025 22:25:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:38,444 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8180e209-ad5f-43c0-b3f6-3bcf42750f63
127.0.0.1 - - [14/Feb/2025 22:25:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:38,487 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b80ea26e-c095-48be-8aa5-655543039fa8
127.0.0.1 - - [14/Feb/2025 22:25:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:38,743 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.374043
2025-02-14 22:25:38,767 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.465794
2025-02-14 22:25:38,861 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
2025-02-14 22:25:38,882 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f1a89fb2-6595-487f-a3e5-f3a9648e9475
127.0.0.1 - - [14/Feb/2025 22:25:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:38,930 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bd0f3909-0b4a-4720-9503-972a7765a4f2
127.0.0.1 - - [14/Feb/2025 22:25:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:39,179 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cdb9f93c-2f10-4b47-ae92-46400930d16e
127.0.0.1 - - [14/Feb/2025 22:25:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:39,222 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.559861
2025-02-14 22:25:39,351 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.559861
2025-02-14 22:25:39,425 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.64948
2025-02-14 22:25:39,698 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.190029
2025-02-14 22:25:39,779 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.465794
2025-02-14 22:25:39,829 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.465794
2025-02-14 22:25:40,215 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
2025-02-14 22:25:40,292 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.465794
2025-02-14 22:25:40,302 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-14 22:25:40,702 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-14 22:25:40,802 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.374043
2025-02-14 22:25:40,906 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-14 22:25:41,202 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-14 22:25:41,261 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.281418
2025-02-14 22:25:41,270 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.374043
2025-02-14 22:25:41,817 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.374043
2025-02-14 22:25:41,877 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-14 22:25:41,953 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-14 22:25:42,218 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.465794
2025-02-14 22:25:42,271 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.374043
2025-02-14 22:25:42,305 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.64948
2025-02-14 22:25:42,716 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-14 22:25:42,761 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.190029
2025-02-14 22:25:42,769 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.281418
2025-02-14 22:25:43,203 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-14 22:25:43,294 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-14 22:25:43,391 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
2025-02-14 22:25:43,514 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4146a427-cb34-41d5-b884-8926f7647221
127.0.0.1 - - [14/Feb/2025 22:25:43] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:43,555 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8531ec3e-67ef-4c49-98d2-77d2a2e36256
127.0.0.1 - - [14/Feb/2025 22:25:43] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:43,710 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-14 22:25:43,761 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.281418
2025-02-14 22:25:43,822 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
2025-02-14 22:25:44,231 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-14 22:25:44,264 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-14 22:25:44,273 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
2025-02-14 22:25:44,640 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2887e0e1-4bab-40b4-a5fe-ee3fd7508a73
127.0.0.1 - - [14/Feb/2025 22:25:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:44,651 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a6e65edf-0486-46a9-a5c4-212f0a0b3544
127.0.0.1 - - [14/Feb/2025 22:25:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:44,685 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6812ac96-6805-43ba-b40e-4cffc5906efe
127.0.0.1 - - [14/Feb/2025 22:25:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:44,716 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.281418
2025-02-14 22:25:44,770 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.374043
2025-02-14 22:25:44,802 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.64948
2025-02-14 22:25:45,003 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 79e5427b-5262-4418-879d-cf28f305ba70
127.0.0.1 - - [14/Feb/2025 22:25:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:45,021 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2a630405-6a28-4498-8717-e02538f40169
127.0.0.1 - - [14/Feb/2025 22:25:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:45,071 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fe8ad912-fb66-404e-8fcc-a315763ecc2a
127.0.0.1 - - [14/Feb/2025 22:25:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:45,092 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 76996db8-45cf-437b-b2ac-7af6e4c79644
127.0.0.1 - - [14/Feb/2025 22:25:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:45,100 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b30753f8-9c6c-487b-a968-49d07692a9ee
127.0.0.1 - - [14/Feb/2025 22:25:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:45,131 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1fc05f07-1292-4af9-8641-e42afeb78c39
127.0.0.1 - - [14/Feb/2025 22:25:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:45,258 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.190029
2025-02-14 22:25:45,271 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.465794
2025-02-14 22:25:45,359 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.374043
2025-02-14 22:25:45,704 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-14 22:25:45,763 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.190029
2025-02-14 22:25:45,776 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.281418
2025-02-14 22:25:46,213 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-14 22:25:46,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-14 22:25:46,307 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
2025-02-14 22:25:46,491 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 668bbf56-7bc5-4550-9d0f-a5a9ff34783e
127.0.0.1 - - [14/Feb/2025 22:25:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:46,538 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4571f267-bc39-49bc-80e1-a5d47153caee
127.0.0.1 - - [14/Feb/2025 22:25:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:46,545 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3afe731c-bf6c-4b5c-ac55-f89fc064c848
127.0.0.1 - - [14/Feb/2025 22:25:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:46,704 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-14 22:25:46,778 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.374043
2025-02-14 22:25:46,782 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.190029
2025-02-14 22:25:47,193 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-14 22:25:47,262 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.281418
2025-02-14 22:25:47,282 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
2025-02-14 22:25:47,766 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
2025-02-14 22:25:47,902 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-14 22:25:47,912 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.374043
2025-02-14 22:25:47,942 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a3dda0cb-24b7-4e93-99a1-43c26644e569
127.0.0.1 - - [14/Feb/2025 22:25:47] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:48,288 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.374043
2025-02-14 22:25:48,288 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.190029
2025-02-14 22:25:48,338 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.374043
2025-02-14 22:25:48,742 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.190029
2025-02-14 22:25:48,745 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-14 22:25:48,770 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.281418
2025-02-14 22:25:49,336 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.465794
2025-02-14 22:25:49,360 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.64948
2025-02-14 22:25:49,563 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-14 22:25:49,744 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-14 22:25:49,756 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-14 22:25:49,882 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.465794
2025-02-14 22:25:50,288 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
2025-02-14 22:25:50,459 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.559861
2025-02-14 22:25:50,499 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-14 22:25:50,784 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-14 22:25:50,892 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.465794
2025-02-14 22:25:51,149 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.64948
2025-02-14 22:25:51,267 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-14 22:25:51,332 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-14 22:25:51,372 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.098841
2025-02-14 22:25:51,829 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
2025-02-14 22:25:51,834 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.374043
2025-02-14 22:25:51,846 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.559861
2025-02-14 22:25:52,195 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-14 22:25:52,237 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 67ae5ac7-9469-4341-918e-9019eaefc94a
127.0.0.1 - - [14/Feb/2025 22:25:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:52,267 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-14 22:25:52,275 - LoudVA - INFO - [LoudServer] - Completed. Request ID: eb44226f-92c1-4327-9e04-eca18154da9e
127.0.0.1 - - [14/Feb/2025 22:25:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:52,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-14 22:25:52,332 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e3833a3f-3e6b-47a2-aa4c-3cce6274d83e
127.0.0.1 - - [14/Feb/2025 22:25:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:52,726 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.374043
2025-02-14 22:25:52,770 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
2025-02-14 22:25:52,905 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-14 22:25:53,262 - LoudVA - INFO - [LoudServer] - Completed. Request ID: efcb7f15-4e80-4b96-b4f8-c7ef0be13d9b
127.0.0.1 - - [14/Feb/2025 22:25:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:53,266 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.374043
2025-02-14 22:25:53,320 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d7e976c3-ae5a-4cd9-a5f1-7573e1e956cc
127.0.0.1 - - [14/Feb/2025 22:25:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:53,331 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-14 22:25:53,370 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.374043
2025-02-14 22:25:53,603 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9fb1c3eb-a37e-43af-9f23-e099803589f8
127.0.0.1 - - [14/Feb/2025 22:25:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:53,605 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bb2f3ca5-3a52-45d3-83c1-e6ef6671fd12
127.0.0.1 - - [14/Feb/2025 22:25:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:53,618 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 762fa3de-b42c-400f-8163-d4c757c82776
127.0.0.1 - - [14/Feb/2025 22:25:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:53,683 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8342ff60-d2ad-49af-9a4b-a1507a4c6fc4
127.0.0.1 - - [14/Feb/2025 22:25:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:25:53,717 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-14 22:25:53,773 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.190029
2025-02-14 22:25:53,793 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.281418
2025-02-14 22:25:54,228 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.374043
2025-02-14 22:25:54,265 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-14 22:25:54,402 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
2025-02-14 22:25:54,748 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-14 22:25:54,758 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.374043
2025-02-14 22:25:54,791 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.281418
2025-02-14 22:25:55,226 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.374043
2025-02-14 22:25:55,363 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.374043
2025-02-14 22:25:55,690 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.64948
2025-02-14 22:25:55,715 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
2025-02-14 22:25:55,766 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.281418
2025-02-14 22:25:55,898 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-14 22:25:56,190 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
2025-02-14 22:25:56,284 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.374043
2025-02-14 22:25:56,330 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-14 22:25:56,693 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-14 22:25:56,754 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-14 22:25:56,802 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-14 22:25:57,243 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
2025-02-14 22:25:57,304 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.281418
2025-02-14 22:25:57,333 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.465794
2025-02-14 22:25:57,741 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-14 22:25:57,773 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-14 22:25:57,842 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.559861
2025-02-14 22:25:58,252 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-14 22:25:58,371 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.559861
2025-02-14 22:25:58,570 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.64948
2025-02-14 22:25:58,726 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
2025-02-14 22:25:58,806 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
2025-02-14 22:25:58,943 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.190029
2025-02-14 22:25:59,379 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-14 22:25:59,430 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-14 22:25:59,666 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.64948
2025-02-14 22:25:59,800 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.374043
2025-02-14 22:25:59,867 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.374043
2025-02-14 22:25:59,923 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.281418
2025-02-14 22:26:00,274 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.281418
2025-02-14 22:26:00,427 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.190029
2025-02-14 22:26:00,463 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.559861
2025-02-14 22:26:00,773 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-14 22:26:00,796 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
2025-02-14 22:26:00,822 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c4984fb3-7595-4256-9c96-bdca8597aa9b
127.0.0.1 - - [14/Feb/2025 22:26:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:00,859 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.559861
2025-02-14 22:26:00,954 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 85ca1a79-234d-42d9-896c-802839fe963d
127.0.0.1 - - [14/Feb/2025 22:26:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:00,967 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c70cbba5-125e-4ae4-b677-1b4365353788
127.0.0.1 - - [14/Feb/2025 22:26:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:01,018 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8760abf2-0434-4cef-905f-c09a2aeeb286
127.0.0.1 - - [14/Feb/2025 22:26:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:01,040 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 69104fbe-bcaa-445c-a9b2-daf460efd80c
127.0.0.1 - - [14/Feb/2025 22:26:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:01,057 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a796ccea-76c6-4452-adbb-7700c4efd49d
127.0.0.1 - - [14/Feb/2025 22:26:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:01,264 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-14 22:26:01,272 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.64948
2025-02-14 22:26:01,298 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.281418
2025-02-14 22:26:01,743 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.190029
2025-02-14 22:26:01,803 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8fc7964b-9d77-47bd-897f-ea45dd890604
127.0.0.1 - - [14/Feb/2025 22:26:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:01,817 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-14 22:26:01,822 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ed4487dc-b770-462d-916b-b6a5f65a51e5
127.0.0.1 - - [14/Feb/2025 22:26:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:01,848 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5dc3dbac-ccf8-4cc2-b226-ef039f45aa14
127.0.0.1 - - [14/Feb/2025 22:26:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:01,852 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-14 22:26:01,854 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 32c215fa-d6b4-4687-a056-6e937889a834
2025-02-14 22:26:01,860 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a71e8b6c-85d9-4bd6-bce2-ee74f9883345
127.0.0.1 - - [14/Feb/2025 22:26:01] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:26:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:02,220 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
2025-02-14 22:26:02,251 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-14 22:26:02,488 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.374043
2025-02-14 22:26:02,727 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-14 22:26:02,823 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.374043
2025-02-14 22:26:02,834 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.465794
2025-02-14 22:26:03,280 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.559861
2025-02-14 22:26:03,333 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-14 22:26:03,369 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.559861
2025-02-14 22:26:03,781 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.559861
2025-02-14 22:26:03,864 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.190029
2025-02-14 22:26:04,053 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
2025-02-14 22:26:04,238 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.465794
2025-02-14 22:26:04,267 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-14 22:26:04,275 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-14 22:26:04,827 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-14 22:26:04,837 - LoudVA - INFO - [LoudServer] - Completed. Request ID: af4c6465-7d61-4c79-bb79-3946274f6ebe
127.0.0.1 - - [14/Feb/2025 22:26:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:04,876 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ee915ed8-0713-4ecc-af12-6993e225dc0f
127.0.0.1 - - [14/Feb/2025 22:26:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:04,948 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-14 22:26:05,054 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.559861
2025-02-14 22:26:05,373 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-14 22:26:05,458 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.64948
2025-02-14 22:26:05,637 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.374043
2025-02-14 22:26:05,970 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.374043
2025-02-14 22:26:05,995 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
2025-02-14 22:26:05,997 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.559861
2025-02-14 22:26:06,273 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-14 22:26:06,325 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-14 22:26:06,437 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 20897f77-19d0-4f2f-9353-972690eebf1a
127.0.0.1 - - [14/Feb/2025 22:26:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:06,464 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-14 22:26:06,499 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2621819e-c845-4b7a-b8d1-8b62dc0106b9
127.0.0.1 - - [14/Feb/2025 22:26:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:06,529 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f1ba3397-6b34-4922-8dd3-4aa394820478
127.0.0.1 - - [14/Feb/2025 22:26:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:06,750 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
2025-02-14 22:26:06,828 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-14 22:26:07,107 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.374043
2025-02-14 22:26:07,275 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-14 22:26:07,643 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
2025-02-14 22:26:07,649 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
2025-02-14 22:26:07,771 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-14 22:26:07,806 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-14 22:26:07,997 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.64948
2025-02-14 22:26:08,146 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 39420017-9124-4e7e-95fb-f74c990aca39
127.0.0.1 - - [14/Feb/2025 22:26:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:08,291 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-14 22:26:08,307 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.281418
2025-02-14 22:26:08,329 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 015aaee8-54b6-4776-95a6-7ab4808618ba
127.0.0.1 - - [14/Feb/2025 22:26:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:08,500 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.64948
2025-02-14 22:26:08,528 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7adfa6b4-cb47-4987-b501-2da073722d52
127.0.0.1 - - [14/Feb/2025 22:26:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:08,586 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 66715eae-c804-44ee-b1c7-1dcb7749116f
127.0.0.1 - - [14/Feb/2025 22:26:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:08,590 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c8cce975-c3b1-460b-9d14-be7f6927529e
127.0.0.1 - - [14/Feb/2025 22:26:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:08,611 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d07e5908-6dca-41f7-a9a5-392e1d361ed6
127.0.0.1 - - [14/Feb/2025 22:26:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:08,776 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-14 22:26:08,785 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.098841
2025-02-14 22:26:08,845 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.281418
2025-02-14 22:26:09,243 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-14 22:26:09,510 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.374043
2025-02-14 22:26:09,608 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.465794
2025-02-14 22:26:09,790 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.190029
2025-02-14 22:26:09,826 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-14 22:26:09,900 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-14 22:26:10,199 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:26:10,285 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.281418
2025-02-14 22:26:10,288 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.64948
2025-02-14 22:26:10,615 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5222672a-e444-449f-9a95-dad96906ec15
127.0.0.1 - - [14/Feb/2025 22:26:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:10,721 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 040eb749-bfd6-40b8-8062-660daf3d0475
2025-02-14 22:26:10,732 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
127.0.0.1 - - [14/Feb/2025 22:26:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:10,779 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.190029
2025-02-14 22:26:10,787 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.190029
2025-02-14 22:26:10,995 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 60a3d48f-fae8-408c-b53c-536fb58075ad
127.0.0.1 - - [14/Feb/2025 22:26:11] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:11,222 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
2025-02-14 22:26:11,268 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-14 22:26:11,295 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.190029
2025-02-14 22:26:11,721 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-14 22:26:11,784 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-14 22:26:11,828 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
2025-02-14 22:26:12,288 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.190029
2025-02-14 22:26:12,297 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
2025-02-14 22:26:12,412 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
2025-02-14 22:26:12,747 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.281418
2025-02-14 22:26:12,763 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.281418
2025-02-14 22:26:12,831 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.465794
2025-02-14 22:26:12,853 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0afb8eb0-1541-4275-bb1c-f13c2c536277
127.0.0.1 - - [14/Feb/2025 22:26:12] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:12,873 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ddd1d0a0-49e7-4170-ac07-7c95522f29a3
127.0.0.1 - - [14/Feb/2025 22:26:12] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:12,977 - LoudVA - INFO - [LoudServer] - Completed. Request ID: def8a313-74f1-4fcf-b964-57f4290b309c
127.0.0.1 - - [14/Feb/2025 22:26:12] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:13,109 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6fb51ce4-0056-4450-81b5-c04e4981bb24
127.0.0.1 - - [14/Feb/2025 22:26:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:13,135 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 83992500-be83-4256-8280-82206a6011e4
127.0.0.1 - - [14/Feb/2025 22:26:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:13,213 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5646cdf1-a435-4314-bbd7-dc077dd68b17
127.0.0.1 - - [14/Feb/2025 22:26:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:13,293 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.190029
2025-02-14 22:26:13,309 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.465794
2025-02-14 22:26:13,585 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.190029
2025-02-14 22:26:13,707 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-14 22:26:13,797 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
2025-02-14 22:26:13,976 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.374043
2025-02-14 22:26:14,278 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:26:14,307 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.374043
2025-02-14 22:26:14,512 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bd0ae524-ed2d-4b2b-becf-4e5067167a8a
127.0.0.1 - - [14/Feb/2025 22:26:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:14,519 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5275467d-0491-4fd3-b1ab-3806422d65f3
127.0.0.1 - - [14/Feb/2025 22:26:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:14,548 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-14 22:26:14,671 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7a6bd5ae-4840-4471-96a8-c90a619afa1f
127.0.0.1 - - [14/Feb/2025 22:26:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:14,782 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:26:14,799 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.465794
2025-02-14 22:26:14,808 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:26:15,254 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2408ee8f-f1b5-4fa2-bae1-ebc083998ac6
127.0.0.1 - - [14/Feb/2025 22:26:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:15,291 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7923dab1-841a-4257-96c9-e320f4f4e664
127.0.0.1 - - [14/Feb/2025 22:26:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:15,311 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.281418
2025-02-14 22:26:15,600 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.190029
2025-02-14 22:26:15,753 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-14 22:26:15,798 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
2025-02-14 22:26:15,850 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
2025-02-14 22:26:16,006 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.559861
2025-02-14 22:26:16,202 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-14 22:26:16,313 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.190029
2025-02-14 22:26:16,417 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.465794
2025-02-14 22:26:16,606 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 32af7685-e3c5-49fb-abd8-3741d02c52cd
127.0.0.1 - - [14/Feb/2025 22:26:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:16,797 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.190029
2025-02-14 22:26:16,909 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.374043
2025-02-14 22:26:17,051 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.465794
2025-02-14 22:26:17,243 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
2025-02-14 22:26:17,319 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-14 22:26:17,377 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.64948
2025-02-14 22:26:17,753 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-14 22:26:17,807 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-14 22:26:18,028 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.465794
2025-02-14 22:26:18,269 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.190029
2025-02-14 22:26:18,284 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-14 22:26:18,395 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-14 22:26:18,740 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
2025-02-14 22:26:18,802 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:26:18,966 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.281418
2025-02-14 22:26:19,308 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.281418
2025-02-14 22:26:19,333 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.374043
2025-02-14 22:26:19,356 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
2025-02-14 22:26:19,851 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
2025-02-14 22:26:20,019 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-14 22:26:20,111 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.64948
2025-02-14 22:26:20,318 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-14 22:26:20,342 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-14 22:26:20,489 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.465794
2025-02-14 22:26:20,771 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-14 22:26:20,903 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.374043
2025-02-14 22:26:20,982 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-14 22:26:21,251 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-14 22:26:21,380 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-14 22:26:21,835 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.190029
2025-02-14 22:26:21,836 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-14 22:26:21,897 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.190029
2025-02-14 22:26:21,991 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a4eccff3-a71f-44f2-8128-700b97eb567d
127.0.0.1 - - [14/Feb/2025 22:26:21] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:22,023 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-14 22:26:22,182 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a8b47a11-1c80-436f-a0aa-74e529ed6114
127.0.0.1 - - [14/Feb/2025 22:26:22] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:22,254 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-14 22:26:22,435 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.465794
2025-02-14 22:26:22,473 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.64948
2025-02-14 22:26:22,809 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.281418
2025-02-14 22:26:22,892 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:26:22,896 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
2025-02-14 22:26:23,250 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.098841
2025-02-14 22:26:23,354 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b6769004-16da-4578-9696-74d298fa6cfc
127.0.0.1 - - [14/Feb/2025 22:26:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:23,375 - LoudVA - INFO - [LoudServer] - Completed. Request ID: aa2fc655-2a11-4f38-900b-6b38e16f95f0
127.0.0.1 - - [14/Feb/2025 22:26:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:23,408 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f6658757-d5fc-495b-8112-b88d95513761
127.0.0.1 - - [14/Feb/2025 22:26:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:23,442 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
2025-02-14 22:26:23,626 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.64948
2025-02-14 22:26:23,639 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a4542abd-f14a-43f5-a915-38f378769e7a
127.0.0.1 - - [14/Feb/2025 22:26:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:23,688 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6767e6c2-02eb-49af-9532-038a9e046b44
127.0.0.1 - - [14/Feb/2025 22:26:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:23,734 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0fe8214e-0ddb-400b-a12d-a55fca0a5df5
127.0.0.1 - - [14/Feb/2025 22:26:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:23,750 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 64e4074b-12bf-427b-83a0-c6ae035dbc5f
127.0.0.1 - - [14/Feb/2025 22:26:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:23,817 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-14 22:26:23,828 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fd9c242c-4ee7-4447-8191-fef25bac87d1
127.0.0.1 - - [14/Feb/2025 22:26:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:23,898 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ee69227e-0c84-4d59-a841-022e14bc3ae7
127.0.0.1 - - [14/Feb/2025 22:26:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:23,936 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
2025-02-14 22:26:24,021 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.374043
2025-02-14 22:26:24,204 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:26:24,419 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-14 22:26:24,450 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.190029
2025-02-14 22:26:24,906 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-14 22:26:24,955 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-14 22:26:25,237 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-14 22:26:25,270 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
2025-02-14 22:26:25,364 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.190029
2025-02-14 22:26:25,461 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.281418
2025-02-14 22:26:25,837 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
2025-02-14 22:26:26,045 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.465794
2025-02-14 22:26:26,219 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-14 22:26:26,317 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.465794
2025-02-14 22:26:26,560 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-14 22:26:26,564 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.465794
2025-02-14 22:26:26,800 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-14 22:26:26,801 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-14 22:26:27,011 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.374043
2025-02-14 22:26:27,258 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
2025-02-14 22:26:27,299 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-14 22:26:27,312 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-14 22:26:27,791 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.374043
2025-02-14 22:26:27,998 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
2025-02-14 22:26:28,051 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.190029
2025-02-14 22:26:28,233 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-14 22:26:28,423 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.281418
2025-02-14 22:26:28,470 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.559861
2025-02-14 22:26:28,533 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c56e225c-8804-4def-84e5-436e3497340a
127.0.0.1 - - [14/Feb/2025 22:26:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:28,571 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a851e0c5-62b1-426d-a81b-4f691543e2f9
127.0.0.1 - - [14/Feb/2025 22:26:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:28,866 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.374043
2025-02-14 22:26:28,889 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.64948
2025-02-14 22:26:29,034 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
2025-02-14 22:26:29,414 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.374043
2025-02-14 22:26:29,456 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.465794
2025-02-14 22:26:29,655 - LoudVA - INFO - [LoudServer] - Completed. Request ID: eb3c8d9e-5953-405c-a656-72090542eb56
127.0.0.1 - - [14/Feb/2025 22:26:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:26:29,782 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-14 22:26:29,813 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
2025-02-14 22:26:29,821 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.281418
2025-02-14 22:26:29,884 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.281418
2025-02-14 22:26:30,250 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-14 22:26:30,375 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.374043
2025-02-14 22:26:30,411 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.374043
Exception in thread Thread-84:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:30,789 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
2025-02-14 22:26:30,809 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.190029
2025-02-14 22:26:31,202 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.559861
2025-02-14 22:26:31,276 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-14 22:26:31,277 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-14 22:26:31,439 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.559861
Exception in thread Thread-86:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:31,945 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.559861
2025-02-14 22:26:32,026 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.559861
2025-02-14 22:26:32,248 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-14 22:26:32,323 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-14 22:26:32,353 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.281418
Exception in thread Thread-85:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:32,557 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.64948
Exception in thread Thread-91:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:32,778 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-14 22:26:32,779 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-14 22:26:32,842 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
Exception in thread Thread-92:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-89:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-88:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-93:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:33,406 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.559861
2025-02-14 22:26:33,439 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.374043
2025-02-14 22:26:33,458 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.374043
Exception in thread Thread-95:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:33,870 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.281418
Exception in thread Thread-90:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:33,935 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
Exception in thread Thread-94:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:34,259 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
2025-02-14 22:26:34,819 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-14 22:26:34,858 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.281418
Exception in thread Thread-83:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:34,981 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
2025-02-14 22:26:35,501 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.374043
Exception in thread Thread-97:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:35,852 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.559861
2025-02-14 22:26:35,908 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.374043
Exception in thread Thread-98:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-96:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:36,409 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.374043
2025-02-14 22:26:36,496 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.64948
Exception in thread Thread-99:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:36,824 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.559861
2025-02-14 22:26:36,828 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
2025-02-14 22:26:36,957 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.190029
Exception in thread Thread-100:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:37,336 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.465794
2025-02-14 22:26:37,412 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.465794
Exception in thread Thread-101:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:37,848 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.281418
2025-02-14 22:26:38,010 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.465794
2025-02-14 22:26:38,393 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.281418
2025-02-14 22:26:38,549 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
Exception in thread Thread-105:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:38,856 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.465794
Exception in thread Thread-102:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:38,871 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
Exception in thread Thread-106:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:39,296 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.374043
2025-02-14 22:26:39,513 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-14 22:26:39,795 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.281418
Exception in thread Thread-109:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-107:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:40,073 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
Exception in thread Thread-110:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:40,511 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.098841
2025-02-14 22:26:40,528 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.465794
Exception in thread Thread-113:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:40,806 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.190029
2025-02-14 22:26:40,814 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.190029
Exception in thread Thread-108:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:41,257 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
Exception in thread Thread-103:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:41,665 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.281418
2025-02-14 22:26:41,853 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.281418
2025-02-14 22:26:41,988 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.465794
Exception in thread Thread-115:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-111:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-104:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:42,289 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
Exception in thread Thread-116:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-118:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:42,807 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:26:42,907 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-14 22:26:43,208 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
Exception in thread Thread-117:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:43,373 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.281418
Exception in thread Thread-112:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:43,894 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-14 22:26:44,069 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.374043
2025-02-14 22:26:44,275 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.374043
2025-02-14 22:26:44,280 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.374043
Exception in thread Thread-120:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:44,553 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
Exception in thread Thread-119:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:44,859 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.465794
Exception in thread Thread-123:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
Exception in thread Thread-122:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-121:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:45,263 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
2025-02-14 22:26:45,291 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-14 22:26:45,328 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.281418
2025-02-14 22:26:45,861 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.281418
2025-02-14 22:26:45,905 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.465794
Exception in thread Thread-114:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-124:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-127:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:46,677 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.281418
2025-02-14 22:26:46,711 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-14 22:26:46,855 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.190029
Exception in thread Thread-125:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:47,334 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-14 22:26:47,385 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.465794
Exception in thread Thread-129:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-130:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:48,117 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-14 22:26:48,220 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.559861
Exception in thread Thread-128:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:48,534 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.559861
2025-02-14 22:26:48,778 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
Exception in thread Thread-126:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:48,892 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.465794
2025-02-14 22:26:48,913 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.374043
2025-02-14 22:26:49,051 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.374043
2025-02-14 22:26:49,373 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
Exception in thread Thread-134:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:49,753 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.374043
2025-02-14 22:26:49,785 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-14 22:26:49,940 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-14 22:26:50,333 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.190029
2025-02-14 22:26:50,348 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
Exception in thread Thread-136:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-133:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-132:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-137:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-131:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:50,852 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
Exception in thread Thread-135:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-138:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:51,524 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.374043
Exception in thread Thread-140:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:52,071 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
2025-02-14 22:26:52,337 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
Exception in thread Thread-142:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-143:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:53,211 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.190029
2025-02-14 22:26:53,459 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
2025-02-14 22:26:53,702 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-14 22:26:53,718 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-14 22:26:53,912 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.465794
2025-02-14 22:26:54,236 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.098841
Exception in thread Thread-144:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-146:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-145:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-139:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:54,944 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.374043
2025-02-14 22:26:54,953 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.281418
2025-02-14 22:26:55,518 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.559861
Exception in thread Thread-148:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:55,737 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.190029
2025-02-14 22:26:55,755 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
Exception in thread Thread-149:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:56,311 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.374043
Exception in thread Thread-150:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-151:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:56,720 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.190029
2025-02-14 22:26:57,051 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-14 22:26:57,230 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
Exception in thread Thread-153:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:57,723 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-14 22:26:57,748 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
Exception in thread Thread-154:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:58,309 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.190029
Exception in thread Thread-152:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:58,925 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
2025-02-14 22:26:58,955 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.281418
Exception in thread Thread-155:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:59,244 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
Exception in thread Thread-156:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:26:59,919 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.281418
2025-02-14 22:27:00,023 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.190029
Exception in thread Thread-157:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-158:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:00,667 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-14 22:27:00,794 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.190029
2025-02-14 22:27:00,873 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.559861
Exception in thread Thread-161:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:01,291 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.374043
Exception in thread Thread-163:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-160:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-165:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-164:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:01,948 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-14 22:27:02,226 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.64948
Exception in thread Thread-166:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:02,725 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.281418
2025-02-14 22:27:02,799 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-14 22:27:02,923 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.281418
Exception in thread Thread-169:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:03,321 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.190029
2025-02-14 22:27:03,781 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.190029
Exception in thread Thread-171:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-168:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
Exception in thread Thread-170:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:04,405 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
Exception in thread Thread-162:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-167:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:04,672 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.559861
2025-02-14 22:27:04,805 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-14 22:27:04,846 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
Exception in thread Thread-174:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-172:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:05,369 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.374043
2025-02-14 22:27:05,729 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
Exception in thread Thread-176:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:05,875 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
Exception in thread Thread-175:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:06,254 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.374043
2025-02-14 22:27:06,734 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
Exception in thread Thread-173:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-177:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-179:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:06,999 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
Exception in thread Thread-178:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:07,469 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.64948
Exception in thread Thread-159:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-180:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:07,732 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.281418
2025-02-14 22:27:07,746 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-14 22:27:08,248 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
Exception in thread Thread-181:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:08,839 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-14 22:27:08,885 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.190029
Exception in thread Thread-185:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-183:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-182:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:09,307 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
Exception in thread Thread-184:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:10,196 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.374043
2025-02-14 22:27:10,417 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
2025-02-14 22:27:10,443 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
Exception in thread Thread-188:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-189:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-187:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:10,724 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
Exception in thread Thread-190:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:11,237 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.190029
2025-02-14 22:27:11,328 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
2025-02-14 22:27:11,702 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.281418
2025-02-14 22:27:11,744 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
2025-02-14 22:27:12,533 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-14 22:27:12,705 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.281418
Exception in thread Thread-191:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-141:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:13,004 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.64948
Exception in thread Thread-192:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:13,059 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.64948
2025-02-14 22:27:13,404 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
Exception in thread Thread-194:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:13,667 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
Exception in thread Thread-196:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:13,730 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.281418
2025-02-14 22:27:13,750 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.190029
2025-02-14 22:27:13,805 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.190029
2025-02-14 22:27:14,197 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.64948
Exception in thread Thread-195:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:14,522 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
Exception in thread Thread-198:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:14,827 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.281418
2025-02-14 22:27:14,852 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.374043
2025-02-14 22:27:14,877 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-14 22:27:14,979 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.374043
Exception in thread Thread-197:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:15,299 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
Exception in thread Thread-186:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-199:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:15,806 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.190029
2025-02-14 22:27:15,915 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.190029
2025-02-14 22:27:16,010 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.559861
2025-02-14 22:27:16,148 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
2025-02-14 22:27:16,479 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
Exception in thread Thread-200:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:16,726 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-14 22:27:16,803 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.281418
Exception in thread Thread-202:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:16,907 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
Exception in thread Thread-201:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-203:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-147:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:17,287 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
2025-02-14 22:27:17,379 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.559861
2025-02-14 22:27:17,798 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.465794
2025-02-14 22:27:17,806 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.374043
Exception in thread Thread-206:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-204:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-205:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:18,012 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-14 22:27:18,027 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
2025-02-14 22:27:18,395 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
Exception in thread Thread-207:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:18,812 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
2025-02-14 22:27:18,871 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.281418
2025-02-14 22:27:18,920 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-14 22:27:19,355 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
2025-02-14 22:27:19,506 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
2025-02-14 22:27:19,865 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-14 22:27:19,950 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.374043
2025-02-14 22:27:20,079 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
Exception in thread Thread-209:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-210:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:20,248 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
Exception in thread Thread-211:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:20,821 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-14 22:27:20,977 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.465794
2025-02-14 22:27:21,000 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.64948
2025-02-14 22:27:21,028 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.465794
2025-02-14 22:27:21,185 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.374043
Exception in thread Thread-212:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:21,486 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
2025-02-14 22:27:21,514 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.374043
Exception in thread Thread-214:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-213:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:22,319 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.281418
2025-02-14 22:27:22,344 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.559861
2025-02-14 22:27:22,430 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.559861
2025-02-14 22:27:22,575 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.559861
2025-02-14 22:27:22,578 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.190029
2025-02-14 22:27:22,788 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.190029
2025-02-14 22:27:22,820 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
Exception in thread Thread-217:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:23,347 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.190029
2025-02-14 22:27:23,412 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.64948
2025-02-14 22:27:23,595 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.190029
2025-02-14 22:27:23,719 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
Exception in thread Thread-218:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-215:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-219:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:23,976 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.374043
2025-02-14 22:27:24,040 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-14 22:27:24,299 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.190029
Exception in thread Thread-216:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-222:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:24,897 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
2025-02-14 22:27:25,185 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
2025-02-14 22:27:25,226 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
Exception in thread Thread-223:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:25,485 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.374043
2025-02-14 22:27:25,616 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.374043
Exception in thread Thread-221:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:25,740 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-14 22:27:25,892 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.374043
2025-02-14 22:27:25,905 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.281418
2025-02-14 22:27:26,075 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.190029
2025-02-14 22:27:26,411 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
Exception in thread Thread-225:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:26,464 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
Exception in thread Thread-224:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:26,875 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.281418
2025-02-14 22:27:26,894 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
Exception in thread Thread-226:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-220:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-229:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:27,397 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
2025-02-14 22:27:27,415 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.190029
2025-02-14 22:27:27,437 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.559861
Exception in thread Thread-228:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-227:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:27,978 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
2025-02-14 22:27:28,009 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.559861
Exception in thread Thread-231:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:28,354 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
2025-02-14 22:27:28,508 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.374043
2025-02-14 22:27:28,563 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
Exception in thread Thread-230:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:28,758 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
Exception in thread Thread-232:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:28,820 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.374043
2025-02-14 22:27:28,983 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-14 22:27:29,395 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.465794
2025-02-14 22:27:29,432 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
Exception in thread Thread-234:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-233:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:30,003 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.281418
Exception in thread Thread-236:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:30,108 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.281418
Exception in thread Thread-235:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:30,436 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.190029
2025-02-14 22:27:30,571 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
2025-02-14 22:27:30,737 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.465794
Exception in thread Thread-237:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:30,821 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.098841
Exception in thread Thread-238:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:31,147 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.559861
2025-02-14 22:27:31,313 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.190029
2025-02-14 22:27:31,491 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-14 22:27:31,753 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-14 22:27:31,910 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.374043
Exception in thread Thread-240:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:31,980 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.559861
2025-02-14 22:27:32,047 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.281418
Exception in thread Thread-239:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:32,326 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.374043
2025-02-14 22:27:32,448 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.190029
Exception in thread Thread-242:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:33,033 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.190029
Exception in thread Thread-241:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:33,212 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.374043
Exception in thread Thread-243:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:33,258 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
2025-02-14 22:27:33,509 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
2025-02-14 22:27:33,738 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.098841
2025-02-14 22:27:34,064 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.559861
Exception in thread Thread-245:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-244:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:34,385 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.190029
2025-02-14 22:27:34,461 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
2025-02-14 22:27:35,080 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.559861
2025-02-14 22:27:35,179 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.281418
2025-02-14 22:27:35,252 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.098841
Exception in thread Thread-247:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:35,405 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.190029
Exception in thread Thread-246:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-248:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-249:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:36,523 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-14 22:27:36,670 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.281418
2025-02-14 22:27:36,726 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.374043
2025-02-14 22:27:36,819 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
Exception in thread Thread-250:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:37,001 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.281418
2025-02-14 22:27:37,095 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.559861
2025-02-14 22:27:37,253 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
Exception in thread Thread-251:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:37,952 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.281418
2025-02-14 22:27:38,060 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.374043
Exception in thread Thread-252:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:38,363 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.281418
Exception in thread Thread-254:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:38,393 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.374043
2025-02-14 22:27:38,402 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.098841
2025-02-14 22:27:38,784 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.281418
Exception in thread Thread-253:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:38,945 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.098841
2025-02-14 22:27:39,381 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.465794
Exception in thread Thread-256:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:39,794 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.190029
2025-02-14 22:27:39,832 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.281418
2025-02-14 22:27:40,008 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
Exception in thread Thread-255:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-257:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:40,694 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.374043
2025-02-14 22:27:40,807 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.374043
2025-02-14 22:27:40,967 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.281418
Exception in thread Thread-258:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:41,233 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.374043
2025-02-14 22:27:41,417 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.098841
2025-02-14 22:27:41,734 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.281418
2025-02-14 22:27:41,884 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.190029
2025-02-14 22:27:41,952 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.098841
2025-02-14 22:27:42,714 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.559861
2025-02-14 22:27:42,721 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.098841
Exception in thread Thread-260:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:43,055 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.559861
2025-02-14 22:27:43,302 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.465794
2025-02-14 22:27:43,375 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.190029
2025-02-14 22:27:43,464 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.098841
Exception in thread Thread-261:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:44,126 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.559861
2025-02-14 22:27:44,138 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.190029
2025-02-14 22:27:44,261 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:27:44,601 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.64948
Exception in thread Thread-262:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
Exception in thread Thread-259:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    raise timeout('timed out')
socket.timeout: timed out
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:44,803 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
2025-02-14 22:27:45,242 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
Exception in thread Thread-264:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:45,676 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.098841
Exception in thread Thread-263:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:45,832 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.098841
2025-02-14 22:27:45,892 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
Exception in thread Thread-265:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:46,004 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.098841
2025-02-14 22:27:46,394 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.098841
2025-02-14 22:27:46,480 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-14 22:27:46,878 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.64948
2025-02-14 22:27:47,346 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.559861
2025-02-14 22:27:47,440 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.64948
Exception in thread Thread-267:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:47,567 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
Exception in thread Thread-266:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:47,899 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.098841
2025-02-14 22:27:48,163 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.465794
2025-02-14 22:27:48,444 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.374043
Exception in thread Thread-268:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:48,460 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.098841
Exception in thread Thread-193:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 331, in __send_chunk
    data_sent += socket.send(chunk, flags, timeout=timeleft)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 730, in send
    self._wait(self._write_event)
  File "src/gevent/_hub_primitives.py", line 317, in gevent._gevent_c_hub_primitives.wait_on_socket
  File "src/gevent/_hub_primitives.py", line 322, in gevent._gevent_c_hub_primitives.wait_on_socket
  File "src/gevent/_hub_primitives.py", line 313, in gevent._gevent_c_hub_primitives._primitive_wait
  File "src/gevent/_hub_primitives.py", line 314, in gevent._gevent_c_hub_primitives._primitive_wait
  File "src/gevent/_hub_primitives.py", line 46, in gevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait
  File "src/gevent/_hub_primitives.py", line 46, in gevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait
  File "src/gevent/_hub_primitives.py", line 55, in gevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait
  File "src/gevent/_waiter.py", line 154, in gevent._gevent_c_waiter.Waiter.get
  File "src/gevent/_greenlet_primitives.py", line 61, in gevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch
  File "src/gevent/_greenlet_primitives.py", line 61, in gevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch
  File "src/gevent/_greenlet_primitives.py", line 65, in gevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch
  File "src/gevent/_gevent_c_greenlet_primitives.pxd", line 35, in gevent._gevent_c_greenlet_primitives._greenlet_switch
socket.timeout: timed out
2025-02-14 22:27:48,858 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.190029
Exception in thread Thread-271:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:49,365 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.559861
Exception in thread Thread-270:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:49,627 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.559861
Exception in thread Thread-272:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:50,000 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.374043
Exception in thread Thread-274:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:50,463 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.098841
Exception in thread Thread-269:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-275:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:51,054 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.281418
2025-02-14 22:27:51,376 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.098841
Exception in thread Thread-276:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:52,120 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.281418
2025-02-14 22:27:52,754 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.465794
Exception in thread Thread-277:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:53,052 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.190029
2025-02-14 22:27:53,515 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.374043
Exception in thread Thread-273:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-278:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:54,479 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.374043
Exception in thread Thread-279:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:55,407 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.374043
2025-02-14 22:27:55,471 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-14 22:27:55,541 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.559861
Exception in thread Thread-280:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:56,359 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.281418
Exception in thread Thread-281:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:56,754 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.281418
Exception in thread Thread-282:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:57,458 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.190029
2025-02-14 22:27:57,554 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.559861
Exception in thread Thread-283:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:57,930 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.098841
2025-02-14 22:27:58,640 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.374043
2025-02-14 22:27:59,088 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.190029
Exception in thread Thread-284:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:27:59,704 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.465794
2025-02-14 22:28:00,041 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.190029
Exception in thread Thread-285:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:28:00,527 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.374043
2025-02-14 22:28:00,968 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.098841
2025-02-14 22:28:01,471 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.465794
Exception in thread Thread-287:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-286:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-288:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-289:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-290:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-291:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-292:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-293:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-294:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-295:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-296:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-297:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-208:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 331, in __send_chunk
    data_sent += socket.send(chunk, flags, timeout=timeleft)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 730, in send
    self._wait(self._write_event)
  File "src/gevent/_hub_primitives.py", line 317, in gevent._gevent_c_hub_primitives.wait_on_socket
  File "src/gevent/_hub_primitives.py", line 322, in gevent._gevent_c_hub_primitives.wait_on_socket
  File "src/gevent/_hub_primitives.py", line 313, in gevent._gevent_c_hub_primitives._primitive_wait
  File "src/gevent/_hub_primitives.py", line 314, in gevent._gevent_c_hub_primitives._primitive_wait
  File "src/gevent/_hub_primitives.py", line 46, in gevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait
  File "src/gevent/_hub_primitives.py", line 46, in gevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait
  File "src/gevent/_hub_primitives.py", line 55, in gevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait
  File "src/gevent/_waiter.py", line 154, in gevent._gevent_c_waiter.Waiter.get
  File "src/gevent/_greenlet_primitives.py", line 61, in gevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch
  File "src/gevent/_greenlet_primitives.py", line 61, in gevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch
  File "src/gevent/_greenlet_primitives.py", line 65, in gevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch
  File "src/gevent/_gevent_c_greenlet_primitives.pxd", line 35, in gevent._gevent_c_greenlet_primitives._greenlet_switch
socket.timeout: timed out
Exception in thread Thread-298:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:28:12,083 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 84e51a0b-09dc-4521-ac6f-c33871fffc7b
127.0.0.1 - - [14/Feb/2025 22:28:12] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-299:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:28:12,343 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4b465d69-15af-4ee0-bc5c-84c6b7226839
127.0.0.1 - - [14/Feb/2025 22:28:12] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-300:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-301:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-302:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-303:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-305:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-306:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-308:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-307:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-309:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-310:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-311:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-312:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-313:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-315:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-316:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:28:20,869 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1e1970ea-ff55-40b6-802b-3664c10a5d15
127.0.0.1 - - [14/Feb/2025 22:28:20] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:21,203 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d22a6d54-d50a-46cb-bc31-782d20dfe21a
127.0.0.1 - - [14/Feb/2025 22:28:21] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-318:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:28:22,071 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cce6e818-4289-4d03-9aa1-c60fa2d20559
127.0.0.1 - - [14/Feb/2025 22:28:22] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-319:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:28:22,195 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 12aa482c-8294-4666-804d-a7189e4041ee
127.0.0.1 - - [14/Feb/2025 22:28:22] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-320:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-322:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-324:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-325:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:28:24,964 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 574bde85-a414-45fe-8753-b17383f9fb7a
127.0.0.1 - - [14/Feb/2025 22:28:24] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:25,120 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4d60e9c4-4603-47f7-9030-18abe6379c2e
127.0.0.1 - - [14/Feb/2025 22:28:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:25,179 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fef47332-f5c0-472a-a903-134a2f7cafb9
127.0.0.1 - - [14/Feb/2025 22:28:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:25,213 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ec7763d3-27ad-428b-abdb-ac903892b522
127.0.0.1 - - [14/Feb/2025 22:28:25] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-327:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-328:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:28:26,844 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bb9d9d3f-ced8-493a-a22b-9d1373e511b1
127.0.0.1 - - [14/Feb/2025 22:28:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:26,923 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4ea351ff-7c62-49d0-9218-56f8553af937
127.0.0.1 - - [14/Feb/2025 22:28:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:26,943 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 35c3f305-23d4-4869-9389-7d752566ee0a
127.0.0.1 - - [14/Feb/2025 22:28:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:27,266 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f8c396dd-4034-4e73-b469-7ec023bf303c
127.0.0.1 - - [14/Feb/2025 22:28:27] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:27,548 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f3c1e5a7-4377-480e-9e4b-fcb0c7ee0dd2
127.0.0.1 - - [14/Feb/2025 22:28:27] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:27,614 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4f1d8b0e-2fd6-486f-b861-3932ad9f4a82
127.0.0.1 - - [14/Feb/2025 22:28:27] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:27,665 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f2f8aaf7-e401-4ec8-85cd-6fe1eb5a096d
127.0.0.1 - - [14/Feb/2025 22:28:27] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-330:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 262, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-14 22:28:27,777 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d6f8fe73-237c-41a5-b9fa-865dda6b352c
127.0.0.1 - - [14/Feb/2025 22:28:27] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:27,898 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8886cdc1-f9b2-42c5-ac3f-822dd3aa69bb
127.0.0.1 - - [14/Feb/2025 22:28:27] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:28,096 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4eadb16f-3c12-4c0a-a100-e4e5a164262e
127.0.0.1 - - [14/Feb/2025 22:28:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:28,186 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5e404805-f9a8-4ef4-8b4d-837e1f0bb606
127.0.0.1 - - [14/Feb/2025 22:28:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:28,194 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 77a810b0-0ba4-4df0-b91b-17a8442897b9
127.0.0.1 - - [14/Feb/2025 22:28:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:28,417 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8446c77a-f4f1-4c5a-a58b-8aabeee79f70
127.0.0.1 - - [14/Feb/2025 22:28:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:28,521 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d36e714b-8164-4e23-a4c9-0fa71cd0d435
127.0.0.1 - - [14/Feb/2025 22:28:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:28,849 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fa42b900-68be-410f-9045-0fd276f86609
127.0.0.1 - - [14/Feb/2025 22:28:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:28,864 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 491409d2-9a71-46fe-8e42-98995ae13181
127.0.0.1 - - [14/Feb/2025 22:28:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:29,487 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e4d3396c-227b-441c-b6e1-68b2d54d58e9
127.0.0.1 - - [14/Feb/2025 22:28:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:29,755 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d79bc7b9-5405-45b2-bd37-7e8f20e5a75f
127.0.0.1 - - [14/Feb/2025 22:28:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:29,977 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fadd8893-ed38-4a76-bfb2-dbef0dae621d
127.0.0.1 - - [14/Feb/2025 22:28:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:30,258 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 92775f22-63e0-4f73-8216-a3edd5a4eefb
127.0.0.1 - - [14/Feb/2025 22:28:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:30,289 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e8742af3-8dba-48dc-b41f-0c0b2ac92da1
127.0.0.1 - - [14/Feb/2025 22:28:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:30,355 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fc1ede5a-916f-49f6-ba14-7099d2c639d7
127.0.0.1 - - [14/Feb/2025 22:28:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:30,372 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fd9f31e6-3f60-4781-94df-99911a94e548
127.0.0.1 - - [14/Feb/2025 22:28:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:30,437 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 524deb4e-b1c8-4e0b-93a0-f6dd0bb3e8a2
127.0.0.1 - - [14/Feb/2025 22:28:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:30,791 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8a2f7f5f-93a7-4171-9525-009f283bafd2
127.0.0.1 - - [14/Feb/2025 22:28:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:30,820 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1f493912-ee48-4103-81ae-cc6e53fe5a43
127.0.0.1 - - [14/Feb/2025 22:28:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:30,833 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 27eef2ab-5aed-4ac8-ba4c-a1d92694415f
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:30,979 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3a1d8239-aee7-4b48-a84a-2c0e5cb7b209
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,034 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c4392704-808b-4606-95c5-aedc69a89068
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,085 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 829c0889-2d58-4edc-b46f-7959c0fdaf86
2025-02-14 22:28:31,092 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 82d8a320-4d85-42f3-aba1-e817dc1b8daa
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,095 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0805105f-8102-48b2-8a7c-7ae4288c1001
2025-02-14 22:28:31,139 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 74da4210-1c40-4e76-b51c-e33176eec3ee
2025-02-14 22:28:31,143 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 731545c7-c082-4b9c-a76f-dfd46878be50
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,159 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e69a6d72-0f0e-40e8-bf88-c448eda15756
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,163 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 51231d29-b354-422d-bcdf-bc931d286d78
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,181 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8cd08976-f298-40ac-868f-48f009bc45f3
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,230 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d6537db9-782c-4659-ba69-45b75e3c6cf1
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,416 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 310a8072-36c1-407f-851a-7db8db095885
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,454 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 03c867cd-53f0-4a05-ab7b-4e14da854075
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,479 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e7d0e2d6-a105-4ab9-a638-397eb720f18b
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,488 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b3ae931f-0415-4a42-ac61-da8a4bae4651
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,510 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1df5e7e6-be85-4e9d-9bca-2dee4e861751
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,591 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d0b96bee-dead-4d78-81d6-2dc508990b16
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,634 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 22703f62-dda8-4834-adc5-c45de8c4c126
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,703 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f10b6dbc-3cce-403d-a42a-848df8abbcde
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,716 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2045d985-768b-495b-85fa-7650085b399e
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,781 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a6b7b515-4545-4d9f-9d17-eb9d180db4f6
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,791 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f2dab9e1-8318-4d3b-aae8-c81482efe757
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,808 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2034b9b0-0e31-49e0-87ed-ecb5b58d550b
127.0.0.1 - - [14/Feb/2025 22:28:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:31,911 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 099ce133-4b3f-413d-bcde-f313c8307150
127.0.0.1 - - [14/Feb/2025 22:28:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:32,029 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1d04a31f-e300-42a1-b1ed-0909a9110796
127.0.0.1 - - [14/Feb/2025 22:28:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:32,068 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2593d8aa-4f72-4090-936b-a8acf223be23
127.0.0.1 - - [14/Feb/2025 22:28:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:32,114 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bffedc62-471a-4f8d-b38e-f87aadcacf7a
127.0.0.1 - - [14/Feb/2025 22:28:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:32,171 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d9291a99-a80c-469b-b8e1-88536a461393
2025-02-14 22:28:32,181 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b1f15452-3f9f-4064-b55f-5791611f74e7
127.0.0.1 - - [14/Feb/2025 22:28:32] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:32,409 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 023094db-1c3b-4279-b127-1d6600593a84
127.0.0.1 - - [14/Feb/2025 22:28:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:32,534 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1d41852e-625f-4dbd-82b5-99eca3c0a670
127.0.0.1 - - [14/Feb/2025 22:28:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:32,707 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 66098fc4-0e50-4cbb-847f-d3709b6aa917
127.0.0.1 - - [14/Feb/2025 22:28:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:32,722 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 68fb6842-797c-4b14-aae6-34b124b08818
127.0.0.1 - - [14/Feb/2025 22:28:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:32,941 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 22fe413c-78e9-4a03-a004-0bf226181882
127.0.0.1 - - [14/Feb/2025 22:28:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,057 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ad4c4c05-a7d2-4959-9648-3985d0e19f03
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,192 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4b6bd158-2a84-47b7-8878-6e3cdbc06fe3
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,309 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7f44eeda-41c1-4499-97c6-7a2cc9fd776e
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,370 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 217d9ce3-c308-4fbb-8e0e-9b383b788154
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,376 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 53430434-0857-49b3-bdd7-26a29e9ba095
2025-02-14 22:28:33,380 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8e88afa5-7ca5-4a99-9581-aade30e5cbbb
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,431 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b517a46b-763f-4aef-9a23-8448da486563
2025-02-14 22:28:33,504 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 96b64106-75ef-4252-bfd6-d8b1b1893e0f
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,590 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f3a5be04-cbb3-4108-afb8-1f8a4df5f36b
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,600 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b6947e4a-65f3-4aa8-b4d3-865d0af59a41
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,638 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0f401ed6-107d-413c-9d60-b8bfcb84ed76
2025-02-14 22:28:33,639 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 19d64a5d-0490-42d3-8ad2-bc29dc234a92
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,703 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 05f11115-5997-4a1d-8aa9-3c263143999d
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,810 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fde4c610-0fc5-4350-ab62-7df20b14171c
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,842 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d8a66fed-2ea2-4ab9-af28-8c0aa4e37e7c
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,959 - LoudVA - INFO - [LoudServer] - Completed. Request ID: de841498-85e6-44c9-9057-79f6e984e727
127.0.0.1 - - [14/Feb/2025 22:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,970 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 56485ca3-f4ba-4af0-a58f-7e551d941717
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:33,997 - LoudVA - INFO - [LoudServer] - Completed. Request ID: af8b6baf-de2c-46f9-a814-19a1e1ad5cc8
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,095 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ab9e1062-6e3f-426d-972c-5470420c9932
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,147 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 13dbee1f-0e09-40ff-a54e-f54f8fc1ebcc
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,258 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c8103f3e-0a2a-4a16-b671-020a2a45bce2
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,274 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1524a856-29d1-4773-aea6-5e63d2c5131e
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,323 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cef70862-7fe2-4ed6-9882-c532a57adbfe
2025-02-14 22:28:34,392 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9b4e0aea-7c36-44bf-b693-88f5acb6a1f7
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,421 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1ef1dc9e-e2c5-47dc-9aeb-be0cef079fb1
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,432 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5e5ebcbc-352b-4c95-a87d-4ead9749ee9a
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,438 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 44f0934d-0433-4bc8-ab78-8e924e2d6693
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,441 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bd2967a9-953c-4c7f-a1d3-5b5335a8be18
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,447 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5420f386-ec02-4e4c-b8ca-780e34acb452
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,476 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f8e7796d-89fa-45d4-9dc1-acfe117fdf04
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,619 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 79537dd3-4971-45a7-aca9-e37d4f12382c
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,652 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f14fd1ef-4821-4d23-bf5d-9a427256549e
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,682 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 54f38eb8-abb3-40ee-8299-d7d5912fc5bd
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,713 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e257a11d-263d-40f4-9df2-5f9b1d9c0da8
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,725 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c9bf9b9d-152c-465d-a319-e9b53b0f3b9d
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,739 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6ddb8468-8343-4647-9896-e8ad5fe10be4
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,775 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 06ee1ea2-5a86-42a2-8533-f116e8329456
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,795 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0fb63db6-c3cd-40bf-9459-178379a01e55
127.0.0.1 - - [14/Feb/2025 22:28:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,885 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d2d5132b-47da-43e8-a414-77dba22739ad
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,902 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5fd52d62-6c21-4047-8e6d-87b87dd51183
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,907 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 561a13cf-d793-4bb2-a4a6-cfaa932a22f9
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:34,996 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6d25788f-ea9c-4e67-9278-ea339c7e301c
2025-02-14 22:28:35,014 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b96a4e89-f918-4879-b9dd-00e82bf353df
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,124 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2c4fd3a7-11bf-4e42-87d3-0425d1112769
2025-02-14 22:28:35,147 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6861fcc3-b3bf-4b20-854e-3b089e82b587
2025-02-14 22:28:35,217 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2341ec51-50ff-476e-9ab4-a38354b0adfd
2025-02-14 22:28:35,236 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4493a359-211f-4369-9e3e-a5ca3f44d4c7
2025-02-14 22:28:35,240 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4c9c39a9-33db-4b27-88f8-eb45873c295b
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,339 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 85dce2d5-433f-42b7-8eed-f4b1f5f5a745
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,405 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 49cbabe7-dee4-455f-82f5-071ed6b33946
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,434 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 86d301a4-01cf-4a52-b29f-96d82f9202a7
2025-02-14 22:28:35,477 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6dc1074c-040d-40a1-84f6-986e6143202d
2025-02-14 22:28:35,484 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5174d753-3c9d-4aff-a894-856ca5834d3c
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,541 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d0bd45c7-60b3-4bc0-b079-022a7ea0ff07
2025-02-14 22:28:35,556 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 505d2994-1c8e-4cae-af22-ec27ce1a9dad
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,580 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e1890df8-9d30-4b96-9cdd-c7dc9830eb59
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,596 - LoudVA - INFO - [LoudServer] - Completed. Request ID: dd712c01-a0a2-499e-bc94-9b2050556d83
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,608 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 86791c3d-4174-4c0d-8bfa-1c4b21afb0f9
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,639 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4adac554-9b37-4da9-8649-cbec146d4657
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,678 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 22396474-99fb-4151-ae7a-bdb0706544a2
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,757 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0588ba2d-852b-4bdf-866a-393d96b02e46
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,783 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 336a6cc7-37db-43c3-9850-08ad0109c69f
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,830 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d605acfd-19ba-470b-adcb-57e7f6fa1ec2
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:28:35,849 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 955141ec-aadc-4be0-b6f6-b02255b2b632
127.0.0.1 - - [14/Feb/2025 22:28:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:28,894 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 28ddf29d-6b9a-4662-9d85-47c90dc1fee0
2025-02-14 22:30:29,295 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ee2ebfc1-f3be-4820-94fb-07d7b32ed7c3
2025-02-14 22:30:29,297 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 70591223-fca2-4f2b-8c2d-40080819d9b9
2025-02-14 22:30:29,316 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 28ddf29d-6b9a-4662-9d85-47c90dc1fee0
127.0.0.1 - - [14/Feb/2025 22:30:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:29,345 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ee2ebfc1-f3be-4820-94fb-07d7b32ed7c3
127.0.0.1 - - [14/Feb/2025 22:30:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:29,412 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 70591223-fca2-4f2b-8c2d-40080819d9b9
127.0.0.1 - - [14/Feb/2025 22:30:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:29,475 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ec76221c-bff7-453f-a697-4c6f9682d27b
2025-02-14 22:30:29,684 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ec76221c-bff7-453f-a697-4c6f9682d27b
127.0.0.1 - - [14/Feb/2025 22:30:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:29,739 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 42e7c7f1-1224-454e-b016-9a730fdd0b8d
2025-02-14 22:30:29,798 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 125d01f6-f2ce-4bc6-b3f3-46262c503154
2025-02-14 22:30:29,835 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 42e7c7f1-1224-454e-b016-9a730fdd0b8d
127.0.0.1 - - [14/Feb/2025 22:30:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:29,928 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1624a375-cb1b-4bb6-9610-aac3efa78e69
2025-02-14 22:30:29,991 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 125d01f6-f2ce-4bc6-b3f3-46262c503154
127.0.0.1 - - [14/Feb/2025 22:30:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:30,176 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1624a375-cb1b-4bb6-9610-aac3efa78e69
127.0.0.1 - - [14/Feb/2025 22:30:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:30,215 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6a4170a3-a310-4e9a-8c82-9b9ea0e29aa3
2025-02-14 22:30:30,269 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6a4170a3-a310-4e9a-8c82-9b9ea0e29aa3
127.0.0.1 - - [14/Feb/2025 22:30:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:30,355 - LoudVA - WARNING - [LoudServer] - Timeout reached for request adf2ded9-4209-4bff-8ebd-e7e0c133bad4
2025-02-14 22:30:30,402 - LoudVA - INFO - [LoudServer] - Completed. Request ID: adf2ded9-4209-4bff-8ebd-e7e0c133bad4
127.0.0.1 - - [14/Feb/2025 22:30:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:30,419 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c0b1f754-5b9a-4318-aed3-0bbf5b9455fb
2025-02-14 22:30:30,683 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c0b1f754-5b9a-4318-aed3-0bbf5b9455fb
127.0.0.1 - - [14/Feb/2025 22:30:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:30,830 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 51f21fb6-414d-45b7-9d39-aab819dcb926
2025-02-14 22:30:30,868 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ab7972e1-3f1e-47e8-8007-e958f1969ec3
2025-02-14 22:30:31,042 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 51f21fb6-414d-45b7-9d39-aab819dcb926
127.0.0.1 - - [14/Feb/2025 22:30:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:31,072 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ab7972e1-3f1e-47e8-8007-e958f1969ec3
127.0.0.1 - - [14/Feb/2025 22:30:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:31,222 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e65ceb4f-ae95-48b1-877f-cdb2c157eb55
2025-02-14 22:30:31,258 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e65ceb4f-ae95-48b1-877f-cdb2c157eb55
127.0.0.1 - - [14/Feb/2025 22:30:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:31,337 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f1b48e80-1540-4107-bdb6-6bff33150590
2025-02-14 22:30:31,371 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ac5a769c-965e-47c5-8f8b-82acbb9d05c7
2025-02-14 22:30:31,612 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f1b48e80-1540-4107-bdb6-6bff33150590
127.0.0.1 - - [14/Feb/2025 22:30:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:31,687 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ac5a769c-965e-47c5-8f8b-82acbb9d05c7
127.0.0.1 - - [14/Feb/2025 22:30:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:31,775 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b2faf060-97e7-4248-9b5f-a0605fd252a1
2025-02-14 22:30:31,831 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 48537d60-1e10-481d-b4d5-fe693c4e098b
2025-02-14 22:30:31,881 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b2faf060-97e7-4248-9b5f-a0605fd252a1
127.0.0.1 - - [14/Feb/2025 22:30:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:31,935 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f17d78e6-153c-4532-a24e-51bbc9c92f8d
2025-02-14 22:30:31,963 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 48537d60-1e10-481d-b4d5-fe693c4e098b
127.0.0.1 - - [14/Feb/2025 22:30:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:32,144 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f17d78e6-153c-4532-a24e-51bbc9c92f8d
127.0.0.1 - - [14/Feb/2025 22:30:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:32,253 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 64bda223-3d5f-435d-ae38-2e0823688d37
2025-02-14 22:30:32,349 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f157ba17-4fa6-4620-a7ed-9c3d4f73f833
2025-02-14 22:30:32,390 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 676f0dcd-b352-48dc-a32a-a031a0e013da
2025-02-14 22:30:32,471 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f157ba17-4fa6-4620-a7ed-9c3d4f73f833
127.0.0.1 - - [14/Feb/2025 22:30:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:32,512 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 676f0dcd-b352-48dc-a32a-a031a0e013da
127.0.0.1 - - [14/Feb/2025 22:30:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:32,778 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bafba847-1b3b-4748-8924-eeb7638416c0
2025-02-14 22:30:32,804 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 160c27d8-a039-4d14-bb26-6922aecb9340
2025-02-14 22:30:32,826 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 64bda223-3d5f-435d-ae38-2e0823688d37
127.0.0.1 - - [14/Feb/2025 22:30:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:32,834 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 160c27d8-a039-4d14-bb26-6922aecb9340
127.0.0.1 - - [14/Feb/2025 22:30:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:32,844 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bafba847-1b3b-4748-8924-eeb7638416c0
2025-02-14 22:30:32,895 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9b3cf389-83db-4c28-8341-ec91839499e9
127.0.0.1 - - [14/Feb/2025 22:30:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:33,146 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9b3cf389-83db-4c28-8341-ec91839499e9
127.0.0.1 - - [14/Feb/2025 22:30:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:33,198 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fc928752-9a55-48c8-81a8-0fd7b7694ad5
2025-02-14 22:30:33,229 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fc928752-9a55-48c8-81a8-0fd7b7694ad5
127.0.0.1 - - [14/Feb/2025 22:30:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:33,344 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5ada3833-b18d-422c-9a0d-78fc9277a9dd
2025-02-14 22:30:33,397 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 82231dfe-38ad-4229-83d9-1f6f519d5604
2025-02-14 22:30:33,573 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5ada3833-b18d-422c-9a0d-78fc9277a9dd
127.0.0.1 - - [14/Feb/2025 22:30:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:33,651 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 82231dfe-38ad-4229-83d9-1f6f519d5604
127.0.0.1 - - [14/Feb/2025 22:30:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:33,713 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8ef64c68-92f4-4a25-98b7-5be58b4540d4
2025-02-14 22:30:33,803 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c8363957-6976-410d-94d6-8834bd762bde
2025-02-14 22:30:33,804 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4d601f75-9e21-4379-8e8b-f0f071d6b3d7
2025-02-14 22:30:33,859 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4d601f75-9e21-4379-8e8b-f0f071d6b3d7
127.0.0.1 - - [14/Feb/2025 22:30:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:33,889 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c8363957-6976-410d-94d6-8834bd762bde
127.0.0.1 - - [14/Feb/2025 22:30:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:33,957 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8ef64c68-92f4-4a25-98b7-5be58b4540d4
127.0.0.1 - - [14/Feb/2025 22:30:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:34,277 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6a379261-95c1-41f5-906b-e01f203b0518
2025-02-14 22:30:34,292 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cb6f1e0b-9a53-448d-879e-5f6724731af2
2025-02-14 22:30:34,292 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cb6f1e0b-9a53-448d-879e-5f6724731af2
127.0.0.1 - - [14/Feb/2025 22:30:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:34,328 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6a379261-95c1-41f5-906b-e01f203b0518
127.0.0.1 - - [14/Feb/2025 22:30:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:34,387 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 202c13b1-18f6-4c98-ad98-c6c29d03b7e3
2025-02-14 22:30:34,566 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 202c13b1-18f6-4c98-ad98-c6c29d03b7e3
127.0.0.1 - - [14/Feb/2025 22:30:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:34,717 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1f6f6c93-70d4-4064-851c-167cf727ac7e
2025-02-14 22:30:34,744 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 31f3d27b-aab6-4899-96b3-c8a20d6eceae
2025-02-14 22:30:34,763 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1f6f6c93-70d4-4064-851c-167cf727ac7e
127.0.0.1 - - [14/Feb/2025 22:30:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:34,764 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 31f3d27b-aab6-4899-96b3-c8a20d6eceae
127.0.0.1 - - [14/Feb/2025 22:30:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:34,813 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 80eaf8db-9ed6-43a8-b446-36a16b5d0b08
2025-02-14 22:30:34,858 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 80eaf8db-9ed6-43a8-b446-36a16b5d0b08
127.0.0.1 - - [14/Feb/2025 22:30:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:35,223 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d356e149-8e08-49af-918c-5f9cf103aea6
2025-02-14 22:30:35,260 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 917f11fd-8132-48e6-bcdb-2e9c3199f243
2025-02-14 22:30:35,306 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 917f11fd-8132-48e6-bcdb-2e9c3199f243
127.0.0.1 - - [14/Feb/2025 22:30:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:35,319 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d356e149-8e08-49af-918c-5f9cf103aea6
127.0.0.1 - - [14/Feb/2025 22:30:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:35,336 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ceea77a9-053f-40db-9e4a-b0503f115c4c
2025-02-14 22:30:35,617 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ceea77a9-053f-40db-9e4a-b0503f115c4c
127.0.0.1 - - [14/Feb/2025 22:30:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:35,826 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ab537dce-ae50-459e-96f2-eca4b2ba5eac
2025-02-14 22:30:35,843 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a19be1d3-615f-48d0-8eae-2c6ca7fa9d99
2025-02-14 22:30:35,882 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ab537dce-ae50-459e-96f2-eca4b2ba5eac
127.0.0.1 - - [14/Feb/2025 22:30:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:35,966 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5cee2373-3478-4d6d-8661-e334841014d5
2025-02-14 22:30:36,030 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a19be1d3-615f-48d0-8eae-2c6ca7fa9d99
127.0.0.1 - - [14/Feb/2025 22:30:36] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:36,239 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5cee2373-3478-4d6d-8661-e334841014d5
127.0.0.1 - - [14/Feb/2025 22:30:36] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:36,278 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f9e7db7e-f459-485a-ac0b-4c736560a02e
2025-02-14 22:30:36,309 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f9e7db7e-f459-485a-ac0b-4c736560a02e
127.0.0.1 - - [14/Feb/2025 22:30:36] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:36,409 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6cda997c-5a05-4bb8-881c-a303b93db400
2025-02-14 22:30:36,430 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3184568b-6bbc-4ede-8364-418e00853047
2025-02-14 22:30:36,597 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6cda997c-5a05-4bb8-881c-a303b93db400
2025-02-14 22:30:36,603 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3184568b-6bbc-4ede-8364-418e00853047
127.0.0.1 - - [14/Feb/2025 22:30:36] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:30:36] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:36,718 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 502770f3-638a-4a8f-bdd4-b3b88b229243
2025-02-14 22:30:36,764 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 502770f3-638a-4a8f-bdd4-b3b88b229243
127.0.0.1 - - [14/Feb/2025 22:30:36] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:36,775 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 04dca9d4-4e43-4b3a-887e-e9d6cd6cb331
2025-02-14 22:30:36,800 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 04dca9d4-4e43-4b3a-887e-e9d6cd6cb331
127.0.0.1 - - [14/Feb/2025 22:30:36] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:36,923 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f0957af8-96d5-480b-be04-a84fac378733
2025-02-14 22:30:37,268 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f0957af8-96d5-480b-be04-a84fac378733
2025-02-14 22:30:37,270 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6d2d5ed5-1f07-4ab1-9414-e7adefc196c4
2025-02-14 22:30:37,270 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6d2d5ed5-1f07-4ab1-9414-e7adefc196c4
127.0.0.1 - - [14/Feb/2025 22:30:37] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:30:37] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:37,303 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ced565cd-faa0-4a23-9d1d-c6985bf9ebbe
2025-02-14 22:30:37,341 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 81cfa852-0a88-4e90-91f1-c826dd899018
2025-02-14 22:30:37,369 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ced565cd-faa0-4a23-9d1d-c6985bf9ebbe
127.0.0.1 - - [14/Feb/2025 22:30:37] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:37,407 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 81cfa852-0a88-4e90-91f1-c826dd899018
127.0.0.1 - - [14/Feb/2025 22:30:37] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:37,789 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c0582da1-0603-4f9f-abdc-7cd69e2b4d93
2025-02-14 22:30:37,800 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ce9db91a-f6d6-4c5b-bd3b-0a21f9c19a20
2025-02-14 22:30:37,824 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a5af4af5-d67a-41d6-8236-da8dda209820
2025-02-14 22:30:37,996 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a5af4af5-d67a-41d6-8236-da8dda209820
127.0.0.1 - - [14/Feb/2025 22:30:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:38,007 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c0582da1-0603-4f9f-abdc-7cd69e2b4d93
127.0.0.1 - - [14/Feb/2025 22:30:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:38,084 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ce9db91a-f6d6-4c5b-bd3b-0a21f9c19a20
127.0.0.1 - - [14/Feb/2025 22:30:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:38,225 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 128f75c7-3036-4478-9604-c13f7bdd8ede
2025-02-14 22:30:38,298 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c33e72af-1166-4a58-9b9a-bf12d0c8f07b
2025-02-14 22:30:38,302 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 128f75c7-3036-4478-9604-c13f7bdd8ede
127.0.0.1 - - [14/Feb/2025 22:30:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:38,310 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3be91fe2-6158-4165-809e-2ad0b5223f7a
2025-02-14 22:30:38,349 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c33e72af-1166-4a58-9b9a-bf12d0c8f07b
127.0.0.1 - - [14/Feb/2025 22:30:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:38,429 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3be91fe2-6158-4165-809e-2ad0b5223f7a
127.0.0.1 - - [14/Feb/2025 22:30:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:38,778 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 45f6eb15-ab40-442c-be53-0f3f7f821a18
2025-02-14 22:30:38,834 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 79b38c29-47b9-4cd2-9e3f-87bf3e854a1e
2025-02-14 22:30:38,925 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 45f6eb15-ab40-442c-be53-0f3f7f821a18
127.0.0.1 - - [14/Feb/2025 22:30:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:39,012 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6c377ef1-ef4a-492f-af71-f1cb19fe98a2
2025-02-14 22:30:39,100 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 79b38c29-47b9-4cd2-9e3f-87bf3e854a1e
127.0.0.1 - - [14/Feb/2025 22:30:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:39,259 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6c377ef1-ef4a-492f-af71-f1cb19fe98a2
2025-02-14 22:30:39,319 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2b73b4ef-eed1-41f7-9e87-b44f9d25dcf7
127.0.0.1 - - [14/Feb/2025 22:30:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:39,460 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2b73b4ef-eed1-41f7-9e87-b44f9d25dcf7
127.0.0.1 - - [14/Feb/2025 22:30:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:39,477 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ef9b66cd-0cda-468f-9538-9d3dae2a52e8
2025-02-14 22:30:39,523 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a490dc1c-1016-487e-9a7f-d82769b8c39b
2025-02-14 22:30:39,659 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ef9b66cd-0cda-468f-9538-9d3dae2a52e8
127.0.0.1 - - [14/Feb/2025 22:30:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:39,738 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 555107dc-075e-43de-a59a-c35f7faf0507
2025-02-14 22:30:39,788 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 555107dc-075e-43de-a59a-c35f7faf0507
127.0.0.1 - - [14/Feb/2025 22:30:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:39,840 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3912d1fa-7b87-4f69-8b03-43cd1e7295c1
2025-02-14 22:30:39,842 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1c0eb709-ac67-41ec-8b3f-7eb603a14812
2025-02-14 22:30:39,903 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a490dc1c-1016-487e-9a7f-d82769b8c39b
2025-02-14 22:30:39,957 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3912d1fa-7b87-4f69-8b03-43cd1e7295c1
127.0.0.1 - - [14/Feb/2025 22:30:39] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:30:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:40,018 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1c0eb709-ac67-41ec-8b3f-7eb603a14812
127.0.0.1 - - [14/Feb/2025 22:30:40] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:40,229 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 968b4e4e-1d15-4856-8b0f-74f40c232a3f
2025-02-14 22:30:40,290 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 968b4e4e-1d15-4856-8b0f-74f40c232a3f
127.0.0.1 - - [14/Feb/2025 22:30:40] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:40,327 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f5ff8f25-cdcd-4718-a96a-3180fae01c1c
2025-02-14 22:30:40,354 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 77ee7d31-6f89-4f9f-b502-24d7e8dc95d9
2025-02-14 22:30:40,388 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f5ff8f25-cdcd-4718-a96a-3180fae01c1c
127.0.0.1 - - [14/Feb/2025 22:30:40] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:40,562 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 77ee7d31-6f89-4f9f-b502-24d7e8dc95d9
127.0.0.1 - - [14/Feb/2025 22:30:40] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:40,712 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4631204b-a4a6-422f-a08a-658192986b34
2025-02-14 22:30:40,813 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4631204b-a4a6-422f-a08a-658192986b34
127.0.0.1 - - [14/Feb/2025 22:30:40] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:40,853 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 039cb10e-3d67-444f-b033-9706b3e8986c
2025-02-14 22:30:40,958 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 876b4252-b760-4e2b-919a-eb25b8d49f71
2025-02-14 22:30:41,125 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 876b4252-b760-4e2b-919a-eb25b8d49f71
2025-02-14 22:30:41,151 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 039cb10e-3d67-444f-b033-9706b3e8986c
127.0.0.1 - - [14/Feb/2025 22:30:41] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:30:41] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:41,224 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ac141369-3cf4-45d1-8040-b4178eef0e9d
2025-02-14 22:30:41,282 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 28abc329-916e-4f21-8180-2ac260bfc363
2025-02-14 22:30:41,296 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ac141369-3cf4-45d1-8040-b4178eef0e9d
127.0.0.1 - - [14/Feb/2025 22:30:41] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:41,314 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1e9b59b9-3120-47ee-8ab1-babd1f38bb57
2025-02-14 22:30:41,426 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1e9b59b9-3120-47ee-8ab1-babd1f38bb57
127.0.0.1 - - [14/Feb/2025 22:30:41] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:41,455 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 28abc329-916e-4f21-8180-2ac260bfc363
127.0.0.1 - - [14/Feb/2025 22:30:41] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:41,877 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 911d528b-f7bc-41e2-b2e4-bfa2ee18ba19
2025-02-14 22:30:41,940 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b0b861a4-68fc-42e8-8ffc-15aa8f723fcd
2025-02-14 22:30:41,966 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b0b861a4-68fc-42e8-8ffc-15aa8f723fcd
127.0.0.1 - - [14/Feb/2025 22:30:41] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:42,001 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c88714d7-3fb5-4b88-83e1-889c5dbec812
2025-02-14 22:30:42,034 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 911d528b-f7bc-41e2-b2e4-bfa2ee18ba19
127.0.0.1 - - [14/Feb/2025 22:30:42] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:42,244 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c88714d7-3fb5-4b88-83e1-889c5dbec812
127.0.0.1 - - [14/Feb/2025 22:30:42] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:42,352 - LoudVA - WARNING - [LoudServer] - Timeout reached for request be47ff24-215e-431f-846b-092cdbd2839a
2025-02-14 22:30:42,371 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 35a5f104-ed86-4071-bd55-b1f417c88736
2025-02-14 22:30:42,450 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 27a15f5b-d28e-40cd-bb1a-4a0d88b5bd0b
2025-02-14 22:30:42,615 - LoudVA - INFO - [LoudServer] - Completed. Request ID: be47ff24-215e-431f-846b-092cdbd2839a
127.0.0.1 - - [14/Feb/2025 22:30:42] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:42,632 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 27a15f5b-d28e-40cd-bb1a-4a0d88b5bd0b
127.0.0.1 - - [14/Feb/2025 22:30:42] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:42,728 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7a1dc5e3-fc8d-4d6d-a071-ba7c0f6c140f
2025-02-14 22:30:42,730 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 35a5f104-ed86-4071-bd55-b1f417c88736
127.0.0.1 - - [14/Feb/2025 22:30:42] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:42,743 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7a1dc5e3-fc8d-4d6d-a071-ba7c0f6c140f
127.0.0.1 - - [14/Feb/2025 22:30:42] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:42,783 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e85623ba-e7c6-4d40-ac47-848f45226bd8
2025-02-14 22:30:42,813 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bc0f7108-5f28-4049-9699-df73edf379e9
2025-02-14 22:30:42,863 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bc0f7108-5f28-4049-9699-df73edf379e9
127.0.0.1 - - [14/Feb/2025 22:30:42] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:42,894 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e85623ba-e7c6-4d40-ac47-848f45226bd8
127.0.0.1 - - [14/Feb/2025 22:30:42] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:43,218 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8a4a2a1d-a3a5-4f75-9aa0-5f6ba0728583
2025-02-14 22:30:43,294 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8a4a2a1d-a3a5-4f75-9aa0-5f6ba0728583
127.0.0.1 - - [14/Feb/2025 22:30:43] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:43,305 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5daf078a-5619-495b-8880-e897aacb0d6f
2025-02-14 22:30:43,315 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5daf078a-5619-495b-8880-e897aacb0d6f
127.0.0.1 - - [14/Feb/2025 22:30:43] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:43,488 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bd84d058-8432-4683-9a77-80894eae828b
2025-02-14 22:30:43,656 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bd84d058-8432-4683-9a77-80894eae828b
127.0.0.1 - - [14/Feb/2025 22:30:43] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:43,733 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 73fe62c9-d857-42fb-94aa-6fad4c9eab59
2025-02-14 22:30:43,764 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 73fe62c9-d857-42fb-94aa-6fad4c9eab59
127.0.0.1 - - [14/Feb/2025 22:30:43] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:43,786 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 37cbcce4-ed72-4fad-b778-0b8a7e6100e0
2025-02-14 22:30:43,887 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 37cbcce4-ed72-4fad-b778-0b8a7e6100e0
127.0.0.1 - - [14/Feb/2025 22:30:43] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:44,006 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9c2441bc-fe85-4eaa-b1c1-99955b81595f
2025-02-14 22:30:44,263 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 93931ac3-7ab5-4674-bccf-d21ede835a79
2025-02-14 22:30:44,264 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9c2441bc-fe85-4eaa-b1c1-99955b81595f
127.0.0.1 - - [14/Feb/2025 22:30:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:44,326 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aacc22a2-76c5-4e8d-92d3-b1538bf90827
2025-02-14 22:30:44,343 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 409e44cd-6b5f-42d2-9f6e-f2579f253e32
2025-02-14 22:30:44,414 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 409e44cd-6b5f-42d2-9f6e-f2579f253e32
127.0.0.1 - - [14/Feb/2025 22:30:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:44,427 - LoudVA - INFO - [LoudServer] - Completed. Request ID: aacc22a2-76c5-4e8d-92d3-b1538bf90827
127.0.0.1 - - [14/Feb/2025 22:30:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:44,512 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 93931ac3-7ab5-4674-bccf-d21ede835a79
127.0.0.1 - - [14/Feb/2025 22:30:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:44,749 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 23859bb5-63bd-4e03-9004-cc135adb0f4b
2025-02-14 22:30:44,823 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7f438969-6341-4c05-9bd0-57ba24b75796
2025-02-14 22:30:44,855 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 23859bb5-63bd-4e03-9004-cc135adb0f4b
127.0.0.1 - - [14/Feb/2025 22:30:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:44,917 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5de42b90-f800-46de-9ea7-9afe29431c9e
2025-02-14 22:30:45,010 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7f438969-6341-4c05-9bd0-57ba24b75796
127.0.0.1 - - [14/Feb/2025 22:30:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:45,196 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5de42b90-f800-46de-9ea7-9afe29431c9e
127.0.0.1 - - [14/Feb/2025 22:30:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:45,264 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fec1a6ce-74fe-4fb1-aa3f-81f1bc9a287f
2025-02-14 22:30:45,297 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b4fe1c91-3cb5-4cec-a7ac-28f0dcfc3e97
2025-02-14 22:30:45,304 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fec1a6ce-74fe-4fb1-aa3f-81f1bc9a287f
127.0.0.1 - - [14/Feb/2025 22:30:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:45,379 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3dbe052f-c58d-4e2f-825d-dc2410ffc84c
2025-02-14 22:30:45,491 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b4fe1c91-3cb5-4cec-a7ac-28f0dcfc3e97
127.0.0.1 - - [14/Feb/2025 22:30:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:45,551 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3dbe052f-c58d-4e2f-825d-dc2410ffc84c
127.0.0.1 - - [14/Feb/2025 22:30:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:45,786 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fa59dcd6-eca1-4a5f-ba71-c727b69491ed
2025-02-14 22:30:45,802 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fa421533-e8a3-4fa0-89bc-cfacfdd1fa50
2025-02-14 22:30:45,811 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fa59dcd6-eca1-4a5f-ba71-c727b69491ed
127.0.0.1 - - [14/Feb/2025 22:30:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:45,812 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 02b4eb46-f983-43c4-b0b5-a3e16577540e
2025-02-14 22:30:45,857 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 02b4eb46-f983-43c4-b0b5-a3e16577540e
127.0.0.1 - - [14/Feb/2025 22:30:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:45,954 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fa421533-e8a3-4fa0-89bc-cfacfdd1fa50
127.0.0.1 - - [14/Feb/2025 22:30:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:46,268 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b0c72f20-6c56-41c0-82e1-7eb34e859f44
2025-02-14 22:30:46,290 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 01140e05-8b6d-47ac-a3d8-fa80a11a5706
2025-02-14 22:30:46,323 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bca41da2-63bb-40d4-8b5b-59aa93062863
2025-02-14 22:30:46,371 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 01140e05-8b6d-47ac-a3d8-fa80a11a5706
127.0.0.1 - - [14/Feb/2025 22:30:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:46,430 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bca41da2-63bb-40d4-8b5b-59aa93062863
127.0.0.1 - - [14/Feb/2025 22:30:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:46,436 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b0c72f20-6c56-41c0-82e1-7eb34e859f44
127.0.0.1 - - [14/Feb/2025 22:30:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:46,710 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 93e0e7a9-32e5-4f79-9b18-729bc508ec79
2025-02-14 22:30:46,720 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 93e0e7a9-32e5-4f79-9b18-729bc508ec79
127.0.0.1 - - [14/Feb/2025 22:30:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:46,820 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a489bfa0-96be-4cc8-9100-a6000b92fe6e
2025-02-14 22:30:46,879 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c52007bf-fbe1-4d5e-bb58-5efc3fb98db8
2025-02-14 22:30:46,880 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a489bfa0-96be-4cc8-9100-a6000b92fe6e
127.0.0.1 - - [14/Feb/2025 22:30:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:47,026 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c52007bf-fbe1-4d5e-bb58-5efc3fb98db8
127.0.0.1 - - [14/Feb/2025 22:30:47] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:47,210 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 321f20cc-2f01-41b9-9040-54f5bbb2f6fd
2025-02-14 22:30:47,225 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 321f20cc-2f01-41b9-9040-54f5bbb2f6fd
127.0.0.1 - - [14/Feb/2025 22:30:47] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:47,315 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0ec8097a-022d-4f01-a56b-bffc510a0de4
2025-02-14 22:30:47,369 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6a255f15-4c79-4abc-b15c-c94070da513a
2025-02-14 22:30:47,426 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0ec8097a-022d-4f01-a56b-bffc510a0de4
127.0.0.1 - - [14/Feb/2025 22:30:47] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:47,505 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6a255f15-4c79-4abc-b15c-c94070da513a
127.0.0.1 - - [14/Feb/2025 22:30:47] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:47,844 - LoudVA - WARNING - [LoudServer] - Timeout reached for request be4df810-059c-4750-9533-3c88ada2d599
2025-02-14 22:30:47,960 - LoudVA - INFO - [LoudServer] - Completed. Request ID: be4df810-059c-4750-9533-3c88ada2d599
127.0.0.1 - - [14/Feb/2025 22:30:47] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:48,002 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f989b456-8e87-4852-884b-bd24f7a037d6
2025-02-14 22:30:48,054 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 26a6fb51-dcd7-4e72-b4ac-d6a9cc33b665
2025-02-14 22:30:48,143 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f989b456-8e87-4852-884b-bd24f7a037d6
127.0.0.1 - - [14/Feb/2025 22:30:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:48,276 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 26a6fb51-dcd7-4e72-b4ac-d6a9cc33b665
127.0.0.1 - - [14/Feb/2025 22:30:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:48,309 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5b3fdc31-81bd-4928-a8a1-83c9e297d00c
2025-02-14 22:30:48,388 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 82aa2c82-b475-4925-87b1-727f7fe674cd
2025-02-14 22:30:48,410 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5b3fdc31-81bd-4928-a8a1-83c9e297d00c
127.0.0.1 - - [14/Feb/2025 22:30:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:48,423 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e1165f27-91b4-4c26-90c3-06eedede46e9
2025-02-14 22:30:48,562 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e1165f27-91b4-4c26-90c3-06eedede46e9
127.0.0.1 - - [14/Feb/2025 22:30:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:48,640 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 82aa2c82-b475-4925-87b1-727f7fe674cd
127.0.0.1 - - [14/Feb/2025 22:30:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:48,757 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 378dfc0f-f0d5-4751-8a9d-e2cd2ff84a2d
2025-02-14 22:30:48,767 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f2b11e4e-aa74-43e4-861c-ddba5e45004b
2025-02-14 22:30:48,781 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 766192b8-8dcf-4cac-a6b1-31f718cca644
2025-02-14 22:30:48,782 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f2b11e4e-aa74-43e4-861c-ddba5e45004b
127.0.0.1 - - [14/Feb/2025 22:30:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:48,782 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 378dfc0f-f0d5-4751-8a9d-e2cd2ff84a2d
127.0.0.1 - - [14/Feb/2025 22:30:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:48,817 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 766192b8-8dcf-4cac-a6b1-31f718cca644
127.0.0.1 - - [14/Feb/2025 22:30:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:49,366 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3186ef29-8057-4049-9afe-9bfb85096026
2025-02-14 22:30:49,476 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 776098a4-e9c4-4a6f-8935-624eae43c5bf
2025-02-14 22:30:49,532 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3186ef29-8057-4049-9afe-9bfb85096026
127.0.0.1 - - [14/Feb/2025 22:30:49] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:49,771 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 500caf8e-01a1-4d32-9a8e-7b503ad68d1a
2025-02-14 22:30:49,785 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6c440238-8fdc-471f-9d06-1aa163ab0737
2025-02-14 22:30:49,816 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ec99c1e8-6ac9-4251-995a-acd94b64aba9
2025-02-14 22:30:49,827 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6c440238-8fdc-471f-9d06-1aa163ab0737
127.0.0.1 - - [14/Feb/2025 22:30:49] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:49,837 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ec99c1e8-6ac9-4251-995a-acd94b64aba9
127.0.0.1 - - [14/Feb/2025 22:30:49] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:49,893 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3cbad30b-1b3e-487a-9e21-49978c9bc8a4
2025-02-14 22:30:49,915 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 776098a4-e9c4-4a6f-8935-624eae43c5bf
127.0.0.1 - - [14/Feb/2025 22:30:49] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:49,998 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 500caf8e-01a1-4d32-9a8e-7b503ad68d1a
127.0.0.1 - - [14/Feb/2025 22:30:50] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:50,085 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3cbad30b-1b3e-487a-9e21-49978c9bc8a4
127.0.0.1 - - [14/Feb/2025 22:30:50] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:50,300 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c74e22f9-2d24-47fa-8747-e3e810b6b1a0
2025-02-14 22:30:50,493 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 541f789f-ee40-4971-b2ca-5e3658500ac2
2025-02-14 22:30:50,537 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 342a2817-70f8-47f3-8475-40351d14ddba
2025-02-14 22:30:50,568 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c74e22f9-2d24-47fa-8747-e3e810b6b1a0
127.0.0.1 - - [14/Feb/2025 22:30:50] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:50,812 - LoudVA - WARNING - [LoudServer] - Timeout reached for request db1044a4-3bb4-4c2a-ac51-63b499a716f6
2025-02-14 22:30:50,827 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 541f789f-ee40-4971-b2ca-5e3658500ac2
127.0.0.1 - - [14/Feb/2025 22:30:50] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:50,866 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 342a2817-70f8-47f3-8475-40351d14ddba
127.0.0.1 - - [14/Feb/2025 22:30:50] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:50,872 - LoudVA - INFO - [LoudServer] - Completed. Request ID: db1044a4-3bb4-4c2a-ac51-63b499a716f6
127.0.0.1 - - [14/Feb/2025 22:30:50] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:50,914 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cf843bac-ab0a-441a-bd55-f52b0087f133
2025-02-14 22:30:51,161 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cf843bac-ab0a-441a-bd55-f52b0087f133
127.0.0.1 - - [14/Feb/2025 22:30:51] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:51,269 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a83cdee8-f3fa-4bd1-9d3a-eb18ecf68619
2025-02-14 22:30:51,328 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0be29cd6-c41b-4f4e-8e0d-a797cc789cbc
2025-02-14 22:30:51,336 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6ed14f9f-8b7f-4960-9a94-6ba5bbdfa5ab
2025-02-14 22:30:51,344 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a83cdee8-f3fa-4bd1-9d3a-eb18ecf68619
127.0.0.1 - - [14/Feb/2025 22:30:51] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:51,389 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6ed14f9f-8b7f-4960-9a94-6ba5bbdfa5ab
127.0.0.1 - - [14/Feb/2025 22:30:51] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:51,432 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0f54881a-9f29-42eb-8b90-4ee58c06930c
2025-02-14 22:30:51,506 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0f54881a-9f29-42eb-8b90-4ee58c06930c
127.0.0.1 - - [14/Feb/2025 22:30:51] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:51,591 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0be29cd6-c41b-4f4e-8e0d-a797cc789cbc
127.0.0.1 - - [14/Feb/2025 22:30:51] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:51,849 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4cfc8d47-445c-4d7a-adec-c17828166f4c
2025-02-14 22:30:51,874 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3c9f332a-c591-4d69-9964-92e635781fed
2025-02-14 22:30:51,904 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2acd1f9e-499f-409f-9942-e2d80bbca9aa
2025-02-14 22:30:51,975 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3c9f332a-c591-4d69-9964-92e635781fed
127.0.0.1 - - [14/Feb/2025 22:30:51] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:52,022 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4cfc8d47-445c-4d7a-adec-c17828166f4c
127.0.0.1 - - [14/Feb/2025 22:30:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:52,121 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2acd1f9e-499f-409f-9942-e2d80bbca9aa
127.0.0.1 - - [14/Feb/2025 22:30:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:52,228 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c8760d45-0ec2-4bfa-9e4d-ab7d0e338f5e
2025-02-14 22:30:52,286 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1ce4058e-ef7e-4b60-b38d-53be741a164e
2025-02-14 22:30:52,293 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c8760d45-0ec2-4bfa-9e4d-ab7d0e338f5e
127.0.0.1 - - [14/Feb/2025 22:30:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:52,300 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e08faad6-5e7f-4757-bfac-6d9a4f04b82e
2025-02-14 22:30:52,307 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1ce4058e-ef7e-4b60-b38d-53be741a164e
127.0.0.1 - - [14/Feb/2025 22:30:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:52,413 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e08faad6-5e7f-4757-bfac-6d9a4f04b82e
127.0.0.1 - - [14/Feb/2025 22:30:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:52,773 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 90956229-0616-4a28-87cb-0d2e4f871ee5
2025-02-14 22:30:52,782 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e6f50239-a7e8-4717-b9da-b223533b38c2
2025-02-14 22:30:52,833 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e6f50239-a7e8-4717-b9da-b223533b38c2
127.0.0.1 - - [14/Feb/2025 22:30:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:52,947 - LoudVA - WARNING - [LoudServer] - Timeout reached for request dbc9c78e-cf7f-49dd-9e54-adfe43d6b976
2025-02-14 22:30:52,951 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 90956229-0616-4a28-87cb-0d2e4f871ee5
127.0.0.1 - - [14/Feb/2025 22:30:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:53,023 - LoudVA - INFO - [LoudServer] - Completed. Request ID: dbc9c78e-cf7f-49dd-9e54-adfe43d6b976
127.0.0.1 - - [14/Feb/2025 22:30:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:53,340 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e8bfa6ae-b61e-4a8c-b525-4d92d13e0bfb
2025-02-14 22:30:53,392 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f58902b8-61ce-4a46-a8c9-f90554b406ba
2025-02-14 22:30:53,468 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f58902b8-61ce-4a46-a8c9-f90554b406ba
2025-02-14 22:30:53,469 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 32183a1f-cb76-4523-ab1d-603e14119762
127.0.0.1 - - [14/Feb/2025 22:30:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:53,516 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e8bfa6ae-b61e-4a8c-b525-4d92d13e0bfb
127.0.0.1 - - [14/Feb/2025 22:30:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:53,690 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 32183a1f-cb76-4523-ab1d-603e14119762
127.0.0.1 - - [14/Feb/2025 22:30:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:53,750 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bceee941-1003-463a-ae34-170856e6ee43
2025-02-14 22:30:53,806 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bceee941-1003-463a-ae34-170856e6ee43
127.0.0.1 - - [14/Feb/2025 22:30:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:53,814 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 550f3974-63bb-44ef-9f99-7b9beb316bc4
2025-02-14 22:30:53,891 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4cb7e4ab-756a-45ee-90ee-af9a6eb71145
2025-02-14 22:30:53,915 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 550f3974-63bb-44ef-9f99-7b9beb316bc4
127.0.0.1 - - [14/Feb/2025 22:30:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:54,118 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4cb7e4ab-756a-45ee-90ee-af9a6eb71145
127.0.0.1 - - [14/Feb/2025 22:30:54] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:54,238 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fd3f2d0c-7dd4-47c5-9127-753f57986597
2025-02-14 22:30:54,309 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b42db8f2-3e64-4dca-b211-9a745c807909
2025-02-14 22:30:54,365 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b42db8f2-3e64-4dca-b211-9a745c807909
127.0.0.1 - - [14/Feb/2025 22:30:54] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:54,510 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fd3f2d0c-7dd4-47c5-9127-753f57986597
127.0.0.1 - - [14/Feb/2025 22:30:54] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:54,525 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5892703c-728b-4e38-9905-1e68c6250d0b
2025-02-14 22:30:54,698 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5892703c-728b-4e38-9905-1e68c6250d0b
127.0.0.1 - - [14/Feb/2025 22:30:54] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:54,766 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b4db645d-2b5e-47e9-8e9b-e43dccfccf1d
2025-02-14 22:30:54,802 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b4db645d-2b5e-47e9-8e9b-e43dccfccf1d
127.0.0.1 - - [14/Feb/2025 22:30:54] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:54,803 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f60084ff-cf01-4470-9a4f-234187722fb9
2025-02-14 22:30:54,881 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d319561f-1a67-4fd0-9504-8abf32c0471f
2025-02-14 22:30:54,983 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d319561f-1a67-4fd0-9504-8abf32c0471f
127.0.0.1 - - [14/Feb/2025 22:30:54] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:54,999 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f60084ff-cf01-4470-9a4f-234187722fb9
127.0.0.1 - - [14/Feb/2025 22:30:55] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:55,234 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7fe49f37-441d-41fe-8bfa-e38c06f1da54
2025-02-14 22:30:55,376 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7fe49f37-441d-41fe-8bfa-e38c06f1da54
127.0.0.1 - - [14/Feb/2025 22:30:55] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:55,455 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4ec9762c-fc62-448d-b925-976c3d613748
2025-02-14 22:30:55,586 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4ec9762c-fc62-448d-b925-976c3d613748
127.0.0.1 - - [14/Feb/2025 22:30:55] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:55,735 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f2b6e00e-e40b-40e1-995b-94e64e11776b
2025-02-14 22:30:55,760 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f2b6e00e-e40b-40e1-995b-94e64e11776b
127.0.0.1 - - [14/Feb/2025 22:30:55] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:55,803 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8b6dd864-0080-4495-aa37-ceba124a75cd
2025-02-14 22:30:55,929 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8b6dd864-0080-4495-aa37-ceba124a75cd
127.0.0.1 - - [14/Feb/2025 22:30:55] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:55,960 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 638b434f-739c-43e5-9e19-279ea14bd26a
2025-02-14 22:30:55,997 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d8518afe-a78d-475e-8221-705711f2aba5
2025-02-14 22:30:56,192 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 638b434f-739c-43e5-9e19-279ea14bd26a
2025-02-14 22:30:56,197 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2f3cda51-97ee-4fdd-95db-ed9a7834763c
127.0.0.1 - - [14/Feb/2025 22:30:56] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:56,232 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2f3cda51-97ee-4fdd-95db-ed9a7834763c
127.0.0.1 - - [14/Feb/2025 22:30:56] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:56,255 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d8518afe-a78d-475e-8221-705711f2aba5
127.0.0.1 - - [14/Feb/2025 22:30:56] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:56,337 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1e8184e7-f05e-4b2f-939a-1f626b009065
2025-02-14 22:30:56,378 - LoudVA - WARNING - [LoudServer] - Timeout reached for request da8400cb-2d71-42ca-b694-bc9c1ac32d22
2025-02-14 22:30:56,473 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1e8184e7-f05e-4b2f-939a-1f626b009065
127.0.0.1 - - [14/Feb/2025 22:30:56] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:56,559 - LoudVA - INFO - [LoudServer] - Completed. Request ID: da8400cb-2d71-42ca-b694-bc9c1ac32d22
127.0.0.1 - - [14/Feb/2025 22:30:56] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:56,702 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b5b98ba4-cd77-42a2-a06e-900bb88909e4
2025-02-14 22:30:56,763 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b5b98ba4-cd77-42a2-a06e-900bb88909e4
127.0.0.1 - - [14/Feb/2025 22:30:56] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:56,787 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5f11a6f7-abf0-423f-92ba-0aa9aa814f9e
2025-02-14 22:30:56,837 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5f11a6f7-abf0-423f-92ba-0aa9aa814f9e
127.0.0.1 - - [14/Feb/2025 22:30:56] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:56,883 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 39d465c7-3c4a-4a0d-95c2-f91402e03d61
2025-02-14 22:30:57,229 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 39d465c7-3c4a-4a0d-95c2-f91402e03d61
127.0.0.1 - - [14/Feb/2025 22:30:57] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:57,246 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 39190d61-5869-426f-8aee-41dfec8d7a26
2025-02-14 22:30:57,281 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 39190d61-5869-426f-8aee-41dfec8d7a26
127.0.0.1 - - [14/Feb/2025 22:30:57] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:57,380 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f46a2ccc-7f15-4390-8c4f-c3d73ca938b0
2025-02-14 22:30:57,393 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c2729fcb-2300-4de8-a5c3-94a4245fc46f
2025-02-14 22:30:57,508 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c2729fcb-2300-4de8-a5c3-94a4245fc46f
127.0.0.1 - - [14/Feb/2025 22:30:57] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:57,530 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f46a2ccc-7f15-4390-8c4f-c3d73ca938b0
127.0.0.1 - - [14/Feb/2025 22:30:57] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:57,747 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a6baef00-4194-41ce-b8f1-fa3fd9e88ea2
2025-02-14 22:30:57,767 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a6baef00-4194-41ce-b8f1-fa3fd9e88ea2
127.0.0.1 - - [14/Feb/2025 22:30:57] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:57,797 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1be66835-fcba-4ab8-9908-f48d67a98f38
2025-02-14 22:30:57,822 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1be66835-fcba-4ab8-9908-f48d67a98f38
127.0.0.1 - - [14/Feb/2025 22:30:57] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:57,904 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d62cc050-36b5-4bb3-8821-eda43c359771
2025-02-14 22:30:58,104 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d62cc050-36b5-4bb3-8821-eda43c359771
127.0.0.1 - - [14/Feb/2025 22:30:58] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:58,277 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f9ecc1ea-15ef-4c41-904f-2103ca1380f1
2025-02-14 22:30:58,293 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f9ecc1ea-15ef-4c41-904f-2103ca1380f1
127.0.0.1 - - [14/Feb/2025 22:30:58] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:58,388 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 18e94a36-f056-43e0-9d7d-ba87dc63d8f6
2025-02-14 22:30:58,653 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3e1433d3-7467-496f-b8e9-6ce343b5ccbf
2025-02-14 22:30:58,751 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 286dd7bf-1bdc-47fd-a8e9-ab3d1db4d97a
2025-02-14 22:30:58,766 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 18e94a36-f056-43e0-9d7d-ba87dc63d8f6
127.0.0.1 - - [14/Feb/2025 22:30:58] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:58,852 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 286dd7bf-1bdc-47fd-a8e9-ab3d1db4d97a
127.0.0.1 - - [14/Feb/2025 22:30:58] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:58,909 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3e1433d3-7467-496f-b8e9-6ce343b5ccbf
2025-02-14 22:30:58,911 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 732765bb-91e5-457c-9d66-f22de18853cb
127.0.0.1 - - [14/Feb/2025 22:30:58] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:58,971 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d83df21d-d79a-439b-9bdb-9a5de100a9e3
2025-02-14 22:30:59,057 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d83df21d-d79a-439b-9bdb-9a5de100a9e3
127.0.0.1 - - [14/Feb/2025 22:30:59] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:59,362 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 732765bb-91e5-457c-9d66-f22de18853cb
127.0.0.1 - - [14/Feb/2025 22:30:59] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:59,406 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c208d161-b8d8-404b-8487-c178041efa73
2025-02-14 22:30:59,493 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a33fd438-15a6-43b8-b77b-a3e3d0a23695
2025-02-14 22:30:59,645 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a33fd438-15a6-43b8-b77b-a3e3d0a23695
127.0.0.1 - - [14/Feb/2025 22:30:59] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:59,722 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c208d161-b8d8-404b-8487-c178041efa73
127.0.0.1 - - [14/Feb/2025 22:30:59] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:30:59,824 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5e86a289-a4f8-4414-b75d-da264a86fe57
2025-02-14 22:30:59,851 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b262a025-090c-4223-9ae4-abc724601529
2025-02-14 22:30:59,881 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 76c72792-7588-4b10-96ea-5fbf3082c30d
2025-02-14 22:30:59,964 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a1fb35fe-c29b-4261-87d0-c6ebec658bae
2025-02-14 22:30:59,967 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b262a025-090c-4223-9ae4-abc724601529
127.0.0.1 - - [14/Feb/2025 22:31:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:00,060 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a1fb35fe-c29b-4261-87d0-c6ebec658bae
127.0.0.1 - - [14/Feb/2025 22:31:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:00,094 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 76c72792-7588-4b10-96ea-5fbf3082c30d
127.0.0.1 - - [14/Feb/2025 22:31:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:00,183 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5e86a289-a4f8-4414-b75d-da264a86fe57
127.0.0.1 - - [14/Feb/2025 22:31:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:00,323 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0a65688c-64f4-46c8-8090-a5cf14d72d17
2025-02-14 22:31:00,424 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0a65688c-64f4-46c8-8090-a5cf14d72d17
127.0.0.1 - - [14/Feb/2025 22:31:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:00,486 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 45812336-ed21-4d80-9529-c92a50d8b035
2025-02-14 22:31:00,544 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fcb3c0f9-d618-4d11-a63c-a7e37401fde2
2025-02-14 22:31:00,546 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 45812336-ed21-4d80-9529-c92a50d8b035
127.0.0.1 - - [14/Feb/2025 22:31:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:00,818 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c3234ada-5ad6-4cac-9225-d7e79baf6a21
2025-02-14 22:31:00,833 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c3234ada-5ad6-4cac-9225-d7e79baf6a21
127.0.0.1 - - [14/Feb/2025 22:31:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:00,862 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4adbb209-b3ff-40ac-93de-3af05416702b
2025-02-14 22:31:00,865 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fcb3c0f9-d618-4d11-a63c-a7e37401fde2
127.0.0.1 - - [14/Feb/2025 22:31:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:00,930 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9d79abee-8726-494c-87f6-746bc8056be2
2025-02-14 22:31:00,987 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4adbb209-b3ff-40ac-93de-3af05416702b
127.0.0.1 - - [14/Feb/2025 22:31:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:01,203 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9d79abee-8726-494c-87f6-746bc8056be2
127.0.0.1 - - [14/Feb/2025 22:31:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:01,278 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6503cbf7-6619-4a15-807b-1144433c2b71
2025-02-14 22:31:01,319 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6503cbf7-6619-4a15-807b-1144433c2b71
127.0.0.1 - - [14/Feb/2025 22:31:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:01,337 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 42d4e3a3-114a-4689-86ce-7ee4c97b9432
2025-02-14 22:31:01,376 - LoudVA - WARNING - [LoudServer] - Timeout reached for request dfbdef14-a569-47d1-bcf2-bd97479d2371
2025-02-14 22:31:01,518 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 42d4e3a3-114a-4689-86ce-7ee4c97b9432
127.0.0.1 - - [14/Feb/2025 22:31:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:01,617 - LoudVA - INFO - [LoudServer] - Completed. Request ID: dfbdef14-a569-47d1-bcf2-bd97479d2371
127.0.0.1 - - [14/Feb/2025 22:31:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:01,792 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 782beccd-784b-400a-9650-51cec18fad4e
2025-02-14 22:31:01,837 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 782beccd-784b-400a-9650-51cec18fad4e
127.0.0.1 - - [14/Feb/2025 22:31:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:01,880 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9dbbf5ed-ba92-442b-a636-5a3707ac4b4a
2025-02-14 22:31:01,956 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a9fc5ec8-e64c-4240-89c6-145027f6fcb0
2025-02-14 22:31:01,991 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a9fc5ec8-e64c-4240-89c6-145027f6fcb0
127.0.0.1 - - [14/Feb/2025 22:31:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:02,097 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9dbbf5ed-ba92-442b-a636-5a3707ac4b4a
127.0.0.1 - - [14/Feb/2025 22:31:02] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:02,247 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7cd438c3-4e02-4b79-92f8-a1083b5f9f2a
2025-02-14 22:31:02,282 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 96336c08-682b-47de-aaa8-8eeaf4a56a5d
2025-02-14 22:31:02,288 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7cd438c3-4e02-4b79-92f8-a1083b5f9f2a
127.0.0.1 - - [14/Feb/2025 22:31:02] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:02,317 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 96336c08-682b-47de-aaa8-8eeaf4a56a5d
127.0.0.1 - - [14/Feb/2025 22:31:02] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:02,647 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c5c37ddf-fea9-4ad7-be4f-ea16070b9567
2025-02-14 22:31:02,749 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3b06e66d-73a5-4531-850b-37a0989a4eef
2025-02-14 22:31:02,774 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c5c37ddf-fea9-4ad7-be4f-ea16070b9567
127.0.0.1 - - [14/Feb/2025 22:31:02] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:02,804 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3b06e66d-73a5-4531-850b-37a0989a4eef
127.0.0.1 - - [14/Feb/2025 22:31:02] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:02,898 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cee2a081-5cf2-4c8d-992b-63b0389412cf
2025-02-14 22:31:02,898 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c987b9a5-85f8-425d-8aad-1c2a399f93e4
2025-02-14 22:31:03,040 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c987b9a5-85f8-425d-8aad-1c2a399f93e4
127.0.0.1 - - [14/Feb/2025 22:31:03] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:03,160 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cee2a081-5cf2-4c8d-992b-63b0389412cf
127.0.0.1 - - [14/Feb/2025 22:31:03] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:03,321 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1500c213-7692-413c-b002-8e1c8b58dc08
2025-02-14 22:31:03,425 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a2cb35fb-ec26-424e-937b-836ccc2592ed
2025-02-14 22:31:03,480 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1122ad70-c04a-4fd6-91da-f6a76cbd8570
2025-02-14 22:31:03,490 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1500c213-7692-413c-b002-8e1c8b58dc08
127.0.0.1 - - [14/Feb/2025 22:31:03] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:03,551 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a2cb35fb-ec26-424e-937b-836ccc2592ed
127.0.0.1 - - [14/Feb/2025 22:31:03] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:03,641 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1122ad70-c04a-4fd6-91da-f6a76cbd8570
127.0.0.1 - - [14/Feb/2025 22:31:03] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:03,839 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f6b9b5dc-83c4-4f43-9644-bc312b4bcbee
2025-02-14 22:31:03,910 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1f6e94b6-d21d-4940-99bf-5976a9b64f0a
2025-02-14 22:31:04,034 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1f6e94b6-d21d-4940-99bf-5976a9b64f0a
127.0.0.1 - - [14/Feb/2025 22:31:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:04,117 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c544eb63-824e-49de-b166-086f65695ce1
2025-02-14 22:31:04,130 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f6b9b5dc-83c4-4f43-9644-bc312b4bcbee
127.0.0.1 - - [14/Feb/2025 22:31:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:04,228 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c544eb63-824e-49de-b166-086f65695ce1
127.0.0.1 - - [14/Feb/2025 22:31:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:04,282 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0bdd3dc6-cab2-43d3-9c74-065587c2823e
2025-02-14 22:31:04,306 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d887cc7b-8ed6-4da7-b827-94315ec52884
2025-02-14 22:31:04,307 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0bdd3dc6-cab2-43d3-9c74-065587c2823e
127.0.0.1 - - [14/Feb/2025 22:31:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:04,321 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d887cc7b-8ed6-4da7-b827-94315ec52884
127.0.0.1 - - [14/Feb/2025 22:31:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:04,433 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9cfb6889-455d-49d0-8c9c-dae4c3259562
2025-02-14 22:31:04,712 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9cfb6889-455d-49d0-8c9c-dae4c3259562
127.0.0.1 - - [14/Feb/2025 22:31:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:04,861 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e136902f-db2f-4f75-a0c5-52b71da8f43b
2025-02-14 22:31:04,941 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e136902f-db2f-4f75-a0c5-52b71da8f43b
127.0.0.1 - - [14/Feb/2025 22:31:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:05,058 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f0b611be-07c9-44a8-8181-0c106368d2a7
2025-02-14 22:31:05,213 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 66bba2d8-ba65-4e3f-8d62-8eee0d8641ce
2025-02-14 22:31:05,232 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f0b611be-07c9-44a8-8181-0c106368d2a7
127.0.0.1 - - [14/Feb/2025 22:31:05] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:05,424 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 82d7de70-0b35-41c3-aba0-ab7c0f86af84
2025-02-14 22:31:05,447 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 66bba2d8-ba65-4e3f-8d62-8eee0d8641ce
127.0.0.1 - - [14/Feb/2025 22:31:05] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:05,514 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2c56b6d2-ce84-4960-bbcf-de3e6bc97b86
2025-02-14 22:31:05,587 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 82d7de70-0b35-41c3-aba0-ab7c0f86af84
127.0.0.1 - - [14/Feb/2025 22:31:05] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:05,698 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6e2ac999-1c8b-4cb7-9dde-eedf2fcbb996
2025-02-14 22:31:05,732 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2c56b6d2-ce84-4960-bbcf-de3e6bc97b86
127.0.0.1 - - [14/Feb/2025 22:31:05] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:05,816 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6e2ac999-1c8b-4cb7-9dde-eedf2fcbb996
127.0.0.1 - - [14/Feb/2025 22:31:05] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:06,063 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 36b71ed9-4a8f-4d3b-b007-7e871c9079c0
2025-02-14 22:31:06,081 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8f924734-0b4d-4fbe-a827-bce041eaf1c0
2025-02-14 22:31:06,108 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ea28eaad-4b34-436e-99cf-60a3b6a3895a
2025-02-14 22:31:06,201 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ea28eaad-4b34-436e-99cf-60a3b6a3895a
127.0.0.1 - - [14/Feb/2025 22:31:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:06,263 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 36b71ed9-4a8f-4d3b-b007-7e871c9079c0
127.0.0.1 - - [14/Feb/2025 22:31:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:06,302 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8f924734-0b4d-4fbe-a827-bce041eaf1c0
127.0.0.1 - - [14/Feb/2025 22:31:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:06,336 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 83469f3f-1d6d-4751-80df-f333212276a9
2025-02-14 22:31:06,380 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 83469f3f-1d6d-4751-80df-f333212276a9
127.0.0.1 - - [14/Feb/2025 22:31:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:06,389 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aa5ad538-99a0-49a5-be3e-f1d49f026f7a
2025-02-14 22:31:06,502 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8b7b7cae-624e-4512-b2b8-ed31339ec6a7
2025-02-14 22:31:06,563 - LoudVA - INFO - [LoudServer] - Completed. Request ID: aa5ad538-99a0-49a5-be3e-f1d49f026f7a
127.0.0.1 - - [14/Feb/2025 22:31:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:06,659 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8b7b7cae-624e-4512-b2b8-ed31339ec6a7
127.0.0.1 - - [14/Feb/2025 22:31:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:06,760 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 389829c9-5f0f-4c76-94da-171dbc3d0aad
2025-02-14 22:31:06,775 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 389829c9-5f0f-4c76-94da-171dbc3d0aad
127.0.0.1 - - [14/Feb/2025 22:31:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:06,851 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4ba78cfa-f195-4e22-9b8d-2451871d24bd
2025-02-14 22:31:06,994 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4ba78cfa-f195-4e22-9b8d-2451871d24bd
127.0.0.1 - - [14/Feb/2025 22:31:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:07,189 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8f11cb42-bbbc-4db1-b188-cd360fa9a00f
2025-02-14 22:31:07,298 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 31a634af-298f-4395-9d40-42d4495c41fb
2025-02-14 22:31:07,307 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8f11cb42-bbbc-4db1-b188-cd360fa9a00f
127.0.0.1 - - [14/Feb/2025 22:31:07] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:07,322 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 31a634af-298f-4395-9d40-42d4495c41fb
127.0.0.1 - - [14/Feb/2025 22:31:07] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:07,723 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8f926f76-a464-43a9-ac5f-d5825916092f
2025-02-14 22:31:07,727 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8a4d86fa-67da-4a62-8c0c-4190f3c6a115
2025-02-14 22:31:07,738 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8f926f76-a464-43a9-ac5f-d5825916092f
127.0.0.1 - - [14/Feb/2025 22:31:07] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:07,813 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 213d49ec-43d2-4c96-84af-d638b71d2c93
2025-02-14 22:31:07,821 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8a4d86fa-67da-4a62-8c0c-4190f3c6a115
2025-02-14 22:31:07,832 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 213d49ec-43d2-4c96-84af-d638b71d2c93
127.0.0.1 - - [14/Feb/2025 22:31:07] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:07,856 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7aeb9f44-edfa-47d7-aa30-3dada75e627b
127.0.0.1 - - [14/Feb/2025 22:31:07] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:07,929 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7aeb9f44-edfa-47d7-aa30-3dada75e627b
127.0.0.1 - - [14/Feb/2025 22:31:07] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:08,136 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 867c8265-2b3b-4bc9-bf44-c3074270faf8
2025-02-14 22:31:08,319 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 61355248-de21-44c2-bd4b-3aceae3f6a0e
2025-02-14 22:31:08,359 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 867c8265-2b3b-4bc9-bf44-c3074270faf8
2025-02-14 22:31:08,367 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 61355248-de21-44c2-bd4b-3aceae3f6a0e
127.0.0.1 - - [14/Feb/2025 22:31:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:08,372 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1dbb7675-b5f2-47f4-a306-9a84a05734bf
127.0.0.1 - - [14/Feb/2025 22:31:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:08,468 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1dbb7675-b5f2-47f4-a306-9a84a05734bf
127.0.0.1 - - [14/Feb/2025 22:31:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:08,599 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e4e5070d-8c54-4bdd-92f9-9de6c373f95a
2025-02-14 22:31:08,769 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e4e5070d-8c54-4bdd-92f9-9de6c373f95a
127.0.0.1 - - [14/Feb/2025 22:31:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:08,809 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ec71cc6e-e213-401f-a82e-65a9b0c92fca
2025-02-14 22:31:08,834 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ec71cc6e-e213-401f-a82e-65a9b0c92fca
127.0.0.1 - - [14/Feb/2025 22:31:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:08,850 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7af21665-6a5f-4363-8134-64e1dfea4e65
2025-02-14 22:31:08,892 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7af21665-6a5f-4363-8134-64e1dfea4e65
127.0.0.1 - - [14/Feb/2025 22:31:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:08,897 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a565afdf-68bc-4161-9ef5-e3edec52993f
2025-02-14 22:31:09,015 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a565afdf-68bc-4161-9ef5-e3edec52993f
127.0.0.1 - - [14/Feb/2025 22:31:09] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:09,279 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 87bf23b1-fce0-4b25-ada2-46b923ebb500
2025-02-14 22:31:09,302 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 87bf23b1-fce0-4b25-ada2-46b923ebb500
127.0.0.1 - - [14/Feb/2025 22:31:09] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:09,596 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 402bdfe7-2585-4af5-be37-163aa500c100
2025-02-14 22:31:09,689 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 363c94c0-3dd8-419f-a2b9-2b2c64b720b7
2025-02-14 22:31:09,766 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 402bdfe7-2585-4af5-be37-163aa500c100
127.0.0.1 - - [14/Feb/2025 22:31:09] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:09,817 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bac30a3f-66be-47c6-9f8b-1738fab44a54
2025-02-14 22:31:09,831 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 363c94c0-3dd8-419f-a2b9-2b2c64b720b7
2025-02-14 22:31:09,868 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cbc59a79-4483-4b24-9f91-85e1c7886747
2025-02-14 22:31:09,883 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bac30a3f-66be-47c6-9f8b-1738fab44a54
127.0.0.1 - - [14/Feb/2025 22:31:09] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:31:09] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:09,935 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cbc59a79-4483-4b24-9f91-85e1c7886747
127.0.0.1 - - [14/Feb/2025 22:31:09] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:10,035 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ab92bc7a-eba8-43a5-883f-9d128884d809
2025-02-14 22:31:10,238 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ff2dec2e-2328-4c64-9d63-a1c457c05086
2025-02-14 22:31:10,252 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ab92bc7a-eba8-43a5-883f-9d128884d809
2025-02-14 22:31:10,267 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ff2dec2e-2328-4c64-9d63-a1c457c05086
127.0.0.1 - - [14/Feb/2025 22:31:10] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [14/Feb/2025 22:31:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:10,320 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2e1d90f2-3c1b-451f-8a1c-7edbeb63b117
2025-02-14 22:31:10,329 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1f7e95d8-12e9-4d43-96f5-87885e533d39
2025-02-14 22:31:10,382 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1f7e95d8-12e9-4d43-96f5-87885e533d39
127.0.0.1 - - [14/Feb/2025 22:31:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:10,484 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2e1d90f2-3c1b-451f-8a1c-7edbeb63b117
127.0.0.1 - - [14/Feb/2025 22:31:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:10,749 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d12ec1d7-d198-456c-ac34-9a405c9f67c5
2025-02-14 22:31:10,784 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d12ec1d7-d198-456c-ac34-9a405c9f67c5
127.0.0.1 - - [14/Feb/2025 22:31:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:10,791 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8d06434a-c639-4046-ad90-83056e170267
2025-02-14 22:31:10,816 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cc74c681-c694-4dc8-9e98-8ffb6b2b8723
2025-02-14 22:31:10,835 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cc74c681-c694-4dc8-9e98-8ffb6b2b8723
127.0.0.1 - - [14/Feb/2025 22:31:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:10,841 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8d06434a-c639-4046-ad90-83056e170267
127.0.0.1 - - [14/Feb/2025 22:31:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:11,233 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1ed43f5f-b745-4f00-86b0-deac78807341
2025-02-14 22:31:11,250 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1ed43f5f-b745-4f00-86b0-deac78807341
127.0.0.1 - - [14/Feb/2025 22:31:11] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:11,295 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5439f87c-ec1a-4fb6-b4c8-995bea65af37
2025-02-14 22:31:11,301 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8688c3cc-0ff2-4e88-bab4-40d6beced5b1
2025-02-14 22:31:11,310 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8688c3cc-0ff2-4e88-bab4-40d6beced5b1
127.0.0.1 - - [14/Feb/2025 22:31:11] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:11,322 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5439f87c-ec1a-4fb6-b4c8-995bea65af37
127.0.0.1 - - [14/Feb/2025 22:31:11] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:11,738 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ec3a9055-6460-4bf4-b942-2e0d204e9146
2025-02-14 22:31:11,793 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ec3a9055-6460-4bf4-b942-2e0d204e9146
127.0.0.1 - - [14/Feb/2025 22:31:11] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:11,824 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4ac803c7-d0cb-4bc8-bef2-be3f9d928025
2025-02-14 22:31:11,862 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4ac803c7-d0cb-4bc8-bef2-be3f9d928025
127.0.0.1 - - [14/Feb/2025 22:31:11] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:11,931 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9799656b-3a47-43db-82e1-3dc3816efe7d
2025-02-14 22:31:11,981 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9799656b-3a47-43db-82e1-3dc3816efe7d
127.0.0.1 - - [14/Feb/2025 22:31:11] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:12,312 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6cece501-6f0c-476b-bb4b-1e9b168bf307
2025-02-14 22:31:12,342 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9cc0e4b4-dd6b-4682-afce-dd9e8cc8b97a
2025-02-14 22:31:12,382 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6cece501-6f0c-476b-bb4b-1e9b168bf307
127.0.0.1 - - [14/Feb/2025 22:31:12] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:12,436 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9cc0e4b4-dd6b-4682-afce-dd9e8cc8b97a
127.0.0.1 - - [14/Feb/2025 22:31:12] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:12,508 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 41665716-160b-41b3-8e12-61a123ba27fa
2025-02-14 22:31:12,607 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 41665716-160b-41b3-8e12-61a123ba27fa
127.0.0.1 - - [14/Feb/2025 22:31:12] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:12,816 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c420c476-4849-4d3e-be15-ce4aacc37697
2025-02-14 22:31:12,818 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f8f695c5-d1bd-4a30-8f74-a02ca7b6be68
2025-02-14 22:31:12,875 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8688f0ea-f79c-4788-b4ce-6d66822a5b0e
2025-02-14 22:31:12,907 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f8f695c5-d1bd-4a30-8f74-a02ca7b6be68
127.0.0.1 - - [14/Feb/2025 22:31:12] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:12,925 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c420c476-4849-4d3e-be15-ce4aacc37697
127.0.0.1 - - [14/Feb/2025 22:31:12] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:13,036 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8688f0ea-f79c-4788-b4ce-6d66822a5b0e
127.0.0.1 - - [14/Feb/2025 22:31:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:13,322 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2da3066f-2e88-45ed-b8fe-96f3c0489577
2025-02-14 22:31:13,335 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2da3066f-2e88-45ed-b8fe-96f3c0489577
127.0.0.1 - - [14/Feb/2025 22:31:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:13,375 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 59f2c816-1867-46e9-b518-2fe54b7fd305
2025-02-14 22:31:13,486 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 59f2c816-1867-46e9-b518-2fe54b7fd305
127.0.0.1 - - [14/Feb/2025 22:31:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:13,626 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1046fc0a-4950-4aa8-873a-6469f0a876a1
2025-02-14 22:31:13,689 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1046fc0a-4950-4aa8-873a-6469f0a876a1
127.0.0.1 - - [14/Feb/2025 22:31:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:13,731 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4fa83604-ee9b-4896-9c55-dc1fe73e5b85
2025-02-14 22:31:13,773 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4fa83604-ee9b-4896-9c55-dc1fe73e5b85
127.0.0.1 - - [14/Feb/2025 22:31:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:13,803 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ee216c1c-601d-427e-a78d-cebcd37603d2
2025-02-14 22:31:13,834 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ee216c1c-601d-427e-a78d-cebcd37603d2
127.0.0.1 - - [14/Feb/2025 22:31:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:14,021 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 13d38f91-e15d-4abc-a354-7c09befe3294
2025-02-14 22:31:14,145 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 13d38f91-e15d-4abc-a354-7c09befe3294
127.0.0.1 - - [14/Feb/2025 22:31:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:14,304 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 37a9060e-7bdf-4c29-b5b7-0e7ed18eaabb
2025-02-14 22:31:14,324 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 37a9060e-7bdf-4c29-b5b7-0e7ed18eaabb
127.0.0.1 - - [14/Feb/2025 22:31:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:14,364 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4898e01b-4afb-4a7d-b60c-f7ab64233b96
2025-02-14 22:31:14,450 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4898e01b-4afb-4a7d-b60c-f7ab64233b96
127.0.0.1 - - [14/Feb/2025 22:31:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:14,691 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3d24c754-d239-4ee2-aac7-9301e5fb3fb4
2025-02-14 22:31:14,832 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d902e7c7-4f23-4549-8d65-7a93329c43c0
2025-02-14 22:31:14,836 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 67cbde64-0c00-498a-bfbb-d2fb8c68dcff
2025-02-14 22:31:14,845 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d902e7c7-4f23-4549-8d65-7a93329c43c0
127.0.0.1 - - [14/Feb/2025 22:31:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:14,856 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e5d22c37-4c45-475a-ad48-90ac6f30cb53
2025-02-14 22:31:14,867 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 67cbde64-0c00-498a-bfbb-d2fb8c68dcff
127.0.0.1 - - [14/Feb/2025 22:31:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:14,881 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3d24c754-d239-4ee2-aac7-9301e5fb3fb4
127.0.0.1 - - [14/Feb/2025 22:31:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:14,920 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e5d22c37-4c45-475a-ad48-90ac6f30cb53
127.0.0.1 - - [14/Feb/2025 22:31:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:15,330 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 152cc35a-f785-4f34-812f-ec4e462ca438
2025-02-14 22:31:15,402 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 152cc35a-f785-4f34-812f-ec4e462ca438
127.0.0.1 - - [14/Feb/2025 22:31:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:15,657 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5739b859-d243-4ce5-9474-379d80003d72
2025-02-14 22:31:15,679 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5739b859-d243-4ce5-9474-379d80003d72
127.0.0.1 - - [14/Feb/2025 22:31:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:15,783 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9267e20b-687f-4aeb-b47c-43cfd8d526e3
2025-02-14 22:31:15,820 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9267e20b-687f-4aeb-b47c-43cfd8d526e3
127.0.0.1 - - [14/Feb/2025 22:31:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:15,893 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4ef7198d-edce-4883-9213-0de4d377eff1
2025-02-14 22:31:15,894 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d1ffd53b-2036-4c22-abb4-850e5bae1748
2025-02-14 22:31:15,933 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4ef7198d-edce-4883-9213-0de4d377eff1
127.0.0.1 - - [14/Feb/2025 22:31:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:16,094 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4e47ad58-2671-4d8f-8d78-022fda589b2d
2025-02-14 22:31:16,171 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d1ffd53b-2036-4c22-abb4-850e5bae1748
127.0.0.1 - - [14/Feb/2025 22:31:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:16,199 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4e47ad58-2671-4d8f-8d78-022fda589b2d
127.0.0.1 - - [14/Feb/2025 22:31:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:16,235 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7ff089ee-c8fc-44cf-bf87-09f95116fac9
2025-02-14 22:31:16,274 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7ff089ee-c8fc-44cf-bf87-09f95116fac9
127.0.0.1 - - [14/Feb/2025 22:31:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:16,360 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ffadf290-a892-4364-a4a0-b88f59b66364
2025-02-14 22:31:16,394 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ffadf290-a892-4364-a4a0-b88f59b66364
127.0.0.1 - - [14/Feb/2025 22:31:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:16,442 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 127b3ddc-5de4-4b45-aced-31739786b61a
2025-02-14 22:31:16,585 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 127b3ddc-5de4-4b45-aced-31739786b61a
127.0.0.1 - - [14/Feb/2025 22:31:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:16,824 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 87aba67a-91c7-4049-a2d7-ecd34472e8f6
2025-02-14 22:31:16,878 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 87aba67a-91c7-4049-a2d7-ecd34472e8f6
127.0.0.1 - - [14/Feb/2025 22:31:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:16,935 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 84a32ca3-d1dc-493d-ac7f-73811679c223
2025-02-14 22:31:17,025 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 84a32ca3-d1dc-493d-ac7f-73811679c223
127.0.0.1 - - [14/Feb/2025 22:31:17] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:17,133 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 04abf4c8-7a38-4461-80b6-1a1ed93a9a18
2025-02-14 22:31:17,259 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 04abf4c8-7a38-4461-80b6-1a1ed93a9a18
127.0.0.1 - - [14/Feb/2025 22:31:17] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:17,304 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aad68e25-72d7-4da9-8725-a853af91cac6
2025-02-14 22:31:17,340 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 61a5a763-8eee-4a26-8c43-829bbb85bd56
2025-02-14 22:31:17,340 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 61a5a763-8eee-4a26-8c43-829bbb85bd56
127.0.0.1 - - [14/Feb/2025 22:31:17] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:17,349 - LoudVA - INFO - [LoudServer] - Completed. Request ID: aad68e25-72d7-4da9-8725-a853af91cac6
127.0.0.1 - - [14/Feb/2025 22:31:17] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:17,449 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9de52a75-0e4a-4cf9-8ac0-58197e88a1e7
2025-02-14 22:31:17,608 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9de52a75-0e4a-4cf9-8ac0-58197e88a1e7
127.0.0.1 - - [14/Feb/2025 22:31:17] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:17,791 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4c8e2f15-00b0-49f1-a01d-53fdf03042a3
2025-02-14 22:31:17,810 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 45f824ba-946b-41bd-9e75-06ab982738ca
2025-02-14 22:31:17,843 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 45f824ba-946b-41bd-9e75-06ab982738ca
127.0.0.1 - - [14/Feb/2025 22:31:17] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:17,868 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4c8e2f15-00b0-49f1-a01d-53fdf03042a3
127.0.0.1 - - [14/Feb/2025 22:31:17] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:18,071 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0b182355-3f7a-4161-9550-176dfda8ca39
2025-02-14 22:31:18,147 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0b182355-3f7a-4161-9550-176dfda8ca39
127.0.0.1 - - [14/Feb/2025 22:31:18] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:18,296 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a22d54e4-f2e8-4a1e-a7f9-b4de81aa32bb
2025-02-14 22:31:18,308 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9c22b9dc-7bcf-40fc-8ccf-393e22675582
2025-02-14 22:31:18,327 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9c22b9dc-7bcf-40fc-8ccf-393e22675582
127.0.0.1 - - [14/Feb/2025 22:31:18] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:18,370 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a22d54e4-f2e8-4a1e-a7f9-b4de81aa32bb
127.0.0.1 - - [14/Feb/2025 22:31:18] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:18,448 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b738fa03-a04d-4811-846e-18a07d711dfc
2025-02-14 22:31:18,494 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b738fa03-a04d-4811-846e-18a07d711dfc
127.0.0.1 - - [14/Feb/2025 22:31:18] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:18,768 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 75a5bf26-128f-40dc-8386-e0f670813d45
2025-02-14 22:31:18,786 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 75a5bf26-128f-40dc-8386-e0f670813d45
127.0.0.1 - - [14/Feb/2025 22:31:18] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:18,823 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 48d6d354-bf02-402d-92e6-d3e7281e4423
2025-02-14 22:31:18,885 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 48d6d354-bf02-402d-92e6-d3e7281e4423
127.0.0.1 - - [14/Feb/2025 22:31:18] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:19,014 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 894f463c-19d1-44a0-8586-f50afd824e9b
2025-02-14 22:31:19,048 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 894f463c-19d1-44a0-8586-f50afd824e9b
127.0.0.1 - - [14/Feb/2025 22:31:19] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:19,352 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cece0938-87c9-4e63-8ed0-12427dc3958c
2025-02-14 22:31:19,366 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ab58498a-e9db-423c-a2a4-7ba2201d266c
2025-02-14 22:31:19,367 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cece0938-87c9-4e63-8ed0-12427dc3958c
127.0.0.1 - - [14/Feb/2025 22:31:19] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:19,382 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fdf2fa2e-73e5-4526-9cec-3f8dca1df471
2025-02-14 22:31:19,425 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fdf2fa2e-73e5-4526-9cec-3f8dca1df471
127.0.0.1 - - [14/Feb/2025 22:31:19] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:19,490 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ab58498a-e9db-423c-a2a4-7ba2201d266c
127.0.0.1 - - [14/Feb/2025 22:31:19] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:19,900 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 01054801-9a67-46ec-96a4-e06fc5d72af5
2025-02-14 22:31:20,054 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6c68dfdb-e579-4c3d-a9f1-629efacc658b
2025-02-14 22:31:20,078 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6c68dfdb-e579-4c3d-a9f1-629efacc658b
127.0.0.1 - - [14/Feb/2025 22:31:20] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:20,085 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 01054801-9a67-46ec-96a4-e06fc5d72af5
127.0.0.1 - - [14/Feb/2025 22:31:20] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:20,181 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 76ea6d84-4d85-43c3-9acf-02336d4fd3c9
2025-02-14 22:31:20,337 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 76ea6d84-4d85-43c3-9acf-02336d4fd3c9
127.0.0.1 - - [14/Feb/2025 22:31:20] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:20,338 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e7460f94-7224-4d00-8676-ed3f8b313e09
2025-02-14 22:31:20,364 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f270ae39-41a8-4522-8da3-bdc3c431bc3a
2025-02-14 22:31:20,370 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f270ae39-41a8-4522-8da3-bdc3c431bc3a
127.0.0.1 - - [14/Feb/2025 22:31:20] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:20,393 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e7460f94-7224-4d00-8676-ed3f8b313e09
127.0.0.1 - - [14/Feb/2025 22:31:20] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:20,529 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8a4e9f75-e7bf-4f49-be59-8e7f587d5be0
2025-02-14 22:31:20,580 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8a4e9f75-e7bf-4f49-be59-8e7f587d5be0
127.0.0.1 - - [14/Feb/2025 22:31:20] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:20,803 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a3e77651-8a91-414f-872e-5e2e9b03ceba
2025-02-14 22:31:20,807 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a3e77651-8a91-414f-872e-5e2e9b03ceba
127.0.0.1 - - [14/Feb/2025 22:31:20] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:20,934 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 849e8504-7dcc-410a-b824-e1539e74a95e
2025-02-14 22:31:20,997 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 849e8504-7dcc-410a-b824-e1539e74a95e
127.0.0.1 - - [14/Feb/2025 22:31:21] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:21,060 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8778b2b4-0ac4-4b4a-b5d3-974df73992e6
2025-02-14 22:31:21,245 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8778b2b4-0ac4-4b4a-b5d3-974df73992e6
127.0.0.1 - - [14/Feb/2025 22:31:21] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:21,274 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0580511d-ab22-4558-b37a-355aef7f6ed7
2025-02-14 22:31:21,328 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0580511d-ab22-4558-b37a-355aef7f6ed7
127.0.0.1 - - [14/Feb/2025 22:31:21] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:21,405 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7f5c77e2-e2f5-443c-8813-ca364be1566e
2025-02-14 22:31:21,444 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7f5c77e2-e2f5-443c-8813-ca364be1566e
127.0.0.1 - - [14/Feb/2025 22:31:21] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:21,849 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e99adb90-3992-44f7-99b1-aedcc4f097a2
2025-02-14 22:31:21,875 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e99adb90-3992-44f7-99b1-aedcc4f097a2
127.0.0.1 - - [14/Feb/2025 22:31:21] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:21,911 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 80f18193-ba66-4c4e-8f38-786f578884c5
2025-02-14 22:31:21,941 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 558ab784-fabd-4236-9c50-eb562fa07bd0
2025-02-14 22:31:21,960 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 80f18193-ba66-4c4e-8f38-786f578884c5
127.0.0.1 - - [14/Feb/2025 22:31:21] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:22,031 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 96ba6183-0c8d-47d1-987c-63c0afbf3e4d
2025-02-14 22:31:22,054 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 558ab784-fabd-4236-9c50-eb562fa07bd0
127.0.0.1 - - [14/Feb/2025 22:31:22] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:22,075 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 96ba6183-0c8d-47d1-987c-63c0afbf3e4d
127.0.0.1 - - [14/Feb/2025 22:31:22] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:22,277 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 76440c2a-5ee2-426c-804b-3b77ea45df70
2025-02-14 22:31:22,326 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 76440c2a-5ee2-426c-804b-3b77ea45df70
127.0.0.1 - - [14/Feb/2025 22:31:22] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:22,496 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 43025c97-c7b4-4bc9-9321-a276ba0700b7
2025-02-14 22:31:22,547 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6a886d17-a516-4806-942c-4914d2d4bae4
2025-02-14 22:31:22,559 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 43025c97-c7b4-4bc9-9321-a276ba0700b7
127.0.0.1 - - [14/Feb/2025 22:31:22] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:22,621 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6a886d17-a516-4806-942c-4914d2d4bae4
127.0.0.1 - - [14/Feb/2025 22:31:22] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:22,861 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1da5730d-ab7f-4275-83a1-c6428742b428
2025-02-14 22:31:22,934 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d0effc5a-d7a8-4e54-a1ce-d18a93574803
2025-02-14 22:31:22,945 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f92292b2-50ee-46f7-89c3-5fb80dc26c3c
2025-02-14 22:31:22,947 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1da5730d-ab7f-4275-83a1-c6428742b428
127.0.0.1 - - [14/Feb/2025 22:31:22] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:22,979 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f92292b2-50ee-46f7-89c3-5fb80dc26c3c
127.0.0.1 - - [14/Feb/2025 22:31:22] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:23,034 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d0effc5a-d7a8-4e54-a1ce-d18a93574803
127.0.0.1 - - [14/Feb/2025 22:31:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:23,299 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5e820227-d4c9-409e-9516-1e05237807db
2025-02-14 22:31:23,321 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5e820227-d4c9-409e-9516-1e05237807db
127.0.0.1 - - [14/Feb/2025 22:31:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:23,469 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 82f18670-54fc-44ff-a06a-7ea74020ab79
2025-02-14 22:31:23,539 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 82f18670-54fc-44ff-a06a-7ea74020ab79
127.0.0.1 - - [14/Feb/2025 22:31:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:23,703 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 90625336-1127-4a31-873e-5820b1f5a198
2025-02-14 22:31:23,796 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 90625336-1127-4a31-873e-5820b1f5a198
127.0.0.1 - - [14/Feb/2025 22:31:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:23,830 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 036cdb40-79e9-418f-af0c-d32cf3edeed3
2025-02-14 22:31:23,833 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 036cdb40-79e9-418f-af0c-d32cf3edeed3
127.0.0.1 - - [14/Feb/2025 22:31:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:23,980 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 70a48e93-7019-457c-ae39-11684d12df35
2025-02-14 22:31:24,025 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 70a48e93-7019-457c-ae39-11684d12df35
127.0.0.1 - - [14/Feb/2025 22:31:24] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:24,102 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d1405788-4e2d-4d87-8971-034d689a726d
2025-02-14 22:31:24,164 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d1405788-4e2d-4d87-8971-034d689a726d
127.0.0.1 - - [14/Feb/2025 22:31:24] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:24,218 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7f8d6e4c-3304-4649-9366-c6fd610476da
2025-02-14 22:31:24,246 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7f8d6e4c-3304-4649-9366-c6fd610476da
127.0.0.1 - - [14/Feb/2025 22:31:24] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:24,466 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aae0e86f-6aba-40a2-b036-f3f0e83ceae4
2025-02-14 22:31:24,470 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c66d9379-18f1-4854-a443-56ce9dc1069a
2025-02-14 22:31:24,523 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c66d9379-18f1-4854-a443-56ce9dc1069a
127.0.0.1 - - [14/Feb/2025 22:31:24] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:24,528 - LoudVA - INFO - [LoudServer] - Completed. Request ID: aae0e86f-6aba-40a2-b036-f3f0e83ceae4
127.0.0.1 - - [14/Feb/2025 22:31:24] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:24,977 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 948d2374-86de-4458-90ad-add4b7ff6587
2025-02-14 22:31:24,986 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a6beedd3-a16e-4ac2-88f4-0243526e2f79
2025-02-14 22:31:25,065 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 948d2374-86de-4458-90ad-add4b7ff6587
127.0.0.1 - - [14/Feb/2025 22:31:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:25,065 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a6beedd3-a16e-4ac2-88f4-0243526e2f79
127.0.0.1 - - [14/Feb/2025 22:31:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:25,276 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a82d4566-aea7-48d1-83ed-aa43b8e77cda
2025-02-14 22:31:25,302 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 19b50af1-6d34-489d-895d-64bdf1f97973
2025-02-14 22:31:25,312 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a82d4566-aea7-48d1-83ed-aa43b8e77cda
127.0.0.1 - - [14/Feb/2025 22:31:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:25,377 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e3879b11-2e31-40b1-ae7e-8cf133bdffb2
2025-02-14 22:31:25,400 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 19b50af1-6d34-489d-895d-64bdf1f97973
127.0.0.1 - - [14/Feb/2025 22:31:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:25,420 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e3879b11-2e31-40b1-ae7e-8cf133bdffb2
127.0.0.1 - - [14/Feb/2025 22:31:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:25,498 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1d079d74-c2f0-4329-ae54-414a6be33641
2025-02-14 22:31:25,556 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1d079d74-c2f0-4329-ae54-414a6be33641
127.0.0.1 - - [14/Feb/2025 22:31:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:25,867 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e8ee62d1-a4c7-42fa-8913-f21223b2a97c
2025-02-14 22:31:25,914 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e8ee62d1-a4c7-42fa-8913-f21223b2a97c
127.0.0.1 - - [14/Feb/2025 22:31:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:26,108 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d815b89f-e3c1-4185-9a99-2aadca628b0d
2025-02-14 22:31:26,159 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d815b89f-e3c1-4185-9a99-2aadca628b0d
127.0.0.1 - - [14/Feb/2025 22:31:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:26,340 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 718bd3a3-e58a-4284-abec-0f9b0f1b791a
2025-02-14 22:31:26,357 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 05bf6ec7-7700-4e40-8755-d23903019f72
2025-02-14 22:31:26,436 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 718bd3a3-e58a-4284-abec-0f9b0f1b791a
127.0.0.1 - - [14/Feb/2025 22:31:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:26,442 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 05bf6ec7-7700-4e40-8755-d23903019f72
127.0.0.1 - - [14/Feb/2025 22:31:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:26,605 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4066d72e-e17c-416a-a32f-f94ec7b70809
2025-02-14 22:31:26,657 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4066d72e-e17c-416a-a32f-f94ec7b70809
127.0.0.1 - - [14/Feb/2025 22:31:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:26,673 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1c5055a8-cb4d-426e-9516-90fa064480a0
2025-02-14 22:31:26,771 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1c5055a8-cb4d-426e-9516-90fa064480a0
127.0.0.1 - - [14/Feb/2025 22:31:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:26,849 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ef5b71d7-d155-4545-825d-7513e0387b16
2025-02-14 22:31:26,856 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 397b0854-19f4-4fab-8116-4080d81e573c
2025-02-14 22:31:26,870 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 397b0854-19f4-4fab-8116-4080d81e573c
127.0.0.1 - - [14/Feb/2025 22:31:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:26,880 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ef5b71d7-d155-4545-825d-7513e0387b16
127.0.0.1 - - [14/Feb/2025 22:31:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:27,054 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5e55d90d-4967-432c-8a62-11ce02ab30f2
2025-02-14 22:31:27,089 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5e55d90d-4967-432c-8a62-11ce02ab30f2
127.0.0.1 - - [14/Feb/2025 22:31:27] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:27,264 - LoudVA - WARNING - [LoudServer] - Timeout reached for request af7d4554-01ca-4878-9f33-ea0199309553
2025-02-14 22:31:27,284 - LoudVA - INFO - [LoudServer] - Completed. Request ID: af7d4554-01ca-4878-9f33-ea0199309553
127.0.0.1 - - [14/Feb/2025 22:31:27] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:27,321 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a47c82d2-d3f4-4ec4-9473-a09f09d69734
2025-02-14 22:31:27,332 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 815e68fe-6488-43fd-936d-329adf3f1ebd
2025-02-14 22:31:27,358 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 815e68fe-6488-43fd-936d-329adf3f1ebd
127.0.0.1 - - [14/Feb/2025 22:31:27] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:27,399 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a47c82d2-d3f4-4ec4-9473-a09f09d69734
127.0.0.1 - - [14/Feb/2025 22:31:27] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:27,808 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b1e74b03-91d8-4a5d-a293-45034ada8d57
2025-02-14 22:31:27,883 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b1e74b03-91d8-4a5d-a293-45034ada8d57
127.0.0.1 - - [14/Feb/2025 22:31:27] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:28,041 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4a7ea5a2-c8c9-426b-bae8-8b6a56ff6c00
2025-02-14 22:31:28,068 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0fe538b9-4b99-40b0-b4e1-e053bf491145
2025-02-14 22:31:28,089 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0fe538b9-4b99-40b0-b4e1-e053bf491145
127.0.0.1 - - [14/Feb/2025 22:31:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:28,131 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4a7ea5a2-c8c9-426b-bae8-8b6a56ff6c00
127.0.0.1 - - [14/Feb/2025 22:31:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:28,265 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 87eed234-fc8e-4748-93d0-021d53699aaa
2025-02-14 22:31:28,280 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 87eed234-fc8e-4748-93d0-021d53699aaa
127.0.0.1 - - [14/Feb/2025 22:31:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:28,457 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c1815435-a5f5-4cf3-b898-116e17b5f0b5
2025-02-14 22:31:28,497 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c1815435-a5f5-4cf3-b898-116e17b5f0b5
127.0.0.1 - - [14/Feb/2025 22:31:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:28,544 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6de534c9-a447-4dea-88c6-1b9a24bc8fcd
2025-02-14 22:31:28,639 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6de534c9-a447-4dea-88c6-1b9a24bc8fcd
127.0.0.1 - - [14/Feb/2025 22:31:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:28,877 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9b3d8a61-fe66-4c9b-8559-9c04ccc47502
2025-02-14 22:31:28,920 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9b3d8a61-fe66-4c9b-8559-9c04ccc47502
127.0.0.1 - - [14/Feb/2025 22:31:28] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:28,930 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e393b351-8905-4b6a-a244-41addc5ba872
2025-02-14 22:31:29,056 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e393b351-8905-4b6a-a244-41addc5ba872
127.0.0.1 - - [14/Feb/2025 22:31:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:29,073 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8d6db346-a04e-4796-bc31-c026501a5112
2025-02-14 22:31:29,180 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8d6db346-a04e-4796-bc31-c026501a5112
127.0.0.1 - - [14/Feb/2025 22:31:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:29,444 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b1ae50ef-6218-449b-84ab-6e950c4c5e66
2025-02-14 22:31:29,493 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b1ae50ef-6218-449b-84ab-6e950c4c5e66
127.0.0.1 - - [14/Feb/2025 22:31:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:29,522 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 217d10e3-7b22-4332-9e3c-db77c61ec99c
2025-02-14 22:31:29,619 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 217d10e3-7b22-4332-9e3c-db77c61ec99c
127.0.0.1 - - [14/Feb/2025 22:31:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:29,800 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 13b7fbfb-d4dc-4ea7-9d01-37c719baa606
2025-02-14 22:31:29,812 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 13b7fbfb-d4dc-4ea7-9d01-37c719baa606
127.0.0.1 - - [14/Feb/2025 22:31:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:29,878 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c0a13ba2-9946-470a-a351-25bfb610c5d6
2025-02-14 22:31:29,889 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 21e894d3-2c8a-4d20-b6e2-3c8b2342b938
2025-02-14 22:31:29,891 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cec7d929-1f3f-406d-96c8-2d14fc1047c3
2025-02-14 22:31:29,908 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c0a13ba2-9946-470a-a351-25bfb610c5d6
127.0.0.1 - - [14/Feb/2025 22:31:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:29,913 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 21e894d3-2c8a-4d20-b6e2-3c8b2342b938
127.0.0.1 - - [14/Feb/2025 22:31:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:29,933 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cec7d929-1f3f-406d-96c8-2d14fc1047c3
127.0.0.1 - - [14/Feb/2025 22:31:29] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:30,261 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b9dc6007-0619-467b-a861-78c8c4d1a1a4
2025-02-14 22:31:30,269 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b9dc6007-0619-467b-a861-78c8c4d1a1a4
127.0.0.1 - - [14/Feb/2025 22:31:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:30,430 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b5de5d86-d6ef-4009-ab71-3b3fa2ef8567
2025-02-14 22:31:30,446 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0e5c3528-a78f-406b-9614-db3365fc48c6
2025-02-14 22:31:30,467 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b5de5d86-d6ef-4009-ab71-3b3fa2ef8567
127.0.0.1 - - [14/Feb/2025 22:31:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:30,479 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0e5c3528-a78f-406b-9614-db3365fc48c6
127.0.0.1 - - [14/Feb/2025 22:31:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:30,817 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 86fac85a-1822-4ab1-a5c0-81f64cd2a369
2025-02-14 22:31:30,819 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 86fac85a-1822-4ab1-a5c0-81f64cd2a369
127.0.0.1 - - [14/Feb/2025 22:31:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:30,839 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a184e2f8-19c9-4661-94fa-3f49d7bb81e4
2025-02-14 22:31:30,853 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a184e2f8-19c9-4661-94fa-3f49d7bb81e4
127.0.0.1 - - [14/Feb/2025 22:31:30] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:31,310 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b4f39ffb-0846-4482-8082-600ce651a2cc
2025-02-14 22:31:31,316 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b4f39ffb-0846-4482-8082-600ce651a2cc
127.0.0.1 - - [14/Feb/2025 22:31:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:31,317 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ceaaf556-0afc-4877-9519-d79d09222272
2025-02-14 22:31:31,340 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ceaaf556-0afc-4877-9519-d79d09222272
127.0.0.1 - - [14/Feb/2025 22:31:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:31,350 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6d9c90fa-9a64-44dd-899d-c2373dfd5140
2025-02-14 22:31:31,403 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6d9c90fa-9a64-44dd-899d-c2373dfd5140
127.0.0.1 - - [14/Feb/2025 22:31:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:31,448 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 742623d9-ac50-4dd0-8be7-61b417f3abb9
2025-02-14 22:31:31,578 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 742623d9-ac50-4dd0-8be7-61b417f3abb9
127.0.0.1 - - [14/Feb/2025 22:31:31] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:32,025 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b896d93c-2fd0-426f-b90f-36614dcab240
2025-02-14 22:31:32,058 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9915a3a5-cb22-47f3-a739-d263ced7018e
2025-02-14 22:31:32,101 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b896d93c-2fd0-426f-b90f-36614dcab240
127.0.0.1 - - [14/Feb/2025 22:31:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:32,116 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9915a3a5-cb22-47f3-a739-d263ced7018e
127.0.0.1 - - [14/Feb/2025 22:31:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:32,250 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0a1ee196-212f-4ffd-9348-662cac2c7b90
2025-02-14 22:31:32,265 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0a1ee196-212f-4ffd-9348-662cac2c7b90
127.0.0.1 - - [14/Feb/2025 22:31:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:32,331 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 03fef43e-2f58-448f-b07e-870b3dfd1ff2
2025-02-14 22:31:32,351 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 03fef43e-2f58-448f-b07e-870b3dfd1ff2
127.0.0.1 - - [14/Feb/2025 22:31:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:32,384 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1856fa23-f24e-4446-96d1-7aa2c4e1e5a1
2025-02-14 22:31:32,468 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1856fa23-f24e-4446-96d1-7aa2c4e1e5a1
127.0.0.1 - - [14/Feb/2025 22:31:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:32,593 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 48137097-2f1c-458c-a4b1-4f35aa6a511f
2025-02-14 22:31:32,706 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 48137097-2f1c-458c-a4b1-4f35aa6a511f
127.0.0.1 - - [14/Feb/2025 22:31:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:32,785 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fe361cc4-a523-4142-895d-87c19801387f
2025-02-14 22:31:32,816 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fe361cc4-a523-4142-895d-87c19801387f
127.0.0.1 - - [14/Feb/2025 22:31:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:32,825 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9b7e23aa-c403-4e5f-840c-a263db72497f
2025-02-14 22:31:32,830 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9b7e23aa-c403-4e5f-840c-a263db72497f
127.0.0.1 - - [14/Feb/2025 22:31:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:32,877 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 58ab3383-ce90-4ee4-b6d7-df489bc71815
2025-02-14 22:31:32,895 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 58ab3383-ce90-4ee4-b6d7-df489bc71815
127.0.0.1 - - [14/Feb/2025 22:31:32] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:33,453 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 04dd5e61-176f-47bb-b212-39e625175c8b
2025-02-14 22:31:33,474 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cc72364e-ae7e-47f2-b067-fbd9bcc23c2e
2025-02-14 22:31:33,511 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cc72364e-ae7e-47f2-b067-fbd9bcc23c2e
127.0.0.1 - - [14/Feb/2025 22:31:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:33,554 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 04dd5e61-176f-47bb-b212-39e625175c8b
127.0.0.1 - - [14/Feb/2025 22:31:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:33,568 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b469940e-8c75-4315-81be-36fc189a76bb
2025-02-14 22:31:33,611 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b469940e-8c75-4315-81be-36fc189a76bb
127.0.0.1 - - [14/Feb/2025 22:31:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:33,889 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ef1a1a50-9149-4b9c-ba85-c7e3231573aa
2025-02-14 22:31:33,950 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ef1a1a50-9149-4b9c-ba85-c7e3231573aa
127.0.0.1 - - [14/Feb/2025 22:31:33] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:33,964 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 225a2d17-631a-4ad2-b9d2-69a2b84a6e59
2025-02-14 22:31:34,016 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 225a2d17-631a-4ad2-b9d2-69a2b84a6e59
127.0.0.1 - - [14/Feb/2025 22:31:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:34,282 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 79333473-ca1d-442d-9b5c-aae4de0bfff4
2025-02-14 22:31:34,312 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 79333473-ca1d-442d-9b5c-aae4de0bfff4
127.0.0.1 - - [14/Feb/2025 22:31:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:34,859 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cc16ed07-0e2a-492d-8bd1-4558359f506a
2025-02-14 22:31:34,876 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cc16ed07-0e2a-492d-8bd1-4558359f506a
127.0.0.1 - - [14/Feb/2025 22:31:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:34,897 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0fb35e60-ad5b-4141-8010-eec7c8a768b1
2025-02-14 22:31:34,929 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0fb35e60-ad5b-4141-8010-eec7c8a768b1
127.0.0.1 - - [14/Feb/2025 22:31:34] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:35,009 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9902ae0a-129e-465a-99de-d727654f25d2
2025-02-14 22:31:35,151 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9902ae0a-129e-465a-99de-d727654f25d2
127.0.0.1 - - [14/Feb/2025 22:31:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:35,531 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a59dea70-a088-4990-997b-c8e0087315f8
2025-02-14 22:31:35,559 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a59dea70-a088-4990-997b-c8e0087315f8
127.0.0.1 - - [14/Feb/2025 22:31:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:35,922 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 595fcc71-4dc4-4c60-bd30-57fdc8095329
2025-02-14 22:31:35,942 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ca29ee77-560e-4da4-9b9f-8eee141ae63a
2025-02-14 22:31:35,976 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ca29ee77-560e-4da4-9b9f-8eee141ae63a
127.0.0.1 - - [14/Feb/2025 22:31:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:35,988 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 595fcc71-4dc4-4c60-bd30-57fdc8095329
127.0.0.1 - - [14/Feb/2025 22:31:35] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:36,458 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f9e576d6-61c8-49d2-af30-f476f6c82073
2025-02-14 22:31:36,471 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f9e576d6-61c8-49d2-af30-f476f6c82073
127.0.0.1 - - [14/Feb/2025 22:31:36] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:36,608 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d74f1183-6503-49e8-baf6-2803864f1fe9
2025-02-14 22:31:36,676 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d74f1183-6503-49e8-baf6-2803864f1fe9
127.0.0.1 - - [14/Feb/2025 22:31:36] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:36,860 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7607b552-f2dd-417a-853f-10dc469f634a
2025-02-14 22:31:36,875 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 00be02ed-a9e7-423b-b8e7-be3dd7f479d2
2025-02-14 22:31:36,886 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 00be02ed-a9e7-423b-b8e7-be3dd7f479d2
127.0.0.1 - - [14/Feb/2025 22:31:36] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:36,899 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7607b552-f2dd-417a-853f-10dc469f634a
127.0.0.1 - - [14/Feb/2025 22:31:36] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:36,978 - LoudVA - WARNING - [LoudServer] - Timeout reached for request dc6a41cd-cbf6-4253-a871-35c55f3d0b3f
2025-02-14 22:31:37,001 - LoudVA - INFO - [LoudServer] - Completed. Request ID: dc6a41cd-cbf6-4253-a871-35c55f3d0b3f
127.0.0.1 - - [14/Feb/2025 22:31:37] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:37,373 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7bceff94-b788-49ca-b722-55f3ca8bea48
2025-02-14 22:31:37,401 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7bceff94-b788-49ca-b722-55f3ca8bea48
127.0.0.1 - - [14/Feb/2025 22:31:37] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:37,415 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9886d051-cb77-4c1f-9a54-1abee74e29e5
2025-02-14 22:31:37,448 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9886d051-cb77-4c1f-9a54-1abee74e29e5
127.0.0.1 - - [14/Feb/2025 22:31:37] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:37,871 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3ba36f39-14d8-4e14-a130-ce77ee1a7c97
2025-02-14 22:31:37,903 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3ba36f39-14d8-4e14-a130-ce77ee1a7c97
127.0.0.1 - - [14/Feb/2025 22:31:37] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:38,061 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 36063b7b-4bf1-4db2-9098-ca92f0eca7f6
2025-02-14 22:31:38,117 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 36063b7b-4bf1-4db2-9098-ca92f0eca7f6
127.0.0.1 - - [14/Feb/2025 22:31:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:38,422 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 307a7814-3cac-4cf4-a029-363b1c5f8b2f
2025-02-14 22:31:38,444 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 307a7814-3cac-4cf4-a029-363b1c5f8b2f
127.0.0.1 - - [14/Feb/2025 22:31:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:38,619 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e9fcc669-ce27-4c17-9967-ee306aa0e40c
2025-02-14 22:31:38,647 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e9fcc669-ce27-4c17-9967-ee306aa0e40c
127.0.0.1 - - [14/Feb/2025 22:31:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:38,870 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 53872a5a-fee8-4ea9-90af-eb8b46463bf2
2025-02-14 22:31:38,893 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3482e4c0-776f-48df-9194-870744dbf3fb
2025-02-14 22:31:38,908 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3482e4c0-776f-48df-9194-870744dbf3fb
127.0.0.1 - - [14/Feb/2025 22:31:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:38,920 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 53872a5a-fee8-4ea9-90af-eb8b46463bf2
127.0.0.1 - - [14/Feb/2025 22:31:38] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:39,320 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0c8fb025-f74d-450e-9b5d-21dbd536a42f
2025-02-14 22:31:39,356 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0c8fb025-f74d-450e-9b5d-21dbd536a42f
127.0.0.1 - - [14/Feb/2025 22:31:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:39,546 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fda2e443-652c-47d0-9150-ea13badc2fc6
2025-02-14 22:31:39,556 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fda2e443-652c-47d0-9150-ea13badc2fc6
127.0.0.1 - - [14/Feb/2025 22:31:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:39,818 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b46d4369-0a4c-4cdf-8206-6034b6e7bd50
2025-02-14 22:31:39,847 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b46d4369-0a4c-4cdf-8206-6034b6e7bd50
127.0.0.1 - - [14/Feb/2025 22:31:39] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:40,168 - LoudVA - WARNING - [LoudServer] - Timeout reached for request da85c224-b259-4eda-94d3-7c330fbca663
2025-02-14 22:31:40,198 - LoudVA - INFO - [LoudServer] - Completed. Request ID: da85c224-b259-4eda-94d3-7c330fbca663
127.0.0.1 - - [14/Feb/2025 22:31:40] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:40,523 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d19adc7c-8ebd-4e3e-ab74-181caa2c4c79
2025-02-14 22:31:40,533 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d19adc7c-8ebd-4e3e-ab74-181caa2c4c79
127.0.0.1 - - [14/Feb/2025 22:31:40] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:40,592 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9c86d3c6-604c-43d3-a3af-a2d7306b8084
2025-02-14 22:31:40,676 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9c86d3c6-604c-43d3-a3af-a2d7306b8084
127.0.0.1 - - [14/Feb/2025 22:31:40] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:40,820 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 02b9c1ca-a859-4838-b96a-bfa7fc1e4162
2025-02-14 22:31:40,839 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 02b9c1ca-a859-4838-b96a-bfa7fc1e4162
127.0.0.1 - - [14/Feb/2025 22:31:40] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:40,842 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4d1f0bfe-26ce-4f86-b268-fdb6fd203457
2025-02-14 22:31:40,850 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4d1f0bfe-26ce-4f86-b268-fdb6fd203457
127.0.0.1 - - [14/Feb/2025 22:31:40] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:41,280 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d17c4921-6125-42e3-8a1e-342c37216ecf
2025-02-14 22:31:41,289 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d17c4921-6125-42e3-8a1e-342c37216ecf
127.0.0.1 - - [14/Feb/2025 22:31:41] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:41,678 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 98473d9a-51a2-42e5-92b1-c54c9ca10c10
2025-02-14 22:31:41,710 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 98473d9a-51a2-42e5-92b1-c54c9ca10c10
127.0.0.1 - - [14/Feb/2025 22:31:41] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:41,857 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6bde3604-c131-42cc-86b9-6a1363f639af
2025-02-14 22:31:41,871 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6bde3604-c131-42cc-86b9-6a1363f639af
127.0.0.1 - - [14/Feb/2025 22:31:41] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:42,047 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ce7f64ab-15e1-4495-9f91-0bb31dac8a96
2025-02-14 22:31:42,083 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ce7f64ab-15e1-4495-9f91-0bb31dac8a96
127.0.0.1 - - [14/Feb/2025 22:31:42] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:42,325 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 16dbf333-c7c0-4863-acc4-b87252b2eeb5
2025-02-14 22:31:42,332 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 16dbf333-c7c0-4863-acc4-b87252b2eeb5
127.0.0.1 - - [14/Feb/2025 22:31:42] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:42,830 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c8c7cfc9-7bc6-4190-ad96-a99121405f93
2025-02-14 22:31:42,844 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c8c7cfc9-7bc6-4190-ad96-a99121405f93
127.0.0.1 - - [14/Feb/2025 22:31:42] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:42,957 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ca57bf43-81c7-430a-9f38-d7f63fbae38a
2025-02-14 22:31:42,968 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ca57bf43-81c7-430a-9f38-d7f63fbae38a
127.0.0.1 - - [14/Feb/2025 22:31:42] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:43,266 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 88a59f45-df1b-4269-93db-d8915a4f2a2a
2025-02-14 22:31:43,291 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 88a59f45-df1b-4269-93db-d8915a4f2a2a
127.0.0.1 - - [14/Feb/2025 22:31:43] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:43,417 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c0f2b460-419c-49ba-a9c0-835bc89bab3c
2025-02-14 22:31:43,437 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c0f2b460-419c-49ba-a9c0-835bc89bab3c
127.0.0.1 - - [14/Feb/2025 22:31:43] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:43,906 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c3c4f2d1-ba5c-4953-99b6-98fbb6218904
2025-02-14 22:31:43,914 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c3c4f2d1-ba5c-4953-99b6-98fbb6218904
127.0.0.1 - - [14/Feb/2025 22:31:43] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:44,097 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6342ecae-a028-4f57-aad0-f5ccbc1af8db
2025-02-14 22:31:44,122 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6342ecae-a028-4f57-aad0-f5ccbc1af8db
127.0.0.1 - - [14/Feb/2025 22:31:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:44,284 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a0cf961b-fe19-499f-a5e2-5fb03453f254
2025-02-14 22:31:44,308 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a0cf961b-fe19-499f-a5e2-5fb03453f254
127.0.0.1 - - [14/Feb/2025 22:31:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:44,335 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 61a11a7b-972f-42e0-977c-cf6c3ecf0040
2025-02-14 22:31:44,354 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 61a11a7b-972f-42e0-977c-cf6c3ecf0040
127.0.0.1 - - [14/Feb/2025 22:31:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:44,638 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c75e3c8a-636c-43dc-9a3a-22e54def9ac9
2025-02-14 22:31:44,700 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c75e3c8a-636c-43dc-9a3a-22e54def9ac9
127.0.0.1 - - [14/Feb/2025 22:31:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:44,876 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0442d75a-6e99-4d45-abd8-0ab614247a46
2025-02-14 22:31:44,894 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0442d75a-6e99-4d45-abd8-0ab614247a46
127.0.0.1 - - [14/Feb/2025 22:31:44] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:45,279 - LoudVA - WARNING - [LoudServer] - Timeout reached for request dcb0e1b3-7cd6-4b14-8774-40dc1f9ea48f
2025-02-14 22:31:45,300 - LoudVA - INFO - [LoudServer] - Completed. Request ID: dcb0e1b3-7cd6-4b14-8774-40dc1f9ea48f
127.0.0.1 - - [14/Feb/2025 22:31:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:45,303 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a6e37dec-49c5-409b-9eb1-22919f55a902
2025-02-14 22:31:45,310 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a6e37dec-49c5-409b-9eb1-22919f55a902
127.0.0.1 - - [14/Feb/2025 22:31:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:45,386 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 962afe98-fed9-4b01-8c1d-bf20323f0b2f
2025-02-14 22:31:45,398 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 962afe98-fed9-4b01-8c1d-bf20323f0b2f
127.0.0.1 - - [14/Feb/2025 22:31:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:45,899 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 205f5fca-87b1-452f-ad2d-ae8c022f2f39
2025-02-14 22:31:45,915 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 13ae2049-b79d-459b-bf33-a520ace869bb
2025-02-14 22:31:45,919 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 205f5fca-87b1-452f-ad2d-ae8c022f2f39
127.0.0.1 - - [14/Feb/2025 22:31:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:45,946 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 13ae2049-b79d-459b-bf33-a520ace869bb
127.0.0.1 - - [14/Feb/2025 22:31:45] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:46,723 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0dd95ccb-279f-4c40-885a-d545c6a8af5e
2025-02-14 22:31:46,725 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3ccc99fa-55a0-4ae7-a72d-ca7865926145
2025-02-14 22:31:46,737 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0dd95ccb-279f-4c40-885a-d545c6a8af5e
127.0.0.1 - - [14/Feb/2025 22:31:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:46,740 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3ccc99fa-55a0-4ae7-a72d-ca7865926145
127.0.0.1 - - [14/Feb/2025 22:31:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:46,883 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9c235539-037c-4f46-b140-b77e520862b5
2025-02-14 22:31:46,892 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9c235539-037c-4f46-b140-b77e520862b5
127.0.0.1 - - [14/Feb/2025 22:31:46] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:47,349 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2fd3c7f4-a620-4395-8edb-fbd337fac1a5
2025-02-14 22:31:47,357 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2fd3c7f4-a620-4395-8edb-fbd337fac1a5
127.0.0.1 - - [14/Feb/2025 22:31:47] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:47,549 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b8a63fe7-5bc9-4466-a1c2-175d18137bb7
2025-02-14 22:31:47,564 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b8a63fe7-5bc9-4466-a1c2-175d18137bb7
127.0.0.1 - - [14/Feb/2025 22:31:47] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:48,272 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0678f33f-da06-4d93-a561-45b82c46a3e7
2025-02-14 22:31:48,307 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1837cbff-10d6-43e0-b428-cc89f63f4aa7
2025-02-14 22:31:48,311 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0678f33f-da06-4d93-a561-45b82c46a3e7
127.0.0.1 - - [14/Feb/2025 22:31:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:48,342 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1837cbff-10d6-43e0-b428-cc89f63f4aa7
127.0.0.1 - - [14/Feb/2025 22:31:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:48,544 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bd52cf1d-a1d4-40bf-a899-fd53e98ba9e7
2025-02-14 22:31:48,578 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bd52cf1d-a1d4-40bf-a899-fd53e98ba9e7
127.0.0.1 - - [14/Feb/2025 22:31:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:48,789 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cdc6a23d-2b5c-4d4f-ab2d-cb3eca497e0a
2025-02-14 22:31:48,791 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cdc6a23d-2b5c-4d4f-ab2d-cb3eca497e0a
127.0.0.1 - - [14/Feb/2025 22:31:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:48,919 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5a03aa91-6316-41d7-a197-d6dd4ea063e7
2025-02-14 22:31:48,940 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5a03aa91-6316-41d7-a197-d6dd4ea063e7
127.0.0.1 - - [14/Feb/2025 22:31:48] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:49,074 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2f38b9ec-1d8b-4557-b916-41aebbe149a3
2025-02-14 22:31:49,101 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2f38b9ec-1d8b-4557-b916-41aebbe149a3
127.0.0.1 - - [14/Feb/2025 22:31:49] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:49,113 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1d744c30-5f23-41b7-9db4-2be86b2f44e3
2025-02-14 22:31:49,126 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1d744c30-5f23-41b7-9db4-2be86b2f44e3
127.0.0.1 - - [14/Feb/2025 22:31:49] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:49,407 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0228039b-e489-4dc5-8912-bfdfdd899c50
2025-02-14 22:31:49,437 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0228039b-e489-4dc5-8912-bfdfdd899c50
127.0.0.1 - - [14/Feb/2025 22:31:49] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:49,792 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3753fa5e-d2bc-4399-8866-ec45fc521f15
2025-02-14 22:31:49,795 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e6c56983-8487-4133-8f51-3fb0e6b64520
2025-02-14 22:31:49,796 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3753fa5e-d2bc-4399-8866-ec45fc521f15
127.0.0.1 - - [14/Feb/2025 22:31:49] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:49,813 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e6c56983-8487-4133-8f51-3fb0e6b64520
127.0.0.1 - - [14/Feb/2025 22:31:49] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:49,951 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a41e66a0-fc95-4947-be65-bcbe68e394b8
2025-02-14 22:31:49,974 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a41e66a0-fc95-4947-be65-bcbe68e394b8
127.0.0.1 - - [14/Feb/2025 22:31:49] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:50,341 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3926b018-a3fa-43c0-9306-2c7541fc1951
2025-02-14 22:31:50,347 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3926b018-a3fa-43c0-9306-2c7541fc1951
127.0.0.1 - - [14/Feb/2025 22:31:50] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:50,358 - LoudVA - WARNING - [LoudServer] - Timeout reached for request afba4da2-081e-4d8d-a9f6-3bb7b48afebd
2025-02-14 22:31:50,363 - LoudVA - INFO - [LoudServer] - Completed. Request ID: afba4da2-081e-4d8d-a9f6-3bb7b48afebd
127.0.0.1 - - [14/Feb/2025 22:31:50] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:50,894 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1a846ba9-e929-491c-8cbc-c74fa416a4fb
2025-02-14 22:31:50,923 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1a846ba9-e929-491c-8cbc-c74fa416a4fb
127.0.0.1 - - [14/Feb/2025 22:31:50] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:51,587 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c9c68dfe-ae35-4954-a1de-56f9d7bbf450
2025-02-14 22:31:51,602 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c9c68dfe-ae35-4954-a1de-56f9d7bbf450
127.0.0.1 - - [14/Feb/2025 22:31:51] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:52,122 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7a6afe6a-e214-48ee-9f1c-03b39347e376
2025-02-14 22:31:52,149 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7a6afe6a-e214-48ee-9f1c-03b39347e376
127.0.0.1 - - [14/Feb/2025 22:31:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:52,353 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4cabb46f-0c93-4f69-9861-98048424e176
2025-02-14 22:31:52,362 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4cabb46f-0c93-4f69-9861-98048424e176
127.0.0.1 - - [14/Feb/2025 22:31:52] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:53,255 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8b413dc8-277b-4f0e-9ad8-5c4bc94721d1
2025-02-14 22:31:53,258 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 8b413dc8-277b-4f0e-9ad8-5c4bc94721d1
127.0.0.1 - - [14/Feb/2025 22:31:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:53,537 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 252394b6-da26-4569-8a5b-9bdca7da56f5
2025-02-14 22:31:53,550 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 252394b6-da26-4569-8a5b-9bdca7da56f5
127.0.0.1 - - [14/Feb/2025 22:31:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:53,722 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ba9cde55-9f14-4cad-94ac-996818aef826
2025-02-14 22:31:53,724 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ba9cde55-9f14-4cad-94ac-996818aef826
127.0.0.1 - - [14/Feb/2025 22:31:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:53,725 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c6a7e44f-f3ff-440e-bac9-fc86c512f515
2025-02-14 22:31:53,747 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c6a7e44f-f3ff-440e-bac9-fc86c512f515
127.0.0.1 - - [14/Feb/2025 22:31:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:53,935 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 63c7f7a4-cd59-4f48-a997-d4685e61c34e
2025-02-14 22:31:53,944 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 63c7f7a4-cd59-4f48-a997-d4685e61c34e
127.0.0.1 - - [14/Feb/2025 22:31:53] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:54,243 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d6592ab1-a161-4051-88e4-f897da88923d
2025-02-14 22:31:54,247 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d6592ab1-a161-4051-88e4-f897da88923d
127.0.0.1 - - [14/Feb/2025 22:31:54] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:54,969 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 67f834ea-cc38-496c-bbb4-910f173cfc4e
2025-02-14 22:31:54,972 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6d28715a-e05b-459f-be53-1c3d1df8b6d6
2025-02-14 22:31:54,985 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6d28715a-e05b-459f-be53-1c3d1df8b6d6
127.0.0.1 - - [14/Feb/2025 22:31:54] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:55,001 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 67f834ea-cc38-496c-bbb4-910f173cfc4e
127.0.0.1 - - [14/Feb/2025 22:31:55] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:55,585 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2b1b3bf9-8f81-4970-9760-5b68f603d8bf
2025-02-14 22:31:55,600 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2b1b3bf9-8f81-4970-9760-5b68f603d8bf
127.0.0.1 - - [14/Feb/2025 22:31:55] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:55,754 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1fded175-2c42-46e9-87ac-035b91c185d8
2025-02-14 22:31:55,757 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1fded175-2c42-46e9-87ac-035b91c185d8
127.0.0.1 - - [14/Feb/2025 22:31:55] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:55,776 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b5a78bb2-4d93-4626-a5f6-9535f84474f1
2025-02-14 22:31:55,780 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b5a78bb2-4d93-4626-a5f6-9535f84474f1
127.0.0.1 - - [14/Feb/2025 22:31:55] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:56,348 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9d5bbf66-c31d-4b83-8e05-ecf1bce5ce1d
2025-02-14 22:31:56,350 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9d5bbf66-c31d-4b83-8e05-ecf1bce5ce1d
127.0.0.1 - - [14/Feb/2025 22:31:56] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:56,735 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f4fc4a07-7f9b-4aac-8160-dac133cd8752
2025-02-14 22:31:56,743 - LoudVA - INFO - [LoudServer] - Completed. Request ID: f4fc4a07-7f9b-4aac-8160-dac133cd8752
127.0.0.1 - - [14/Feb/2025 22:31:56] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:57,106 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 96fd8ec7-12af-448b-8a9b-ccb6cff56ea8
2025-02-14 22:31:57,132 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 96fd8ec7-12af-448b-8a9b-ccb6cff56ea8
127.0.0.1 - - [14/Feb/2025 22:31:57] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:57,260 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7648ee42-1023-4fd6-8a1a-9161f4f7db6c
2025-02-14 22:31:57,263 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7648ee42-1023-4fd6-8a1a-9161f4f7db6c
127.0.0.1 - - [14/Feb/2025 22:31:57] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:57,740 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4932b334-18cd-4bf7-8789-704a6ab74213
2025-02-14 22:31:57,742 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4932b334-18cd-4bf7-8789-704a6ab74213
127.0.0.1 - - [14/Feb/2025 22:31:57] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:57,772 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cba853d9-dcbf-49a0-b390-6824257e83b3
2025-02-14 22:31:57,780 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cba853d9-dcbf-49a0-b390-6824257e83b3
127.0.0.1 - - [14/Feb/2025 22:31:57] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:58,320 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9f09b3f6-6dbb-48ae-a226-7b6e193c4265
2025-02-14 22:31:58,322 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9f09b3f6-6dbb-48ae-a226-7b6e193c4265
127.0.0.1 - - [14/Feb/2025 22:31:58] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:58,933 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 231d3f29-45e5-4e9c-bf9d-98f105cb0e3e
2025-02-14 22:31:58,936 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 231d3f29-45e5-4e9c-bf9d-98f105cb0e3e
127.0.0.1 - - [14/Feb/2025 22:31:58] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:58,986 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4d23005e-2a5a-4802-b05d-7640d5342f0b
2025-02-14 22:31:58,997 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4d23005e-2a5a-4802-b05d-7640d5342f0b
127.0.0.1 - - [14/Feb/2025 22:31:58] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:59,249 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1a7536c8-5379-41e6-a7c8-116bb7ec825e
2025-02-14 22:31:59,250 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1a7536c8-5379-41e6-a7c8-116bb7ec825e
127.0.0.1 - - [14/Feb/2025 22:31:59] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:31:59,933 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4e0e6ebe-1d12-465b-b87f-6875c4123eea
2025-02-14 22:31:59,938 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4e0e6ebe-1d12-465b-b87f-6875c4123eea
127.0.0.1 - - [14/Feb/2025 22:31:59] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:00,085 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 80c549ed-11e3-47b4-90d1-ba86c7cdac40
2025-02-14 22:32:00,090 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 80c549ed-11e3-47b4-90d1-ba86c7cdac40
127.0.0.1 - - [14/Feb/2025 22:32:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:00,731 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1bc08bd4-3e45-4c55-9155-1cc9da0d65ac
2025-02-14 22:32:00,739 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1bc08bd4-3e45-4c55-9155-1cc9da0d65ac
127.0.0.1 - - [14/Feb/2025 22:32:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:00,825 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e9066e4e-7df8-4ff8-8a9c-b63a0fe7969b
2025-02-14 22:32:00,826 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e9066e4e-7df8-4ff8-8a9c-b63a0fe7969b
127.0.0.1 - - [14/Feb/2025 22:32:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:00,901 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4d4d44ce-b312-46ce-a25c-d6bfd8f2bac0
2025-02-14 22:32:00,917 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4d4d44ce-b312-46ce-a25c-d6bfd8f2bac0
127.0.0.1 - - [14/Feb/2025 22:32:00] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:01,304 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 39591abe-cd02-4398-b5db-3da7cb8fbfcb
2025-02-14 22:32:01,309 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 39591abe-cd02-4398-b5db-3da7cb8fbfcb
127.0.0.1 - - [14/Feb/2025 22:32:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:01,991 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2a63303e-e736-4668-bd62-fc7a6ba84986
2025-02-14 22:32:01,995 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2a63303e-e736-4668-bd62-fc7a6ba84986
127.0.0.1 - - [14/Feb/2025 22:32:01] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:02,308 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 664c733a-077b-4e50-b641-1ebc4c2baecb
2025-02-14 22:32:02,323 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 664c733a-077b-4e50-b641-1ebc4c2baecb
127.0.0.1 - - [14/Feb/2025 22:32:02] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:02,778 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 11e8d7e1-afe5-416e-a6fb-31b02d437944
2025-02-14 22:32:02,785 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 11e8d7e1-afe5-416e-a6fb-31b02d437944
127.0.0.1 - - [14/Feb/2025 22:32:02] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:02,811 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4708e0fe-aa1a-4f25-91bf-3240b610b65f
2025-02-14 22:32:02,813 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4708e0fe-aa1a-4f25-91bf-3240b610b65f
127.0.0.1 - - [14/Feb/2025 22:32:02] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:02,943 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ff5b6f69-69a9-4643-9044-bfd4cd0d9ee3
2025-02-14 22:32:02,954 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ff5b6f69-69a9-4643-9044-bfd4cd0d9ee3
127.0.0.1 - - [14/Feb/2025 22:32:02] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:03,333 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c28e2907-c00c-4886-984a-6b02b3a28a3c
2025-02-14 22:32:03,336 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c28e2907-c00c-4886-984a-6b02b3a28a3c
127.0.0.1 - - [14/Feb/2025 22:32:03] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:03,810 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a75fd216-4cfe-48a5-8785-590741159d47
2025-02-14 22:32:03,811 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a75fd216-4cfe-48a5-8785-590741159d47
127.0.0.1 - - [14/Feb/2025 22:32:03] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:04,426 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a7cdf808-c18b-4c95-8272-9f00ac2d3689
2025-02-14 22:32:04,438 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a7cdf808-c18b-4c95-8272-9f00ac2d3689
127.0.0.1 - - [14/Feb/2025 22:32:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:04,817 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d41f6166-bb73-407b-bb19-ad7b26346168
2025-02-14 22:32:04,820 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d41f6166-bb73-407b-bb19-ad7b26346168
127.0.0.1 - - [14/Feb/2025 22:32:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:04,826 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5183a035-9878-47c9-a216-22dcfadca3fb
2025-02-14 22:32:04,836 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5183a035-9878-47c9-a216-22dcfadca3fb
127.0.0.1 - - [14/Feb/2025 22:32:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:04,880 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3c0ba4a6-e91f-4af8-b502-0efa976633c7
2025-02-14 22:32:04,882 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3c0ba4a6-e91f-4af8-b502-0efa976633c7
127.0.0.1 - - [14/Feb/2025 22:32:04] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:05,390 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 34fd7eef-60a7-46fb-a0d7-9054244739ec
2025-02-14 22:32:05,394 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 34fd7eef-60a7-46fb-a0d7-9054244739ec
127.0.0.1 - - [14/Feb/2025 22:32:05] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:05,749 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1f3d50e6-08ef-4150-bfb7-cbc52cdf9070
2025-02-14 22:32:05,752 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1f3d50e6-08ef-4150-bfb7-cbc52cdf9070
127.0.0.1 - - [14/Feb/2025 22:32:05] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:05,886 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e1cb2a23-4a6f-4b94-9fe0-21171bd866c2
2025-02-14 22:32:05,887 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e1cb2a23-4a6f-4b94-9fe0-21171bd866c2
127.0.0.1 - - [14/Feb/2025 22:32:05] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:06,283 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7ffa9f83-592e-4465-a249-3cdf26844eda
2025-02-14 22:32:06,284 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 7ffa9f83-592e-4465-a249-3cdf26844eda
127.0.0.1 - - [14/Feb/2025 22:32:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:06,735 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a197eddc-896e-4698-9b44-b3f91adfa035
2025-02-14 22:32:06,739 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a197eddc-896e-4698-9b44-b3f91adfa035
127.0.0.1 - - [14/Feb/2025 22:32:06] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:07,045 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 03ff33cd-d5a5-4ca9-a93b-44c0434e1284
2025-02-14 22:32:07,045 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 03ff33cd-d5a5-4ca9-a93b-44c0434e1284
127.0.0.1 - - [14/Feb/2025 22:32:07] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:07,508 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b6011c00-4cd2-4111-a00f-b8a7f43d50f0
2025-02-14 22:32:07,519 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b6011c00-4cd2-4111-a00f-b8a7f43d50f0
127.0.0.1 - - [14/Feb/2025 22:32:07] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:07,734 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3f0a6801-07ac-45fd-b341-2c8ae3c5b629
2025-02-14 22:32:07,736 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3f0a6801-07ac-45fd-b341-2c8ae3c5b629
127.0.0.1 - - [14/Feb/2025 22:32:07] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:07,762 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 41828932-15e0-46bc-b546-6fb3faacf3b8
2025-02-14 22:32:07,765 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 41828932-15e0-46bc-b546-6fb3faacf3b8
127.0.0.1 - - [14/Feb/2025 22:32:07] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:08,251 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 503e066c-c3ac-4852-85f3-ea5d460620c2
2025-02-14 22:32:08,251 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 503e066c-c3ac-4852-85f3-ea5d460620c2
127.0.0.1 - - [14/Feb/2025 22:32:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:08,851 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 14024e5a-7774-4231-b065-6297c9be6508
2025-02-14 22:32:08,853 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 14024e5a-7774-4231-b065-6297c9be6508
127.0.0.1 - - [14/Feb/2025 22:32:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:08,915 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a891b525-f471-49d7-801a-9a1dadbe7726
2025-02-14 22:32:08,917 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a891b525-f471-49d7-801a-9a1dadbe7726
127.0.0.1 - - [14/Feb/2025 22:32:08] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:09,314 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ea3faca5-fb3f-4699-9a61-a697c43d201a
2025-02-14 22:32:09,318 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ea3faca5-fb3f-4699-9a61-a697c43d201a
127.0.0.1 - - [14/Feb/2025 22:32:09] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:10,252 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 35f79095-08b9-451d-bfc3-11c50640fdcf
2025-02-14 22:32:10,260 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 35f79095-08b9-451d-bfc3-11c50640fdcf
127.0.0.1 - - [14/Feb/2025 22:32:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:10,443 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 448dc4c9-a008-4dd4-85ee-dec7a1ab330f
2025-02-14 22:32:10,446 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 448dc4c9-a008-4dd4-85ee-dec7a1ab330f
127.0.0.1 - - [14/Feb/2025 22:32:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:10,456 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 14f38663-06d3-4ee2-a793-86e52477f3d3
2025-02-14 22:32:10,460 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 14f38663-06d3-4ee2-a793-86e52477f3d3
127.0.0.1 - - [14/Feb/2025 22:32:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:10,738 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 15b0bd02-7ac7-4557-b0d8-a39a9ce8afa4
2025-02-14 22:32:10,741 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 15b0bd02-7ac7-4557-b0d8-a39a9ce8afa4
127.0.0.1 - - [14/Feb/2025 22:32:10] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:11,251 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 292d730d-0c69-4eda-a937-bdb37e7d0b91
2025-02-14 22:32:11,252 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 292d730d-0c69-4eda-a937-bdb37e7d0b91
127.0.0.1 - - [14/Feb/2025 22:32:11] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:11,358 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 094d3180-f0a9-4537-8a91-21c24e484412
2025-02-14 22:32:11,370 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 094d3180-f0a9-4537-8a91-21c24e484412
127.0.0.1 - - [14/Feb/2025 22:32:11] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:11,731 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cf958b13-e8b4-45c8-a8f4-62e2bad6743b
2025-02-14 22:32:11,736 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cf958b13-e8b4-45c8-a8f4-62e2bad6743b
127.0.0.1 - - [14/Feb/2025 22:32:11] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:11,753 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 78b8ed04-7f1b-41ab-b6d9-dc24cb2d7d4c
2025-02-14 22:32:11,753 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 78b8ed04-7f1b-41ab-b6d9-dc24cb2d7d4c
127.0.0.1 - - [14/Feb/2025 22:32:11] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:12,564 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1350581f-2415-461d-b31b-7c7413f63028
2025-02-14 22:32:12,568 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1350581f-2415-461d-b31b-7c7413f63028
127.0.0.1 - - [14/Feb/2025 22:32:12] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:12,724 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1e77e3e1-1da6-4889-bc30-e193dcb03629
2025-02-14 22:32:12,725 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1e77e3e1-1da6-4889-bc30-e193dcb03629
127.0.0.1 - - [14/Feb/2025 22:32:12] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:13,065 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 74f46f86-152d-44b0-a6ab-e94ae1ffc049
2025-02-14 22:32:13,072 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 74f46f86-152d-44b0-a6ab-e94ae1ffc049
127.0.0.1 - - [14/Feb/2025 22:32:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:13,099 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fd7813d0-477b-4889-9848-2cafb61f98dc
2025-02-14 22:32:13,105 - LoudVA - INFO - [LoudServer] - Completed. Request ID: fd7813d0-477b-4889-9848-2cafb61f98dc
127.0.0.1 - - [14/Feb/2025 22:32:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:13,415 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e628c8c8-8489-4527-a3e2-bf660edaa486
2025-02-14 22:32:13,420 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e628c8c8-8489-4527-a3e2-bf660edaa486
127.0.0.1 - - [14/Feb/2025 22:32:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:13,833 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5c6cb1ca-adbf-4d61-9cde-51463910e021
2025-02-14 22:32:13,834 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 67e9cb35-bfc3-4448-a60e-d6a1eec67437
2025-02-14 22:32:13,835 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5c6cb1ca-adbf-4d61-9cde-51463910e021
127.0.0.1 - - [14/Feb/2025 22:32:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:13,843 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 67e9cb35-bfc3-4448-a60e-d6a1eec67437
127.0.0.1 - - [14/Feb/2025 22:32:13] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:14,209 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b1f90bb9-31c9-4fe4-ae97-730d5726f8f9
2025-02-14 22:32:14,217 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b1f90bb9-31c9-4fe4-ae97-730d5726f8f9
127.0.0.1 - - [14/Feb/2025 22:32:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:14,536 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 66326e87-a1e4-4be3-97ce-74a54a67274a
2025-02-14 22:32:14,536 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 66326e87-a1e4-4be3-97ce-74a54a67274a
127.0.0.1 - - [14/Feb/2025 22:32:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:14,835 - LoudVA - WARNING - [LoudServer] - Timeout reached for request da280d6a-6140-402f-a81a-b119219de834
2025-02-14 22:32:14,835 - LoudVA - INFO - [LoudServer] - Completed. Request ID: da280d6a-6140-402f-a81a-b119219de834
127.0.0.1 - - [14/Feb/2025 22:32:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:14,919 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c7cbada3-e564-4d09-8be5-5cc652608114
2025-02-14 22:32:14,921 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c7cbada3-e564-4d09-8be5-5cc652608114
127.0.0.1 - - [14/Feb/2025 22:32:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:14,940 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 35368f4d-736c-4fcf-8a1b-3429c1717adb
2025-02-14 22:32:14,943 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 35368f4d-736c-4fcf-8a1b-3429c1717adb
127.0.0.1 - - [14/Feb/2025 22:32:14] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:15,001 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6e4dad50-f5cd-4691-9bdf-1234c8138b93
2025-02-14 22:32:15,004 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6e4dad50-f5cd-4691-9bdf-1234c8138b93
127.0.0.1 - - [14/Feb/2025 22:32:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:15,311 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4bac04fc-bd8f-42eb-a4b5-c76f17dbefdf
2025-02-14 22:32:15,313 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4bac04fc-bd8f-42eb-a4b5-c76f17dbefdf
127.0.0.1 - - [14/Feb/2025 22:32:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:15,837 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0559a576-8daf-4f62-86c1-303fc32a802d
2025-02-14 22:32:15,839 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 0559a576-8daf-4f62-86c1-303fc32a802d
127.0.0.1 - - [14/Feb/2025 22:32:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:15,928 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 68208f61-5762-43bc-83d8-4b0df90f55d9
2025-02-14 22:32:15,933 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 68208f61-5762-43bc-83d8-4b0df90f55d9
127.0.0.1 - - [14/Feb/2025 22:32:15] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:16,044 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3f5743ce-11d9-4e9d-8f95-aeb48a7ec262
2025-02-14 22:32:16,045 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3f5743ce-11d9-4e9d-8f95-aeb48a7ec262
127.0.0.1 - - [14/Feb/2025 22:32:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:16,213 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bd0f5e9d-a1f0-4656-a047-d01884c232f2
2025-02-14 22:32:16,219 - LoudVA - INFO - [LoudServer] - Completed. Request ID: bd0f5e9d-a1f0-4656-a047-d01884c232f2
127.0.0.1 - - [14/Feb/2025 22:32:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:16,533 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6b3d01c8-ac62-40e4-9632-e9e875631581
2025-02-14 22:32:16,535 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6b3d01c8-ac62-40e4-9632-e9e875631581
127.0.0.1 - - [14/Feb/2025 22:32:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:16,761 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 043115a2-9528-4e3b-9597-25bf71b889be
2025-02-14 22:32:16,761 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 043115a2-9528-4e3b-9597-25bf71b889be
127.0.0.1 - - [14/Feb/2025 22:32:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:16,822 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e5c880e9-31e1-4393-bafd-6cde29e605da
2025-02-14 22:32:16,822 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e5c880e9-31e1-4393-bafd-6cde29e605da
127.0.0.1 - - [14/Feb/2025 22:32:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:16,915 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ecc46a80-e7cc-4d36-96f4-ab7ce5fb5784
2025-02-14 22:32:16,917 - LoudVA - INFO - [LoudServer] - Completed. Request ID: ecc46a80-e7cc-4d36-96f4-ab7ce5fb5784
127.0.0.1 - - [14/Feb/2025 22:32:16] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:17,300 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 53efbbf8-a1f8-4a1a-b736-e9c466267887
2025-02-14 22:32:17,304 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 53efbbf8-a1f8-4a1a-b736-e9c466267887
127.0.0.1 - - [14/Feb/2025 22:32:17] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:17,396 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a4b0276f-833c-4735-99a5-30ccd6b89676
2025-02-14 22:32:17,406 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a4b0276f-833c-4735-99a5-30ccd6b89676
127.0.0.1 - - [14/Feb/2025 22:32:17] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:17,812 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c9ca0cbf-b26c-4b61-93e7-7e56648b7357
2025-02-14 22:32:17,816 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c9ca0cbf-b26c-4b61-93e7-7e56648b7357
127.0.0.1 - - [14/Feb/2025 22:32:17] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:17,835 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c438a9a6-8245-4f58-8c39-192a18094798
2025-02-14 22:32:17,837 - LoudVA - INFO - [LoudServer] - Completed. Request ID: c438a9a6-8245-4f58-8c39-192a18094798
127.0.0.1 - - [14/Feb/2025 22:32:17] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:18,032 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9dff3f47-70a9-43dc-abd0-e42cd7b417e3
2025-02-14 22:32:18,034 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9dff3f47-70a9-43dc-abd0-e42cd7b417e3
127.0.0.1 - - [14/Feb/2025 22:32:18] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:18,035 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2f89c92d-759e-4680-bde1-b3664216fa04
2025-02-14 22:32:18,049 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 2f89c92d-759e-4680-bde1-b3664216fa04
127.0.0.1 - - [14/Feb/2025 22:32:18] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:18,411 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 09d60462-273b-459e-be77-5b04fb5d0a82
2025-02-14 22:32:18,411 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 09d60462-273b-459e-be77-5b04fb5d0a82
127.0.0.1 - - [14/Feb/2025 22:32:18] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:18,820 - LoudVA - WARNING - [LoudServer] - Timeout reached for request de010a44-090e-4366-9981-d79bf63d54a3
2025-02-14 22:32:18,821 - LoudVA - INFO - [LoudServer] - Completed. Request ID: de010a44-090e-4366-9981-d79bf63d54a3
127.0.0.1 - - [14/Feb/2025 22:32:18] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:19,389 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 66eb812f-7b77-4649-ad03-5980cdfe186e
2025-02-14 22:32:19,401 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 66eb812f-7b77-4649-ad03-5980cdfe186e
127.0.0.1 - - [14/Feb/2025 22:32:19] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:19,592 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b9a6ec42-b635-4277-9ac5-ec7f5b29a328
2025-02-14 22:32:19,595 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b9a6ec42-b635-4277-9ac5-ec7f5b29a328
127.0.0.1 - - [14/Feb/2025 22:32:19] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:19,883 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4fddb8d4-9d3b-4ca8-9586-aef1c088cbd4
2025-02-14 22:32:19,892 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 4fddb8d4-9d3b-4ca8-9586-aef1c088cbd4
127.0.0.1 - - [14/Feb/2025 22:32:19] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:20,030 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 85d21cf8-ce30-4941-bf96-758e708d42f0
2025-02-14 22:32:20,032 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 85d21cf8-ce30-4941-bf96-758e708d42f0
127.0.0.1 - - [14/Feb/2025 22:32:20] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:20,094 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b6d8e156-8eaf-4f71-926b-2027c1f4ddf5
2025-02-14 22:32:20,097 - LoudVA - INFO - [LoudServer] - Completed. Request ID: b6d8e156-8eaf-4f71-926b-2027c1f4ddf5
127.0.0.1 - - [14/Feb/2025 22:32:20] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:21,025 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3edd372c-d37a-4dec-be18-60bb812d9f28
2025-02-14 22:32:21,027 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cd4d0682-09e8-4c81-af50-88722b27ac09
2025-02-14 22:32:21,039 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cd4d0682-09e8-4c81-af50-88722b27ac09
127.0.0.1 - - [14/Feb/2025 22:32:21] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:21,052 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 3edd372c-d37a-4dec-be18-60bb812d9f28
127.0.0.1 - - [14/Feb/2025 22:32:21] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:21,061 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 56a75471-9638-4d19-8b1e-3c7c69174c3b
2025-02-14 22:32:21,073 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 56a75471-9638-4d19-8b1e-3c7c69174c3b
127.0.0.1 - - [14/Feb/2025 22:32:21] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:21,254 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d93a2c92-76d3-460a-9429-8597fe5c391c
2025-02-14 22:32:21,267 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d93a2c92-76d3-460a-9429-8597fe5c391c
127.0.0.1 - - [14/Feb/2025 22:32:21] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:21,525 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 21396b01-fb0c-4592-948d-96a7becba61e
2025-02-14 22:32:21,529 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 21396b01-fb0c-4592-948d-96a7becba61e
127.0.0.1 - - [14/Feb/2025 22:32:21] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:21,547 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 149080dc-96a8-494b-90c5-df805daf0020
2025-02-14 22:32:21,558 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 149080dc-96a8-494b-90c5-df805daf0020
127.0.0.1 - - [14/Feb/2025 22:32:21] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:22,348 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9207b7ab-91aa-4a64-a3b4-2ad11977b4c7
2025-02-14 22:32:22,356 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 9207b7ab-91aa-4a64-a3b4-2ad11977b4c7
127.0.0.1 - - [14/Feb/2025 22:32:22] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:22,456 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 43d622e3-0e03-4637-85cc-043efa3c494c
2025-02-14 22:32:22,467 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 43d622e3-0e03-4637-85cc-043efa3c494c
127.0.0.1 - - [14/Feb/2025 22:32:22] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:22,607 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d5ba3633-055f-4811-b6dc-98744d1e3be4
2025-02-14 22:32:22,611 - LoudVA - INFO - [LoudServer] - Completed. Request ID: d5ba3633-055f-4811-b6dc-98744d1e3be4
127.0.0.1 - - [14/Feb/2025 22:32:22] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:23,353 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1bc1cede-8ded-4b16-8a73-025cea629ec3
2025-02-14 22:32:23,356 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 1bc1cede-8ded-4b16-8a73-025cea629ec3
127.0.0.1 - - [14/Feb/2025 22:32:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:23,532 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5eb8c875-feda-4746-9377-3509baefc2e4
2025-02-14 22:32:23,538 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 5eb8c875-feda-4746-9377-3509baefc2e4
127.0.0.1 - - [14/Feb/2025 22:32:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:23,618 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 81412978-7971-4b82-be43-e0b56f05f4aa
2025-02-14 22:32:23,619 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 81412978-7971-4b82-be43-e0b56f05f4aa
127.0.0.1 - - [14/Feb/2025 22:32:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:23,728 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 845fb217-c023-4f67-ab22-77e09b24b36e
2025-02-14 22:32:23,729 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 845fb217-c023-4f67-ab22-77e09b24b36e
127.0.0.1 - - [14/Feb/2025 22:32:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:23,994 - LoudVA - WARNING - [LoudServer] - Timeout reached for request dd7ac986-4736-4c98-a40d-06cfd6f5c955
2025-02-14 22:32:23,995 - LoudVA - INFO - [LoudServer] - Completed. Request ID: dd7ac986-4736-4c98-a40d-06cfd6f5c955
127.0.0.1 - - [14/Feb/2025 22:32:23] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:25,198 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e80cc29a-f980-46ca-9b80-f897108c9bfe
2025-02-14 22:32:25,203 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e80cc29a-f980-46ca-9b80-f897108c9bfe
127.0.0.1 - - [14/Feb/2025 22:32:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:25,310 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 67fb590a-9513-4b34-98fa-0d6050b546d3
2025-02-14 22:32:25,311 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 67fb590a-9513-4b34-98fa-0d6050b546d3
127.0.0.1 - - [14/Feb/2025 22:32:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:25,540 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 24407df4-860b-4526-bb91-b1279035f73e
2025-02-14 22:32:25,542 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 24407df4-860b-4526-bb91-b1279035f73e
127.0.0.1 - - [14/Feb/2025 22:32:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:25,628 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cb586caf-5276-4450-ba1a-442f247f6a05
2025-02-14 22:32:25,630 - LoudVA - INFO - [LoudServer] - Completed. Request ID: cb586caf-5276-4450-ba1a-442f247f6a05
127.0.0.1 - - [14/Feb/2025 22:32:25] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:26,113 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6db1bb6a-9ae6-4070-b582-f2422e8264e1
2025-02-14 22:32:26,114 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 6db1bb6a-9ae6-4070-b582-f2422e8264e1
127.0.0.1 - - [14/Feb/2025 22:32:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:26,431 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 56b12c9e-d26d-40a6-956c-47407002bb63
2025-02-14 22:32:26,432 - LoudVA - INFO - [LoudServer] - Completed. Request ID: 56b12c9e-d26d-40a6-956c-47407002bb63
127.0.0.1 - - [14/Feb/2025 22:32:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:26,477 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a1a49f4a-c566-44bf-8848-1c0ea96b3273
2025-02-14 22:32:26,477 - LoudVA - INFO - [LoudServer] - Completed. Request ID: a1a49f4a-c566-44bf-8848-1c0ea96b3273
127.0.0.1 - - [14/Feb/2025 22:32:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:26,881 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e874df33-a028-49a8-9517-a9d194a26ce0
2025-02-14 22:32:26,882 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e874df33-a028-49a8-9517-a9d194a26ce0
127.0.0.1 - - [14/Feb/2025 22:32:26] "POST /inference HTTP/1.1" 200 -
2025-02-14 22:32:26,903 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e28dce50-2113-44ac-b138-f3c7d92f6ee7
2025-02-14 22:32:26,904 - LoudVA - INFO - [LoudServer] - Completed. Request ID: e28dce50-2113-44ac-b138-f3c7d92f6ee7
127.0.0.1 - - [14/Feb/2025 22:32:26] "POST /inference HTTP/1.1" 200 -
