2025-02-08 05:07:28,980 - LoudVA - INFO - [LoudController] - Starting LoudController...
2025-02-08 05:07:28,980 - LoudVA - INFO - [LoudController] - Press CTRL+C to stop the controller.
2025-02-08 05:07:28,980 - LoudVA - INFO - [LoudController] - Debug mode: False
2025-02-08 05:07:29,008 - LoudVA - INFO - [LoudController] - Selected scheduler: fixed_batch
2025-02-08 05:07:29,016 - LoudVA - INFO - [LoudServer] - Starting LoudVA server...
 * Serving Flask app 'LoudServer'
 * Debug mode: off
WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:5000
Press CTRL+C to quit
2025-02-08 05:07:30,287 - LoudVA - INFO - [DeviceData] - Using profiling data for decision making.
2025-02-08 05:07:30,287 - LoudVA - INFO - [DeviceData] - Filling missing profile data with predictions.
2025-02-08 05:07:30,296 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/Profiling.csv
2025-02-08 05:07:30,296 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/xavier-nx-00/measurements/xavier-nx-00_filtered_freqs.csv
2025-02-08 05:07:30,296 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/LoudJetson0/measurements/LoudJetson0_filtered_freqs.csv
2025-02-08 05:07:30,296 - LoudVA - INFO - [DeviceData] - Loaded GPU specs from /home/louduser/LoudVA/LoudController/../data/devices/gpu_specs.csv
2025-02-08 05:07:30,326 - LoudVA - INFO - [DeviceData] - Initial frequency on agx-xavier-00: 114750000
2025-02-08 05:07:30,326 - LoudVA - INFO - [DeviceData] - agx-xavier-00 : Filling missing profile data...
2025-02-08 05:07:30,326 - LoudVA - INFO - [DeviceData] - agx-xavier-00 : Missing profile data filled with predictions.
2025-02-08 05:07:30,326 - LoudVA - INFO - [DeviceData] - Devices initialized successfully
2025-02-08 05:07:30,326 - LoudVA - INFO - [LoudController] - Using fixed batch size 8
127.0.0.1 - - [08/Feb/2025 05:08:31] "GET / HTTP/1.1" 200 -
2025-02-08 05:09:24,836 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:09:25,283 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:09:25,782 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:09:26,280 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:09:26,792 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:09:27,278 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:09:27,808 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:09:28,282 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:09:28,553 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 65b3a217-d820-4a8b-b39d-bedfc40f1437
127.0.0.1 - - [08/Feb/2025 05:09:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:28,555 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f96e131e-f920-4ff6-ad64-550cabbdca7a
127.0.0.1 - - [08/Feb/2025 05:09:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:28,560 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 612f417b-b99e-4eca-8b0d-0f0debefd7e0
127.0.0.1 - - [08/Feb/2025 05:09:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:28,562 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1fda4712-3e04-4403-908c-88be318b778a
127.0.0.1 - - [08/Feb/2025 05:09:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:28,564 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ce9ebf74-8668-493d-b4d6-71f447257e14
127.0.0.1 - - [08/Feb/2025 05:09:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:28,567 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ad296e60-242a-4f11-97a1-265e2df05826
127.0.0.1 - - [08/Feb/2025 05:09:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:28,801 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:09:29,280 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:09:29,780 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:09:30,275 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:09:30,786 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:09:31,279 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:09:31,398 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 159ec3ea-8e8d-413c-ae96-b477fe41ab56
2025-02-08 05:09:31,400 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d18e9a35-7478-4e2d-af60-fa66d792f497
127.0.0.1 - - [08/Feb/2025 05:09:31] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:09:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:31,407 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f6e6bad0-133e-4875-b275-fbb444d8490a
127.0.0.1 - - [08/Feb/2025 05:09:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:31,408 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2219fccc-267f-4c2b-a8c6-f3b4a4a0b6b0
127.0.0.1 - - [08/Feb/2025 05:09:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:31,780 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:09:32,285 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:09:32,786 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:09:33,284 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:09:33,365 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7d087bde-b79b-4c4e-b024-efc931965114
127.0.0.1 - - [08/Feb/2025 05:09:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:33,367 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 15b9764f-69bb-4b10-9abe-8a16fbb0a680
127.0.0.1 - - [08/Feb/2025 05:09:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:33,370 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: baa52202-30aa-4a54-8fb2-cf3df4627460
127.0.0.1 - - [08/Feb/2025 05:09:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:33,372 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8c265046-9a76-44ec-a91a-d66d27949f76
127.0.0.1 - - [08/Feb/2025 05:09:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:33,374 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a659d392-dbea-4db1-b86f-de834c5514e7
127.0.0.1 - - [08/Feb/2025 05:09:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:33,378 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6ad6d540-bc88-4951-a281-d28bf6d012c8
127.0.0.1 - - [08/Feb/2025 05:09:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:33,780 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:09:34,290 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:09:34,779 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:09:35,291 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:09:35,783 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:09:35,937 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 512f95e6-8e8d-416f-a986-68622d2022fb
127.0.0.1 - - [08/Feb/2025 05:09:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:35,939 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 08aa899e-1899-404e-8a16-29423870eff1
127.0.0.1 - - [08/Feb/2025 05:09:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:35,943 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 78ec79c5-4590-4fee-a369-6a937fcd1d0e
127.0.0.1 - - [08/Feb/2025 05:09:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:35,946 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f292b3fd-e1fe-4be2-bac0-5dc96a24cd18
127.0.0.1 - - [08/Feb/2025 05:09:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:36,289 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:09:36,779 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:09:37,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:09:37,382 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 56e9606c-3fcf-40c0-a9fa-92d839ba1a83
127.0.0.1 - - [08/Feb/2025 05:09:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:37,386 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5377030d-48fd-4149-9ca4-cef15649640e
127.0.0.1 - - [08/Feb/2025 05:09:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:37,388 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3356afdf-b5a5-4314-b2c1-df4dac0ede77
127.0.0.1 - - [08/Feb/2025 05:09:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:37,775 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:09:38,274 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:09:38,774 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:09:39,273 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:09:39,780 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:09:40,283 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:09:40,780 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:09:40,817 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: dbd5c8f8-8edc-42d1-ab46-e83a0dfa404d
127.0.0.1 - - [08/Feb/2025 05:09:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:40,821 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f16e315f-b5c4-48f0-9ab9-ea57f0484f7f
127.0.0.1 - - [08/Feb/2025 05:09:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:40,824 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f476ade0-fdca-42bc-9db4-f5b5b067a157
127.0.0.1 - - [08/Feb/2025 05:09:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:40,825 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ebe198a4-9358-45c3-bb6a-6b643a11c5e3
127.0.0.1 - - [08/Feb/2025 05:09:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:40,828 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1f07367c-eb7e-4d87-b093-fd593e3e8b9a
127.0.0.1 - - [08/Feb/2025 05:09:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:40,832 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 860b2039-f57f-4ae1-a0b7-6d19288d1599
127.0.0.1 - - [08/Feb/2025 05:09:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:40,837 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ef0a26f1-b1e2-486a-9f58-25f4940b307e
127.0.0.1 - - [08/Feb/2025 05:09:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:40,839 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b646512c-77fd-4301-83d3-99a628ec8442
127.0.0.1 - - [08/Feb/2025 05:09:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:41,287 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:09:41,780 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:09:42,283 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:09:42,776 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:09:43,276 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:09:43,331 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 02a3c3a7-9c50-4869-b411-7d2e066095ce
127.0.0.1 - - [08/Feb/2025 05:09:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:43,332 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 21a461fa-979e-4d08-a782-8b1e0ab7afaa
127.0.0.1 - - [08/Feb/2025 05:09:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:43,334 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ba5e22f0-7e50-43b6-88f8-c6b13a383f03
127.0.0.1 - - [08/Feb/2025 05:09:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:43,337 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d35019be-254a-4a64-be3d-11911b63081a
127.0.0.1 - - [08/Feb/2025 05:09:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:43,592 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:09:43,778 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:09:44,022 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:09:44,275 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:09:44,529 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:09:44,620 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1eaf89ad-a38f-4cc7-bfcc-c753b914324f
127.0.0.1 - - [08/Feb/2025 05:09:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:44,626 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c65d1f02-8cfb-4b2a-8bcd-8dafddf66e2e
127.0.0.1 - - [08/Feb/2025 05:09:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:44,628 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d804602b-440f-4f80-af0d-d56347116c42
127.0.0.1 - - [08/Feb/2025 05:09:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:44,628 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0e3e3fac-65bf-4ed3-8990-2d6152d94387
127.0.0.1 - - [08/Feb/2025 05:09:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:44,778 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:09:45,044 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:09:45,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:09:45,544 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:09:45,785 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:09:45,999 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e987ce10-622f-4816-b3ad-725dfade6522
127.0.0.1 - - [08/Feb/2025 05:09:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:46,002 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4d74c54f-214d-4253-b57e-145da82dabb7
127.0.0.1 - - [08/Feb/2025 05:09:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:46,005 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 21088382-21a7-46a0-bfc1-36c7cd168577
127.0.0.1 - - [08/Feb/2025 05:09:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:46,010 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 433ddffc-a0a8-4d65-9502-c0d277244ab5
127.0.0.1 - - [08/Feb/2025 05:09:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:46,015 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:09:46,280 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:09:46,554 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:09:46,775 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:09:46,884 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e4db7ba1-ddc9-4be7-94ed-d98a5020a861
127.0.0.1 - - [08/Feb/2025 05:09:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:46,889 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 18d611af-123e-4ffe-9fb6-6cc4b93304eb
127.0.0.1 - - [08/Feb/2025 05:09:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:46,893 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8eb6ddce-553e-46ea-9657-f75b371bd634
127.0.0.1 - - [08/Feb/2025 05:09:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:47,018 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:09:47,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:09:47,479 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 07701285-6a99-45b7-8e7e-470c87da0c47
127.0.0.1 - - [08/Feb/2025 05:09:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:47,482 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 383a1506-258c-4668-b80f-8f20e499156e
127.0.0.1 - - [08/Feb/2025 05:09:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:47,555 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:09:47,781 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:09:48,040 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:09:48,184 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 088c2e57-a48b-4b90-a511-4965c8b12920
127.0.0.1 - - [08/Feb/2025 05:09:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:48,190 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ea6a045c-c45f-4ab6-8c0a-4b367c274daa
2025-02-08 05:09:48,191 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0bb5bf1c-4833-4f24-aec2-f3ef9f1b1709
127.0.0.1 - - [08/Feb/2025 05:09:48] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:09:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:48,288 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:09:48,520 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:09:48,774 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:09:48,937 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7419b3e8-c2b3-4cb2-8cb1-aca73395c725
127.0.0.1 - - [08/Feb/2025 05:09:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:48,939 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c09d5627-e34a-454b-87f8-5a8781069581
127.0.0.1 - - [08/Feb/2025 05:09:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:48,941 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6c357c8f-0199-4f4a-a163-1c6eaba20421
127.0.0.1 - - [08/Feb/2025 05:09:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:49,026 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:09:49,278 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:09:49,524 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:09:49,785 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:09:50,022 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:09:50,292 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:09:50,299 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5edcf9f9-7d01-4fda-832b-00d2ae64e37f
127.0.0.1 - - [08/Feb/2025 05:09:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:50,302 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 31b26c00-7994-4b75-a969-b206f8af74d6
127.0.0.1 - - [08/Feb/2025 05:09:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:50,312 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9758dae9-95e8-49d1-af45-e4bd4deac426
127.0.0.1 - - [08/Feb/2025 05:09:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:50,316 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 407ace28-c0f4-4dac-b9a0-0d849b8a2996
127.0.0.1 - - [08/Feb/2025 05:09:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:50,518 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:09:50,776 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:09:50,923 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ee842495-dd5f-4822-82b7-3a545c075ae2
127.0.0.1 - - [08/Feb/2025 05:09:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:50,926 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 53ecc59e-b84e-426f-83cd-841ab5cb492c
127.0.0.1 - - [08/Feb/2025 05:09:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:50,931 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b59426c1-8a90-40ba-9a89-452c902a8abb
127.0.0.1 - - [08/Feb/2025 05:09:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:51,015 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:09:51,283 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:09:51,447 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9653482f-81c2-4c08-bd08-6340d77ad140
127.0.0.1 - - [08/Feb/2025 05:09:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:51,451 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4ea312c4-f345-4409-88a0-9a2b6f7487d3
127.0.0.1 - - [08/Feb/2025 05:09:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:51,453 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c5e58f0b-94c3-4b53-b02b-c703ce7ab7c2
127.0.0.1 - - [08/Feb/2025 05:09:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:51,536 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:09:51,786 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:09:52,044 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:09:52,277 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:09:52,542 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:09:52,783 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:09:52,953 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fe372df6-63a9-45b4-b7e3-debe6f8d33db
127.0.0.1 - - [08/Feb/2025 05:09:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:52,956 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3712936a-d62b-42d6-9314-87854e012346
127.0.0.1 - - [08/Feb/2025 05:09:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:52,959 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0a7c54f5-ef72-4301-8f2e-e3fd22af1411
127.0.0.1 - - [08/Feb/2025 05:09:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:52,962 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 20fdef75-1d10-4882-a1a1-c4bab23ebd35
127.0.0.1 - - [08/Feb/2025 05:09:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:52,963 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a5c57279-6ee2-4878-9e39-3b0894d62929
127.0.0.1 - - [08/Feb/2025 05:09:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:52,969 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9cf4bc7f-f885-49b1-b159-11ac8acf1a0f
127.0.0.1 - - [08/Feb/2025 05:09:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:53,033 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:09:53,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:09:53,516 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:09:53,783 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:09:54,015 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:09:54,211 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0f03aabc-327e-4c96-85ef-840e83be676f
127.0.0.1 - - [08/Feb/2025 05:09:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:54,219 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 59524997-427f-4798-85ff-a90d7847d974
127.0.0.1 - - [08/Feb/2025 05:09:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:54,275 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:09:54,530 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:09:54,780 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:09:55,040 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:09:55,105 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 11adb907-eb1a-40ef-aadf-fc230173638c
127.0.0.1 - - [08/Feb/2025 05:09:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:55,117 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2418d3e9-5398-4d68-a69b-7b3c41f1259b
127.0.0.1 - - [08/Feb/2025 05:09:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:55,283 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:09:55,521 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:09:55,800 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:09:56,073 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:09:56,176 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a4df75f9-6637-4c6d-a624-333489b758ef
127.0.0.1 - - [08/Feb/2025 05:09:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:56,181 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cd04564d-b283-48bf-8414-25e39515c33f
127.0.0.1 - - [08/Feb/2025 05:09:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:56,280 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:09:56,289 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f272ac3c-4cc6-4411-a74c-6976d6d00a37
127.0.0.1 - - [08/Feb/2025 05:09:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:56,296 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c8aace31-6474-4fd1-9438-a4f7c77c4e36
127.0.0.1 - - [08/Feb/2025 05:09:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:56,304 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 232a05f2-81b9-49be-8ce4-397265f28453
127.0.0.1 - - [08/Feb/2025 05:09:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:56,544 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:09:56,779 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:09:57,026 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:09:57,292 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:09:57,525 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:09:57,644 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b39c83e5-31e0-4012-a01d-968262ae5910
127.0.0.1 - - [08/Feb/2025 05:09:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:57,646 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 247edf31-75c0-4f9b-ae73-f48a3eda6ac3
127.0.0.1 - - [08/Feb/2025 05:09:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:57,651 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 50bef920-89c5-4a79-8c54-aac7dd70eca6
127.0.0.1 - - [08/Feb/2025 05:09:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:57,781 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:09:57,894 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bebf8396-a5e1-454b-9683-b10d8f898bf6
127.0.0.1 - - [08/Feb/2025 05:09:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:57,903 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0e23436e-a576-4ae1-be7c-2419b8960a20
127.0.0.1 - - [08/Feb/2025 05:09:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:58,020 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:09:58,285 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:09:58,528 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:09:58,755 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ef267b16-3e98-481b-b1eb-6d54f37d4652
127.0.0.1 - - [08/Feb/2025 05:09:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:58,764 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3da85fe8-8e3c-4f52-b4c2-50e7b107014a
127.0.0.1 - - [08/Feb/2025 05:09:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:58,793 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:09:59,041 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:09:59,301 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:09:59,315 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 86f5e8db-d539-4e11-a68c-c22c65ba9555
127.0.0.1 - - [08/Feb/2025 05:09:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:59,319 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 53802228-0902-42a9-b23b-9ea713139006
127.0.0.1 - - [08/Feb/2025 05:09:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:59,321 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 66bfc3a8-993e-4476-8aba-b537a4776e8e
127.0.0.1 - - [08/Feb/2025 05:09:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:59,549 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:09:59,615 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cb9c88f0-1b78-4869-b991-cb3996edd307
127.0.0.1 - - [08/Feb/2025 05:09:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:59,620 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3126a95a-8169-4b6e-a2ff-b2de6c5a52d9
127.0.0.1 - - [08/Feb/2025 05:09:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:59,624 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e42e745f-79cf-4147-859c-f886a8bbf162
127.0.0.1 - - [08/Feb/2025 05:09:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:59,631 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ef8d7a45-2008-4e64-ae2a-eedb48f539b6
127.0.0.1 - - [08/Feb/2025 05:09:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:09:59,784 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:00,037 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:00,278 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:00,525 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:00,784 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:00,951 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1bb8466a-b31b-4128-843c-bd84a4254996
127.0.0.1 - - [08/Feb/2025 05:10:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:01,034 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:01,282 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:01,285 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 995ddcdc-20eb-4171-9bdd-b6bb12de8676
127.0.0.1 - - [08/Feb/2025 05:10:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:01,289 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a382c90d-e6cf-4aa2-bfba-d3bd1240242f
127.0.0.1 - - [08/Feb/2025 05:10:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:01,292 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e3f6c23c-d8e0-462c-b40b-ba2b829a1a18
2025-02-08 05:10:01,294 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bdf983ee-303e-4b55-9b4e-9a84cf7eed1a
127.0.0.1 - - [08/Feb/2025 05:10:01] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:10:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:01,313 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9652b59a-38bd-4b01-85b8-22800661f0ab
127.0.0.1 - - [08/Feb/2025 05:10:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:01,319 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: edf82285-e0ac-4ee5-abd9-feb79fde445b
127.0.0.1 - - [08/Feb/2025 05:10:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:01,527 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:01,795 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:02,023 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:02,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:02,517 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:02,725 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c242c50f-74d1-4e24-9ee4-a93b97277e3f
127.0.0.1 - - [08/Feb/2025 05:10:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:02,732 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 52a20e98-4c82-41b2-8f44-7b832cf59a4f
127.0.0.1 - - [08/Feb/2025 05:10:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:02,779 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:10:03,046 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:03,292 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:03,545 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:03,647 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3e7d9030-beb4-4adb-bcbb-8182c301a5e6
127.0.0.1 - - [08/Feb/2025 05:10:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:03,670 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a535ff93-fb90-43e5-a8c4-2789f6052e6f
2025-02-08 05:10:03,673 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2a68579e-4305-40e2-b1ea-60fd49354350
127.0.0.1 - - [08/Feb/2025 05:10:03] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:10:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:03,797 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:10:04,000 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e6ff9c6a-7d38-42ab-81fe-9397e12bb93d
127.0.0.1 - - [08/Feb/2025 05:10:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:04,007 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 52887b32-c85a-4982-b299-df00bd5d1a38
127.0.0.1 - - [08/Feb/2025 05:10:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:04,015 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 399ba2de-c9fb-463e-a4ca-9adf405bea01
127.0.0.1 - - [08/Feb/2025 05:10:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:04,042 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:04,279 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:04,519 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:04,788 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:10:04,881 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7b32d161-ed04-48ba-9cf4-b7e85df94815
127.0.0.1 - - [08/Feb/2025 05:10:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:04,888 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0c60da4a-c567-421d-b06f-3eb9451eab18
127.0.0.1 - - [08/Feb/2025 05:10:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:04,981 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b7ce5fad-b67d-4f17-a2e9-d1f424550711
127.0.0.1 - - [08/Feb/2025 05:10:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:04,992 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3b9d4021-0d17-42d7-907c-a5608a4fc055
127.0.0.1 - - [08/Feb/2025 05:10:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:04,996 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eeb8c7e1-27e3-4e6c-b3fb-cf2334563636
127.0.0.1 - - [08/Feb/2025 05:10:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:05,029 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:05,278 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:05,529 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:05,782 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:06,024 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:06,124 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3050c53e-c0c5-479b-b99b-7cf7c1477fb0
127.0.0.1 - - [08/Feb/2025 05:10:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:06,131 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3ecb3eac-40d9-4d36-9e39-abe8b9fb1f4b
127.0.0.1 - - [08/Feb/2025 05:10:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:06,144 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1c0218f0-998d-4ffa-b8f8-9815f7bf1375
127.0.0.1 - - [08/Feb/2025 05:10:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:06,287 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:06,554 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:06,779 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:07,043 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:07,246 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ad4ffc75-b159-4769-87a0-3450e7a01ef0
127.0.0.1 - - [08/Feb/2025 05:10:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:07,252 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8f290109-c27b-4445-8770-041e48efd40d
127.0.0.1 - - [08/Feb/2025 05:10:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:07,262 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: adfd94bf-7a67-4c8b-aea6-8a0d9233a742
127.0.0.1 - - [08/Feb/2025 05:10:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:07,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:07,515 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:07,772 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:08,061 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:08,171 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 128ac838-e49d-4dd4-86ca-58b8b1f6d1eb
127.0.0.1 - - [08/Feb/2025 05:10:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:08,175 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: efb1c2bf-cb70-4aa8-9b97-e1f6f72bfe65
127.0.0.1 - - [08/Feb/2025 05:10:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:08,186 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b24ba772-a297-4055-868b-762d2cbe2cb8
2025-02-08 05:10:08,187 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ff788808-846a-4c7c-b84f-12c3b15566d4
127.0.0.1 - - [08/Feb/2025 05:10:08] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:10:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:08,277 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:08,514 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:08,761 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2f4dbe77-5513-4006-a69e-1a04e292994b
127.0.0.1 - - [08/Feb/2025 05:10:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:08,782 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:08,865 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6aea09d6-7648-410f-b758-b283d66b6293
127.0.0.1 - - [08/Feb/2025 05:10:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:08,871 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 362d937f-6e7f-4ab6-9ae5-89b8ce834cd2
127.0.0.1 - - [08/Feb/2025 05:10:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:08,872 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f4e40741-0acd-481b-8b43-90fff726f250
127.0.0.1 - - [08/Feb/2025 05:10:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:09,050 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:09,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:10:09,519 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:09,658 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cb42199c-dddb-48cd-9406-e2a9d5966c7a
127.0.0.1 - - [08/Feb/2025 05:10:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:09,677 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a46a4aa8-e5ee-4b25-b1c7-f65e0df2e2c4
127.0.0.1 - - [08/Feb/2025 05:10:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:09,687 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c331a54f-dca5-4901-9c01-1dc2df25ece6
127.0.0.1 - - [08/Feb/2025 05:10:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:09,797 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:10,020 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:10,095 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cc06c571-12b0-442c-b0ff-3373d2f75296
127.0.0.1 - - [08/Feb/2025 05:10:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:10,106 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 17649858-142d-4344-bb9a-1cad26062505
127.0.0.1 - - [08/Feb/2025 05:10:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:10,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:10,545 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:10,785 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:10,899 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3dc4f167-e51b-4c73-83dc-6eb8d09654f2
127.0.0.1 - - [08/Feb/2025 05:10:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:10,914 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 98ff20b5-0f01-4942-9b16-808411446c15
127.0.0.1 - - [08/Feb/2025 05:10:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:10,920 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 56e462cb-8a0e-4cf3-bd6d-db5900f67165
127.0.0.1 - - [08/Feb/2025 05:10:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:10,921 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7ce18229-2470-4ba6-90bb-74f4171619f0
127.0.0.1 - - [08/Feb/2025 05:10:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:11,015 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:11,105 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:11,282 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:11,554 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:11,615 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:11,789 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:10:11,987 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 65d6ba6d-1809-457f-80a1-61b4ee7a86c7
127.0.0.1 - - [08/Feb/2025 05:10:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:11,997 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 569d13be-ed74-4b21-b5f0-e800b9a7e4f5
127.0.0.1 - - [08/Feb/2025 05:10:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:12,002 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e1fc36b3-aa17-4be3-85b8-8123f4ca4827
127.0.0.1 - - [08/Feb/2025 05:10:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:12,011 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 50096540-9b89-45cb-8eca-2667c8ccea26
127.0.0.1 - - [08/Feb/2025 05:10:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:12,028 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:12,115 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:12,284 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:12,554 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:12,618 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:12,632 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 84b7a2fa-9fbc-43af-96f8-3dd9f51ff1ec
127.0.0.1 - - [08/Feb/2025 05:10:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:12,639 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 41465ef8-bd95-4d71-8b5e-35bb237f3a86
127.0.0.1 - - [08/Feb/2025 05:10:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:12,646 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ef2e7d56-9c15-4571-a148-2d293abca1f6
127.0.0.1 - - [08/Feb/2025 05:10:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:12,811 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:13,015 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:13,078 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b456d9f0-ec5b-4fac-a94e-9651cc8180c2
127.0.0.1 - - [08/Feb/2025 05:10:13] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:13,085 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e2187c46-90e6-4173-bf6b-580b22856a7d
127.0.0.1 - - [08/Feb/2025 05:10:13] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:13,094 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5c5bbffd-ca6f-43f1-8d9f-cf97bf6aca8e
127.0.0.1 - - [08/Feb/2025 05:10:13] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:13,118 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:13,276 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:10:13,523 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:13,616 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:13,795 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:14,035 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:14,127 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:14,279 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:14,390 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0c8e7122-c1eb-416c-9e38-1d62c16a3872
127.0.0.1 - - [08/Feb/2025 05:10:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:14,394 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4aa1efbc-0939-415f-b060-ebffab17d5bb
127.0.0.1 - - [08/Feb/2025 05:10:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:14,407 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 097fcbf9-60a9-447f-bfa6-98f7a65d8ce4
127.0.0.1 - - [08/Feb/2025 05:10:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:14,514 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:14,615 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:14,778 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:15,035 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:15,142 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:15,280 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:15,401 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 14705f23-ea15-4171-a4c1-49522f05d38a
127.0.0.1 - - [08/Feb/2025 05:10:15] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:15,404 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f97e11a7-2da0-43bb-bab2-1de14fed4267
127.0.0.1 - - [08/Feb/2025 05:10:15] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:15,419 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1af9fc7c-af9c-4cb5-b46d-35ff6977ac8a
127.0.0.1 - - [08/Feb/2025 05:10:15] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:15,533 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:15,612 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:15,787 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:16,014 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:16,114 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:16,283 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:16,542 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:16,617 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:16,724 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7115ba37-ffa6-466f-accf-89d526e97588
127.0.0.1 - - [08/Feb/2025 05:10:16] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:16,728 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fa83cfb0-f81e-455f-be8c-99238b656c9b
127.0.0.1 - - [08/Feb/2025 05:10:16] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:16,733 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8c728443-a3e6-4b16-8253-a797c4c35617
127.0.0.1 - - [08/Feb/2025 05:10:16] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:16,775 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:17,008 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d6fac68b-8d22-4485-be9a-ad1f4fa2e5e2
127.0.0.1 - - [08/Feb/2025 05:10:17] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:17,014 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3d93accf-a092-4e2d-8678-07a5cc594c1e
127.0.0.1 - - [08/Feb/2025 05:10:17] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:17,027 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5bc50371-9fb1-4fad-98ba-a2a6af2b0bdb
2025-02-08 05:10:17,029 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
127.0.0.1 - - [08/Feb/2025 05:10:17] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:17,123 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:17,287 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:17,517 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:17,614 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:17,784 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:18,029 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:18,091 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a0438cf7-ddf1-4e22-b8af-34ed2324251f
127.0.0.1 - - [08/Feb/2025 05:10:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:18,099 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1a5b9259-78b3-4748-ab2d-57ff2d539349
127.0.0.1 - - [08/Feb/2025 05:10:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:18,103 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 559e7fdd-0f79-402f-97af-f0acfa16ac00
127.0.0.1 - - [08/Feb/2025 05:10:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:18,119 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:18,121 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 46d2b48e-1a03-4414-8230-8a6ac479433c
127.0.0.1 - - [08/Feb/2025 05:10:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:18,288 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:18,518 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:18,615 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:18,784 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:19,041 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:19,113 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:19,277 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:19,435 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 30597df4-cf3a-4f26-932d-5cd21f7d27fb
127.0.0.1 - - [08/Feb/2025 05:10:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:19,453 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e04ff1fe-5e53-41b6-be94-a93a01c03c5f
127.0.0.1 - - [08/Feb/2025 05:10:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:19,468 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7a8b5544-d25d-4afc-8983-2483058fd67d
127.0.0.1 - - [08/Feb/2025 05:10:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:19,476 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 54f501ec-5f9d-4016-bf36-9fcd672807ba
127.0.0.1 - - [08/Feb/2025 05:10:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:19,533 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:19,609 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:19,806 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:20,043 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 05:10:20,177 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:20,288 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:20,549 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:20,643 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:10:20,775 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:20,937 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7dd9aafa-4bb5-4c2c-9131-5d952e610d0f
127.0.0.1 - - [08/Feb/2025 05:10:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:20,947 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 66d594cb-b7c3-4eb4-8c7f-51d66b719d4d
127.0.0.1 - - [08/Feb/2025 05:10:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:20,952 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f4db4323-6a41-452e-9f27-207cc26aa99b
127.0.0.1 - - [08/Feb/2025 05:10:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:20,953 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9526c5f4-96c1-4ac0-8c86-9e1b72c14476
127.0.0.1 - - [08/Feb/2025 05:10:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:20,956 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bb2e1512-9f53-4d1c-a54e-7d31ae885c2f
127.0.0.1 - - [08/Feb/2025 05:10:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:21,023 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:21,113 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:21,284 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:21,557 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:21,616 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:10:21,777 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:10:22,025 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:22,091 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1fc54f7c-4f42-447d-8d2d-09938f5c3a1b
127.0.0.1 - - [08/Feb/2025 05:10:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:22,098 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c856dcc7-c654-4d25-80ee-1970346e4453
127.0.0.1 - - [08/Feb/2025 05:10:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:22,104 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e116c7d2-cdec-4e3f-88bb-e78a3d77ecaa
127.0.0.1 - - [08/Feb/2025 05:10:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:22,114 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ca5a1096-e2cb-40aa-b00b-f3b08b4ab070
127.0.0.1 - - [08/Feb/2025 05:10:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:22,118 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:22,278 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:10:22,547 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:22,610 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:10:22,787 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:23,028 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:23,104 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:23,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:23,365 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f02c91c0-a612-4a84-ab9f-a0a11195d868
127.0.0.1 - - [08/Feb/2025 05:10:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:23,374 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f5250a7c-eb7d-40fe-9e9d-0b1d0acc7299
127.0.0.1 - - [08/Feb/2025 05:10:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:23,380 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ec6b936e-7ce3-4d02-9f85-d30b01898613
127.0.0.1 - - [08/Feb/2025 05:10:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:23,392 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 51808cd9-c2b2-4064-97d1-a0aebeff355c
127.0.0.1 - - [08/Feb/2025 05:10:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:23,531 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:23,625 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:23,782 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:24,011 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:24,117 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:24,238 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6804ce59-dc1a-4966-b233-49574bab458b
127.0.0.1 - - [08/Feb/2025 05:10:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:24,249 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 93f04a38-0942-4071-9f46-94f57086f42f
127.0.0.1 - - [08/Feb/2025 05:10:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:24,273 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:24,335 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e9695c47-8218-47d3-967e-93578a41401a
127.0.0.1 - - [08/Feb/2025 05:10:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:24,339 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e7c8ba95-5429-46c9-909d-fffd2ba2261e
127.0.0.1 - - [08/Feb/2025 05:10:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:24,343 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7d555257-4e07-41a5-a437-943b0a269a96
127.0.0.1 - - [08/Feb/2025 05:10:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:24,515 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:24,527 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 16dbf4a9-d8a7-48bf-8d6d-c14b1fb66f0e
127.0.0.1 - - [08/Feb/2025 05:10:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:24,530 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cc0c465a-ec98-4720-ae8c-1b75a99a3ff3
127.0.0.1 - - [08/Feb/2025 05:10:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:24,611 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:24,773 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:25,020 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:25,114 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:10:25,270 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:25,517 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:25,630 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:25,792 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:25,968 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 26f0fbcc-7d44-47a3-8ec4-0433f558bdef
127.0.0.1 - - [08/Feb/2025 05:10:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:25,980 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f4b16427-9654-4e4c-afed-5f0b2ef64030
127.0.0.1 - - [08/Feb/2025 05:10:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:25,994 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 75fe4ff9-9881-4c70-9087-bbf18ef7d8ca
127.0.0.1 - - [08/Feb/2025 05:10:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:26,024 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:26,103 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:26,275 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:26,522 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:26,620 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:10:26,797 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:26,889 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4971a70c-e98c-42b8-abee-9f6751ff98ce
127.0.0.1 - - [08/Feb/2025 05:10:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:26,895 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 622ca260-b775-49f1-acea-1dba1eb962ea
2025-02-08 05:10:26,896 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3198a98c-fba3-44f1-a9d7-e4b495d17802
127.0.0.1 - - [08/Feb/2025 05:10:26] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:10:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:26,898 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5b3d9c38-d88b-4b51-a223-f492cd178a7c
127.0.0.1 - - [08/Feb/2025 05:10:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:26,921 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9830e618-6f29-4041-a308-90ed63300f6d
127.0.0.1 - - [08/Feb/2025 05:10:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:27,011 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:27,105 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:27,275 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:27,515 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:27,616 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:27,786 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:28,051 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:28,119 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:28,292 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:28,518 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:28,606 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:28,793 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:29,030 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:29,111 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:29,280 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:29,462 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d9852edb-fcb1-4f97-95b2-628332c0368b
127.0.0.1 - - [08/Feb/2025 05:10:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:29,469 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 70feddeb-b730-45fe-b6f5-75e2e4b86def
127.0.0.1 - - [08/Feb/2025 05:10:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:29,489 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6666c927-5050-45c4-843e-cc68b6889abd
127.0.0.1 - - [08/Feb/2025 05:10:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:29,503 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 15ad916e-7f3d-40e1-b61f-26cbe3e8f0fb
127.0.0.1 - - [08/Feb/2025 05:10:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:29,538 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:29,618 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:10:29,772 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:10:29,979 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fafbaf9a-0480-4ff2-b7b8-9b57000d48ed
127.0.0.1 - - [08/Feb/2025 05:10:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:29,989 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d60f380c-39a1-479a-9a05-e4e8dc3d3a2f
127.0.0.1 - - [08/Feb/2025 05:10:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:29,996 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3aae7bc7-9e1f-4d16-a5b9-50a878a1dc2d
127.0.0.1 - - [08/Feb/2025 05:10:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:30,020 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:30,031 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 10afbae0-0983-4713-9a91-a96d55887e7d
127.0.0.1 - - [08/Feb/2025 05:10:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:30,127 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:30,273 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:10:30,467 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 180c8afb-8efa-404e-8702-c3973985cbcb
127.0.0.1 - - [08/Feb/2025 05:10:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:30,524 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:30,630 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:30,772 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:31,025 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:31,117 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:31,283 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:31,515 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:31,599 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:31,826 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:32,058 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:32,103 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:32,200 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a547b917-6062-4b3f-9061-e1ab25b94c06
127.0.0.1 - - [08/Feb/2025 05:10:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:32,205 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6e5199c7-fec2-46b0-afcc-613876b22254
127.0.0.1 - - [08/Feb/2025 05:10:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:32,242 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e25ef29d-9c1a-4bf3-adc4-31795199b997
127.0.0.1 - - [08/Feb/2025 05:10:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:32,291 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:32,524 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:32,606 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:32,776 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:33,024 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:33,112 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:33,159 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f808638a-42a3-4685-acfd-d49adf5b000a
127.0.0.1 - - [08/Feb/2025 05:10:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:33,166 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b68e406a-3fb1-405d-b480-2f636068dad7
127.0.0.1 - - [08/Feb/2025 05:10:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:33,166 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 44341d15-715a-48a6-9d9d-418f9309ab3e
127.0.0.1 - - [08/Feb/2025 05:10:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:33,167 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f2676daa-d172-4901-9d39-57485df1c7e2
127.0.0.1 - - [08/Feb/2025 05:10:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:33,182 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b7d51efe-632f-4024-8b50-828248810e19
127.0.0.1 - - [08/Feb/2025 05:10:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:33,272 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:33,521 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:33,524 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5cb163f4-6538-4804-b43f-4ecda1324d1b
127.0.0.1 - - [08/Feb/2025 05:10:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:33,530 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6cf7ef31-9fbb-47e6-82bf-847f975ed17f
127.0.0.1 - - [08/Feb/2025 05:10:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:33,532 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ce3ea226-2624-4078-aa41-467c47f0c2be
127.0.0.1 - - [08/Feb/2025 05:10:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:33,599 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:33,698 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f4283702-0166-4c1d-8c52-f7b50e627bf2
127.0.0.1 - - [08/Feb/2025 05:10:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:33,703 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c5a8aaae-52a4-49e4-9269-8f32c28a3bbf
127.0.0.1 - - [08/Feb/2025 05:10:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:33,709 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0af1fbb9-62e4-4a4a-a0b2-ca92a37490a6
127.0.0.1 - - [08/Feb/2025 05:10:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:33,773 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:34,023 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:34,107 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:34,272 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:34,523 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:34,604 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:34,782 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:10:35,091 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:35,117 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:35,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:35,511 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:35,607 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:35,781 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:36,017 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:36,109 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:36,242 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8e18a932-9ca6-484e-9232-f32ab6aff64f
127.0.0.1 - - [08/Feb/2025 05:10:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:36,254 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 19c9491c-fcc4-41b4-bf89-a9b3acf35631
2025-02-08 05:10:36,256 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 17233845-b82e-4978-9d7d-d66b9c1dfba3
127.0.0.1 - - [08/Feb/2025 05:10:36] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:10:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:36,282 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:36,524 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:36,610 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:36,776 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:36,844 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e98d7261-4e5d-4a6a-b431-8e7a89a6fd44
127.0.0.1 - - [08/Feb/2025 05:10:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:36,862 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 06596715-f39e-4b50-b651-917125dfb48c
127.0.0.1 - - [08/Feb/2025 05:10:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:36,876 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 055233a2-2252-4d9c-a85e-3244a325cee9
127.0.0.1 - - [08/Feb/2025 05:10:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:37,032 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:37,104 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:37,272 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:37,550 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:37,554 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: aeda6187-c0c6-457e-bde9-fb2eb5048960
127.0.0.1 - - [08/Feb/2025 05:10:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:37,556 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7043be31-2107-4633-bc88-9750d94899d7
127.0.0.1 - - [08/Feb/2025 05:10:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:37,572 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a038b6ce-a407-4748-abd8-05b9d54b9740
127.0.0.1 - - [08/Feb/2025 05:10:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:37,590 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 34741ac5-1794-4175-afd8-8ef3af4666c4
127.0.0.1 - - [08/Feb/2025 05:10:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:37,621 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:37,794 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:38,024 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:38,111 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:38,277 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:38,522 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:38,624 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:38,745 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d046b3ce-fb4c-4122-a909-304dedb18106
127.0.0.1 - - [08/Feb/2025 05:10:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:38,746 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7c71c8b9-19e1-45e3-b060-d255226cad8e
127.0.0.1 - - [08/Feb/2025 05:10:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:38,760 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b76214ac-f344-4bcb-8866-0f600ee89752
127.0.0.1 - - [08/Feb/2025 05:10:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:38,761 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fde6d681-8968-45b9-94d4-1dd55f090712
127.0.0.1 - - [08/Feb/2025 05:10:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:38,770 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 76fa1bed-3ffb-4b63-8168-7e17af50983c
127.0.0.1 - - [08/Feb/2025 05:10:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:38,786 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:39,030 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:39,112 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:39,294 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:39,410 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d55475e4-72aa-4f93-9882-6f51c007e0fb
127.0.0.1 - - [08/Feb/2025 05:10:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:39,412 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1c0c914d-881b-4456-a523-7c27eda7f85a
127.0.0.1 - - [08/Feb/2025 05:10:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:39,438 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f64bcf37-1cc4-4f4c-8b01-33ef781a587d
127.0.0.1 - - [08/Feb/2025 05:10:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:39,508 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d4d6b5c0-0870-4a07-be27-ce9f4a0cdb2a
127.0.0.1 - - [08/Feb/2025 05:10:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:39,514 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a6c1edaa-3fc6-4094-a6e5-c1f8ed8d6976
127.0.0.1 - - [08/Feb/2025 05:10:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:39,559 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:39,612 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0559ea58-051a-4bbf-a4c1-fcabb6e04688
127.0.0.1 - - [08/Feb/2025 05:10:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:39,622 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:39,627 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3ad966ac-03e1-479a-b3e4-5bd16a1c2f14
127.0.0.1 - - [08/Feb/2025 05:10:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:39,636 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1dbeb719-ba8a-4bd7-b8a7-daa7debf88c3
127.0.0.1 - - [08/Feb/2025 05:10:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:39,656 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 99e50267-b6b9-4cdc-8370-7e91f7ed95f8
127.0.0.1 - - [08/Feb/2025 05:10:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:39,786 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:40,030 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:40,110 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:40,279 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:40,501 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 72498575-a856-4f0b-a244-6cb7498a7f3f
127.0.0.1 - - [08/Feb/2025 05:10:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:40,512 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 10ce3340-f9dd-4994-bf1f-624f59868911
127.0.0.1 - - [08/Feb/2025 05:10:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:40,517 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: de849701-90d2-4a24-ac35-04233db03a06
127.0.0.1 - - [08/Feb/2025 05:10:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:40,521 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 92102b4b-b8d5-4d8b-9921-2e85bd35a23c
2025-02-08 05:10:40,527 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
127.0.0.1 - - [08/Feb/2025 05:10:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:40,615 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:40,788 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:10:41,071 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:41,124 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:41,310 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:41,546 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:41,637 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:41,690 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6a7d8811-c249-4099-9955-417883b14340
127.0.0.1 - - [08/Feb/2025 05:10:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:41,692 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0e845e13-4685-4366-b9e6-341be3700588
127.0.0.1 - - [08/Feb/2025 05:10:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:41,699 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0601c09f-e9ad-44e8-821e-5a8a16e3934a
127.0.0.1 - - [08/Feb/2025 05:10:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:41,710 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4a76857e-9573-4e75-b800-d84d4870c334
127.0.0.1 - - [08/Feb/2025 05:10:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:41,718 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3bed5b71-fdd0-4f9e-87d5-44a6f8a707c5
127.0.0.1 - - [08/Feb/2025 05:10:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:41,797 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:42,032 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:42,104 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:10:42,550 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 487a5d4b-25f7-487b-970e-71cf9ea98794
127.0.0.1 - - [08/Feb/2025 05:10:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:42,565 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 812e4508-dac2-4d9b-8154-106fce1e1c7f
127.0.0.1 - - [08/Feb/2025 05:10:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:42,569 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c9e1f35a-03ad-4bba-baad-51865a011d4d
127.0.0.1 - - [08/Feb/2025 05:10:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:42,573 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:42,583 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 946a7765-83f1-466f-b07b-1dae1be85043
127.0.0.1 - - [08/Feb/2025 05:10:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:42,611 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:43,036 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:43,105 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:43,514 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:43,619 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:43,970 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9847aaba-bf67-430c-94c0-1dc47e2e41f6
127.0.0.1 - - [08/Feb/2025 05:10:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:43,987 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 456fdd73-fc13-43b1-b182-e1619d8f0caf
127.0.0.1 - - [08/Feb/2025 05:10:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:44,018 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:44,114 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:44,521 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:44,613 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:45,040 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:45,117 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:45,538 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:45,631 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:46,040 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:46,108 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1e486036-72ee-40fe-822e-eb61c5cc98cc
127.0.0.1 - - [08/Feb/2025 05:10:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:46,114 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 99e93273-2deb-4e99-a367-d68822310264
127.0.0.1 - - [08/Feb/2025 05:10:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:46,117 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:46,126 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 59909c41-4f21-4904-9224-0ecabb40a0a5
127.0.0.1 - - [08/Feb/2025 05:10:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:46,527 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:46,617 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:46,870 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:47,058 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:47,115 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:47,311 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:47,515 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:47,541 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1f5aa63e-ff22-45ae-b719-722906ec1918
127.0.0.1 - - [08/Feb/2025 05:10:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:47,549 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f3410186-4f02-4f32-aae7-50d83ccf03cb
127.0.0.1 - - [08/Feb/2025 05:10:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:47,561 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bbcf26fd-10ab-4e1b-977b-e5fa2b87cf91
127.0.0.1 - - [08/Feb/2025 05:10:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:47,636 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5542feb9-f85b-4470-941b-fb5777751b22
127.0.0.1 - - [08/Feb/2025 05:10:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:47,640 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a7c6a133-9c0d-4a6f-a343-1f7cb0fe5f78
127.0.0.1 - - [08/Feb/2025 05:10:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:47,643 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a8a0126f-3d6b-4450-a888-5bd4a28f3dde
127.0.0.1 - - [08/Feb/2025 05:10:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:47,644 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:47,663 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8e43367f-00d8-49a5-a397-558a53059c64
127.0.0.1 - - [08/Feb/2025 05:10:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:47,811 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:48,030 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:48,042 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4a8ef843-e1bb-4830-9a98-aca52998fd04
127.0.0.1 - - [08/Feb/2025 05:10:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:48,093 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 13bcf826-d0b6-43ca-b6c2-571d40196d33
127.0.0.1 - - [08/Feb/2025 05:10:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:48,125 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:48,291 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:48,513 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:48,609 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:48,782 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:49,026 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:49,107 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:49,287 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:49,528 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:49,662 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:49,804 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:50,092 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:50,121 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:50,304 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:50,514 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:50,644 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:50,786 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:51,026 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:51,106 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:51,288 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:51,380 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4d8fdb8a-d8f1-415a-b0d5-ccac0e392cdb
127.0.0.1 - - [08/Feb/2025 05:10:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:51,517 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:51,605 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4e4d0684-38b5-4b09-86e4-9383896e700a
127.0.0.1 - - [08/Feb/2025 05:10:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:51,610 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6e6648bf-5a16-46bd-9767-30a635149965
127.0.0.1 - - [08/Feb/2025 05:10:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:51,613 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 63c5b971-6b92-4dbc-af8d-2b3f8716e2b1
127.0.0.1 - - [08/Feb/2025 05:10:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:51,616 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:51,633 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 279b4a5d-cb97-41b7-ab14-74b7a317e46d
127.0.0.1 - - [08/Feb/2025 05:10:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:51,650 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 015b34aa-8cc6-4493-a52e-db442c11c532
127.0.0.1 - - [08/Feb/2025 05:10:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:51,799 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:51,896 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c56a5d40-cc44-42ee-b914-4e7e59c23066
127.0.0.1 - - [08/Feb/2025 05:10:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:51,900 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3bb66b1a-09ce-45d7-aa91-c307e166822a
127.0.0.1 - - [08/Feb/2025 05:10:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:52,054 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:52,107 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:52,319 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:52,532 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:52,608 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:52,802 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:52,951 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cc910f66-0d9a-4a06-819f-769c5e1d8d6f
127.0.0.1 - - [08/Feb/2025 05:10:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:52,955 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9b464b08-d17b-4be9-a39f-27ce7f9a67ef
127.0.0.1 - - [08/Feb/2025 05:10:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:52,957 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0db68bdb-a7e9-47c1-bbb0-774be5f1c7a8
127.0.0.1 - - [08/Feb/2025 05:10:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:52,980 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9fb70a0d-c31a-4462-a63c-e0964c08c22c
127.0.0.1 - - [08/Feb/2025 05:10:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:52,984 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6daa9207-3c99-41a0-a3ad-e50d6e0e0c83
127.0.0.1 - - [08/Feb/2025 05:10:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:53,095 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:53,160 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:53,298 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:53,542 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:53,633 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:53,808 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:54,050 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:54,108 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:54,289 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:54,519 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:10:54,613 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:10:54,819 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:55,018 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:10:55,065 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2bf0ad9b-a062-468d-bab4-266370321f0e
127.0.0.1 - - [08/Feb/2025 05:10:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:55,076 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4a9813eb-3d9f-471b-8727-d1a13ab7f7a0
127.0.0.1 - - [08/Feb/2025 05:10:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:55,109 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1be075a1-62cc-442d-a8fa-aa4edc434fe4
2025-02-08 05:10:55,113 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
127.0.0.1 - - [08/Feb/2025 05:10:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:55,286 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:55,545 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:55,613 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:55,843 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:10:56,026 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:56,146 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:56,302 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:56,551 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:56,609 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:56,809 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:57,046 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:10:57,056 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d6c493dd-8fa1-45ad-a33d-ccb102eca26a
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,073 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: da914006-2532-42df-adba-8b44474ab323
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,073 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 51fb0226-b055-40ec-8e0b-c307975b0e34
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,079 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 867599e8-6e7b-475a-9eae-f82627b3bbdf
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,113 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:10:57,122 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4d19bb5f-241d-4a56-b00e-b2e037299cf3
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,198 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6192ca30-d446-4f1b-a585-d732c4f1e51f
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,201 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2bfc9d39-875d-48a7-a871-9c6bd1544015
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,211 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9eba31c1-148a-4000-af88-75b4880bed55
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,328 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:57,561 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:57,615 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:10:57,681 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b6890a4d-0803-4b46-8e28-792db1adbdff
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,684 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 81db657e-66a7-4a6d-a36b-3f5287f5e412
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,685 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f04a48f2-cace-41f6-9279-2160f74dd707
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,707 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fd9074c1-bb8b-46b9-a3f1-696475c1a1d1
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,805 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:10:57,807 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4f3c3d33-6cd3-481e-8074-f522628ed86a
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,810 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f33c90cb-45f3-4aa9-8ee3-c99edb762be9
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,852 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7c6a9ec0-1258-4a75-903d-0aac6ec1c2bf
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:57,881 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 53e09764-3ffb-4865-865a-ed1d67b7ffb3
127.0.0.1 - - [08/Feb/2025 05:10:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:10:58,025 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:10:58,113 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:58,367 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:58,518 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:10:58,604 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:10:58,894 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:59,032 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:10:59,122 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:10:59,369 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:10:59,528 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:10:59,696 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:10:59,900 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:00,172 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:00,220 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:00,325 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:00,638 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:11:00,650 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9b98a592-41b4-43b8-a7cd-9b5c882ddc66
127.0.0.1 - - [08/Feb/2025 05:11:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:00,652 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eaa084cb-a94c-4b66-aff6-52a3cdcd0955
127.0.0.1 - - [08/Feb/2025 05:11:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:00,672 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:00,719 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5a8370ab-d106-445a-be17-38343023b0e9
127.0.0.1 - - [08/Feb/2025 05:11:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:00,742 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c03c11fa-6bde-4eb2-a80e-9e5abbc8f6e1
127.0.0.1 - - [08/Feb/2025 05:11:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:00,748 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a7e1cb7b-d0b8-4a15-bf34-8b7eb9d18583
127.0.0.1 - - [08/Feb/2025 05:11:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:00,765 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 22a1801a-1be1-4c13-9f57-5e53919e7663
127.0.0.1 - - [08/Feb/2025 05:11:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:00,770 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ae4a2c42-b06c-45c1-a4ee-e46a312a1035
127.0.0.1 - - [08/Feb/2025 05:11:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:00,777 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ef8c4088-0ca9-4e39-b74d-4917bb8cacc2
127.0.0.1 - - [08/Feb/2025 05:11:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:00,836 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:01,106 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:01,125 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:01,318 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:01,467 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a786c882-bb6e-4214-81ed-252d4afb8adc
127.0.0.1 - - [08/Feb/2025 05:11:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:01,469 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5074cca2-a398-4ef9-93bf-abcb0abb8e7e
127.0.0.1 - - [08/Feb/2025 05:11:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:01,471 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1b04efda-a6fe-4219-889a-27ad85534209
127.0.0.1 - - [08/Feb/2025 05:11:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:01,518 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d7801136-cea1-43db-9af9-361ed9a97963
127.0.0.1 - - [08/Feb/2025 05:11:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:01,651 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:01,689 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:01,797 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:02,023 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:02,137 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:02,381 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:02,588 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:02,616 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:02,629 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6866058b-ea77-4fa4-8917-a83df7b9a144
127.0.0.1 - - [08/Feb/2025 05:11:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:02,630 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e7261420-31b4-4215-8ce7-8b3a60423255
127.0.0.1 - - [08/Feb/2025 05:11:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:02,818 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5565110b-a244-4c70-b7b0-4ce08bff9815
127.0.0.1 - - [08/Feb/2025 05:11:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:02,834 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8ba7c9a5-d964-417d-83d9-baf26841e4ab
127.0.0.1 - - [08/Feb/2025 05:11:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:02,836 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:02,847 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1ae0c567-41ea-4f2d-94d4-c7de028097c3
127.0.0.1 - - [08/Feb/2025 05:11:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:02,858 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 88920645-6665-4074-b110-20befd5fce51
127.0.0.1 - - [08/Feb/2025 05:11:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:03,050 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:03,165 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:03,294 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:03,541 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:03,662 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:03,664 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ff165aa0-60ac-4699-bb6d-9d3263d67e18
127.0.0.1 - - [08/Feb/2025 05:11:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:03,714 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7cd024fe-dd66-47d1-9280-c6ef03a96446
127.0.0.1 - - [08/Feb/2025 05:11:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:03,926 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:04,117 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:04,175 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:04,324 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:04,530 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:04,616 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:04,881 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:05,014 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:05,070 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 432c1a47-ba6f-41d7-9770-d2de57b93ca7
127.0.0.1 - - [08/Feb/2025 05:11:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:05,088 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: dbbc1467-ba10-440c-a63d-a59bb0321870
127.0.0.1 - - [08/Feb/2025 05:11:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:05,139 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:05,155 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2909c7e0-c091-4a65-bc55-dd2bbfaf3c12
127.0.0.1 - - [08/Feb/2025 05:11:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:05,233 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 01d5707a-8eb0-4e5a-a056-82aae51d5357
127.0.0.1 - - [08/Feb/2025 05:11:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:05,396 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:05,523 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:05,609 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ad2e374e-fce9-47a0-953d-c48e9fa47f07
127.0.0.1 - - [08/Feb/2025 05:11:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:05,614 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c0ab4ed5-d3ea-470a-af00-0090108582f9
127.0.0.1 - - [08/Feb/2025 05:11:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:05,627 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 156943a3-da1c-4e7f-8985-1c2a6e73bcbd
127.0.0.1 - - [08/Feb/2025 05:11:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:05,630 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:05,664 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c423d2b0-daf0-45b7-8cc0-237d8a35a46f
127.0.0.1 - - [08/Feb/2025 05:11:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:05,854 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:06,015 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ea17c54b-d0cf-4e2e-a5a3-9a8257ad8dab
127.0.0.1 - - [08/Feb/2025 05:11:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:06,032 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:06,095 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ff650dc7-44f8-494d-ba94-c8b22c6f4a53
127.0.0.1 - - [08/Feb/2025 05:11:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:06,167 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:06,295 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:06,562 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:06,650 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:06,823 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:07,103 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:07,129 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:07,247 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 20f7fb95-1b7d-4914-8d7d-e6e6bdd02cf2
127.0.0.1 - - [08/Feb/2025 05:11:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:07,272 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 68c23722-dc2a-4e78-9392-bb8040f8b3f8
127.0.0.1 - - [08/Feb/2025 05:11:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:07,353 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 74bd296f-e269-433b-910a-07ebe58f59a0
127.0.0.1 - - [08/Feb/2025 05:11:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:07,384 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e5473f29-3488-45db-9865-3eab43095b9f
127.0.0.1 - - [08/Feb/2025 05:11:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:07,397 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:07,424 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0df42d49-4906-4419-8b6b-0d1e9a90faa1
127.0.0.1 - - [08/Feb/2025 05:11:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:07,465 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bec5d886-2fa2-4e4a-9e1c-be2810fc406f
127.0.0.1 - - [08/Feb/2025 05:11:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:07,585 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:07,689 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:07,803 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:08,112 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:08,121 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:08,327 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:08,521 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:08,668 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:11:08,795 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:09,057 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:09,104 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:09,343 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:09,638 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:09,661 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:09,749 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 987a4ee0-8005-4a34-b96e-63c543615166
127.0.0.1 - - [08/Feb/2025 05:11:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:09,753 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 59368629-7cdb-47ae-9860-7f4ffd0ff954
127.0.0.1 - - [08/Feb/2025 05:11:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:09,758 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2029e034-252e-4f51-9aa4-8e15354bab88
127.0.0.1 - - [08/Feb/2025 05:11:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:09,827 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:10,048 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:10,182 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:10,340 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:10,549 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:10,620 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:10,825 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:11,037 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:11,219 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:11,339 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:11,529 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:11:11,670 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:11,828 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:12,138 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 05:11:12,614 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c5948da4-02b7-47b1-8f6b-68d20922a5b7
127.0.0.1 - - [08/Feb/2025 05:11:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:12,759 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0bde7db0-2b22-4e39-ba99-f758f2e8bc8e
127.0.0.1 - - [08/Feb/2025 05:11:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:14,365 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c725e492-1266-4f94-8f30-737f4e570bae
127.0.0.1 - - [08/Feb/2025 05:11:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:14,368 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ab093d6d-9265-4a34-93c3-8bc9a5dcb808
127.0.0.1 - - [08/Feb/2025 05:11:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:14,729 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c3e37b1d-cc2e-4370-a758-8db392299387
127.0.0.1 - - [08/Feb/2025 05:11:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:14,734 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4a3c0962-5772-4bd0-adac-99c32a09bff3
127.0.0.1 - - [08/Feb/2025 05:11:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:14,735 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 66174e4e-b4ed-4e37-86d1-d385edbc471e
127.0.0.1 - - [08/Feb/2025 05:11:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:14,771 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fc9a08b7-8787-44b3-93c1-49963d15e6df
127.0.0.1 - - [08/Feb/2025 05:11:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:14,812 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c9a4b066-3789-4cb7-99d4-7104e6ecb337
127.0.0.1 - - [08/Feb/2025 05:11:14] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:17,600 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:17,651 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:17,669 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:17,677 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:17,708 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:17,743 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:17,754 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:17,777 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:17,805 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:17,828 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d9ed7de8-b584-4380-9c0c-5144a56258c2
127.0.0.1 - - [08/Feb/2025 05:11:17] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:17,842 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6a0cf678-9516-4a17-bea3-8b0967a765dc
2025-02-08 05:11:17,859 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
127.0.0.1 - - [08/Feb/2025 05:11:17] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:17,921 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:11:17,935 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:17,997 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:18,067 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:18,080 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:18,103 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:18,104 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:18,106 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:18,113 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:18,143 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:18,168 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:18,202 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:18,205 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:18,214 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:18,233 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:18,240 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:18,266 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:18,320 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:18,333 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:18,336 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:18,352 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:18,362 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:18,363 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:18,365 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:18,373 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:18,429 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:18,431 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:18,553 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:18,582 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:18,701 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:18,831 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:19,059 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:19,137 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:19,323 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:19,675 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:19,744 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:20,038 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:20,047 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:20,228 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:20,356 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:20,442 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7c079d8a-9a0d-41db-927e-6b278cbeb583
127.0.0.1 - - [08/Feb/2025 05:11:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:20,460 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: dbf19d6a-7270-4327-9607-77ec429e846f
127.0.0.1 - - [08/Feb/2025 05:11:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:20,574 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2abe1176-d788-4a4e-9068-0df0be86bf00
127.0.0.1 - - [08/Feb/2025 05:11:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:20,631 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:20,661 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: daffdd44-1545-4650-9293-6e95e9ea02de
127.0.0.1 - - [08/Feb/2025 05:11:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:20,725 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5c1079b7-eaed-4366-862e-1464b5a21b3e
127.0.0.1 - - [08/Feb/2025 05:11:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:20,759 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:20,904 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:21,025 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5d5e0ecf-c662-492a-a61b-b4918a202dfd
127.0.0.1 - - [08/Feb/2025 05:11:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:21,039 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 86e711f3-897d-456b-abd2-948b7b123d4f
127.0.0.1 - - [08/Feb/2025 05:11:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:21,098 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 35185084-c99a-4651-a5ca-2e7fcb56e336
127.0.0.1 - - [08/Feb/2025 05:11:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:21,119 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:21,132 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: db5556cc-1281-4840-93d8-03ac8cb13a41
127.0.0.1 - - [08/Feb/2025 05:11:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:21,273 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:21,331 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:21,756 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:21,823 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:21,857 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:22,047 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:22,121 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:22,372 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 01da7e02-87ab-41e4-82fb-f541bd3eebb8
2025-02-08 05:11:22,379 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
127.0.0.1 - - [08/Feb/2025 05:11:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:22,381 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4cb23de2-73ab-498f-ba72-2ba58363392c
127.0.0.1 - - [08/Feb/2025 05:11:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:22,567 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:22,630 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:11:22,878 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:23,086 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:23,141 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:23,317 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:23,701 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:23,757 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:23,815 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:23,974 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0376fd20-2032-45c0-886a-cedaaca2ef40
127.0.0.1 - - [08/Feb/2025 05:11:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:23,977 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d48d0dbc-e00e-46f1-b42e-9ab2b467c334
127.0.0.1 - - [08/Feb/2025 05:11:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:23,995 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9f68eeb7-1283-4bc4-8275-710634fa712b
127.0.0.1 - - [08/Feb/2025 05:11:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:24,000 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 52de0b39-c9e3-45ee-b7b6-0beaf539c739
127.0.0.1 - - [08/Feb/2025 05:11:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:24,003 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9bfe09f4-425d-488f-a161-6166ccdc0ff6
127.0.0.1 - - [08/Feb/2025 05:11:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:24,047 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:24,132 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:24,360 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:24,552 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:24,652 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:24,831 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:25,081 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:25,193 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:25,319 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:25,485 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c2bac5d2-3085-46ba-944c-9eee753f0245
127.0.0.1 - - [08/Feb/2025 05:11:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:25,546 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8c24b480-2254-416f-8eb1-6022a9771df7
127.0.0.1 - - [08/Feb/2025 05:11:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:25,549 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 480b04be-ece8-490e-a288-a75a3742548a
127.0.0.1 - - [08/Feb/2025 05:11:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:25,551 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:25,557 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8cf40498-f812-4b68-904b-187a8f6e22ca
127.0.0.1 - - [08/Feb/2025 05:11:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:25,623 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:25,881 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:26,117 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:26,278 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 298234b6-56d1-45f2-8bf4-638e52139657
127.0.0.1 - - [08/Feb/2025 05:11:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:26,314 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:26,322 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:26,384 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cf1039eb-942a-4ba0-bbc2-ab7bf1a8a5ed
127.0.0.1 - - [08/Feb/2025 05:11:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:26,479 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4f5ad35a-c58c-460a-a117-24ad27fba4af
127.0.0.1 - - [08/Feb/2025 05:11:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:26,618 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:26,859 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:11:27,082 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:27,095 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:27,122 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:27,546 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:27,575 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:27,629 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:27,840 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:28,077 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:28,205 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:28,370 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:28,556 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:28,614 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:28,831 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 104223a9-25ea-47a2-8057-8cdf4d133e49
127.0.0.1 - - [08/Feb/2025 05:11:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:29,034 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:29,131 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:29,189 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:29,296 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:29,371 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 28ecae05-f6c8-4205-ab4a-6eceae73e1a9
127.0.0.1 - - [08/Feb/2025 05:11:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:29,559 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:29,629 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:11:29,664 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cf0f7b87-4994-4dc2-b2e6-299a5c4345f9
127.0.0.1 - - [08/Feb/2025 05:11:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:29,734 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 710d964b-1fac-4702-9d04-22acebd070df
127.0.0.1 - - [08/Feb/2025 05:11:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:29,795 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d499e3ca-698a-4e41-8af8-4dacb62a2ea3
127.0.0.1 - - [08/Feb/2025 05:11:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:29,798 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:29,833 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 261e618f-4182-486f-a9e4-4d149b2ba6d3
127.0.0.1 - - [08/Feb/2025 05:11:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:29,846 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0470c338-eb3b-4c75-918d-e7df940dd828
127.0.0.1 - - [08/Feb/2025 05:11:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:29,888 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 450389bf-7f5c-4ffc-b773-a45eeb539f25
127.0.0.1 - - [08/Feb/2025 05:11:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:30,109 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:30,138 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:30,294 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:30,640 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:30,703 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:30,849 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:31,043 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:31,130 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:31,552 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:31,652 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:31,793 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:31,875 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: aaac3cdf-bdd7-4d2f-a1d8-ad07a2116507
127.0.0.1 - - [08/Feb/2025 05:11:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:32,000 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 97ed330d-cd00-44fd-9441-30f0abd36d2a
127.0.0.1 - - [08/Feb/2025 05:11:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:32,012 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 504e2cd7-6887-4bd3-b48d-06ae613a6cd6
127.0.0.1 - - [08/Feb/2025 05:11:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:32,146 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a09e1afb-ed1d-4f50-8419-4a273168a6c6
127.0.0.1 - - [08/Feb/2025 05:11:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:32,149 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:32,293 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:32,364 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:32,593 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:32,628 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:32,641 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:33,019 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:33,068 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:33,133 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:33,463 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:33,597 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:33,641 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 040fdef2-e9ab-4210-a55b-f7e5b0b8af73
127.0.0.1 - - [08/Feb/2025 05:11:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:33,668 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:33,678 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2285598a-1719-4940-9ce6-feefdecfef10
127.0.0.1 - - [08/Feb/2025 05:11:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:33,753 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5d2dc39f-f508-4d83-9bd0-1d3b1b5d71bd
127.0.0.1 - - [08/Feb/2025 05:11:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:33,834 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b9e940f8-1bb8-4de6-bc08-a019cc565e0f
127.0.0.1 - - [08/Feb/2025 05:11:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:33,853 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c296099a-fa34-42dd-b9fb-249a254a75a7
127.0.0.1 - - [08/Feb/2025 05:11:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:33,874 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:33,906 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 936b9e57-b088-4876-99e4-550cbf8fc626
127.0.0.1 - - [08/Feb/2025 05:11:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:34,045 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cbd1eeb1-020f-4e00-888e-feb46d4cac19
127.0.0.1 - - [08/Feb/2025 05:11:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:34,154 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:34,200 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3d26fc32-3369-4bb5-9e86-a89036e6e381
127.0.0.1 - - [08/Feb/2025 05:11:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:34,251 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:34,278 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6556271c-5176-42f8-8d52-48ae59cb0964
127.0.0.1 - - [08/Feb/2025 05:11:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:34,365 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:34,668 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:34,740 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:34,868 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:35,072 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:35,334 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:35,505 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:35,824 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:35,868 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:36,060 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:36,332 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:36,583 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:36,863 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:37,038 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:37,470 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:37,762 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:37,916 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:38,124 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:38,502 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:38,532 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:38,821 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:38,901 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7ff951ec-9eb7-4a69-81ea-8020c2652984
127.0.0.1 - - [08/Feb/2025 05:11:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:38,923 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 052bc407-b106-4f13-9221-8301ff56a444
127.0.0.1 - - [08/Feb/2025 05:11:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:39,064 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f3665310-f36b-439d-8f17-4938124e0d4f
127.0.0.1 - - [08/Feb/2025 05:11:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:39,460 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:39,525 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:39,607 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:39,868 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:39,978 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0d0abcfe-19fc-42ee-af52-29e4a972463c
127.0.0.1 - - [08/Feb/2025 05:11:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:40,069 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:40,329 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cdb67893-50e1-44ee-9333-acc3e93564b7
127.0.0.1 - - [08/Feb/2025 05:11:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:40,394 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:40,638 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:40,820 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:41,071 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 907f4760-763b-44cd-a3e6-a162c2207a56
127.0.0.1 - - [08/Feb/2025 05:11:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:41,074 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a8c3ee38-6fa3-410d-b16c-aaa791ff205f
127.0.0.1 - - [08/Feb/2025 05:11:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:41,086 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b5d658a4-7cf9-4d91-9088-451ae8ca5a5b
127.0.0.1 - - [08/Feb/2025 05:11:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:41,095 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f4a4cc08-48f1-48f9-9bff-12124a5dac57
127.0.0.1 - - [08/Feb/2025 05:11:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:41,170 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: aa97e4ae-171b-4fa8-bac2-f82fa0375f71
127.0.0.1 - - [08/Feb/2025 05:11:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:41,231 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:41,318 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4363c320-5ef7-4f5c-a9fd-271fe699d1b2
127.0.0.1 - - [08/Feb/2025 05:11:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:41,326 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ea571f13-2416-4f21-b3d8-0a9aeee8ca54
127.0.0.1 - - [08/Feb/2025 05:11:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:41,382 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:41,433 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fd13efb7-ba3d-49b8-9f65-417b9576923d
127.0.0.1 - - [08/Feb/2025 05:11:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:41,564 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:41,931 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:42,154 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:42,469 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:42,556 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:42,569 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 073d2569-8b03-43e4-ad05-ac9b45dce151
127.0.0.1 - - [08/Feb/2025 05:11:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:42,583 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f11e7d6d-3c28-4315-baf5-41bfe67f9a80
127.0.0.1 - - [08/Feb/2025 05:11:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:42,626 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4546ada1-de14-4afb-b0d4-c632acde96ec
127.0.0.1 - - [08/Feb/2025 05:11:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:43,247 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:43,305 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 05:11:43,760 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:43,823 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:43,984 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:44,066 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:44,174 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 21846667-ef6e-4f73-8e99-6a0a5b846f8f
127.0.0.1 - - [08/Feb/2025 05:11:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:44,213 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: aab0a2f7-c53b-4d4d-b111-d06ff604bd86
127.0.0.1 - - [08/Feb/2025 05:11:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:44,273 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: aefe0535-c46b-455d-9ece-ad9b9b290e2d
127.0.0.1 - - [08/Feb/2025 05:11:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:44,356 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:44,391 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0f69d1e4-5681-4e55-b46b-9872713f7438
127.0.0.1 - - [08/Feb/2025 05:11:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:44,491 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:44,611 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:44,962 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:45,032 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:45,109 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:45,175 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3cc82e12-9b3e-413b-a139-4a1f2b1bb558
127.0.0.1 - - [08/Feb/2025 05:11:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:45,253 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bf8ed7d0-3fc0-4c78-80f0-da239f1b1ba1
127.0.0.1 - - [08/Feb/2025 05:11:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:45,410 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:45,439 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:45,462 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:45,572 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:45,636 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 43b14040-12e7-41c5-b7a4-c6bebabc172a
127.0.0.1 - - [08/Feb/2025 05:11:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:45,881 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:45,939 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:45,994 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: dc81aff9-91c1-47b6-a9ed-388a958eb47b
127.0.0.1 - - [08/Feb/2025 05:11:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:46,037 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 15dfddc4-9595-4331-9afa-8abfcb62958c
127.0.0.1 - - [08/Feb/2025 05:11:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:46,080 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:46,143 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:46,151 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e085e66b-c408-4130-972b-ba9ed1513889
127.0.0.1 - - [08/Feb/2025 05:11:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:46,247 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0fefd5c3-fa83-4c51-8ab3-6fb64bf70111
127.0.0.1 - - [08/Feb/2025 05:11:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:46,317 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:46,381 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1d2df552-2e98-4f0e-bba3-707b6cae8c74
2025-02-08 05:11:46,389 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
127.0.0.1 - - [08/Feb/2025 05:11:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:46,408 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:46,644 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:46,691 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c2c39f68-f345-4443-ab6f-52cd7ee11003
127.0.0.1 - - [08/Feb/2025 05:11:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:46,819 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9b7d2f14-e5ce-49b7-8af4-2e63f899a209
127.0.0.1 - - [08/Feb/2025 05:11:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:46,836 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:46,840 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3c63b477-2274-4454-8fea-9d08e2cb3214
127.0.0.1 - - [08/Feb/2025 05:11:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:46,888 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:47,088 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:47,143 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:47,373 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:47,413 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:47,458 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:47,489 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c5b9b618-4689-4bf9-91d1-5432c7030ebe
127.0.0.1 - - [08/Feb/2025 05:11:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:47,503 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d9bcdac5-3b03-4551-bf79-b5782ac6d11b
127.0.0.1 - - [08/Feb/2025 05:11:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:47,515 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:47,799 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:47,818 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:47,849 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:48,068 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:48,124 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:48,308 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:48,331 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:48,664 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:48,867 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:48,996 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:49,075 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:49,140 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8f946d8c-4504-43d4-869b-5100700c409e
127.0.0.1 - - [08/Feb/2025 05:11:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:49,141 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:49,208 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:49,229 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:49,324 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:49,364 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:49,376 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1816091b-23f5-4ffb-9b12-6cefc054ce01
127.0.0.1 - - [08/Feb/2025 05:11:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:49,539 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:11:49,581 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:50,089 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:50,092 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:50,099 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:50,160 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:50,405 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:50,406 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:50,429 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:50,552 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:50,698 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:50,837 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:50,957 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:51,067 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:51,099 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:51,150 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:51,363 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:51,465 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:51,478 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:51,526 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:51,662 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:51,872 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:51,981 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:52,069 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:52,127 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:52,166 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:52,225 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:52,263 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:52,375 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:52,392 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:52,554 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:52,600 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:52,686 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:11:52,868 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:52,869 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:52,993 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:53,019 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 98365c10-0c8d-4f50-b00a-416a7780e1c1
127.0.0.1 - - [08/Feb/2025 05:11:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:53,146 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:53,179 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:53,303 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 856d009f-abb9-41b6-919b-66b07b73f528
127.0.0.1 - - [08/Feb/2025 05:11:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:53,363 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:53,456 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:53,545 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:53,643 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:53,683 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:53,901 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9c233717-dfac-474b-9598-a9564b91281d
127.0.0.1 - - [08/Feb/2025 05:11:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:53,943 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:53,951 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:54,027 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:54,031 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b1b24c2b-a5af-40d1-931e-fa381a5ea7f4
127.0.0.1 - - [08/Feb/2025 05:11:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:54,106 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:54,173 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:54,396 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:54,549 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:54,646 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:54,806 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:55,046 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:55,096 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:55,112 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:55,123 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:55,168 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:55,236 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:55,445 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:55,566 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:55,799 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:55,898 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:55,906 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:56,026 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:56,103 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:56,146 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:56,165 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:56,358 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:56,407 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:56,523 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:56,613 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:56,710 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5d1a89a9-00b2-4c1d-9519-7360ab7fac0d
127.0.0.1 - - [08/Feb/2025 05:11:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:56,728 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:56,836 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ad547d18-4194-4c82-ba1e-d7c9249f5e49
127.0.0.1 - - [08/Feb/2025 05:11:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:56,909 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:57,063 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:57,077 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:57,131 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:57,155 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:57,354 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:57,507 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:57,725 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fad5250a-4bf1-4443-82f6-172e00e5430b
127.0.0.1 - - [08/Feb/2025 05:11:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:57,773 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:11:57,785 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:11:57,918 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:11:57,920 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 600ad2f6-5a38-46f5-91f1-b8191647c89d
127.0.0.1 - - [08/Feb/2025 05:11:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:57,948 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:11:57,961 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:58,051 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: dd1bfc81-e753-404a-a740-64eac53c0070
127.0.0.1 - - [08/Feb/2025 05:11:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:58,133 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 20b706d7-8fdd-4c7d-ba3f-0d463aea2256
2025-02-08 05:11:58,151 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
127.0.0.1 - - [08/Feb/2025 05:11:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:58,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:11:58,299 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:58,360 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:11:58,391 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:11:58,441 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:58,672 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:58,689 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:58,939 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:11:59,064 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:59,105 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:11:59,208 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:11:59,227 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:11:59,573 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0cfe8523-968c-4d75-90c5-16982587e8aa
127.0.0.1 - - [08/Feb/2025 05:11:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:59,642 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:59,810 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b1d8372e-ea1c-438c-8901-ffc726e9c15e
127.0.0.1 - - [08/Feb/2025 05:11:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:59,870 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2d1f1bfb-a716-457d-b3e0-b1b721712b12
127.0.0.1 - - [08/Feb/2025 05:11:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:59,912 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 04f208a8-fbb7-4fc6-9ae5-3a860069d510
127.0.0.1 - - [08/Feb/2025 05:11:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:11:59,923 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:11:59,939 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:11:59,946 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:11:59,977 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:11:59,985 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:00,022 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:00,046 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 77c709b8-a957-4e4a-8bf7-74990dbd3394
127.0.0.1 - - [08/Feb/2025 05:12:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:00,058 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6714624a-8da8-4587-9a1d-5105663870f5
127.0.0.1 - - [08/Feb/2025 05:12:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:00,082 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: faebd61e-26aa-42e8-9b9b-8b876e16a106
127.0.0.1 - - [08/Feb/2025 05:12:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:00,082 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 575256ea-aef1-4699-8d9a-f249f900d70e
2025-02-08 05:12:00,136 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
127.0.0.1 - - [08/Feb/2025 05:12:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:00,145 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:00,371 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:00,391 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:00,413 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:00,427 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:00,602 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9dccfe20-014f-49de-baec-f86f65253464
127.0.0.1 - - [08/Feb/2025 05:12:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:00,693 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:00,696 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:00,697 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:01,052 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:01,115 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:01,121 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:01,143 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2dd47e16-1873-4ced-af6c-0a980ccb0cb3
127.0.0.1 - - [08/Feb/2025 05:12:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:01,154 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 918609cf-e51a-4a16-89ef-3422a9582764
127.0.0.1 - - [08/Feb/2025 05:12:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:01,188 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:01,237 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:01,309 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 20f54407-d3bc-4b11-96c6-b3005d8ab588
127.0.0.1 - - [08/Feb/2025 05:12:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:01,366 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:01,416 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cacaa956-fd91-45ca-8f5e-a6c9c7b383cf
127.0.0.1 - - [08/Feb/2025 05:12:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:01,498 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:01,519 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:01,572 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:01,738 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:01,884 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:02,130 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:02,218 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:02,237 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:02,399 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:02,676 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:02,697 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:02,783 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
Exception in thread Thread-139:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:02,816 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:02,909 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:02,930 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c44332d2-23ae-4f14-ab64-e9d5b251a65f
127.0.0.1 - - [08/Feb/2025 05:12:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:03,009 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c2970dd6-5173-4a97-97ec-54aeec09eb5e
2025-02-08 05:12:03,019 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:03,043 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
127.0.0.1 - - [08/Feb/2025 05:12:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:03,138 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:03,151 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:03,207 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 519533f7-f756-4a2e-81c3-d994de19d3ce
2025-02-08 05:12:03,210 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3b0582a7-c3e2-423d-8d84-0dc39e9ba4d1
127.0.0.1 - - [08/Feb/2025 05:12:03] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:12:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:03,362 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 61c33128-4783-4daf-9af1-dc2bacc463b4
2025-02-08 05:12:03,370 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
127.0.0.1 - - [08/Feb/2025 05:12:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:03,444 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1109b078-4de9-4b4c-8a7b-bc35aa3514bf
127.0.0.1 - - [08/Feb/2025 05:12:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:03,479 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:03,508 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3a93e3d4-3ab7-42c1-80b9-58fc724ba903
127.0.0.1 - - [08/Feb/2025 05:12:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:03,524 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:03,589 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bfe9a0ad-95cd-40fa-8d1c-a4e3f09764d9
127.0.0.1 - - [08/Feb/2025 05:12:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:03,617 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7bc2253b-b708-4e31-b4dc-55d1e73976f2
2025-02-08 05:12:03,625 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7a44b228-f49f-47f0-9e03-283d60c414db
127.0.0.1 - - [08/Feb/2025 05:12:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:03,690 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 90f5b9fe-25a7-4163-90a9-3f51b5e47f13
127.0.0.1 - - [08/Feb/2025 05:12:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:03,718 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
127.0.0.1 - - [08/Feb/2025 05:12:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:03,841 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:04,148 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 255f93c8-efeb-4aae-bd92-be1b3137480d
127.0.0.1 - - [08/Feb/2025 05:12:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:04,215 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:04,281 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6a8f8234-47b8-451f-9c7f-46d63c6692e2
127.0.0.1 - - [08/Feb/2025 05:12:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:07,360 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: dc880c4a-c2df-4429-9c87-5579d4a93431
127.0.0.1 - - [08/Feb/2025 05:12:07] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-148:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-152:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-151:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:08,806 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 79c795da-187d-4dba-bf0f-1d092555e295
127.0.0.1 - - [08/Feb/2025 05:12:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:08,899 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 32d9b392-75b5-4c15-ab45-3db4aa07b8df
127.0.0.1 - - [08/Feb/2025 05:12:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:12:08,963 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e752959d-0b82-4d95-add5-deaba0781c52
127.0.0.1 - - [08/Feb/2025 05:12:09] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-153:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-155:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-154:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-157:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-156:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-159:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-160:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-161:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-162:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:17,621 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:17,671 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:17,750 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:17,812 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:17,880 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:18,001 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:18,011 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:18,135 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:18,149 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:12:18,166 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:18,167 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:18,198 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:18,231 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:18,236 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:18,253 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:18,341 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:18,372 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
Exception in thread Thread-164:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:18,485 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:18,515 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:18,576 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:18,649 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:18,655 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:18,678 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:18,702 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:18,730 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:18,744 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:18,759 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:18,782 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:18,806 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:18,838 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:18,850 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:18,987 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:18,996 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:19,116 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
Exception in thread Thread-166:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:19,125 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:19,146 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:19,220 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:19,256 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:19,339 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-171:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:19,375 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:19,446 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:19,455 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:19,473 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:19,591 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
Exception in thread Thread-169:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:19,598 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:19,619 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:19,664 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:19,707 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:19,740 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:19,779 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:19,807 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:19,817 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:19,847 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:19,901 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
Exception in thread Thread-163:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:19,914 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:19,929 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:19,949 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:20,055 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:20,060 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:20,088 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:20,184 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:20,199 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
Exception in thread Thread-170:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-176:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:20,250 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:20,264 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:20,273 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:20,274 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:20,289 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:20,369 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:20,382 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:20,430 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:20,434 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
Exception in thread Thread-175:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:20,511 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:20,536 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-177:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:20,578 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:20,646 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:20,673 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-173:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:20,739 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:20,881 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
Exception in thread Thread-179:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
Exception in thread Thread-172:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:20,907 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:21,039 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:21,050 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:21,088 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:21,101 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:21,167 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:21,171 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:21,189 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:21,195 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:21,197 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:21,201 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:21,235 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:21,285 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
Exception in thread Thread-183:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:21,315 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:21,330 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-182:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:21,391 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
Exception in thread Thread-167:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:21,427 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:21,475 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
Exception in thread Thread-180:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:21,779 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:21,781 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:21,983 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:21,986 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:21,990 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:21,996 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:22,004 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:22,020 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:22,063 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:22,087 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:22,107 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:22,145 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
Exception in thread Thread-184:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:22,190 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:22,214 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:22,283 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
Exception in thread Thread-174:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:22,324 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:22,340 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:22,343 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:22,361 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:22,396 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:22,458 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:22,463 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:12:22,469 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:22,481 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:22,522 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:22,655 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-185:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:22,754 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:22,896 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:23,030 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
Exception in thread Thread-168:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:23,175 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:23,214 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:23,287 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:23,302 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:23,357 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:23,397 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:23,403 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
Exception in thread Thread-187:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:23,491 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:23,501 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:23,516 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:23,593 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:23,641 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:23,699 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-186:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:23,700 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:23,749 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:23,826 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:23,844 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:23,887 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:23,964 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:24,003 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:24,007 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:24,115 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:24,128 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:24,135 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:24,163 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:24,209 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:24,218 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:24,250 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:12:24,294 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:24,368 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:24,494 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:24,600 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:24,631 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:24,650 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:24,674 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:24,681 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:24,711 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:24,729 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:24,794 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:24,879 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:24,908 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:24,956 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:24,978 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:24,991 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:25,059 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 05:12:25,072 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:25,127 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:25,149 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:25,327 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:25,459 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
Exception in thread Thread-191:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:25,551 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:25,621 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:25,654 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:25,657 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:25,705 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:25,739 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:25,815 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:12:25,825 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:25,836 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
Exception in thread Thread-190:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:25,877 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:25,992 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:26,005 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:26,027 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:26,088 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:26,116 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
Exception in thread Thread-192:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:26,252 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:26,274 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:26,297 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:26,356 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:26,445 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:26,452 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:26,460 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:26,557 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:26,575 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:26,605 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:26,643 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:26,650 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:26,684 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:26,866 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:27,039 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:27,054 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:27,146 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:27,232 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:27,325 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
Exception in thread Thread-193:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:27,334 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:12:27,390 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:27,495 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:27,623 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:27,658 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
Exception in thread Thread-194:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:27,659 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:27,724 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:27,760 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:28,022 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:12:28,043 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
Exception in thread Thread-195:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:28,157 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:28,168 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
Exception in thread Thread-196:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:28,560 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
Exception in thread Thread-188:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:28,619 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-197:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:28,636 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:28,926 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:28,944 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
Exception in thread Thread-198:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:29,392 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:29,399 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:29,437 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
Exception in thread Thread-178:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:29,688 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
Exception in thread Thread-199:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:30,119 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
Exception in thread Thread-200:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:30,409 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:30,468 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:30,620 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
Exception in thread Thread-201:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:30,924 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:31,118 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
Exception in thread Thread-202:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:31,178 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:31,519 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:31,604 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:31,791 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:12:31,922 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:31,949 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:32,086 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:32,101 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:32,131 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
Exception in thread Thread-203:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:32,514 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:32,518 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:32,645 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:33,032 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:33,092 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:33,181 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:33,378 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
Exception in thread Thread-207:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:33,791 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:33,837 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:33,900 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-206:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:34,191 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:34,338 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:34,360 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:34,428 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
Exception in thread Thread-209:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-208:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:34,842 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:34,892 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
Exception in thread Thread-205:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:35,513 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
Exception in thread Thread-211:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:35,857 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:35,869 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-204:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:36,070 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:36,115 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:36,206 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:36,282 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:36,307 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:36,653 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
Exception in thread Thread-213:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:37,039 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:37,207 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
Exception in thread Thread-212:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-214:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:37,484 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:37,542 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:37,608 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:37,766 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
Exception in thread Thread-210:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:37,990 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:38,148 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:38,247 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:38,272 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:38,707 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:38,764 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:12:39,081 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:39,182 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:39,257 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
Exception in thread Thread-216:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:39,524 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:39,554 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
Exception in thread Thread-218:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:40,121 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:40,144 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-219:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:40,166 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:40,401 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
Exception in thread Thread-220:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:40,598 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
Exception in thread Thread-217:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:40,869 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:40,971 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
Exception in thread Thread-222:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:41,229 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
Exception in thread Thread-221:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-189:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:41,333 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:41,444 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:41,456 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:41,547 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:41,830 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
Exception in thread Thread-223:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:41,906 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:41,944 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
Exception in thread Thread-165:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:41,991 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:42,256 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
Exception in thread Thread-224:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:42,480 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:42,497 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:42,777 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:42,807 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:43,123 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:43,338 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:43,341 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
Exception in thread Thread-226:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-225:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:43,639 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:43,650 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:43,653 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:43,948 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-227:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:44,119 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:44,289 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:44,524 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:44,810 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:44,856 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
Exception in thread Thread-229:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:45,248 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:45,307 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:45,497 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:12:45,644 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-228:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:45,809 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:12:46,039 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:46,124 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:46,245 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-231:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:46,562 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:46,705 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-232:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:46,930 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
Exception in thread Thread-215:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:47,066 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:47,191 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:47,468 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:47,596 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:47,908 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:48,137 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
Exception in thread Thread-233:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:48,300 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:48,346 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:48,461 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:48,628 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
Exception in thread Thread-238:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:48,760 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:48,772 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:48,965 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
Exception in thread Thread-236:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:49,395 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:49,427 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:49,517 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:49,518 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:49,538 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:49,659 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:49,870 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
Exception in thread Thread-237:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:50,072 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:50,210 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
Exception in thread Thread-241:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:50,628 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:50,795 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:50,915 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:50,984 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:51,022 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
Exception in thread Thread-244:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:51,493 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
Exception in thread Thread-246:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-234:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:51,655 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
Exception in thread Thread-243:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:51,787 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
Exception in thread Thread-230:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:52,239 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
Exception in thread Thread-247:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:52,423 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:52,438 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:12:52,521 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
Exception in thread Thread-248:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-249:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-250:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:53,265 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:12:53,298 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:53,397 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
Exception in thread Thread-251:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:53,609 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:53,611 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
Exception in thread Thread-253:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:53,649 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-254:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:53,868 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:53,936 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:12:53,988 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:54,025 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:12:54,206 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
Exception in thread Thread-240:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:54,248 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:54,382 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
Exception in thread Thread-235:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:54,673 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
Exception in thread Thread-256:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-239:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
Exception in thread Thread-257:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    raise timeout('timed out')
socket.timeout: timed out
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:55,112 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:12:55,192 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:55,550 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
Exception in thread Thread-259:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:55,580 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:55,686 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-261:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:56,021 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-262:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:56,212 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:12:56,282 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:56,314 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
Exception in thread Thread-263:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-258:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
Exception in thread Thread-242:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    raise timeout('timed out')
socket.timeout: timed out
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    raise timeout('timed out')
socket.timeout: timed out
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:56,372 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:12:56,903 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:56,990 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:12:57,037 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
Exception in thread Thread-264:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-267:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
Exception in thread Thread-265:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:57,489 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-245:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:57,626 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:12:57,713 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:12:57,726 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-181:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 331, in __send_chunk
    data_sent += socket.send(chunk, flags, timeout=timeleft)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 730, in send
    self._wait(self._write_event)
  File "src/gevent/_hub_primitives.py", line 317, in gevent._gevent_c_hub_primitives.wait_on_socket
  File "src/gevent/_hub_primitives.py", line 322, in gevent._gevent_c_hub_primitives.wait_on_socket
  File "src/gevent/_hub_primitives.py", line 313, in gevent._gevent_c_hub_primitives._primitive_wait
  File "src/gevent/_hub_primitives.py", line 314, in gevent._gevent_c_hub_primitives._primitive_wait
  File "src/gevent/_hub_primitives.py", line 46, in gevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait
  File "src/gevent/_hub_primitives.py", line 46, in gevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait
  File "src/gevent/_hub_primitives.py", line 55, in gevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait
  File "src/gevent/_waiter.py", line 154, in gevent._gevent_c_waiter.Waiter.get
  File "src/gevent/_greenlet_primitives.py", line 61, in gevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch
  File "src/gevent/_greenlet_primitives.py", line 61, in gevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch
  File "src/gevent/_greenlet_primitives.py", line 65, in gevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch
  File "src/gevent/_gevent_c_greenlet_primitives.pxd", line 35, in gevent._gevent_c_greenlet_primitives._greenlet_switch
socket.timeout: timed out
2025-02-08 05:12:57,834 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:12:57,916 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:12:58,004 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:58,092 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
Exception in thread Thread-269:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-255:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:58,373 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
Exception in thread Thread-266:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:58,559 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:12:58,765 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
Exception in thread Thread-268:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-270:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:58,847 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-271:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:59,044 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
Exception in thread Thread-272:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:59,409 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:12:59,433 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:12:59,577 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:12:59,664 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-274:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:12:59,940 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-273:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:00,001 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
Exception in thread Thread-275:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-252:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:00,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:13:00,319 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-278:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:00,977 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
Exception in thread Thread-277:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:00,982 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
Exception in thread Thread-276:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:01,044 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:13:01,379 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-281:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:01,434 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
Exception in thread Thread-284:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-282:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:01,791 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:13:01,832 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:13:02,085 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
Exception in thread Thread-285:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:02,092 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
Exception in thread Thread-286:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:02,560 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:13:02,873 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:13:02,923 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:13:02,956 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:13:03,025 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
Exception in thread Thread-288:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:03,406 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:13:03,440 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
Exception in thread Thread-287:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:03,593 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:13:03,657 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:13:03,930 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:13:04,031 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:13:04,092 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:13:04,371 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:13:04,424 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
Exception in thread Thread-292:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-291:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-290:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-293:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:04,688 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:13:04,842 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-279:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-283:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:05,187 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:13:05,206 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:13:05,321 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:13:05,650 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:13:05,662 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:13:05,685 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:13:05,786 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:13:05,940 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:13:05,980 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:13:06,119 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:13:06,449 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:13:06,641 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:13:06,794 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:13:06,870 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 05:13:07,037 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
Exception in thread Thread-289:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:07,626 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:13:08,251 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
Exception in thread Thread-260:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:08,393 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 1.0
2025-02-08 05:13:08,440 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:13:08,954 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
2025-02-08 05:13:09,582 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 05:13:09,989 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 05:13:10,995 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:13:11,045 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:13:11,482 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
2025-02-08 05:13:12,790 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:13:12,931 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:13:12,958 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:13:13,431 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
2025-02-08 05:13:14,486 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:13:14,830 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:13:14,921 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:13:15,569 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
2025-02-08 05:13:16,028 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:13:16,454 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:13:16,913 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 05:13:17,506 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
2025-02-08 05:13:17,947 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
Exception in thread Thread-294:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:18,420 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 05:13:18,922 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
Exception in thread Thread-295:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:19,426 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
Exception in thread Thread-300:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-296:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:19,978 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:13:20,371 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
Exception in thread Thread-301:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-299:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-302:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:20,936 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-304:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-305:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:21,647 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
Exception in thread Thread-306:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-307:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:22,194 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
Exception in thread Thread-297:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:22,626 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 3.0
Exception in thread Thread-303:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-313:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
Exception in thread Thread-308:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    raise timeout('timed out')
socket.timeout: timed out
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:22,867 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 6.0
Exception in thread Thread-312:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-298:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-315:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:23,722 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
Exception in thread Thread-309:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-316:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-314:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-310:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:24,424 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 05:13:24,432 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
Exception in thread Thread-318:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-317:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:24,991 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
Exception in thread Thread-319:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-280:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 331, in __send_chunk
    data_sent += socket.send(chunk, flags, timeout=timeleft)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 730, in send
    self._wait(self._write_event)
  File "src/gevent/_hub_primitives.py", line 317, in gevent._gevent_c_hub_primitives.wait_on_socket
  File "src/gevent/_hub_primitives.py", line 322, in gevent._gevent_c_hub_primitives.wait_on_socket
  File "src/gevent/_hub_primitives.py", line 313, in gevent._gevent_c_hub_primitives._primitive_wait
  File "src/gevent/_hub_primitives.py", line 314, in gevent._gevent_c_hub_primitives._primitive_wait
  File "src/gevent/_hub_primitives.py", line 46, in gevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait
  File "src/gevent/_hub_primitives.py", line 46, in gevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait
  File "src/gevent/_hub_primitives.py", line 55, in gevent._gevent_c_hub_primitives.WaitOperationsGreenlet.wait
  File "src/gevent/_waiter.py", line 154, in gevent._gevent_c_waiter.Waiter.get
  File "src/gevent/_greenlet_primitives.py", line 61, in gevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch
  File "src/gevent/_greenlet_primitives.py", line 61, in gevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch
  File "src/gevent/_greenlet_primitives.py", line 65, in gevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch
  File "src/gevent/_gevent_c_greenlet_primitives.pxd", line 35, in gevent._gevent_c_greenlet_primitives._greenlet_switch
socket.timeout: timed out
Exception in thread Thread-311:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-321:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:25,930 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
2025-02-08 05:13:26,252 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
Exception in thread Thread-324:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-323:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-325:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:26,640 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
Exception in thread Thread-320:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:27,053 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 4.0
Exception in thread Thread-326:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-328:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:27,380 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
Exception in thread Thread-329:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-331:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:28,042 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-322:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-332:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-327:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-330:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:28,821 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 05:13:28,981 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 10.0
Exception in thread Thread-335:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:29,509 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 2.0
Exception in thread Thread-333:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-336:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-338:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:30,193 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 05:13:30,431 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 7.0
Exception in thread Thread-339:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-334:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-337:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
Exception in thread Thread-340:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:31,020 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-341:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-342:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-343:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-344:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-345:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-346:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-347:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-348:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-350:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-351:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-354:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-349:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-353:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-356:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-355:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-352:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-358:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-357:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-359:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-361:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-360:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-362:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-363:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-365:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-364:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-366:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-368:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-367:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-369:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-370:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-371:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-372:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-373:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-374:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-375:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-376:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-377:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-378:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-379:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-380:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-382:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-381:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-383:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-385:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-384:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-386:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-388:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-387:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-390:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-389:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-391:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-392:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-393:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-394:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-396:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-395:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-397:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-398:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-399:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-400:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-401:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-402:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-403:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-404:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-405:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-406:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    raise timeout('timed out')
socket.timeout: timed out
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-407:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-408:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-410:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:55,826 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8fda9a83-99c0-4f5f-9d18-4b9926eb5e59
127.0.0.1 - - [08/Feb/2025 05:13:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:13:55,897 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b3fa50fe-ed0f-48d8-9426-43e1386d6451
127.0.0.1 - - [08/Feb/2025 05:13:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:13:55,922 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 168012b1-7455-48ca-a39e-2eb60c415a69
127.0.0.1 - - [08/Feb/2025 05:13:55] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-412:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-411:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:56,720 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 81825679-a3d4-46d8-9b0c-ac6ac42207ed
127.0.0.1 - - [08/Feb/2025 05:13:56] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-413:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-414:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-416:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:58,488 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c80f0bac-02f9-4eea-b859-fd80d879800f
127.0.0.1 - - [08/Feb/2025 05:13:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:13:58,700 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 287a35a1-1855-423a-8637-2b17cdcc2fa1
127.0.0.1 - - [08/Feb/2025 05:13:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:13:58,800 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f275798e-f6af-4ce4-862a-8a387df6afdd
2025-02-08 05:13:58,817 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9cf796db-6caf-4ad3-a45e-fe22ece009cb
Exception in thread Thread-417:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
127.0.0.1 - - [08/Feb/2025 05:13:58] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:13:58] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-415:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:58,874 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5ea3c8b1-bcb4-45c4-9159-f74840ad2acf
127.0.0.1 - - [08/Feb/2025 05:13:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:13:59,053 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ec92b582-7616-465c-8e52-1b0b4851609b
127.0.0.1 - - [08/Feb/2025 05:13:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:13:59,086 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b845e497-c3af-461d-80c2-42a8ecb3221c
127.0.0.1 - - [08/Feb/2025 05:13:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:13:59,105 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f4eb27e1-873b-4b6a-a4a8-b6dbad20f112
2025-02-08 05:13:59,189 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1c7e0068-b18d-458c-bdb4-9d31a15d383d
127.0.0.1 - - [08/Feb/2025 05:13:59] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:13:59] "POST /inference HTTP/1.1" 200 -
Exception in thread Thread-418:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 05:13:59,512 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e642d367-fe4a-469e-9f30-affc2a6d3c56
127.0.0.1 - - [08/Feb/2025 05:13:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:13:59,516 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 40e2d348-1dd1-499d-9e52-deb53de48809
127.0.0.1 - - [08/Feb/2025 05:13:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:13:59,550 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8e02020b-c00d-4750-94b6-46fa1b1a3726
127.0.0.1 - - [08/Feb/2025 05:13:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:13:59,567 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 589b250a-c771-4579-af74-382eaad05138
2025-02-08 05:13:59,621 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 745fe432-25a8-43cd-a69e-bd7d94a0b433
127.0.0.1 - - [08/Feb/2025 05:13:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:13:59,623 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 910e0c5e-4e6e-4cc2-bee1-f26cce1d8920
127.0.0.1 - - [08/Feb/2025 05:13:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:13:59,644 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 48fc2cba-6db5-4cff-8df3-85927e056952
127.0.0.1 - - [08/Feb/2025 05:13:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:13:59,759 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ba7ad5ab-b88c-4a50-a1b7-1f21ec114963
2025-02-08 05:13:59,826 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b94eed70-4934-425e-b9f2-7a7fdfd1ddf1
2025-02-08 05:14:00,036 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 607c2302-2b67-4081-a11a-7cc6cf411a7b
127.0.0.1 - - [08/Feb/2025 05:14:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,225 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 499a119e-d6f3-4159-819d-fd2ec18da04d
127.0.0.1 - - [08/Feb/2025 05:14:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,234 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 791915ef-af7f-4192-82f7-cf2d115e00e8
127.0.0.1 - - [08/Feb/2025 05:14:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,270 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: baab70e6-4a68-433b-861e-817c2cd0047a
127.0.0.1 - - [08/Feb/2025 05:14:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,323 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 870abe57-9541-43dc-80d8-b88f8b3e615d
127.0.0.1 - - [08/Feb/2025 05:14:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,349 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8708b633-c548-4dad-ba14-21a310169146
127.0.0.1 - - [08/Feb/2025 05:14:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,351 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 661c0c70-dbf6-4267-9553-639c2c7af3b3
127.0.0.1 - - [08/Feb/2025 05:14:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,474 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2d35ae1c-1499-417f-80de-2f129866b100
127.0.0.1 - - [08/Feb/2025 05:14:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,520 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7b23ebd3-7ba7-4f25-8719-95102d07ac45
127.0.0.1 - - [08/Feb/2025 05:14:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,548 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5319ccda-c2ad-40c0-bbd5-2a3bf4ff96fb
127.0.0.1 - - [08/Feb/2025 05:14:00] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:14:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,556 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 468c99ba-f6b4-4562-93ab-283d3bc7c6ba
2025-02-08 05:14:00,616 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0aff6c5b-34c5-4fa0-8078-a72f6c49d2ab
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,640 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3ac220e1-1e03-47b1-8e22-f21544881453
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,640 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 86ed6d3b-84f4-46d2-9d39-678df79a6d83
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,696 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5b845aeb-3e61-4d29-8a25-139c6e776e33
2025-02-08 05:14:00,747 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f4b72703-a81f-494a-bb86-72472dd85755
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,798 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cad0ef3a-c426-4c4e-83fe-524cc1a381cd
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,841 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3003c59b-84aa-4c88-931b-cafdbdf2b565
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,903 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f013cf14-1857-4645-9211-ddc00cb4cbea
2025-02-08 05:14:00,912 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 58e5b1be-3af5-428d-b626-a9a7ba511798
2025-02-08 05:14:00,970 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c0ef2471-3402-4995-b85f-2615641ea0be
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:00,987 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a3a94b88-333f-46aa-acee-6cd107778e04
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,006 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7e2ef783-9b72-4d79-8c89-61405efde98b
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,062 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 90b88cdb-ef7c-400f-9bc0-73c5f176c947
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,110 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2d890e38-8888-4f98-b556-508617364454
127.0.0.1 - - [08/Feb/2025 05:14:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,135 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b746bc48-8e1c-4d99-b190-9ea71f237ad3
2025-02-08 05:14:01,143 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 59f3fcb2-4e7f-4866-bae5-1f97d825520e
2025-02-08 05:14:01,151 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5afc2974-9639-4d69-9005-be8585a01880
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,210 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c81ba77f-2a13-4ecd-b64e-90f1721cf403
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,230 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 532eb084-548c-4eca-ad2f-9e6af3508b9c
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,231 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 894d662e-84a9-4872-9a66-f91df19a0f8e
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,246 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 94c8ad76-99c7-4f03-979f-7dc110a792d2
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,261 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: edd95037-0014-4163-8d76-4a2ed11c0f04
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,282 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4c1984f9-b840-43e2-9aeb-f74287217eb4
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,328 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 80809430-a483-4ce0-8e8c-5d924ae9e8cf
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,360 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d7c833b2-db5a-4d69-a187-f7a0153e05f7
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,374 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8c905b5a-066c-4221-ab7d-448f6c261664
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,409 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 06c9201d-fb1f-41a8-8324-aeb949da6f20
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,472 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 53f807f8-d6b9-47e5-a5e7-0ca525a29405
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,487 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ad584e63-284f-498d-b838-a95037a69172
127.0.0.1 - - [08/Feb/2025 05:14:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,508 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c8f14f6b-0349-4e8e-a033-6bb7320128e1
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,572 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 57adb6cc-aa1e-4ceb-b464-5b445b6a68eb
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,578 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d4249e7f-1e10-4981-a886-6792740319f5
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,584 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e1f1b6b6-5c0e-4624-b324-0683e5f13624
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,598 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: acbf9b3d-9d68-41f1-802e-766dc2af75cf
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,599 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eac40d36-9ee7-4eee-a4d0-8471cad27b67
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,630 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5b650e7b-7333-4af7-b1e5-809e44bd0257
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,650 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9b2006f0-786b-4de1-b880-6c01c4be44c8
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,669 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 13f82c0c-b20e-47ec-aa76-d58ab4a8d580
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,682 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 80c1fa04-fb66-4de2-9f0a-d1e435ab197f
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,686 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 068f9fbc-3e8a-48e1-a516-7f1af1c210d2
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,687 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b0828229-33a9-457e-963c-02d4e7610b0b
2025-02-08 05:14:01,691 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 928a6d7f-2779-4bac-b4bc-fd51e2624bf9
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,720 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 38289233-2239-4e96-9d1d-28370bae091b
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,736 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 44140247-e43f-4450-812c-c4df2423072a
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,751 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c928797c-0d37-4ca4-a609-32143f85652c
2025-02-08 05:14:01,772 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f37df6eb-a7f1-40ad-aec9-4101d7e71af5
127.0.0.1 - - [08/Feb/2025 05:14:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,793 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5b1d1f8d-6512-48dd-b1be-7f53dc97a1c5
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,795 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8401e3b9-60e4-4930-b3a9-021cc5fa03e0
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,860 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d906b947-1af5-4470-9b70-003e9d03f50a
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,880 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f660a8a2-0643-477b-84e1-511383eef11f
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,889 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 520d2d3b-a6f8-4aff-a75a-0c11fbff9746
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,924 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f347c0fd-5ec2-4e90-84fc-4ac6f1f0fbc5
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,945 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7e0f1a00-1a64-4359-b6cd-71133f396deb
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,960 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0ac2bfbf-0cb9-4cce-be74-916365f5e18f
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:01,961 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b5c444e1-6ad6-4ac6-a0a0-2ab9dc71a256
2025-02-08 05:14:02,032 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1b2fc40e-7782-4426-aea2-84df23882bfb
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:02,047 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a28749ca-76f8-4112-a397-ff269742b8f6
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:02,061 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a30d140c-606e-4ebd-9cbd-e266e1532264
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:02,072 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bfbd4753-3ba8-4ca1-ae6c-a2c93b3a2a66
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:02,118 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f902f488-c72e-4187-9c55-bb175556dc5b
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:02,191 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d2004dbc-a34a-4f3c-8fa4-3d5c27d8afe6
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:14:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:02,229 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2291310a-6d60-44c8-a448-e07e7f37f7e8
127.0.0.1 - - [08/Feb/2025 05:14:05] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:14:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:02,303 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c8d7613e-4472-459c-afc8-5ea41390b09f
127.0.0.1 - - [08/Feb/2025 05:14:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:02,361 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6c717430-7f50-4bc7-83ec-9cd1e8ed0f7a
127.0.0.1 - - [08/Feb/2025 05:14:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:02,364 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6e9b3248-c645-48bf-986f-51dd162d3dcc
127.0.0.1 - - [08/Feb/2025 05:14:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:02,423 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c09a6170-edf0-4c02-a5da-aebee5277223
2025-02-08 05:14:02,518 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d9a183c3-60a2-4add-80bd-841d0e69b773
127.0.0.1 - - [08/Feb/2025 05:14:05] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:14:05] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:14:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:14:02,707 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f25d218f-a782-47cb-a314-6c56fac1f78a
127.0.0.1 - - [08/Feb/2025 05:14:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:01,906 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e470fbb8-80aa-4a89-9001-5eb2e0f95410
2025-02-08 05:16:01,908 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8ef4b690-d196-4aea-81fc-699cf5cae511
2025-02-08 05:16:02,098 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 13231b85-5da9-474c-ba2b-f2dd00e2c976
2025-02-08 05:16:02,107 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8ef4b690-d196-4aea-81fc-699cf5cae511
127.0.0.1 - - [08/Feb/2025 05:16:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:02,140 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f40569ee-a391-43a2-a576-78cac3d8777b
2025-02-08 05:16:02,300 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e470fbb8-80aa-4a89-9001-5eb2e0f95410
2025-02-08 05:16:02,307 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 13231b85-5da9-474c-ba2b-f2dd00e2c976
127.0.0.1 - - [08/Feb/2025 05:16:02] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:02,455 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f40569ee-a391-43a2-a576-78cac3d8777b
127.0.0.1 - - [08/Feb/2025 05:16:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:06,085 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 41f5fa0a-ff0c-47da-80bb-c701c2139af9
2025-02-08 05:16:06,098 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f5bbf7b0-e54b-4476-b1a1-b66eb78accbd
2025-02-08 05:16:06,222 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b68f3668-aba5-482b-beb2-6c7136c8dcac
2025-02-08 05:16:06,283 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f5bbf7b0-e54b-4476-b1a1-b66eb78accbd
127.0.0.1 - - [08/Feb/2025 05:16:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:06,334 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b68f3668-aba5-482b-beb2-6c7136c8dcac
127.0.0.1 - - [08/Feb/2025 05:16:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:06,398 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 218954a9-fe47-49a1-8178-1e315270aaeb
2025-02-08 05:16:06,604 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6f92161a-3893-47de-b73c-07605f5b4614
2025-02-08 05:16:06,710 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 41f5fa0a-ff0c-47da-80bb-c701c2139af9
127.0.0.1 - - [08/Feb/2025 05:16:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:06,832 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 218954a9-fe47-49a1-8178-1e315270aaeb
127.0.0.1 - - [08/Feb/2025 05:16:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:06,894 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6f92161a-3893-47de-b73c-07605f5b4614
127.0.0.1 - - [08/Feb/2025 05:16:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:07,715 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 76433eb1-5b8f-47cc-91e4-d527af573809
2025-02-08 05:16:07,770 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4dded28d-772f-457c-b15b-4bda692454e4
2025-02-08 05:16:07,773 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 86faaa0b-9613-46fc-8c5c-3bef631b445c
2025-02-08 05:16:08,015 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3093488d-f48e-4745-a21c-cea3b851cffd
2025-02-08 05:16:08,142 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4dded28d-772f-457c-b15b-4bda692454e4
127.0.0.1 - - [08/Feb/2025 05:16:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:08,157 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2be07dd0-7600-4c02-8b09-877c931bc760
2025-02-08 05:16:08,292 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2be07dd0-7600-4c02-8b09-877c931bc760
127.0.0.1 - - [08/Feb/2025 05:16:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:08,311 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3093488d-f48e-4745-a21c-cea3b851cffd
127.0.0.1 - - [08/Feb/2025 05:16:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:08,346 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 86faaa0b-9613-46fc-8c5c-3bef631b445c
2025-02-08 05:16:08,428 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5ae23c5e-fee9-4672-8e59-3753747efd8b
127.0.0.1 - - [08/Feb/2025 05:16:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:08,548 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8a51c4af-2229-4239-8b63-2395a186e68b
2025-02-08 05:16:08,581 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5ae23c5e-fee9-4672-8e59-3753747efd8b
2025-02-08 05:16:08,589 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8a51c4af-2229-4239-8b63-2395a186e68b
127.0.0.1 - - [08/Feb/2025 05:16:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:08,600 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 76433eb1-5b8f-47cc-91e4-d527af573809
127.0.0.1 - - [08/Feb/2025 05:16:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:08,687 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 94c34186-c94c-4f57-a4d9-0b4b745145a0
127.0.0.1 - - [08/Feb/2025 05:16:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:08,688 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d4778cce-95c9-41bf-ba1b-979ca04b6533
2025-02-08 05:16:08,892 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 94c34186-c94c-4f57-a4d9-0b4b745145a0
127.0.0.1 - - [08/Feb/2025 05:16:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:08,930 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 476d1896-e0f3-4531-b3f4-b11dc2a578db
2025-02-08 05:16:08,981 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d4778cce-95c9-41bf-ba1b-979ca04b6533
127.0.0.1 - - [08/Feb/2025 05:16:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:09,127 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 24eb7061-8b43-4bc1-bb8d-59eb5f3dcefc
2025-02-08 05:16:09,160 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 77637fa5-e3aa-438e-9b43-b247092392d0
2025-02-08 05:16:09,298 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 476d1896-e0f3-4531-b3f4-b11dc2a578db
127.0.0.1 - - [08/Feb/2025 05:16:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:09,375 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 24eb7061-8b43-4bc1-bb8d-59eb5f3dcefc
127.0.0.1 - - [08/Feb/2025 05:16:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:09,491 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3c7f4a47-15cf-4c24-99c9-dd142e8b7e44
2025-02-08 05:16:09,568 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 77637fa5-e3aa-438e-9b43-b247092392d0
127.0.0.1 - - [08/Feb/2025 05:16:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:09,670 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1c2ec7ab-4882-4c4d-b143-116b29e54819
2025-02-08 05:16:09,759 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a7216f5b-eb6a-456a-8cc7-9dc852f2b281
2025-02-08 05:16:09,887 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9d8ed49e-64b9-446e-8d8e-aaaa99e58bc4
2025-02-08 05:16:10,012 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1c2ec7ab-4882-4c4d-b143-116b29e54819
127.0.0.1 - - [08/Feb/2025 05:16:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:10,097 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3c7f4a47-15cf-4c24-99c9-dd142e8b7e44
127.0.0.1 - - [08/Feb/2025 05:16:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:10,210 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9d8ed49e-64b9-446e-8d8e-aaaa99e58bc4
127.0.0.1 - - [08/Feb/2025 05:16:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:10,350 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a7216f5b-eb6a-456a-8cc7-9dc852f2b281
127.0.0.1 - - [08/Feb/2025 05:16:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:10,398 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 128d229a-6fc7-4fc9-8a74-4997ea02fcdb
2025-02-08 05:16:10,408 - LoudVA - WARNING - [LoudServer] - Timeout reached for request af6977c0-636b-4af5-aac0-8b6b86fc19cb
2025-02-08 05:16:10,622 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 50b001a6-afab-4d90-ac6e-e13a24067198
2025-02-08 05:16:10,764 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 128d229a-6fc7-4fc9-8a74-4997ea02fcdb
127.0.0.1 - - [08/Feb/2025 05:16:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:10,832 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: af6977c0-636b-4af5-aac0-8b6b86fc19cb
127.0.0.1 - - [08/Feb/2025 05:16:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:10,849 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7d797c79-cee4-4b96-a234-ceb6acb1f18f
2025-02-08 05:16:10,899 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8e1e337d-34fd-44b2-ab64-c74b234217c8
2025-02-08 05:16:11,046 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7d797c79-cee4-4b96-a234-ceb6acb1f18f
127.0.0.1 - - [08/Feb/2025 05:16:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:11,075 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bb5e98aa-627d-4498-869e-b994b50f1021
2025-02-08 05:16:11,197 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bb5e98aa-627d-4498-869e-b994b50f1021
127.0.0.1 - - [08/Feb/2025 05:16:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:11,351 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 50b001a6-afab-4d90-ac6e-e13a24067198
127.0.0.1 - - [08/Feb/2025 05:16:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:11,445 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8e1e337d-34fd-44b2-ab64-c74b234217c8
127.0.0.1 - - [08/Feb/2025 05:16:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:11,468 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c99b3242-bafa-4197-abf1-2686466f76c0
2025-02-08 05:16:11,545 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 40bb6beb-d7ab-434d-9953-241a75040838
2025-02-08 05:16:11,562 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 776da504-3414-40f9-a8ed-db5ac5b0fb4b
2025-02-08 05:16:11,637 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 40bb6beb-d7ab-434d-9953-241a75040838
127.0.0.1 - - [08/Feb/2025 05:16:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:11,696 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c99b3242-bafa-4197-abf1-2686466f76c0
127.0.0.1 - - [08/Feb/2025 05:16:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:11,756 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9e25b4b5-7317-4347-8283-b6c99edc12ec
2025-02-08 05:16:11,883 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9e25b4b5-7317-4347-8283-b6c99edc12ec
127.0.0.1 - - [08/Feb/2025 05:16:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:11,908 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 776da504-3414-40f9-a8ed-db5ac5b0fb4b
127.0.0.1 - - [08/Feb/2025 05:16:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:11,933 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 30724872-850c-49e7-8d8c-680d95b770b7
2025-02-08 05:16:12,482 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5b3d9228-58b0-4ab8-9388-aa898b4903ea
2025-02-08 05:16:12,690 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 30724872-850c-49e7-8d8c-680d95b770b7
127.0.0.1 - - [08/Feb/2025 05:16:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:12,850 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5b3d9228-58b0-4ab8-9388-aa898b4903ea
127.0.0.1 - - [08/Feb/2025 05:16:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:17,617 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 03aff509-e7dc-44da-a0b4-43fc79562659
2025-02-08 05:16:17,648 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 03aff509-e7dc-44da-a0b4-43fc79562659
127.0.0.1 - - [08/Feb/2025 05:16:17] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:17,675 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 28dfdb96-c6b8-45d5-9ca4-cb96daa5d45e
2025-02-08 05:16:17,694 - LoudVA - WARNING - [LoudServer] - Timeout reached for request df75f006-bac2-451a-869e-d68f5fbceffa
2025-02-08 05:16:17,716 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 00964666-3e5d-4855-8ec0-a785a74c25ee
2025-02-08 05:16:17,761 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 073c38d1-8edb-47d3-bfbe-da812fd8bc72
2025-02-08 05:16:17,775 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4b4fc731-9b9c-400b-8e59-948c0f2ee7f5
2025-02-08 05:16:17,789 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 83795eb8-3ee0-44d1-845e-ac06736da8bb
2025-02-08 05:16:17,877 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 52dfef50-9c22-452e-a349-5ff069c200fd
2025-02-08 05:16:17,898 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2cc2c18a-24c8-4fb4-bbc3-57f4ebe0ec2e
2025-02-08 05:16:17,964 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9742406a-4d82-43d1-b23a-3bb99b468df3
2025-02-08 05:16:18,013 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6dde1ab5-daba-4a3c-9009-976df2863d66
2025-02-08 05:16:18,028 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 285041e4-a319-4a67-8677-ed3a980fc37d
2025-02-08 05:16:18,035 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: df75f006-bac2-451a-869e-d68f5fbceffa
127.0.0.1 - - [08/Feb/2025 05:16:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,055 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 00964666-3e5d-4855-8ec0-a785a74c25ee
127.0.0.1 - - [08/Feb/2025 05:16:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,097 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7b318282-db44-4ae7-b487-826b14bc3329
2025-02-08 05:16:18,137 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 69113003-b43e-42e2-9f95-4b6a35f6ec03
2025-02-08 05:16:18,196 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bd9bcbd4-a18b-43dc-933e-058a15aa522c
2025-02-08 05:16:18,199 - LoudVA - WARNING - [LoudServer] - Timeout reached for request de94dcf0-2299-4e84-a4d8-5729af88350a
2025-02-08 05:16:18,212 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4b4fc731-9b9c-400b-8e59-948c0f2ee7f5
127.0.0.1 - - [08/Feb/2025 05:16:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,218 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 25537c59-cf65-4d20-8573-ad8a80265a7b
2025-02-08 05:16:18,222 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 83795eb8-3ee0-44d1-845e-ac06736da8bb
127.0.0.1 - - [08/Feb/2025 05:16:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,233 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 52dfef50-9c22-452e-a349-5ff069c200fd
127.0.0.1 - - [08/Feb/2025 05:16:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,233 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c8faad85-c9fc-4512-bc0f-408f8a220120
2025-02-08 05:16:18,242 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 28dfdb96-c6b8-45d5-9ca4-cb96daa5d45e
127.0.0.1 - - [08/Feb/2025 05:16:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,253 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9742406a-4d82-43d1-b23a-3bb99b468df3
127.0.0.1 - - [08/Feb/2025 05:16:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,276 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f3535e06-71ab-4040-bb9f-8cf68a9ab8dd
2025-02-08 05:16:18,284 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 21b05667-3ffd-4542-8d94-8e726ce53638
2025-02-08 05:16:18,284 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6a8d988a-9557-48c5-aede-84fc8b164aeb
2025-02-08 05:16:18,300 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d109783f-0baa-4ecc-9a3a-40e8d5e32924
2025-02-08 05:16:18,303 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b100796d-c932-4fb3-b170-765ebac8f9bb
2025-02-08 05:16:18,315 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 073c38d1-8edb-47d3-bfbe-da812fd8bc72
127.0.0.1 - - [08/Feb/2025 05:16:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,315 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 027d9df0-0c84-4a46-a435-712d91c28145
2025-02-08 05:16:18,320 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9ffd8b3c-17ce-455a-bc0c-8aaa07f833e0
2025-02-08 05:16:18,326 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 845542ba-4dc2-4b1c-a5b1-eb1ef7647324
2025-02-08 05:16:18,349 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2cc2c18a-24c8-4fb4-bbc3-57f4ebe0ec2e
127.0.0.1 - - [08/Feb/2025 05:16:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,381 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4272ed36-096e-4510-a8d6-c281cd62a56f
2025-02-08 05:16:18,409 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 56d4ffe5-b48a-466e-a015-5a19d498a8d7
2025-02-08 05:16:18,429 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 285041e4-a319-4a67-8677-ed3a980fc37d
127.0.0.1 - - [08/Feb/2025 05:16:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,438 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 38bcd4a1-e465-4065-ae80-9072809bc1f0
2025-02-08 05:16:18,451 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6dde1ab5-daba-4a3c-9009-976df2863d66
127.0.0.1 - - [08/Feb/2025 05:16:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,466 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2ac3b252-9ffc-428e-9513-d9577ead1572
2025-02-08 05:16:18,482 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 815ce5ad-943d-47e3-8dd9-1c5f0cba8eb0
2025-02-08 05:16:18,503 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d36a38e7-7cbe-46e5-9fc6-b14b7ad883b6
2025-02-08 05:16:18,514 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2a928198-c4c2-45d7-be3f-593719d065c6
2025-02-08 05:16:18,542 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d7179179-0391-48cd-ad51-e1fa4d4602cb
2025-02-08 05:16:18,596 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 93537dd7-7428-4940-8914-9ce3dd716531
2025-02-08 05:16:18,606 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 119e1a4f-8417-405a-a3fa-02b98e742464
2025-02-08 05:16:18,610 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 53e36b8f-cc3e-4ea2-a746-7b611eef8007
2025-02-08 05:16:18,637 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 234fe5fe-d135-4832-aa8e-4ec5e7d960a2
2025-02-08 05:16:18,655 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 69113003-b43e-42e2-9f95-4b6a35f6ec03
127.0.0.1 - - [08/Feb/2025 05:16:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,698 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7b318282-db44-4ae7-b487-826b14bc3329
2025-02-08 05:16:18,787 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 25537c59-cf65-4d20-8573-ad8a80265a7b
127.0.0.1 - - [08/Feb/2025 05:16:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,826 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c864d829-a6bb-448b-b708-aa7f25c96552
2025-02-08 05:16:18,826 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c3a9b99d-0def-4603-88e4-7dc888d00a35
127.0.0.1 - - [08/Feb/2025 05:16:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,929 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bd9bcbd4-a18b-43dc-933e-058a15aa522c
127.0.0.1 - - [08/Feb/2025 05:16:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:18,959 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3f7530b8-e33d-4deb-8f0e-64780346b8dd
2025-02-08 05:16:18,972 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6a8d988a-9557-48c5-aede-84fc8b164aeb
2025-02-08 05:16:19,006 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: de94dcf0-2299-4e84-a4d8-5729af88350a
127.0.0.1 - - [08/Feb/2025 05:16:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,008 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f3535e06-71ab-4040-bb9f-8cf68a9ab8dd
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,059 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 21b05667-3ffd-4542-8d94-8e726ce53638
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,075 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 027d9df0-0c84-4a46-a435-712d91c28145
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,091 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9ffd8b3c-17ce-455a-bc0c-8aaa07f833e0
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,168 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4272ed36-096e-4510-a8d6-c281cd62a56f
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,180 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b100796d-c932-4fb3-b170-765ebac8f9bb
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,211 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d109783f-0baa-4ecc-9a3a-40e8d5e32924
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,228 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c8faad85-c9fc-4512-bc0f-408f8a220120
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,237 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8fba931a-7a72-45ba-b68c-455682c3a78d
2025-02-08 05:16:19,281 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 56d4ffe5-b48a-466e-a015-5a19d498a8d7
2025-02-08 05:16:19,331 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 567837bc-9c7c-4bfe-a4e5-1c4fde9d4261
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,407 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 845542ba-4dc2-4b1c-a5b1-eb1ef7647324
2025-02-08 05:16:19,465 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 815ce5ad-943d-47e3-8dd9-1c5f0cba8eb0
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,545 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7a133772-7a01-40dc-b7e0-aefaf8bfa810
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,592 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d36a38e7-7cbe-46e5-9fc6-b14b7ad883b6
2025-02-08 05:16:19,629 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 38bcd4a1-e465-4065-ae80-9072809bc1f0
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,644 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2a928198-c4c2-45d7-be3f-593719d065c6
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,654 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d7179179-0391-48cd-ad51-e1fa4d4602cb
2025-02-08 05:16:19,749 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2ac3b252-9ffc-428e-9513-d9577ead1572
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,811 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 234fe5fe-d135-4832-aa8e-4ec5e7d960a2
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,818 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 80e0f6c3-50cc-4985-a341-84254408370c
2025-02-08 05:16:19,826 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f7b9fde4-2cba-4542-b692-4afed8aef040
2025-02-08 05:16:19,857 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c864d829-a6bb-448b-b708-aa7f25c96552
2025-02-08 05:16:19,963 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 53e36b8f-cc3e-4ea2-a746-7b611eef8007
127.0.0.1 - - [08/Feb/2025 05:16:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:19,998 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 119e1a4f-8417-405a-a3fa-02b98e742464
127.0.0.1 - - [08/Feb/2025 05:16:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:20,000 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3f7530b8-e33d-4deb-8f0e-64780346b8dd
127.0.0.1 - - [08/Feb/2025 05:16:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:20,063 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 65aabdf6-2368-456e-ade1-8c3e5660b7fe
127.0.0.1 - - [08/Feb/2025 05:16:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:20,103 - LoudVA - WARNING - [LoudServer] - Timeout reached for request dc67c75a-36c2-46cf-aaec-c35676df18fd
2025-02-08 05:16:20,242 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 41dc20a6-5164-4174-ac62-9675817104e3
2025-02-08 05:16:20,298 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c3a9b99d-0def-4603-88e4-7dc888d00a35
2025-02-08 05:16:20,385 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 93537dd7-7428-4940-8914-9ce3dd716531
2025-02-08 05:16:20,483 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8fba931a-7a72-45ba-b68c-455682c3a78d
127.0.0.1 - - [08/Feb/2025 05:16:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:20,492 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b5e51558-a46b-49fe-b6f3-337b53cadc75
127.0.0.1 - - [08/Feb/2025 05:16:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:20,606 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 567837bc-9c7c-4bfe-a4e5-1c4fde9d4261
127.0.0.1 - - [08/Feb/2025 05:16:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:20,763 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7a133772-7a01-40dc-b7e0-aefaf8bfa810
127.0.0.1 - - [08/Feb/2025 05:16:21] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:20,817 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 722a85d5-3baa-4ccc-b900-b7b816aa230c
2025-02-08 05:16:21,011 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 90a4b92d-c5f2-41bb-85cf-4ef98e8aa30f
2025-02-08 05:16:21,047 - LoudVA - WARNING - [LoudServer] - Timeout reached for request be4416d3-8de5-44fc-91d3-5ab6a4e7e8d9
2025-02-08 05:16:21,060 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f7b9fde4-2cba-4542-b692-4afed8aef040
2025-02-08 05:16:21,196 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9d808fc0-d5f2-47d5-b527-23741749c5d8
127.0.0.1 - - [08/Feb/2025 05:16:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:21,326 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 39c7c302-fa63-428f-9c0a-e4c83120a652
2025-02-08 05:16:21,334 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b59cdbb2-178d-4f11-8c5c-d93dbc9bf90c
2025-02-08 05:16:21,404 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 80e0f6c3-50cc-4985-a341-84254408370c
2025-02-08 05:16:21,410 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: dc67c75a-36c2-46cf-aaec-c35676df18fd
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:21,420 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 65aabdf6-2368-456e-ade1-8c3e5660b7fe
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:21,528 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 41dc20a6-5164-4174-ac62-9675817104e3
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:21,674 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b5e51558-a46b-49fe-b6f3-337b53cadc75
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:21,815 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5b1dbdb4-f088-4957-838a-1b135887cb7a
2025-02-08 05:16:21,937 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 722a85d5-3baa-4ccc-b900-b7b816aa230c
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:21,967 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 15eb98f1-d6ad-462b-b13a-b788beba7d9f
2025-02-08 05:16:22,069 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3f910890-2a2a-47f0-8ea9-594a168b417b
2025-02-08 05:16:22,107 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7ffdb928-e876-4439-b7bd-0d175c56f429
2025-02-08 05:16:22,110 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9d808fc0-d5f2-47d5-b527-23741749c5d8
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:22,193 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 90a4b92d-c5f2-41bb-85cf-4ef98e8aa30f
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:22,230 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7ef76ff1-d78d-45aa-ab43-86b452444995
2025-02-08 05:16:22,336 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: be4416d3-8de5-44fc-91d3-5ab6a4e7e8d9
2025-02-08 05:16:22,359 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 39c7c302-fa63-428f-9c0a-e4c83120a652
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:22,451 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5b1dbdb4-f088-4957-838a-1b135887cb7a
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:22,465 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b59cdbb2-178d-4f11-8c5c-d93dbc9bf90c
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:22,472 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cabb1d58-3000-4bdb-a06a-e16740de2226
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:22,654 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bd2be713-1f05-4dd8-b196-0db7b0a4ccd9
2025-02-08 05:16:22,659 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 15eb98f1-d6ad-462b-b13a-b788beba7d9f
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:22,683 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3083dec6-fcce-4ae0-b60c-b545c9ee33d1
2025-02-08 05:16:22,732 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7ef76ff1-d78d-45aa-ab43-86b452444995
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:22,761 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7ffdb928-e876-4439-b7bd-0d175c56f429
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:22,770 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3f910890-2a2a-47f0-8ea9-594a168b417b
127.0.0.1 - - [08/Feb/2025 05:16:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:22,963 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7c2f4e41-6de3-4ec0-825d-cde6c22d0279
2025-02-08 05:16:23,046 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bd2be713-1f05-4dd8-b196-0db7b0a4ccd9
127.0.0.1 - - [08/Feb/2025 05:16:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:23,092 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3083dec6-fcce-4ae0-b60c-b545c9ee33d1
127.0.0.1 - - [08/Feb/2025 05:16:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:23,210 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 737ff95d-c19f-4f5a-a1b2-8232813d3cf1
2025-02-08 05:16:23,222 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cabb1d58-3000-4bdb-a06a-e16740de2226
2025-02-08 05:16:23,246 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 737ff95d-c19f-4f5a-a1b2-8232813d3cf1
127.0.0.1 - - [08/Feb/2025 05:16:23] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:23,292 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 76ce97ec-0612-4bd6-8694-6eea186e92c0
2025-02-08 05:16:23,344 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4d5a260c-5e94-42a3-9a52-56f0eff92f94
2025-02-08 05:16:23,352 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7c2f4e41-6de3-4ec0-825d-cde6c22d0279
127.0.0.1 - - [08/Feb/2025 05:16:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:23,355 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4d5a260c-5e94-42a3-9a52-56f0eff92f94
127.0.0.1 - - [08/Feb/2025 05:16:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:23,739 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 02648807-60d7-4e1a-924b-6c28250fb7cd
2025-02-08 05:16:23,752 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 76ce97ec-0612-4bd6-8694-6eea186e92c0
127.0.0.1 - - [08/Feb/2025 05:16:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:23,796 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eb3251ac-e166-47a3-800b-a7dea3543d83
2025-02-08 05:16:23,837 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eb3251ac-e166-47a3-800b-a7dea3543d83
2025-02-08 05:16:23,851 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 02648807-60d7-4e1a-924b-6c28250fb7cd
2025-02-08 05:16:23,858 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a8232bfd-5832-4e3f-b208-b43f4c0d390b
127.0.0.1 - - [08/Feb/2025 05:16:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:23,991 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a8232bfd-5832-4e3f-b208-b43f4c0d390b
127.0.0.1 - - [08/Feb/2025 05:16:23] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:24,161 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5f71b984-c0b0-4503-9241-0a85abb8e217
2025-02-08 05:16:24,208 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0cb7fbbe-e21d-400f-8ed9-985db2a6356a
2025-02-08 05:16:24,268 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5f71b984-c0b0-4503-9241-0a85abb8e217
127.0.0.1 - - [08/Feb/2025 05:16:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:24,271 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0cb7fbbe-e21d-400f-8ed9-985db2a6356a
127.0.0.1 - - [08/Feb/2025 05:16:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:24,457 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a2f25bc3-f2ff-44fa-98d4-a84e12e83f71
2025-02-08 05:16:24,713 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 88accbd7-98e4-4269-9110-3bf5d24875e4
2025-02-08 05:16:24,723 - LoudVA - WARNING - [LoudServer] - Timeout reached for request be2d6737-a59c-421a-984d-f045e9de895e
2025-02-08 05:16:24,802 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 88accbd7-98e4-4269-9110-3bf5d24875e4
127.0.0.1 - - [08/Feb/2025 05:16:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:24,895 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e07944d7-c911-4cc9-8f8f-848e97cda745
2025-02-08 05:16:24,976 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a2f25bc3-f2ff-44fa-98d4-a84e12e83f71
127.0.0.1 - - [08/Feb/2025 05:16:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:25,115 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 80dc46a9-6e35-4d7d-937f-8da553dcf170
2025-02-08 05:16:25,266 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: be2d6737-a59c-421a-984d-f045e9de895e
127.0.0.1 - - [08/Feb/2025 05:16:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:25,404 - LoudVA - WARNING - [LoudServer] - Timeout reached for request dd7cc5dd-62d4-4ba9-9046-6e57288eb3a0
2025-02-08 05:16:25,438 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e53b143a-357d-4bba-a1dd-97b1435687f7
2025-02-08 05:16:25,522 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 80dc46a9-6e35-4d7d-937f-8da553dcf170
127.0.0.1 - - [08/Feb/2025 05:16:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:25,586 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e07944d7-c911-4cc9-8f8f-848e97cda745
127.0.0.1 - - [08/Feb/2025 05:16:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:25,611 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 33f1a592-ef00-4679-a757-b616837696f5
2025-02-08 05:16:25,627 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 33f1a592-ef00-4679-a757-b616837696f5
127.0.0.1 - - [08/Feb/2025 05:16:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:25,646 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 99452f15-294d-4c4d-a50e-2a99bc2f959f
2025-02-08 05:16:25,653 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e53b143a-357d-4bba-a1dd-97b1435687f7
127.0.0.1 - - [08/Feb/2025 05:16:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:25,674 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: dd7cc5dd-62d4-4ba9-9046-6e57288eb3a0
127.0.0.1 - - [08/Feb/2025 05:16:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:25,821 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 99452f15-294d-4c4d-a50e-2a99bc2f959f
127.0.0.1 - - [08/Feb/2025 05:16:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:25,988 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ee030980-b377-40db-b1ee-0f35e6b106fc
2025-02-08 05:16:26,135 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2e4d4adb-e89a-464d-b36d-f1d92fd0d008
2025-02-08 05:16:26,160 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2e4d4adb-e89a-464d-b36d-f1d92fd0d008
127.0.0.1 - - [08/Feb/2025 05:16:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:26,350 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ee030980-b377-40db-b1ee-0f35e6b106fc
127.0.0.1 - - [08/Feb/2025 05:16:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:26,450 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ee5112fb-0fef-49df-8940-0e70a7bc47ba
2025-02-08 05:16:26,568 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 113e6f88-c8f4-4342-97e2-54d158cce9e4
2025-02-08 05:16:26,654 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 00e01d03-3c4d-40b1-be16-e1637fffe8e1
2025-02-08 05:16:26,665 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ee5112fb-0fef-49df-8940-0e70a7bc47ba
127.0.0.1 - - [08/Feb/2025 05:16:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:26,806 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 00e01d03-3c4d-40b1-be16-e1637fffe8e1
127.0.0.1 - - [08/Feb/2025 05:16:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:26,906 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 150cb63c-fcb3-4156-8d3e-25ed3e45ed37
2025-02-08 05:16:27,079 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 150cb63c-fcb3-4156-8d3e-25ed3e45ed37
127.0.0.1 - - [08/Feb/2025 05:16:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:27,123 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 113e6f88-c8f4-4342-97e2-54d158cce9e4
127.0.0.1 - - [08/Feb/2025 05:16:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:27,139 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f78afe02-6972-4609-a1e7-ead825934c34
2025-02-08 05:16:27,161 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1b0730a1-ae41-4cc7-8500-375f54b6d979
2025-02-08 05:16:27,221 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 84795e0f-259e-474d-a09d-7d7d47325d4b
2025-02-08 05:16:27,434 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1b0730a1-ae41-4cc7-8500-375f54b6d979
127.0.0.1 - - [08/Feb/2025 05:16:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:27,555 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 13b19fb3-24e4-4cef-827d-1cd1f35b96c7
2025-02-08 05:16:27,626 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 13b19fb3-24e4-4cef-827d-1cd1f35b96c7
127.0.0.1 - - [08/Feb/2025 05:16:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:27,629 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 84795e0f-259e-474d-a09d-7d7d47325d4b
2025-02-08 05:16:27,659 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 11051abe-3659-4712-9a2c-4a1e68351150
127.0.0.1 - - [08/Feb/2025 05:16:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:27,816 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 11051abe-3659-4712-9a2c-4a1e68351150
127.0.0.1 - - [08/Feb/2025 05:16:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:27,825 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f78afe02-6972-4609-a1e7-ead825934c34
127.0.0.1 - - [08/Feb/2025 05:16:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:27,846 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e2599ea9-c565-4545-94e4-1c4c1e676f02
2025-02-08 05:16:27,878 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 25d9e3ea-1aba-48a1-b9b8-6f8a64cc227d
2025-02-08 05:16:27,903 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 25d9e3ea-1aba-48a1-b9b8-6f8a64cc227d
127.0.0.1 - - [08/Feb/2025 05:16:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:28,263 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bb0beb0d-73c7-46d5-beca-881d10a05ab1
2025-02-08 05:16:28,305 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e7258d00-1ef6-42b4-9ac9-885a45fda500
2025-02-08 05:16:28,344 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bb0beb0d-73c7-46d5-beca-881d10a05ab1
127.0.0.1 - - [08/Feb/2025 05:16:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:28,490 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eeefce92-6216-4f0e-8ca3-d314022fb0da
2025-02-08 05:16:28,626 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e2599ea9-c565-4545-94e4-1c4c1e676f02
2025-02-08 05:16:28,688 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f2e2d324-3bfa-4c57-afd8-84de2ef78354
2025-02-08 05:16:28,719 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f2e2d324-3bfa-4c57-afd8-84de2ef78354
127.0.0.1 - - [08/Feb/2025 05:16:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:28,811 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 62d8b7a0-b003-444c-8e74-0b2b5b603268
127.0.0.1 - - [08/Feb/2025 05:16:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:28,816 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e7258d00-1ef6-42b4-9ac9-885a45fda500
127.0.0.1 - - [08/Feb/2025 05:16:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:28,921 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eeefce92-6216-4f0e-8ca3-d314022fb0da
127.0.0.1 - - [08/Feb/2025 05:16:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:29,070 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 62d8b7a0-b003-444c-8e74-0b2b5b603268
127.0.0.1 - - [08/Feb/2025 05:16:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:29,144 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 49c62b12-56ea-4765-bc6f-ee8391652b5e
2025-02-08 05:16:29,269 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 65f46b94-ddf1-400c-a821-30707f7039cc
2025-02-08 05:16:29,283 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d271fbdd-3e34-4897-9e90-f821e2899f0a
2025-02-08 05:16:29,322 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0b1a133c-4d1a-4901-a5d7-707d293f79ac
2025-02-08 05:16:29,350 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d271fbdd-3e34-4897-9e90-f821e2899f0a
127.0.0.1 - - [08/Feb/2025 05:16:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:29,388 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0b1a133c-4d1a-4901-a5d7-707d293f79ac
127.0.0.1 - - [08/Feb/2025 05:16:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:29,604 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 49c62b12-56ea-4765-bc6f-ee8391652b5e
127.0.0.1 - - [08/Feb/2025 05:16:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:29,630 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 65f46b94-ddf1-400c-a821-30707f7039cc
127.0.0.1 - - [08/Feb/2025 05:16:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:29,630 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2a5be14b-c45f-41b4-8732-1281a812aa7f
2025-02-08 05:16:29,677 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d8d1e6ad-8765-4313-b355-53881c05951f
2025-02-08 05:16:29,759 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2a5be14b-c45f-41b4-8732-1281a812aa7f
127.0.0.1 - - [08/Feb/2025 05:16:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:29,804 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d8d1e6ad-8765-4313-b355-53881c05951f
127.0.0.1 - - [08/Feb/2025 05:16:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:29,805 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b17d23f0-967d-4d88-8bd3-a28228dc4ac1
2025-02-08 05:16:30,027 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b17d23f0-967d-4d88-8bd3-a28228dc4ac1
127.0.0.1 - - [08/Feb/2025 05:16:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:30,120 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1cfd6d6d-516f-4aa7-a3d3-a278bfd43d26
2025-02-08 05:16:30,202 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1cfd6d6d-516f-4aa7-a3d3-a278bfd43d26
127.0.0.1 - - [08/Feb/2025 05:16:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:30,228 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bd692225-0019-44ab-972f-9e5d7dbd83a7
2025-02-08 05:16:30,301 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bd692225-0019-44ab-972f-9e5d7dbd83a7
127.0.0.1 - - [08/Feb/2025 05:16:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:30,390 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 459f7508-6bbd-4bd3-86ee-6248e15a8df9
2025-02-08 05:16:30,650 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 459f7508-6bbd-4bd3-86ee-6248e15a8df9
127.0.0.1 - - [08/Feb/2025 05:16:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:30,690 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 82706de9-96db-4ab6-afe1-7682727c625f
2025-02-08 05:16:30,768 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 82706de9-96db-4ab6-afe1-7682727c625f
127.0.0.1 - - [08/Feb/2025 05:16:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:30,963 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cdc5f1d2-8dd0-4ebb-9f5f-1d9c0e6140b2
2025-02-08 05:16:31,031 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4767a1a1-bb43-461f-a776-6e5ec096cc21
2025-02-08 05:16:31,142 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 222713dc-1178-43b3-a7ee-ac96958dc5d1
2025-02-08 05:16:31,178 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3e16af8a-490d-4f36-84f6-8072095d9217
2025-02-08 05:16:31,214 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cdc5f1d2-8dd0-4ebb-9f5f-1d9c0e6140b2
2025-02-08 05:16:31,228 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 222713dc-1178-43b3-a7ee-ac96958dc5d1
127.0.0.1 - - [08/Feb/2025 05:16:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:31,280 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3e16af8a-490d-4f36-84f6-8072095d9217
127.0.0.1 - - [08/Feb/2025 05:16:31] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:31,556 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4767a1a1-bb43-461f-a776-6e5ec096cc21
127.0.0.1 - - [08/Feb/2025 05:16:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:31,646 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 727544aa-7f2b-4da9-8056-7340ac606bee
2025-02-08 05:16:31,722 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 19bc21c2-87da-41ee-9e8f-915f91bb9b4c
2025-02-08 05:16:31,820 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 19bc21c2-87da-41ee-9e8f-915f91bb9b4c
127.0.0.1 - - [08/Feb/2025 05:16:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:32,008 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 727544aa-7f2b-4da9-8056-7340ac606bee
127.0.0.1 - - [08/Feb/2025 05:16:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:32,029 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 928337c6-1e39-44dd-bdef-9f73b5cd7b9d
2025-02-08 05:16:32,184 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 365ddecc-2d91-4209-88cd-270a79dcee58
2025-02-08 05:16:32,364 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d8b9744e-60ba-4549-bdf6-9f413538492e
2025-02-08 05:16:32,371 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 928337c6-1e39-44dd-bdef-9f73b5cd7b9d
127.0.0.1 - - [08/Feb/2025 05:16:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:32,439 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 365ddecc-2d91-4209-88cd-270a79dcee58
127.0.0.1 - - [08/Feb/2025 05:16:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:32,502 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d8b9744e-60ba-4549-bdf6-9f413538492e
127.0.0.1 - - [08/Feb/2025 05:16:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:32,660 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fd72aceb-35b6-43e0-8802-0c55a1fc552c
2025-02-08 05:16:32,666 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0439135a-bd4e-46f4-aa0f-3b4b62c5d926
2025-02-08 05:16:32,680 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 16ccacac-3b8d-4c03-b046-f31f92ad5bae
2025-02-08 05:16:32,701 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fd72aceb-35b6-43e0-8802-0c55a1fc552c
127.0.0.1 - - [08/Feb/2025 05:16:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:32,789 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 903038f8-91da-43d8-ad7d-d7168e9de0a4
2025-02-08 05:16:32,859 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0439135a-bd4e-46f4-aa0f-3b4b62c5d926
127.0.0.1 - - [08/Feb/2025 05:16:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:33,158 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e20a1b22-8bc6-455d-84f9-36d4a5b3078c
2025-02-08 05:16:33,192 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 903038f8-91da-43d8-ad7d-d7168e9de0a4
127.0.0.1 - - [08/Feb/2025 05:16:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:33,195 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 407e8cf4-2a3b-497c-aaf5-c4360d65a6fe
2025-02-08 05:16:33,208 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 89c852a2-dbfe-4eed-8388-fff5be38bc6e
2025-02-08 05:16:33,245 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e20a1b22-8bc6-455d-84f9-36d4a5b3078c
127.0.0.1 - - [08/Feb/2025 05:16:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:33,279 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 407e8cf4-2a3b-497c-aaf5-c4360d65a6fe
2025-02-08 05:16:33,293 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 16ccacac-3b8d-4c03-b046-f31f92ad5bae
127.0.0.1 - - [08/Feb/2025 05:16:33] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:33,532 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2425a9ac-9837-488e-8b97-e83d3c673210
2025-02-08 05:16:33,690 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c6e267ae-d18b-4c3a-b58c-cb38c8c1aa0f
2025-02-08 05:16:33,699 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b661810c-a0bb-40eb-8c02-b2315233f9be
2025-02-08 05:16:33,707 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 89c852a2-dbfe-4eed-8388-fff5be38bc6e
127.0.0.1 - - [08/Feb/2025 05:16:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:33,870 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b661810c-a0bb-40eb-8c02-b2315233f9be
127.0.0.1 - - [08/Feb/2025 05:16:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:33,892 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c6e267ae-d18b-4c3a-b58c-cb38c8c1aa0f
127.0.0.1 - - [08/Feb/2025 05:16:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:33,955 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a0b30cc3-f488-43a6-9870-f3854eb99df8
2025-02-08 05:16:33,962 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2425a9ac-9837-488e-8b97-e83d3c673210
127.0.0.1 - - [08/Feb/2025 05:16:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:34,191 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e44bbc38-90bc-45d6-8ac5-b13cf0b9a355
2025-02-08 05:16:34,265 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a0b30cc3-f488-43a6-9870-f3854eb99df8
127.0.0.1 - - [08/Feb/2025 05:16:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:34,348 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eaff7582-6405-48f5-959e-54402b06ca63
2025-02-08 05:16:34,405 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 54d3de6e-97d6-42c4-9fa0-d28010945364
2025-02-08 05:16:34,450 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eaff7582-6405-48f5-959e-54402b06ca63
127.0.0.1 - - [08/Feb/2025 05:16:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:34,548 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e44bbc38-90bc-45d6-8ac5-b13cf0b9a355
127.0.0.1 - - [08/Feb/2025 05:16:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:34,679 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 52f74987-260a-4bf4-9893-cd4a0e69f3c9
2025-02-08 05:16:34,793 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 54d3de6e-97d6-42c4-9fa0-d28010945364
127.0.0.1 - - [08/Feb/2025 05:16:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:34,800 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 52f74987-260a-4bf4-9893-cd4a0e69f3c9
127.0.0.1 - - [08/Feb/2025 05:16:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:34,935 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ffc3faea-cbaf-4a4b-bb0e-1968f2d1f392
2025-02-08 05:16:34,955 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 21a5cb6f-956c-4478-9720-4d80b78fd393
2025-02-08 05:16:35,133 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ffc3faea-cbaf-4a4b-bb0e-1968f2d1f392
127.0.0.1 - - [08/Feb/2025 05:16:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:35,143 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 09b13272-875e-46c4-b1e7-a5d64c27a329
2025-02-08 05:16:35,241 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 21a5cb6f-956c-4478-9720-4d80b78fd393
127.0.0.1 - - [08/Feb/2025 05:16:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:35,389 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a072a7c8-071a-466a-b3e0-ba008ed8d100
2025-02-08 05:16:35,404 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 09b13272-875e-46c4-b1e7-a5d64c27a329
127.0.0.1 - - [08/Feb/2025 05:16:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:35,536 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e71be2e9-0ce4-44ba-92fe-6bae2b736f2e
2025-02-08 05:16:35,543 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a072a7c8-071a-466a-b3e0-ba008ed8d100
127.0.0.1 - - [08/Feb/2025 05:16:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:35,582 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e71be2e9-0ce4-44ba-92fe-6bae2b736f2e
127.0.0.1 - - [08/Feb/2025 05:16:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:35,970 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 083efe98-9c38-489d-ad0b-6813eb4b8aa1
2025-02-08 05:16:36,062 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3893c9fa-72dd-4c71-bb01-aad89f7a027e
2025-02-08 05:16:36,078 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 083efe98-9c38-489d-ad0b-6813eb4b8aa1
127.0.0.1 - - [08/Feb/2025 05:16:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:36,221 - LoudVA - WARNING - [LoudServer] - Timeout reached for request db971750-1969-4230-8168-44821afd8c1f
2025-02-08 05:16:36,358 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: db971750-1969-4230-8168-44821afd8c1f
127.0.0.1 - - [08/Feb/2025 05:16:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:36,397 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d4802a31-91e4-4cf8-82d8-ba34f9077313
2025-02-08 05:16:36,714 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3893c9fa-72dd-4c71-bb01-aad89f7a027e
127.0.0.1 - - [08/Feb/2025 05:16:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:36,805 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b50fbe0d-91f4-434d-8f54-baed85e84556
2025-02-08 05:16:36,902 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d4802a31-91e4-4cf8-82d8-ba34f9077313
127.0.0.1 - - [08/Feb/2025 05:16:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:36,937 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e0498a94-3677-4a47-8e6a-674cbc95ac14
2025-02-08 05:16:36,968 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b50fbe0d-91f4-434d-8f54-baed85e84556
127.0.0.1 - - [08/Feb/2025 05:16:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:37,089 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f55318a9-5379-41b7-9df1-26418a7224c9
2025-02-08 05:16:37,191 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f55318a9-5379-41b7-9df1-26418a7224c9
127.0.0.1 - - [08/Feb/2025 05:16:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:37,358 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e0498a94-3677-4a47-8e6a-674cbc95ac14
127.0.0.1 - - [08/Feb/2025 05:16:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:37,530 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fa6c4f43-668e-414b-b128-68cdee458ecf
2025-02-08 05:16:37,934 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ee920fd2-7a2c-4597-8935-ef4ef47d1771
2025-02-08 05:16:37,940 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9e58135d-13a3-4d3b-af69-7d0d72563ee8
2025-02-08 05:16:37,973 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fa6c4f43-668e-414b-b128-68cdee458ecf
127.0.0.1 - - [08/Feb/2025 05:16:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:38,178 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9e58135d-13a3-4d3b-af69-7d0d72563ee8
127.0.0.1 - - [08/Feb/2025 05:16:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:38,219 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ee920fd2-7a2c-4597-8935-ef4ef47d1771
127.0.0.1 - - [08/Feb/2025 05:16:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:38,406 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e36ce552-5b56-4675-ab4f-4b538aed0f71
2025-02-08 05:16:38,559 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0b82e9bc-ce2f-4fe1-98b5-bce0f2e6188e
2025-02-08 05:16:38,600 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e36ce552-5b56-4675-ab4f-4b538aed0f71
127.0.0.1 - - [08/Feb/2025 05:16:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:38,616 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0b82e9bc-ce2f-4fe1-98b5-bce0f2e6188e
127.0.0.1 - - [08/Feb/2025 05:16:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:38,655 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c7a417ea-6c7f-4ed7-bc20-67e618738eca
2025-02-08 05:16:39,037 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f140ce5f-9ffa-4202-b036-afd69f22fc7c
2025-02-08 05:16:39,126 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c7a417ea-6c7f-4ed7-bc20-67e618738eca
127.0.0.1 - - [08/Feb/2025 05:16:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:39,272 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f140ce5f-9ffa-4202-b036-afd69f22fc7c
127.0.0.1 - - [08/Feb/2025 05:16:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:39,716 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0023d5fd-6504-4e0b-b15b-7a968168d874
2025-02-08 05:16:39,786 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 59ff6a07-9ad6-44f9-a8b2-9161d4c5d21b
2025-02-08 05:16:39,827 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f8ec66f2-876d-4492-91d9-1efa9af85f81
2025-02-08 05:16:39,929 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 20104285-7bc9-4157-865d-dd3f2f2380c4
2025-02-08 05:16:40,076 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 169bf9e6-1c17-48fb-93ca-33c806641aae
2025-02-08 05:16:40,137 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 20104285-7bc9-4157-865d-dd3f2f2380c4
127.0.0.1 - - [08/Feb/2025 05:16:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:40,150 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0023d5fd-6504-4e0b-b15b-7a968168d874
2025-02-08 05:16:40,244 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 169bf9e6-1c17-48fb-93ca-33c806641aae
127.0.0.1 - - [08/Feb/2025 05:16:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:40,252 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f8ec66f2-876d-4492-91d9-1efa9af85f81
127.0.0.1 - - [08/Feb/2025 05:16:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:40,403 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 11746f7a-11ab-43bd-b3b3-23a40c128c41
2025-02-08 05:16:40,453 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 59ff6a07-9ad6-44f9-a8b2-9161d4c5d21b
127.0.0.1 - - [08/Feb/2025 05:16:40] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:40,784 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 11746f7a-11ab-43bd-b3b3-23a40c128c41
127.0.0.1 - - [08/Feb/2025 05:16:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:40,796 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 27c0d612-71a7-442d-9db3-9dbe33679319
2025-02-08 05:16:40,841 - LoudVA - WARNING - [LoudServer] - Timeout reached for request faf66ef6-1f34-4fad-83e4-7b646bd3b8df
2025-02-08 05:16:40,852 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: faf66ef6-1f34-4fad-83e4-7b646bd3b8df
127.0.0.1 - - [08/Feb/2025 05:16:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:40,934 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 27c0d612-71a7-442d-9db3-9dbe33679319
127.0.0.1 - - [08/Feb/2025 05:16:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:41,256 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ef2db5e9-c478-44b0-9265-dc2eb108d3b2
2025-02-08 05:16:41,413 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ef2db5e9-c478-44b0-9265-dc2eb108d3b2
127.0.0.1 - - [08/Feb/2025 05:16:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:41,550 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8a3489aa-2e13-43aa-849e-b8599b13e502
2025-02-08 05:16:41,604 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fc46a0fd-30a8-46d3-bee4-b88c3a667740
2025-02-08 05:16:41,725 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fc46a0fd-30a8-46d3-bee4-b88c3a667740
127.0.0.1 - - [08/Feb/2025 05:16:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:42,048 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9c2e2070-015f-468f-a994-bc1dd8146842
2025-02-08 05:16:42,175 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9c2e2070-015f-468f-a994-bc1dd8146842
127.0.0.1 - - [08/Feb/2025 05:16:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:42,189 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0ccb8a30-62ff-40be-918c-e474abf231e3
2025-02-08 05:16:42,358 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8a3489aa-2e13-43aa-849e-b8599b13e502
127.0.0.1 - - [08/Feb/2025 05:16:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:42,568 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ffe0a9ff-7e6d-4e0b-b09b-7a06933781f0
2025-02-08 05:16:42,643 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 050bd2f8-cec9-4228-a163-748340c05455
2025-02-08 05:16:42,658 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0ccb8a30-62ff-40be-918c-e474abf231e3
127.0.0.1 - - [08/Feb/2025 05:16:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:42,750 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 050bd2f8-cec9-4228-a163-748340c05455
127.0.0.1 - - [08/Feb/2025 05:16:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:42,797 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ffe0a9ff-7e6d-4e0b-b09b-7a06933781f0
127.0.0.1 - - [08/Feb/2025 05:16:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:43,332 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c4c4e4dd-7620-4e29-a53f-349eb7fa9b63
2025-02-08 05:16:43,607 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c4c4e4dd-7620-4e29-a53f-349eb7fa9b63
127.0.0.1 - - [08/Feb/2025 05:16:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:43,729 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 96d28eb3-b97d-4cbf-b778-f99e5c6fa284
2025-02-08 05:16:43,904 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 96a364c8-e166-4d81-85cd-6e5a028e1aed
2025-02-08 05:16:43,997 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 82fdf8c7-e616-46a4-8d5d-f77ffdb51390
2025-02-08 05:16:44,071 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 96d28eb3-b97d-4cbf-b778-f99e5c6fa284
127.0.0.1 - - [08/Feb/2025 05:16:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:44,192 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fbde9446-8c5e-4c29-8060-9593901bfab5
2025-02-08 05:16:44,232 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 96a364c8-e166-4d81-85cd-6e5a028e1aed
127.0.0.1 - - [08/Feb/2025 05:16:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:44,305 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 06ed88a0-b3f8-463a-a369-95c0523f15e2
2025-02-08 05:16:44,393 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c8764557-67cf-41e3-b911-63c99e58f961
2025-02-08 05:16:44,450 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 82fdf8c7-e616-46a4-8d5d-f77ffdb51390
127.0.0.1 - - [08/Feb/2025 05:16:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:44,479 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 06ed88a0-b3f8-463a-a369-95c0523f15e2
127.0.0.1 - - [08/Feb/2025 05:16:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:44,509 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c8764557-67cf-41e3-b911-63c99e58f961
127.0.0.1 - - [08/Feb/2025 05:16:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:44,513 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fbde9446-8c5e-4c29-8060-9593901bfab5
2025-02-08 05:16:44,601 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b94b4667-21a6-4cf4-a754-7acffc24ee7c
127.0.0.1 - - [08/Feb/2025 05:16:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:44,644 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 25e37d90-5b26-48b1-b554-40cbf5596228
2025-02-08 05:16:44,849 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b94b4667-21a6-4cf4-a754-7acffc24ee7c
127.0.0.1 - - [08/Feb/2025 05:16:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:44,918 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 25e37d90-5b26-48b1-b554-40cbf5596228
127.0.0.1 - - [08/Feb/2025 05:16:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:45,076 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5c5728b8-e03a-41dc-a8be-aa05ebe1e070
2025-02-08 05:16:45,106 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f25969ce-e4ff-4a6a-b9ca-b986f30fb54e
2025-02-08 05:16:45,135 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8560a2e4-8aa0-42b8-9dbb-e63c234b47a8
2025-02-08 05:16:45,243 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f25969ce-e4ff-4a6a-b9ca-b986f30fb54e
2025-02-08 05:16:45,282 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8560a2e4-8aa0-42b8-9dbb-e63c234b47a8
127.0.0.1 - - [08/Feb/2025 05:16:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:45,357 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5c5728b8-e03a-41dc-a8be-aa05ebe1e070
127.0.0.1 - - [08/Feb/2025 05:16:45] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:45,491 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5069778a-1fa0-4318-9102-205d88b181c1
2025-02-08 05:16:45,502 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0ce03c59-f952-4a52-a46a-d49fa3adc3c7
2025-02-08 05:16:45,608 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0f9b65dd-d422-4812-8dbd-a5f38f7b6981
2025-02-08 05:16:45,655 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5069778a-1fa0-4318-9102-205d88b181c1
127.0.0.1 - - [08/Feb/2025 05:16:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:45,676 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0f9b65dd-d422-4812-8dbd-a5f38f7b6981
127.0.0.1 - - [08/Feb/2025 05:16:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:45,719 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 874bcc41-bca5-448c-a631-7291d0bf53ac
2025-02-08 05:16:45,722 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0ce03c59-f952-4a52-a46a-d49fa3adc3c7
127.0.0.1 - - [08/Feb/2025 05:16:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:45,999 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 24519e9b-9eaf-4c35-a783-4f1def62068f
2025-02-08 05:16:46,080 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4e19a916-d462-40da-8c64-a2833cffccfc
2025-02-08 05:16:46,086 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 24519e9b-9eaf-4c35-a783-4f1def62068f
127.0.0.1 - - [08/Feb/2025 05:16:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:46,176 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2c03bbf9-ace4-436b-a384-0fa27102223f
2025-02-08 05:16:46,184 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 96fe9137-c949-4956-a671-3992119d0213
2025-02-08 05:16:46,208 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 874bcc41-bca5-448c-a631-7291d0bf53ac
2025-02-08 05:16:46,269 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4e19a916-d462-40da-8c64-a2833cffccfc
2025-02-08 05:16:46,356 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 95136052-0810-4c83-889f-3f728b0f7f0f
2025-02-08 05:16:46,357 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 96fe9137-c949-4956-a671-3992119d0213
2025-02-08 05:16:46,399 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 514eb62f-f63d-4a29-a11a-a1f2c7e5d951
127.0.0.1 - - [08/Feb/2025 05:16:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:46,444 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2c03bbf9-ace4-436b-a384-0fa27102223f
127.0.0.1 - - [08/Feb/2025 05:16:46] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:46,511 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 514eb62f-f63d-4a29-a11a-a1f2c7e5d951
127.0.0.1 - - [08/Feb/2025 05:16:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:46,544 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e5a888f6-1079-4c8a-9814-27b7f255b269
127.0.0.1 - - [08/Feb/2025 05:16:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:46,566 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 95136052-0810-4c83-889f-3f728b0f7f0f
2025-02-08 05:16:46,673 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 39c53b0b-b76b-4fbe-8a07-8c310955e8df
127.0.0.1 - - [08/Feb/2025 05:16:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:46,892 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 39c53b0b-b76b-4fbe-8a07-8c310955e8df
127.0.0.1 - - [08/Feb/2025 05:16:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:46,906 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e5a888f6-1079-4c8a-9814-27b7f255b269
127.0.0.1 - - [08/Feb/2025 05:16:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:46,973 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6f884d0c-3879-44cd-9479-e5b2940ae4c1
2025-02-08 05:16:47,031 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 96c27d02-8ea1-4bcb-9189-ea5b60d1bb79
2025-02-08 05:16:47,081 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6f884d0c-3879-44cd-9479-e5b2940ae4c1
127.0.0.1 - - [08/Feb/2025 05:16:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:47,143 - LoudVA - WARNING - [LoudServer] - Timeout reached for request de59c05b-3cc1-408c-9257-89a255e4834b
2025-02-08 05:16:47,159 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 96c27d02-8ea1-4bcb-9189-ea5b60d1bb79
127.0.0.1 - - [08/Feb/2025 05:16:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:47,250 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: de59c05b-3cc1-408c-9257-89a255e4834b
127.0.0.1 - - [08/Feb/2025 05:16:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:47,304 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 43c1d24a-af13-45c2-bbfb-329d92d63c89
2025-02-08 05:16:47,440 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c5be6c9b-15d8-415b-b96d-53ead9178df5
2025-02-08 05:16:47,440 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c5be6c9b-15d8-415b-b96d-53ead9178df5
127.0.0.1 - - [08/Feb/2025 05:16:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:47,485 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3f876e8e-2351-46cd-844c-4ec903238a62
2025-02-08 05:16:47,542 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6eb8794e-b574-4eb5-89b6-beb178263f43
2025-02-08 05:16:47,566 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 43c1d24a-af13-45c2-bbfb-329d92d63c89
127.0.0.1 - - [08/Feb/2025 05:16:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:47,582 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3f876e8e-2351-46cd-844c-4ec903238a62
127.0.0.1 - - [08/Feb/2025 05:16:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:47,583 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6eb8794e-b574-4eb5-89b6-beb178263f43
2025-02-08 05:16:47,653 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eb5131c5-b6ab-4e92-8b9c-82e9be23da4d
127.0.0.1 - - [08/Feb/2025 05:16:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:47,788 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eb5131c5-b6ab-4e92-8b9c-82e9be23da4d
127.0.0.1 - - [08/Feb/2025 05:16:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:47,833 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c7a9c704-c33b-4a2d-b789-8ba518305e32
2025-02-08 05:16:47,888 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7a514463-0cad-4c5e-932e-f699468044fb
2025-02-08 05:16:47,894 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7a514463-0cad-4c5e-932e-f699468044fb
127.0.0.1 - - [08/Feb/2025 05:16:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:47,925 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c7a9c704-c33b-4a2d-b789-8ba518305e32
127.0.0.1 - - [08/Feb/2025 05:16:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:48,030 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 13512e39-6d1a-42f9-9a95-23054f8cc224
2025-02-08 05:16:48,095 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 00496cf2-33b2-4b88-a6d1-2b9887b6cb7b
2025-02-08 05:16:48,152 - LoudVA - WARNING - [LoudServer] - Timeout reached for request abc504db-6c8d-4893-9dfd-d8df831c9b34
2025-02-08 05:16:48,162 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: abc504db-6c8d-4893-9dfd-d8df831c9b34
127.0.0.1 - - [08/Feb/2025 05:16:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:48,247 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 00496cf2-33b2-4b88-a6d1-2b9887b6cb7b
127.0.0.1 - - [08/Feb/2025 05:16:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:48,334 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4e04972d-c6c1-4c26-965c-c12dbabe079f
2025-02-08 05:16:48,340 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 13512e39-6d1a-42f9-9a95-23054f8cc224
127.0.0.1 - - [08/Feb/2025 05:16:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:48,461 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4e04972d-c6c1-4c26-965c-c12dbabe079f
127.0.0.1 - - [08/Feb/2025 05:16:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:48,476 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 03779da1-426d-4a72-8e82-e4a3009cd801
2025-02-08 05:16:48,677 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 03779da1-426d-4a72-8e82-e4a3009cd801
127.0.0.1 - - [08/Feb/2025 05:16:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:48,684 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cd389837-c244-4304-beb0-479e2bf52ad9
2025-02-08 05:16:48,769 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cd389837-c244-4304-beb0-479e2bf52ad9
127.0.0.1 - - [08/Feb/2025 05:16:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:48,882 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e57c0b49-6d03-4507-9fcd-81b4172b0550
2025-02-08 05:16:49,015 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 95838757-5c20-4eef-a888-9f24f0b15b1e
2025-02-08 05:16:49,051 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e57c0b49-6d03-4507-9fcd-81b4172b0550
127.0.0.1 - - [08/Feb/2025 05:16:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:49,077 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 95838757-5c20-4eef-a888-9f24f0b15b1e
127.0.0.1 - - [08/Feb/2025 05:16:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:49,175 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 712e6478-e3e1-485e-bba8-9da7b7bb1ba3
2025-02-08 05:16:49,266 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5dd81706-b923-4a22-bc63-39a72e0e50a4
2025-02-08 05:16:49,347 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0ca71860-5486-4c61-9cb1-f18a739f95e3
2025-02-08 05:16:49,356 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c1a39b3e-705d-450a-b2f5-65852c572a80
2025-02-08 05:16:49,361 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 02ab0c81-6b60-46ca-b27b-c3077a75fbf3
2025-02-08 05:16:49,377 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 294799ce-1683-4144-b9ea-8fa0d4121c4a
2025-02-08 05:16:49,418 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 294799ce-1683-4144-b9ea-8fa0d4121c4a
127.0.0.1 - - [08/Feb/2025 05:16:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:49,427 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c1a39b3e-705d-450a-b2f5-65852c572a80
127.0.0.1 - - [08/Feb/2025 05:16:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:49,429 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5dd81706-b923-4a22-bc63-39a72e0e50a4
2025-02-08 05:16:49,502 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 712e6478-e3e1-485e-bba8-9da7b7bb1ba3
127.0.0.1 - - [08/Feb/2025 05:16:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:49,510 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0ca71860-5486-4c61-9cb1-f18a739f95e3
127.0.0.1 - - [08/Feb/2025 05:16:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:49,548 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1cf03b6f-5f59-425b-b07c-9f5f3e9696b6
127.0.0.1 - - [08/Feb/2025 05:16:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:49,674 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0f730d9e-a3e5-479d-98bc-1445a16109dc
2025-02-08 05:16:49,801 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1cf03b6f-5f59-425b-b07c-9f5f3e9696b6
127.0.0.1 - - [08/Feb/2025 05:16:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:49,907 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0f730d9e-a3e5-479d-98bc-1445a16109dc
127.0.0.1 - - [08/Feb/2025 05:16:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:49,955 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 02ab0c81-6b60-46ca-b27b-c3077a75fbf3
127.0.0.1 - - [08/Feb/2025 05:16:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:50,104 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b1380349-ee20-4a5e-be93-9a8c93cc3299
2025-02-08 05:16:50,165 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b1380349-ee20-4a5e-be93-9a8c93cc3299
127.0.0.1 - - [08/Feb/2025 05:16:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:50,187 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3172e519-7938-43e8-b2cb-2bce52336dcb
2025-02-08 05:16:50,247 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3172e519-7938-43e8-b2cb-2bce52336dcb
2025-02-08 05:16:50,257 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 33e9f0c3-776a-40ba-bde5-530cf502a1da
127.0.0.1 - - [08/Feb/2025 05:16:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:50,261 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 832f152b-158a-4cd7-b7f2-974fa3172843
2025-02-08 05:16:50,338 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 832f152b-158a-4cd7-b7f2-974fa3172843
127.0.0.1 - - [08/Feb/2025 05:16:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:50,458 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ee280408-cee1-4a38-8f5e-a547e30bdca7
2025-02-08 05:16:50,480 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c7f58ce6-24f2-4a65-b0e3-9981a7fdf790
2025-02-08 05:16:50,484 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7c0ec09b-0083-42d4-a36e-1a3c3b909ed8
2025-02-08 05:16:50,606 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ee280408-cee1-4a38-8f5e-a547e30bdca7
127.0.0.1 - - [08/Feb/2025 05:16:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:50,624 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 33e9f0c3-776a-40ba-bde5-530cf502a1da
127.0.0.1 - - [08/Feb/2025 05:16:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:50,642 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c7f58ce6-24f2-4a65-b0e3-9981a7fdf790
2025-02-08 05:16:50,678 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 27aaa68b-d3fa-49e8-ad2d-f022e1045e98
127.0.0.1 - - [08/Feb/2025 05:16:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:50,751 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fe844ada-9315-4716-8b5c-c989cf8c17c5
2025-02-08 05:16:50,859 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fe844ada-9315-4716-8b5c-c989cf8c17c5
127.0.0.1 - - [08/Feb/2025 05:16:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:50,955 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 76dade18-6d22-4765-b999-51d1e353cec2
2025-02-08 05:16:51,005 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 27aaa68b-d3fa-49e8-ad2d-f022e1045e98
127.0.0.1 - - [08/Feb/2025 05:16:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:51,041 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2a8da131-06dd-400f-ae91-8612d9aa99b3
2025-02-08 05:16:51,111 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7c0ec09b-0083-42d4-a36e-1a3c3b909ed8
127.0.0.1 - - [08/Feb/2025 05:16:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:51,112 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2a8da131-06dd-400f-ae91-8612d9aa99b3
127.0.0.1 - - [08/Feb/2025 05:16:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:51,168 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d31f52fa-22fc-47d5-bd41-45abaf49e957
2025-02-08 05:16:51,218 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1022b408-8c4f-4b34-85c4-cb3a762ac990
2025-02-08 05:16:51,231 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7cb9dd6a-3344-4214-a705-080082a6346e
2025-02-08 05:16:51,384 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1022b408-8c4f-4b34-85c4-cb3a762ac990
127.0.0.1 - - [08/Feb/2025 05:16:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:51,408 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 76dade18-6d22-4765-b999-51d1e353cec2
127.0.0.1 - - [08/Feb/2025 05:16:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:51,489 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 21269048-99d0-4011-bea4-daffee45f0b9
2025-02-08 05:16:51,518 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d31f52fa-22fc-47d5-bd41-45abaf49e957
127.0.0.1 - - [08/Feb/2025 05:16:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:51,531 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 674ccf40-29cc-413e-b2e9-1ba28b81be0d
2025-02-08 05:16:51,555 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 21269048-99d0-4011-bea4-daffee45f0b9
127.0.0.1 - - [08/Feb/2025 05:16:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:51,650 - LoudVA - WARNING - [LoudServer] - Timeout reached for request db9b8598-c04f-4016-aae3-b313209e7296
2025-02-08 05:16:51,651 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 674ccf40-29cc-413e-b2e9-1ba28b81be0d
2025-02-08 05:16:51,692 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cf0428ef-32a1-419f-92e5-6283e7f4796d
2025-02-08 05:16:51,709 - LoudVA - WARNING - [LoudServer] - Timeout reached for request db85e582-f9e3-4790-8855-e81d292c48b2
127.0.0.1 - - [08/Feb/2025 05:16:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:51,778 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cf0428ef-32a1-419f-92e5-6283e7f4796d
127.0.0.1 - - [08/Feb/2025 05:16:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:51,795 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7cb9dd6a-3344-4214-a705-080082a6346e
2025-02-08 05:16:51,915 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 11413c18-b490-4936-a1b6-8d1035979c41
127.0.0.1 - - [08/Feb/2025 05:16:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:51,921 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: db9b8598-c04f-4016-aae3-b313209e7296
127.0.0.1 - - [08/Feb/2025 05:16:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:52,096 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 74edcd26-b922-48f7-b832-f7f45607e313
2025-02-08 05:16:52,138 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: db85e582-f9e3-4790-8855-e81d292c48b2
2025-02-08 05:16:52,139 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 11413c18-b490-4936-a1b6-8d1035979c41
127.0.0.1 - - [08/Feb/2025 05:16:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:52,181 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 100a02e8-dd30-4c5e-a0f0-868f7411c740
127.0.0.1 - - [08/Feb/2025 05:16:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:52,228 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e21cc64e-1a9a-4413-bf92-42223c86cc1b
2025-02-08 05:16:52,247 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 33ce27e2-4deb-433c-971c-ca8bdfbe5bde
2025-02-08 05:16:52,320 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2901d640-2d44-43ce-91da-28fa32d542e3
2025-02-08 05:16:52,322 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 100a02e8-dd30-4c5e-a0f0-868f7411c740
127.0.0.1 - - [08/Feb/2025 05:16:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:52,350 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 74edcd26-b922-48f7-b832-f7f45607e313
127.0.0.1 - - [08/Feb/2025 05:16:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:52,386 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e030e901-918a-4edd-9db8-e9390189a01d
2025-02-08 05:16:52,400 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0013c855-6530-48c3-abc0-cd5b5cb5cd18
2025-02-08 05:16:52,428 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 33ce27e2-4deb-433c-971c-ca8bdfbe5bde
127.0.0.1 - - [08/Feb/2025 05:16:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:52,438 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e2e083af-9bc1-4dfa-bdd6-038a7bd76bab
2025-02-08 05:16:52,443 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2901d640-2d44-43ce-91da-28fa32d542e3
2025-02-08 05:16:52,525 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0013c855-6530-48c3-abc0-cd5b5cb5cd18
127.0.0.1 - - [08/Feb/2025 05:16:52] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:52,587 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 897daf87-e114-436d-88d0-8f369c8ffd5e
2025-02-08 05:16:52,596 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e2e083af-9bc1-4dfa-bdd6-038a7bd76bab
127.0.0.1 - - [08/Feb/2025 05:16:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:52,628 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 897daf87-e114-436d-88d0-8f369c8ffd5e
127.0.0.1 - - [08/Feb/2025 05:16:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:52,710 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a98c51b0-9f9e-45ee-b287-0e2d434b423b
2025-02-08 05:16:52,745 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a98c51b0-9f9e-45ee-b287-0e2d434b423b
127.0.0.1 - - [08/Feb/2025 05:16:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:52,805 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a9d3f88e-bf1b-4e54-98d5-eca699c55fe3
2025-02-08 05:16:52,852 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e030e901-918a-4edd-9db8-e9390189a01d
2025-02-08 05:16:52,901 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 19b19b62-bdfb-4a5b-aa12-8f054a6df9ea
2025-02-08 05:16:52,922 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 19b19b62-bdfb-4a5b-aa12-8f054a6df9ea
127.0.0.1 - - [08/Feb/2025 05:16:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:52,958 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e4e0f165-f4c4-4e2d-9a6b-5224af3e3a0a
2025-02-08 05:16:53,005 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e21cc64e-1a9a-4413-bf92-42223c86cc1b
127.0.0.1 - - [08/Feb/2025 05:16:53] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:53,126 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3955258b-d6c3-4726-b2af-47e1a85b53d2
2025-02-08 05:16:53,161 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 176f7a69-a314-40d2-9efc-66becafb6cd2
2025-02-08 05:16:53,213 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a9d3f88e-bf1b-4e54-98d5-eca699c55fe3
127.0.0.1 - - [08/Feb/2025 05:16:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:53,248 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 14b51b68-6f73-425e-8d7f-e4ffdbaa90b6
2025-02-08 05:16:53,248 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 176f7a69-a314-40d2-9efc-66becafb6cd2
127.0.0.1 - - [08/Feb/2025 05:16:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:53,339 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 14b51b68-6f73-425e-8d7f-e4ffdbaa90b6
127.0.0.1 - - [08/Feb/2025 05:16:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:53,390 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e4e0f165-f4c4-4e2d-9a6b-5224af3e3a0a
127.0.0.1 - - [08/Feb/2025 05:16:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:53,406 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3955258b-d6c3-4726-b2af-47e1a85b53d2
127.0.0.1 - - [08/Feb/2025 05:16:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:53,430 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 377e2550-dca8-4d86-a90e-a37151ed3010
2025-02-08 05:16:53,474 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 377e2550-dca8-4d86-a90e-a37151ed3010
127.0.0.1 - - [08/Feb/2025 05:16:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:53,504 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5400cbd7-ab23-4559-9e05-cb13e0ca3fd6
2025-02-08 05:16:53,581 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5400cbd7-ab23-4559-9e05-cb13e0ca3fd6
127.0.0.1 - - [08/Feb/2025 05:16:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:53,593 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 702fe46c-87b7-4206-a1cf-60bed87dcdc4
2025-02-08 05:16:53,712 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bd120581-028f-4266-b123-6b7db33e96e4
2025-02-08 05:16:53,760 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ac085cae-3515-4aeb-9b93-bb4a98413fb4
2025-02-08 05:16:53,773 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bd120581-028f-4266-b123-6b7db33e96e4
127.0.0.1 - - [08/Feb/2025 05:16:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:53,871 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 702fe46c-87b7-4206-a1cf-60bed87dcdc4
127.0.0.1 - - [08/Feb/2025 05:16:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:54,056 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7da9503b-3b6f-4b83-9a57-4c6928f2514e
2025-02-08 05:16:54,090 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fbc4d0f2-b99b-4f11-b205-4c88fb3a75e0
2025-02-08 05:16:54,106 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fa664e87-af46-418a-964a-d14dcd2087d6
2025-02-08 05:16:54,161 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fbc4d0f2-b99b-4f11-b205-4c88fb3a75e0
127.0.0.1 - - [08/Feb/2025 05:16:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:54,179 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8557cf09-b847-4e05-9309-72aaa13ad5e4
2025-02-08 05:16:54,221 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ac085cae-3515-4aeb-9b93-bb4a98413fb4
127.0.0.1 - - [08/Feb/2025 05:16:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:54,221 - LoudVA - WARNING - [LoudServer] - Timeout reached for request df628098-119d-40e2-b5b1-3ce6fb4ad48d
2025-02-08 05:16:54,235 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7da9503b-3b6f-4b83-9a57-4c6928f2514e
127.0.0.1 - - [08/Feb/2025 05:16:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:54,279 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8557cf09-b847-4e05-9309-72aaa13ad5e4
127.0.0.1 - - [08/Feb/2025 05:16:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:54,366 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: df628098-119d-40e2-b5b1-3ce6fb4ad48d
127.0.0.1 - - [08/Feb/2025 05:16:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:54,484 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fa664e87-af46-418a-964a-d14dcd2087d6
127.0.0.1 - - [08/Feb/2025 05:16:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:54,596 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 52a604fb-cf35-4334-a318-41686702d80c
2025-02-08 05:16:54,674 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 57dc1689-e39a-4d32-a546-f767e6cdbdce
2025-02-08 05:16:54,721 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a9efa0c3-7001-41fd-8778-d9b33a624ee3
2025-02-08 05:16:54,856 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 57dc1689-e39a-4d32-a546-f767e6cdbdce
127.0.0.1 - - [08/Feb/2025 05:16:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:54,888 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 52a604fb-cf35-4334-a318-41686702d80c
127.0.0.1 - - [08/Feb/2025 05:16:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:55,006 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a9efa0c3-7001-41fd-8778-d9b33a624ee3
127.0.0.1 - - [08/Feb/2025 05:16:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:55,049 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 17e7177e-6ce5-474c-a933-7909a9b3ee19
2025-02-08 05:16:55,081 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ef3d92ff-498d-4085-8a74-d3fd7b161412
2025-02-08 05:16:55,093 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 17e7177e-6ce5-474c-a933-7909a9b3ee19
127.0.0.1 - - [08/Feb/2025 05:16:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:55,172 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 519e3bb0-1710-4282-922a-7961407180c2
2025-02-08 05:16:55,191 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e813534a-075a-4a3d-ba4d-23e37ddc7edd
2025-02-08 05:16:55,199 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d0dae19e-1698-424d-a3c2-bb1ffc943d4b
2025-02-08 05:16:55,227 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e813534a-075a-4a3d-ba4d-23e37ddc7edd
127.0.0.1 - - [08/Feb/2025 05:16:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:55,279 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ca4704da-d0af-4841-b129-e534c962d211
2025-02-08 05:16:55,366 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ca4704da-d0af-4841-b129-e534c962d211
127.0.0.1 - - [08/Feb/2025 05:16:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:55,378 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ef3d92ff-498d-4085-8a74-d3fd7b161412
2025-02-08 05:16:55,428 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5938abde-8e89-4406-a649-988d39e7ed3e
127.0.0.1 - - [08/Feb/2025 05:16:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:55,455 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a685414f-9766-4e39-a1bb-f4ed66ac5103
2025-02-08 05:16:55,495 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d0dae19e-1698-424d-a3c2-bb1ffc943d4b
2025-02-08 05:16:55,581 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 519e3bb0-1710-4282-922a-7961407180c2
127.0.0.1 - - [08/Feb/2025 05:16:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:55,676 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 773902bd-d3b4-4c89-b174-6e48d43d1745
127.0.0.1 - - [08/Feb/2025 05:16:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:55,848 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 773902bd-d3b4-4c89-b174-6e48d43d1745
127.0.0.1 - - [08/Feb/2025 05:16:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:55,915 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 879fcfab-f2b1-41c8-ae58-40f45f4a3112
2025-02-08 05:16:55,985 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a685414f-9766-4e39-a1bb-f4ed66ac5103
127.0.0.1 - - [08/Feb/2025 05:16:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:55,990 - LoudVA - WARNING - [LoudServer] - Timeout reached for request da35d964-2011-4cdd-8d1a-9d80d5a13f88
2025-02-08 05:16:56,033 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 879fcfab-f2b1-41c8-ae58-40f45f4a3112
127.0.0.1 - - [08/Feb/2025 05:16:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:56,052 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: da35d964-2011-4cdd-8d1a-9d80d5a13f88
127.0.0.1 - - [08/Feb/2025 05:16:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:56,057 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fce690ff-7149-44f7-9166-cacb9e690cc5
2025-02-08 05:16:56,103 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4aa1c4c5-d2b6-48e3-ab76-7c47d53fd88b
2025-02-08 05:16:56,187 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5938abde-8e89-4406-a649-988d39e7ed3e
127.0.0.1 - - [08/Feb/2025 05:16:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:56,228 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aa52cd76-c4c7-448a-8b99-f0276f298628
2025-02-08 05:16:56,235 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 53e8dcad-61e1-42b1-b8f2-2195c1719415
2025-02-08 05:16:56,297 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fce690ff-7149-44f7-9166-cacb9e690cc5
127.0.0.1 - - [08/Feb/2025 05:16:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:56,398 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1fe32e9a-7f3f-4e4b-8cf1-6b5096610449
2025-02-08 05:16:56,416 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e6929824-9fd9-4cbb-ba05-d3cddce7dcf4
2025-02-08 05:16:56,434 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1fe32e9a-7f3f-4e4b-8cf1-6b5096610449
127.0.0.1 - - [08/Feb/2025 05:16:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:56,492 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b93d0777-63d5-493c-b641-f2ff4bb5998e
2025-02-08 05:16:56,515 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: aa52cd76-c4c7-448a-8b99-f0276f298628
127.0.0.1 - - [08/Feb/2025 05:16:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:56,582 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3b9c0e0a-4079-4445-be20-0a2530ffc55f
2025-02-08 05:16:56,608 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4aa1c4c5-d2b6-48e3-ab76-7c47d53fd88b
127.0.0.1 - - [08/Feb/2025 05:16:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:56,614 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b93d0777-63d5-493c-b641-f2ff4bb5998e
127.0.0.1 - - [08/Feb/2025 05:16:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:56,740 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c2a6a53d-7928-436e-b7da-99f379add3fa
2025-02-08 05:16:56,742 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 53e8dcad-61e1-42b1-b8f2-2195c1719415
127.0.0.1 - - [08/Feb/2025 05:16:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:56,775 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 70cd5466-f9d9-4273-992a-b9e90f6df566
2025-02-08 05:16:56,816 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 70cd5466-f9d9-4273-992a-b9e90f6df566
127.0.0.1 - - [08/Feb/2025 05:16:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:56,884 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e6929824-9fd9-4cbb-ba05-d3cddce7dcf4
127.0.0.1 - - [08/Feb/2025 05:16:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:56,889 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c2a6a53d-7928-436e-b7da-99f379add3fa
127.0.0.1 - - [08/Feb/2025 05:16:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:57,013 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d25d26fd-01ec-45d4-ac88-d867aecc4042
2025-02-08 05:16:57,081 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1b97526e-6011-4786-b0e1-86b07aff8069
2025-02-08 05:16:57,103 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3b9c0e0a-4079-4445-be20-0a2530ffc55f
127.0.0.1 - - [08/Feb/2025 05:16:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:57,179 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0f84c4ca-b161-4a57-9f52-6354eb4f48d0
2025-02-08 05:16:57,213 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d25d26fd-01ec-45d4-ac88-d867aecc4042
127.0.0.1 - - [08/Feb/2025 05:16:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:57,228 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1b97526e-6011-4786-b0e1-86b07aff8069
127.0.0.1 - - [08/Feb/2025 05:16:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:57,262 - LoudVA - WARNING - [LoudServer] - Timeout reached for request db95dac7-4abb-49fa-b572-090ab1f8ca9a
2025-02-08 05:16:57,309 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0f84c4ca-b161-4a57-9f52-6354eb4f48d0
127.0.0.1 - - [08/Feb/2025 05:16:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:57,390 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c2086ea1-020a-4dc9-b719-07dea2c15a27
2025-02-08 05:16:57,399 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b10509eb-8572-413f-9bd5-1ccae34a3316
2025-02-08 05:16:57,492 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b10509eb-8572-413f-9bd5-1ccae34a3316
127.0.0.1 - - [08/Feb/2025 05:16:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:57,534 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c2086ea1-020a-4dc9-b719-07dea2c15a27
127.0.0.1 - - [08/Feb/2025 05:16:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:57,609 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: db95dac7-4abb-49fa-b572-090ab1f8ca9a
127.0.0.1 - - [08/Feb/2025 05:16:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:57,695 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 99994f9a-8c67-4010-9150-1405257dd444
2025-02-08 05:16:57,808 - LoudVA - WARNING - [LoudServer] - Timeout reached for request df88deff-010d-40e2-b042-c375eeb27fc3
2025-02-08 05:16:57,823 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: df88deff-010d-40e2-b042-c375eeb27fc3
127.0.0.1 - - [08/Feb/2025 05:16:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:57,852 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 21a35a4e-cbe5-4117-8524-c6e9d893f52a
2025-02-08 05:16:57,963 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e3225417-0d64-4b16-a8cc-3e447f513001
2025-02-08 05:16:57,984 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 21a35a4e-cbe5-4117-8524-c6e9d893f52a
2025-02-08 05:16:58,021 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b953e51c-7fb1-4d28-8d29-97ba3bedcaa3
127.0.0.1 - - [08/Feb/2025 05:16:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:58,064 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e3225417-0d64-4b16-a8cc-3e447f513001
127.0.0.1 - - [08/Feb/2025 05:16:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:58,093 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 659ccc8c-4920-4136-a3cb-33e83909481e
2025-02-08 05:16:58,186 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d6e1213a-e3a1-4d28-a919-61bb4aff08df
2025-02-08 05:16:58,190 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 659ccc8c-4920-4136-a3cb-33e83909481e
2025-02-08 05:16:58,220 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 99994f9a-8c67-4010-9150-1405257dd444
127.0.0.1 - - [08/Feb/2025 05:16:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:58,257 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d6e1213a-e3a1-4d28-a919-61bb4aff08df
127.0.0.1 - - [08/Feb/2025 05:16:58] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:16:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:58,463 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f8c8c228-bf60-4ab7-b5a0-992b9549a363
2025-02-08 05:16:58,467 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2c1e4c97-7a90-4946-843a-51d4715d2dcc
2025-02-08 05:16:58,484 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c6be7a0c-8c79-4b96-99a7-e8ddb7e38cad
2025-02-08 05:16:58,493 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f8c8c228-bf60-4ab7-b5a0-992b9549a363
127.0.0.1 - - [08/Feb/2025 05:16:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:58,494 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b953e51c-7fb1-4d28-8d29-97ba3bedcaa3
2025-02-08 05:16:58,535 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a718c03f-bc8d-42f4-a0b2-b8e9793de8ee
2025-02-08 05:16:58,540 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c6be7a0c-8c79-4b96-99a7-e8ddb7e38cad
127.0.0.1 - - [08/Feb/2025 05:16:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:58,562 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a6926146-2bc1-45ab-b7f9-23c00b55c3fd
127.0.0.1 - - [08/Feb/2025 05:16:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:58,630 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2c1e4c97-7a90-4946-843a-51d4715d2dcc
127.0.0.1 - - [08/Feb/2025 05:16:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:58,713 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d00233e8-03d7-4901-aa67-7a0375e261ac
2025-02-08 05:16:58,718 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a718c03f-bc8d-42f4-a0b2-b8e9793de8ee
127.0.0.1 - - [08/Feb/2025 05:16:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:58,750 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4c51dcf4-00cc-4238-9572-8c5b031c804b
2025-02-08 05:16:58,794 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a6926146-2bc1-45ab-b7f9-23c00b55c3fd
127.0.0.1 - - [08/Feb/2025 05:16:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:58,836 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d00233e8-03d7-4901-aa67-7a0375e261ac
127.0.0.1 - - [08/Feb/2025 05:16:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:58,891 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4c51dcf4-00cc-4238-9572-8c5b031c804b
127.0.0.1 - - [08/Feb/2025 05:16:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:59,136 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 563ca9d7-1d63-49f1-ba67-61e10ffa558b
2025-02-08 05:16:59,157 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b2cc4be4-7a63-4686-97b8-dd42e3f40fea
2025-02-08 05:16:59,205 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 07a6a5ff-bf09-4f9c-9dfb-29f53c4ad557
2025-02-08 05:16:59,239 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b2cc4be4-7a63-4686-97b8-dd42e3f40fea
127.0.0.1 - - [08/Feb/2025 05:16:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:59,257 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2b2ac437-bf77-4be6-a14e-b135612d446d
2025-02-08 05:16:59,258 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 806ad83c-c31d-4c24-aca5-1144f874046c
2025-02-08 05:16:59,292 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 07a6a5ff-bf09-4f9c-9dfb-29f53c4ad557
127.0.0.1 - - [08/Feb/2025 05:16:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:59,415 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 806ad83c-c31d-4c24-aca5-1144f874046c
127.0.0.1 - - [08/Feb/2025 05:16:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:59,600 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 563ca9d7-1d63-49f1-ba67-61e10ffa558b
127.0.0.1 - - [08/Feb/2025 05:16:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:59,742 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 20a10bc6-f3fc-4f09-a19a-7383a2f6f690
2025-02-08 05:16:59,771 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2b2ac437-bf77-4be6-a14e-b135612d446d
127.0.0.1 - - [08/Feb/2025 05:16:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:16:59,971 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 20a10bc6-f3fc-4f09-a19a-7383a2f6f690
127.0.0.1 - - [08/Feb/2025 05:17:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:00,057 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6198bcdf-f8af-400d-8b37-e73f7b5fdcff
2025-02-08 05:17:00,088 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6198bcdf-f8af-400d-8b37-e73f7b5fdcff
127.0.0.1 - - [08/Feb/2025 05:17:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:00,112 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 48741bad-8ba3-4db3-a41e-b330d689c3ec
2025-02-08 05:17:00,147 - LoudVA - WARNING - [LoudServer] - Timeout reached for request db330f8e-558a-4150-a46b-d1e0e127afa9
2025-02-08 05:17:00,181 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b47f1e88-acd9-4518-ae47-5fe5c7a73bdd
2025-02-08 05:17:00,204 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a9fae07f-0f88-486e-baed-41b363269ee8
2025-02-08 05:17:00,228 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: db330f8e-558a-4150-a46b-d1e0e127afa9
2025-02-08 05:17:00,284 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 73729087-ae34-4a6a-8610-f469f152c299
2025-02-08 05:17:00,302 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 48741bad-8ba3-4db3-a41e-b330d689c3ec
127.0.0.1 - - [08/Feb/2025 05:17:00] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:17:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:00,361 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b47f1e88-acd9-4518-ae47-5fe5c7a73bdd
127.0.0.1 - - [08/Feb/2025 05:17:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:00,399 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2442f908-7495-4171-b3e5-c5d3c1686ec3
2025-02-08 05:17:00,467 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 73729087-ae34-4a6a-8610-f469f152c299
127.0.0.1 - - [08/Feb/2025 05:17:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:00,476 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 08328a7e-a73a-42b4-868f-d2880d23581f
2025-02-08 05:17:00,497 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a9fae07f-0f88-486e-baed-41b363269ee8
2025-02-08 05:17:00,506 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 837ab97a-2084-4f9d-b52f-bea791adf4b5
2025-02-08 05:17:00,509 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 965964c7-da09-4b49-92cf-722a58a3e7c0
127.0.0.1 - - [08/Feb/2025 05:17:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:00,510 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2442f908-7495-4171-b3e5-c5d3c1686ec3
2025-02-08 05:17:00,542 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 08328a7e-a73a-42b4-868f-d2880d23581f
127.0.0.1 - - [08/Feb/2025 05:17:00] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:17:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:00,615 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c7236ac3-c617-4c36-acfe-6b7a5f5f33e3
2025-02-08 05:17:00,661 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 74792917-d479-4503-bc72-549079b65604
2025-02-08 05:17:00,668 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 965964c7-da09-4b49-92cf-722a58a3e7c0
127.0.0.1 - - [08/Feb/2025 05:17:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:00,679 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 837ab97a-2084-4f9d-b52f-bea791adf4b5
127.0.0.1 - - [08/Feb/2025 05:17:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:00,731 - LoudVA - WARNING - [LoudServer] - Timeout reached for request dc7feb20-263e-4a35-bdc3-6e5661a33ceb
2025-02-08 05:17:00,796 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c7236ac3-c617-4c36-acfe-6b7a5f5f33e3
127.0.0.1 - - [08/Feb/2025 05:17:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:00,807 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fefaf329-a161-419a-9a58-91c79f3abc28
2025-02-08 05:17:00,817 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4b2a0790-9b82-4dd5-a9b6-2a49369159a4
2025-02-08 05:17:00,838 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: dc7feb20-263e-4a35-bdc3-6e5661a33ceb
127.0.0.1 - - [08/Feb/2025 05:17:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:01,032 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 74792917-d479-4503-bc72-549079b65604
127.0.0.1 - - [08/Feb/2025 05:17:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:01,086 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4b2a0790-9b82-4dd5-a9b6-2a49369159a4
127.0.0.1 - - [08/Feb/2025 05:17:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:01,128 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 35c96c8c-96ce-4b76-b9eb-b942ee0d6db4
2025-02-08 05:17:01,135 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3baf3eb6-cba4-409f-a28f-7da1cd8f2979
2025-02-08 05:17:01,145 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 865351e7-e60f-493f-9be9-cb28cfc6f1fe
2025-02-08 05:17:01,177 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fefaf329-a161-419a-9a58-91c79f3abc28
127.0.0.1 - - [08/Feb/2025 05:17:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:01,189 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b408f119-034c-48c4-9903-f704d5fb31a2
2025-02-08 05:17:01,195 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 865351e7-e60f-493f-9be9-cb28cfc6f1fe
127.0.0.1 - - [08/Feb/2025 05:17:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:01,251 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 35c96c8c-96ce-4b76-b9eb-b942ee0d6db4
127.0.0.1 - - [08/Feb/2025 05:17:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:01,300 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9fb8a1eb-5811-4c66-ace5-280b25166a09
2025-02-08 05:17:01,303 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3baf3eb6-cba4-409f-a28f-7da1cd8f2979
2025-02-08 05:17:01,316 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b408f119-034c-48c4-9903-f704d5fb31a2
127.0.0.1 - - [08/Feb/2025 05:17:01] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:17:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:01,406 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9cbbcb0f-e105-44fe-82a7-1562a6ff3846
2025-02-08 05:17:01,442 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9cbbcb0f-e105-44fe-82a7-1562a6ff3846
127.0.0.1 - - [08/Feb/2025 05:17:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:01,524 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9fb8a1eb-5811-4c66-ace5-280b25166a09
127.0.0.1 - - [08/Feb/2025 05:17:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:01,540 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8c2b04a3-42b5-4920-a2a4-6baadb7c205a
2025-02-08 05:17:01,583 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1f9f5f00-f864-4360-8595-9b8cb2b08148
2025-02-08 05:17:01,676 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b4fc96a1-1972-4379-ab9f-090b19cb53ea
2025-02-08 05:17:01,678 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8c2b04a3-42b5-4920-a2a4-6baadb7c205a
127.0.0.1 - - [08/Feb/2025 05:17:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:01,743 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bfa94bb9-fe19-4d36-8245-045e01fab560
2025-02-08 05:17:01,769 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1f9f5f00-f864-4360-8595-9b8cb2b08148
127.0.0.1 - - [08/Feb/2025 05:17:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:01,859 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b4fc96a1-1972-4379-ab9f-090b19cb53ea
127.0.0.1 - - [08/Feb/2025 05:17:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:01,910 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bfa94bb9-fe19-4d36-8245-045e01fab560
127.0.0.1 - - [08/Feb/2025 05:17:01] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:01,957 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7c704e07-57f3-4f80-bb8a-7a6b16a29610
2025-02-08 05:17:02,018 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7c704e07-57f3-4f80-bb8a-7a6b16a29610
127.0.0.1 - - [08/Feb/2025 05:17:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:02,155 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9d286915-81e2-4d64-9f2e-2a89e16521db
2025-02-08 05:17:02,267 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cec3286d-ecdd-42ee-add7-66084755341b
2025-02-08 05:17:02,335 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cec3286d-ecdd-42ee-add7-66084755341b
127.0.0.1 - - [08/Feb/2025 05:17:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:02,372 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2329f72c-ccbd-4a67-8551-b79a176f741f
2025-02-08 05:17:02,409 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aa7bfe5d-e98b-437c-b9d3-d32fd397cd50
2025-02-08 05:17:02,414 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9d286915-81e2-4d64-9f2e-2a89e16521db
127.0.0.1 - - [08/Feb/2025 05:17:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:02,445 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: aa7bfe5d-e98b-437c-b9d3-d32fd397cd50
127.0.0.1 - - [08/Feb/2025 05:17:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:02,615 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2329f72c-ccbd-4a67-8551-b79a176f741f
127.0.0.1 - - [08/Feb/2025 05:17:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:02,766 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5efdccda-810b-47ff-9278-d958aa4c0fed
2025-02-08 05:17:02,833 - LoudVA - WARNING - [LoudServer] - Timeout reached for request dc756f55-c57a-4f45-ac17-25291deb990b
2025-02-08 05:17:02,845 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5578b0cc-1443-4eaa-a9b3-3e423ab5e330
2025-02-08 05:17:02,845 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 054f43c2-cb20-4755-bdb0-6554a81b4e5c
2025-02-08 05:17:02,879 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: dc756f55-c57a-4f45-ac17-25291deb990b
127.0.0.1 - - [08/Feb/2025 05:17:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:02,992 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5578b0cc-1443-4eaa-a9b3-3e423ab5e330
127.0.0.1 - - [08/Feb/2025 05:17:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:02,997 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 054f43c2-cb20-4755-bdb0-6554a81b4e5c
127.0.0.1 - - [08/Feb/2025 05:17:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:03,009 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eec42048-0216-455e-b9d4-f3d2d5b31c71
2025-02-08 05:17:03,055 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5efdccda-810b-47ff-9278-d958aa4c0fed
2025-02-08 05:17:03,100 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 84c63a72-8425-4157-95a7-a80a1ddaf1cc
127.0.0.1 - - [08/Feb/2025 05:17:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:03,141 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ca73d80f-7dcc-4d38-9a58-11fa3d237f84
2025-02-08 05:17:03,161 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 84c63a72-8425-4157-95a7-a80a1ddaf1cc
127.0.0.1 - - [08/Feb/2025 05:17:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:03,177 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 801a6afe-de9f-4eae-93ef-03744ee6bd84
2025-02-08 05:17:03,192 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ca73d80f-7dcc-4d38-9a58-11fa3d237f84
127.0.0.1 - - [08/Feb/2025 05:17:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:03,198 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 801a6afe-de9f-4eae-93ef-03744ee6bd84
127.0.0.1 - - [08/Feb/2025 05:17:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:03,236 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6ed0235d-6ad7-42ab-9b26-d0a2e6563187
2025-02-08 05:17:03,335 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6ed0235d-6ad7-42ab-9b26-d0a2e6563187
127.0.0.1 - - [08/Feb/2025 05:17:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:03,391 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eec42048-0216-455e-b9d4-f3d2d5b31c71
127.0.0.1 - - [08/Feb/2025 05:17:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:03,453 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 98290110-a607-4ca1-aa32-f14c537d8e1a
2025-02-08 05:17:03,493 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 29964878-0ade-4898-81b3-880a3b4fa07c
2025-02-08 05:17:03,559 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 29964878-0ade-4898-81b3-880a3b4fa07c
127.0.0.1 - - [08/Feb/2025 05:17:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:03,612 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b71f94e3-a673-43f4-a6de-f95e64317e9e
2025-02-08 05:17:03,690 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 98290110-a607-4ca1-aa32-f14c537d8e1a
127.0.0.1 - - [08/Feb/2025 05:17:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:03,811 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0e0e6140-ab0a-4893-9b86-cb4745faeedd
2025-02-08 05:17:03,826 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b71f94e3-a673-43f4-a6de-f95e64317e9e
127.0.0.1 - - [08/Feb/2025 05:17:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:03,897 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0e0e6140-ab0a-4893-9b86-cb4745faeedd
127.0.0.1 - - [08/Feb/2025 05:17:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:03,907 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2443994b-036e-4c3e-aac8-e3a49719ab7e
2025-02-08 05:17:04,110 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2443994b-036e-4c3e-aac8-e3a49719ab7e
127.0.0.1 - - [08/Feb/2025 05:17:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:04,325 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2f1e88b4-874b-479b-8abc-35cc9c48a8cc
2025-02-08 05:17:04,382 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2f1e88b4-874b-479b-8abc-35cc9c48a8cc
127.0.0.1 - - [08/Feb/2025 05:17:04] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:17,704 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b7fbedd6-1098-4324-94ed-1b046333444f
2025-02-08 05:17:17,809 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7ed3384c-3371-48ea-a64d-344f738d1681
2025-02-08 05:17:17,811 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 36efe1bd-5219-4e48-8fee-bb51587f5c9f
2025-02-08 05:17:17,815 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b7fbedd6-1098-4324-94ed-1b046333444f
127.0.0.1 - - [08/Feb/2025 05:17:17] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:17,817 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 66749f59-05f8-454e-bcc3-f97bce2c5485
2025-02-08 05:17:17,907 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 36efe1bd-5219-4e48-8fee-bb51587f5c9f
127.0.0.1 - - [08/Feb/2025 05:17:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:17,916 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d81129a4-ac03-42a1-a2f6-d68f694bfd20
2025-02-08 05:17:17,993 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 66749f59-05f8-454e-bcc3-f97bce2c5485
127.0.0.1 - - [08/Feb/2025 05:17:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:17,998 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7ed3384c-3371-48ea-a64d-344f738d1681
127.0.0.1 - - [08/Feb/2025 05:17:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,079 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ababc6ae-347a-4299-bd1f-7c86aca04d57
2025-02-08 05:17:18,114 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d81129a4-ac03-42a1-a2f6-d68f694bfd20
127.0.0.1 - - [08/Feb/2025 05:17:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,136 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 92b54c53-2485-4fb5-b468-41cf6bdf4c2e
2025-02-08 05:17:18,213 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e5e9b3f5-2a67-423a-a53e-28717afba988
2025-02-08 05:17:18,221 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 74c71987-b75b-4b21-9f5f-27ff9958a511
2025-02-08 05:17:18,234 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f7ab2ee6-48a9-4caf-ad3f-3c550e57d73d
2025-02-08 05:17:18,259 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ababc6ae-347a-4299-bd1f-7c86aca04d57
127.0.0.1 - - [08/Feb/2025 05:17:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,302 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 673a1a1a-dbbc-49fd-94e2-cbc6510504e4
2025-02-08 05:17:18,311 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8fef8dd4-9116-4c6d-9a4a-b2bb4881a6b8
2025-02-08 05:17:18,340 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 19679b86-e889-48f2-85e0-a67870f8fc16
2025-02-08 05:17:18,355 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 92b54c53-2485-4fb5-b468-41cf6bdf4c2e
127.0.0.1 - - [08/Feb/2025 05:17:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,355 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 74c71987-b75b-4b21-9f5f-27ff9958a511
127.0.0.1 - - [08/Feb/2025 05:17:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,359 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c1fd51ac-24ff-4cf8-80b4-20934d3dec4b
2025-02-08 05:17:18,360 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2631126e-54d4-4fc3-9443-581c8680b5aa
2025-02-08 05:17:18,384 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e5e9b3f5-2a67-423a-a53e-28717afba988
127.0.0.1 - - [08/Feb/2025 05:17:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,401 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b611baaf-79e2-4dc3-8062-9b44f7962f0a
2025-02-08 05:17:18,415 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f7ab2ee6-48a9-4caf-ad3f-3c550e57d73d
127.0.0.1 - - [08/Feb/2025 05:17:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,421 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 673a1a1a-dbbc-49fd-94e2-cbc6510504e4
127.0.0.1 - - [08/Feb/2025 05:17:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,428 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fa063d66-7bab-4715-8901-524637509a29
2025-02-08 05:17:18,472 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8fef8dd4-9116-4c6d-9a4a-b2bb4881a6b8
127.0.0.1 - - [08/Feb/2025 05:17:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,528 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2fb9a4a2-e61e-45e0-8fef-1541b59f33d1
2025-02-08 05:17:18,550 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a3c014da-8e98-4215-b80a-2365a64ab4e1
2025-02-08 05:17:18,634 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 19679b86-e889-48f2-85e0-a67870f8fc16
127.0.0.1 - - [08/Feb/2025 05:17:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,676 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2631126e-54d4-4fc3-9443-581c8680b5aa
127.0.0.1 - - [08/Feb/2025 05:17:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,712 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fefa4c43-6171-44ef-b7f9-6a5e516eefaa
2025-02-08 05:17:18,712 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 889c90b1-dcf5-4e61-9ea5-deb893c103e6
2025-02-08 05:17:18,721 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 005ca185-059c-42bf-9559-af824b23bc4a
2025-02-08 05:17:18,773 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0cc3b2ba-e7ae-4ff2-8736-7a1db9fe3164
2025-02-08 05:17:18,787 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c9601c26-5170-4c50-8138-8892e0b2c285
2025-02-08 05:17:18,792 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c1fd51ac-24ff-4cf8-80b4-20934d3dec4b
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,844 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fa063d66-7bab-4715-8901-524637509a29
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,849 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a3c014da-8e98-4215-b80a-2365a64ab4e1
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,859 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a0b37843-e152-40f2-95a1-af7e0d2c9e71
2025-02-08 05:17:18,900 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b14e6e38-7c92-4ade-9b92-29880db1c203
2025-02-08 05:17:18,903 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d8938b0a-8b97-4c75-838e-0ed53719ab3c
2025-02-08 05:17:18,910 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b611baaf-79e2-4dc3-8062-9b44f7962f0a
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,915 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2fb9a4a2-e61e-45e0-8fef-1541b59f33d1
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,943 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 31146abf-3550-4cb3-9806-b639b29dcca9
2025-02-08 05:17:18,959 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6771486f-0e3f-4a5b-bda0-70c0a45b0f8b
2025-02-08 05:17:18,987 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 889c90b1-dcf5-4e61-9ea5-deb893c103e6
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:18,996 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 439f49a0-2072-4872-ae52-97324809d2a4
2025-02-08 05:17:19,015 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 959a1694-1aef-446c-bfa4-6a9f8ab72bcc
2025-02-08 05:17:19,043 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c9601c26-5170-4c50-8138-8892e0b2c285
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,077 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c3602c90-d2d8-4b93-92fc-777a1cf77ed3
2025-02-08 05:17:19,080 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a0b37843-e152-40f2-95a1-af7e0d2c9e71
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,098 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6bb314dd-678d-4723-a963-ff952a130c6f
2025-02-08 05:17:19,119 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fefa4c43-6171-44ef-b7f9-6a5e516eefaa
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,158 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0cc3b2ba-e7ae-4ff2-8736-7a1db9fe3164
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,181 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5e5bad69-4b61-4cf9-8739-085c6ce843cb
2025-02-08 05:17:19,198 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 880c7298-8370-4619-bc95-5d9a7eb10108
2025-02-08 05:17:19,199 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 42f55aef-11f9-4bc3-848c-3e4f7eb5d07d
2025-02-08 05:17:19,207 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b14e6e38-7c92-4ade-9b92-29880db1c203
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,236 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d8938b0a-8b97-4c75-838e-0ed53719ab3c
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,257 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 68c8bada-a06f-445a-8324-7babab4110a2
2025-02-08 05:17:19,259 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 31146abf-3550-4cb3-9806-b639b29dcca9
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,277 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3f176c4a-8948-4de9-8242-55797ab8f42b
2025-02-08 05:17:19,330 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 439f49a0-2072-4872-ae52-97324809d2a4
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,357 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6bb314dd-678d-4723-a963-ff952a130c6f
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,377 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 005ca185-059c-42bf-9559-af824b23bc4a
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,396 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6771486f-0e3f-4a5b-bda0-70c0a45b0f8b
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,416 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 959a1694-1aef-446c-bfa4-6a9f8ab72bcc
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,484 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d2f8cc4e-3fe8-4db4-9661-eb2062ac8864
2025-02-08 05:17:19,499 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 42f55aef-11f9-4bc3-848c-3e4f7eb5d07d
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,505 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3f176c4a-8948-4de9-8242-55797ab8f42b
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,509 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c3602c90-d2d8-4b93-92fc-777a1cf77ed3
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,514 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e5732764-268c-44fe-92f7-4ef4276b56be
2025-02-08 05:17:19,532 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 032de3ff-5c80-4264-8fca-bfdb749dd9ae
2025-02-08 05:17:19,534 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 880c7298-8370-4619-bc95-5d9a7eb10108
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,537 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 455a5224-15e2-4d75-b416-faea1d0553fc
2025-02-08 05:17:19,559 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6f40e5b8-adfe-42bf-9c5a-2b29ef2de683
2025-02-08 05:17:19,591 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5e5bad69-4b61-4cf9-8739-085c6ce843cb
127.0.0.1 - - [08/Feb/2025 05:17:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,612 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 68c8bada-a06f-445a-8324-7babab4110a2
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,676 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7e979b39-b026-4da7-acdf-a870b31d52b1
2025-02-08 05:17:19,733 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 28b04c79-5481-4e52-90e2-1bab7b53e6af
2025-02-08 05:17:19,734 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fbf065e3-0746-4fe6-9aac-97d2a9257775
2025-02-08 05:17:19,781 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c7d3bc56-9933-4ed7-9cf0-03675454f226
2025-02-08 05:17:19,783 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3f2eea8b-c7bf-443f-ad85-2e694f39f451
2025-02-08 05:17:19,844 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c9f44acb-3c24-42ba-8aef-5ba7069e0c01
2025-02-08 05:17:19,849 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3d66c1af-5a4f-4dd1-85d4-bbf5fe36dd5f
2025-02-08 05:17:19,865 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2640870e-241c-464d-9acc-1dc6472aee9b
2025-02-08 05:17:19,871 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b3d72f4e-7713-4414-8956-ae521bbfd8a9
2025-02-08 05:17:19,899 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d2f8cc4e-3fe8-4db4-9661-eb2062ac8864
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,967 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6f40e5b8-adfe-42bf-9c5a-2b29ef2de683
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,981 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e5732764-268c-44fe-92f7-4ef4276b56be
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:19,993 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7656be2c-c12d-4ce6-b738-f83bade54e79
2025-02-08 05:17:19,999 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ad15153e-3a3d-47ae-8dd4-549b9514dfa6
2025-02-08 05:17:20,009 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5c42b004-f6c4-415b-b8c4-9fcd45709290
2025-02-08 05:17:20,032 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5d4f861f-497c-4413-836e-0af1dcccdab2
2025-02-08 05:17:20,042 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 032de3ff-5c80-4264-8fca-bfdb749dd9ae
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,042 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 455a5224-15e2-4d75-b416-faea1d0553fc
2025-02-08 05:17:20,073 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5bf4fbb8-1af2-4733-94f1-a29618fe941e
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,102 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 02d1731d-b3bd-4d51-a1f1-eefe3361bfa3
2025-02-08 05:17:20,186 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7e979b39-b026-4da7-acdf-a870b31d52b1
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,195 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c7d3bc56-9933-4ed7-9cf0-03675454f226
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,210 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fbf065e3-0746-4fe6-9aac-97d2a9257775
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,229 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c0a92200-0aa4-4fda-97c9-0ce3247f80cd
2025-02-08 05:17:20,236 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3f2eea8b-c7bf-443f-ad85-2e694f39f451
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,253 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7d900231-a4a9-4a49-b8d6-f024e8686214
2025-02-08 05:17:20,272 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2640870e-241c-464d-9acc-1dc6472aee9b
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,286 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ce08dc81-91eb-4671-8f44-267d10097237
2025-02-08 05:17:20,287 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c9f44acb-3c24-42ba-8aef-5ba7069e0c01
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,308 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 37f832b4-9204-404e-b97e-029409d502ee
2025-02-08 05:17:20,350 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b3d72f4e-7713-4414-8956-ae521bbfd8a9
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,367 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f1ce23b5-c015-4ee7-a26b-c506a37b0c54
2025-02-08 05:17:20,368 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 28b04c79-5481-4e52-90e2-1bab7b53e6af
127.0.0.1 - - [08/Feb/2025 05:17:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,412 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0583f9b5-93de-4e09-99b9-66239626fb7b
2025-02-08 05:17:20,413 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 788406ee-9dc5-4ee0-827c-0e6d79699c21
2025-02-08 05:17:20,418 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a683e303-c20e-4602-a252-816eaae8348f
2025-02-08 05:17:20,450 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aa16beec-1c5e-45f6-a238-f2b3ce12058c
2025-02-08 05:17:20,494 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3a0b06d6-3053-4927-b25f-b982a1d6eb43
2025-02-08 05:17:20,517 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d1d566d5-2511-45c0-a306-2ce3e33a6579
2025-02-08 05:17:20,543 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5d4f861f-497c-4413-836e-0af1dcccdab2
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,547 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 16eea840-6e89-403d-a537-8d4c063adc49
2025-02-08 05:17:20,551 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7656be2c-c12d-4ce6-b738-f83bade54e79
2025-02-08 05:17:20,552 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5c42b004-f6c4-415b-b8c4-9fcd45709290
2025-02-08 05:17:20,572 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f3ddca80-9963-43f9-9c91-fb5068710a41
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,608 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5bf4fbb8-1af2-4733-94f1-a29618fe941e
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,618 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9b7a0d34-85f1-4dd5-9d93-271840fe1ac3
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,635 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 02d1731d-b3bd-4d51-a1f1-eefe3361bfa3
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,635 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3722c48f-e3b7-412b-835e-d626903e944a
2025-02-08 05:17:20,657 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3d66c1af-5a4f-4dd1-85d4-bbf5fe36dd5f
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,712 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2342386e-0c6b-45f0-9382-04eeff069a0c
2025-02-08 05:17:20,767 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7d900231-a4a9-4a49-b8d6-f024e8686214
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,805 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ad15153e-3a3d-47ae-8dd4-549b9514dfa6
2025-02-08 05:17:20,852 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c0a92200-0aa4-4fda-97c9-0ce3247f80cd
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,856 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 81bf27a6-1671-47d9-b976-a3bc2c43e8b9
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,893 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2459017a-225b-4e28-853a-358d5f90dab4
2025-02-08 05:17:20,894 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 37f832b4-9204-404e-b97e-029409d502ee
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,910 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9ff6116a-97d6-4b85-909f-0b5c8a95f4a8
2025-02-08 05:17:20,936 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e1e436f7-250e-4ece-9432-ccc687f37cbb
2025-02-08 05:17:20,956 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 788406ee-9dc5-4ee0-827c-0e6d79699c21
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,981 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: aa16beec-1c5e-45f6-a238-f2b3ce12058c
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,986 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f1ce23b5-c015-4ee7-a26b-c506a37b0c54
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:20,997 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3a0b06d6-3053-4927-b25f-b982a1d6eb43
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,012 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a67af062-9967-42db-8b74-13b8e43e16fe
2025-02-08 05:17:21,026 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d1d566d5-2511-45c0-a306-2ce3e33a6579
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,041 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0583f9b5-93de-4e09-99b9-66239626fb7b
2025-02-08 05:17:21,045 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ce08dc81-91eb-4671-8f44-267d10097237
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,046 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a683e303-c20e-4602-a252-816eaae8348f
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,049 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2d2ed84a-abb0-4222-9006-76534233faee
2025-02-08 05:17:21,080 - LoudVA - WARNING - [LoudServer] - Timeout reached for request dc949a56-5414-41d2-84b8-4e9f9aa77845
2025-02-08 05:17:21,107 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 16eea840-6e89-403d-a537-8d4c063adc49
127.0.0.1 - - [08/Feb/2025 05:17:21] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,112 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 51c2ce70-6b97-48f1-8a93-57b88fd08b1b
2025-02-08 05:17:21,158 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2adf1152-81b2-4541-9378-e4492d52687e
2025-02-08 05:17:21,246 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 05bb6975-6a89-4109-bc5d-00eb58638b78
2025-02-08 05:17:21,255 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f1ded016-9bdd-4864-8546-f4cd376f4dff
2025-02-08 05:17:21,276 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f3ddca80-9963-43f9-9c91-fb5068710a41
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,277 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8aa1b7fd-0002-4927-8544-8300b7fdc957
2025-02-08 05:17:21,281 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ce354862-e92f-4552-86e2-aee1ba2c955a
2025-02-08 05:17:21,286 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9b7a0d34-85f1-4dd5-9d93-271840fe1ac3
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,306 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c0957482-c65f-43e2-8284-3ed3ba4fca77
2025-02-08 05:17:21,332 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0758f14b-74f1-458e-960a-55784e2c04ce
2025-02-08 05:17:21,344 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9dbbec9c-1559-4cf9-98e3-c0d89dd164ac
2025-02-08 05:17:21,352 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e148152e-a2d1-4fae-aca0-eb0ef3562872
2025-02-08 05:17:21,361 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cdc4dca9-b705-4a48-93fd-211c05a1e543
2025-02-08 05:17:21,380 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 51520ca0-f020-4e05-9063-f11bf5a78e5e
2025-02-08 05:17:21,411 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2342386e-0c6b-45f0-9382-04eeff069a0c
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,414 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a76663c1-d4f2-4813-bb06-a3d4944791c1
2025-02-08 05:17:21,522 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1787d6e8-a005-4120-a373-5d4230f03c34
2025-02-08 05:17:21,533 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eef064aa-5aec-45e2-a1d6-ef9acfe555da
2025-02-08 05:17:21,573 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3722c48f-e3b7-412b-835e-d626903e944a
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,589 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 81bf27a6-1671-47d9-b976-a3bc2c43e8b9
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,752 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2459017a-225b-4e28-853a-358d5f90dab4
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,772 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e1e436f7-250e-4ece-9432-ccc687f37cbb
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,817 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9ff6116a-97d6-4b85-909f-0b5c8a95f4a8
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,926 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a67af062-9967-42db-8b74-13b8e43e16fe
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:21,941 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 08effd5c-e821-4c27-ac73-78a8eaf4af04
2025-02-08 05:17:21,962 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d7e739e6-c56a-4e41-bc6e-f8b56436caad
2025-02-08 05:17:22,022 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2d2ed84a-abb0-4222-9006-76534233faee
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,028 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2adf1152-81b2-4541-9378-e4492d52687e
2025-02-08 05:17:22,043 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9817f53e-cdcd-4da3-936b-05401652cbce
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,053 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 51c2ce70-6b97-48f1-8a93-57b88fd08b1b
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,058 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 05bb6975-6a89-4109-bc5d-00eb58638b78
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,058 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7943a224-5856-46ce-affa-1d4d4b5c9d9c
2025-02-08 05:17:22,073 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7941cf70-4fd0-4e8b-a6fa-72104c4ba847
2025-02-08 05:17:22,083 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: dc949a56-5414-41d2-84b8-4e9f9aa77845
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,109 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f1ded016-9bdd-4864-8546-f4cd376f4dff
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,109 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 33462f4c-2856-4b10-9939-88076508d376
2025-02-08 05:17:22,110 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8f08fb96-5f10-4d86-b080-ae228670c283
2025-02-08 05:17:22,115 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f532262e-123d-40da-9000-948c8f8578ad
2025-02-08 05:17:22,122 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 04b42c63-dfd4-4b10-9059-6abc2041df9c
2025-02-08 05:17:22,125 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1a7a27bd-e027-47be-b09c-dba6e9646d03
2025-02-08 05:17:22,127 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 65c18032-dbf4-4228-8491-e25c5c21053e
2025-02-08 05:17:22,174 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ce354862-e92f-4552-86e2-aee1ba2c955a
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,194 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8aa1b7fd-0002-4927-8544-8300b7fdc957
2025-02-08 05:17:22,225 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9dbbec9c-1559-4cf9-98e3-c0d89dd164ac
127.0.0.1 - - [08/Feb/2025 05:17:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,226 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5e359eaa-676a-4433-bfc4-0bb170b79cc4
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,236 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c0957482-c65f-43e2-8284-3ed3ba4fca77
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,245 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9f14f505-770a-48e1-9dc3-9e9d0ba833cb
2025-02-08 05:17:22,255 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cdc4dca9-b705-4a48-93fd-211c05a1e543
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,265 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a4ee07d1-07de-47ca-83cb-5b63610091dd
2025-02-08 05:17:22,272 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e148152e-a2d1-4fae-aca0-eb0ef3562872
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,315 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a8564427-5d0c-4ad9-9420-c382139f881c
2025-02-08 05:17:22,321 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0758f14b-74f1-458e-960a-55784e2c04ce
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,346 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 22fc3a62-8bc8-4137-9d01-f5a4925b29ad
2025-02-08 05:17:22,386 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 48346caa-92b9-430f-a031-b82bac77448f
2025-02-08 05:17:22,408 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eef064aa-5aec-45e2-a1d6-ef9acfe555da
2025-02-08 05:17:22,410 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 51520ca0-f020-4e05-9063-f11bf5a78e5e
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,412 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1787d6e8-a005-4120-a373-5d4230f03c34
2025-02-08 05:17:22,416 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c273fd87-c86c-4a25-94e7-38a523638498
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,426 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 503acabc-94a8-46bd-b6a7-037a7a277582
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,428 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a76663c1-d4f2-4813-bb06-a3d4944791c1
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,446 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cac6df43-5d0c-42d2-99bf-965fef798fce
2025-02-08 05:17:22,518 - LoudVA - WARNING - [LoudServer] - Timeout reached for request da3d09f7-2cb2-4c4e-9196-6ed42011d547
2025-02-08 05:17:22,582 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d7e739e6-c56a-4e41-bc6e-f8b56436caad
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,625 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5ce81ef8-f6a7-4445-991a-f25cca279d43
2025-02-08 05:17:22,628 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f63433e4-4d1d-4c39-9b47-66e8bbdf53f3
2025-02-08 05:17:22,637 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9817f53e-cdcd-4da3-936b-05401652cbce
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,678 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 93d62368-9162-49af-9edf-720da7509ac9
2025-02-08 05:17:22,685 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 553d1686-fe00-4ebe-a2b9-ee6a4e6b9a59
2025-02-08 05:17:22,709 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 08effd5c-e821-4c27-ac73-78a8eaf4af04
2025-02-08 05:17:22,725 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c2228548-c848-49a6-820f-8ff8d955d252
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,774 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 92ebf53b-f28b-496f-9c0c-5782f1873d50
2025-02-08 05:17:22,829 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7943a224-5856-46ce-affa-1d4d4b5c9d9c
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,891 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 04b42c63-dfd4-4b10-9059-6abc2041df9c
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,911 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8f08fb96-5f10-4d86-b080-ae228670c283
2025-02-08 05:17:22,915 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4f6efb4e-598f-4c90-b0d2-bc07c26c3eca
2025-02-08 05:17:22,936 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f532262e-123d-40da-9000-948c8f8578ad
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,952 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 33462f4c-2856-4b10-9939-88076508d376
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,962 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7941cf70-4fd0-4e8b-a6fa-72104c4ba847
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:22,979 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 65c18032-dbf4-4228-8491-e25c5c21053e
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,043 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1a7a27bd-e027-47be-b09c-dba6e9646d03
127.0.0.1 - - [08/Feb/2025 05:17:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,051 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e36b6922-200b-410b-8fe5-5b78fd5f3faa
2025-02-08 05:17:23,124 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5e359eaa-676a-4433-bfc4-0bb170b79cc4
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,130 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9f14f505-770a-48e1-9dc3-9e9d0ba833cb
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,219 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 19049516-b9ff-4585-ba0f-1a6045d4aee3
2025-02-08 05:17:23,272 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a4ee07d1-07de-47ca-83cb-5b63610091dd
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,312 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f10d08b2-b49c-4704-912b-3c488a1a07f1
2025-02-08 05:17:23,328 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 474d77c0-0078-4643-9a9e-b8c1657d4268
2025-02-08 05:17:23,363 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3b07f60a-7b88-4d74-b2d2-74339c04f31e
2025-02-08 05:17:23,375 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 48346caa-92b9-430f-a031-b82bac77448f
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,377 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 679df522-f4ec-43fc-a60f-61650934adfe
2025-02-08 05:17:23,381 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a8564427-5d0c-4ad9-9420-c382139f881c
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,404 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 22fc3a62-8bc8-4137-9d01-f5a4925b29ad
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,409 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d966937c-8336-4496-a92c-8abc19679f77
2025-02-08 05:17:23,503 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6d7cd568-a4d5-4911-9d01-12f0d5d5fc0d
2025-02-08 05:17:23,530 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fc54c90f-7706-4423-9893-81ef2d012ce3
2025-02-08 05:17:23,607 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 23f56c29-6abd-4119-b9b0-2ada3414cb27
2025-02-08 05:17:23,619 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 073b93d3-0782-43e3-b8ae-7669325063bc
2025-02-08 05:17:23,631 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 503acabc-94a8-46bd-b6a7-037a7a277582
2025-02-08 05:17:23,680 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cac6df43-5d0c-42d2-99bf-965fef798fce
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,685 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: da3d09f7-2cb2-4c4e-9196-6ed42011d547
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,695 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c273fd87-c86c-4a25-94e7-38a523638498
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,764 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 93d62368-9162-49af-9edf-720da7509ac9
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,769 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b3ab42be-c490-4269-9603-b733fc037dd8
2025-02-08 05:17:23,777 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f63433e4-4d1d-4c39-9b47-66e8bbdf53f3
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,793 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5ce81ef8-f6a7-4445-991a-f25cca279d43
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,796 - LoudVA - WARNING - [LoudServer] - Timeout reached for request af0653ad-b201-4e4b-b4c1-055617da4c5c
2025-02-08 05:17:23,855 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 756d0b05-e670-4c62-a739-27b3a95daec2
2025-02-08 05:17:23,881 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d66ea17f-9a5c-4299-8c61-4a0496672a64
2025-02-08 05:17:23,888 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 693adf6b-fa85-4580-a56f-9065ea721a5f
2025-02-08 05:17:23,914 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fffaaffb-44fa-4af1-8a11-65b9ec5113c6
2025-02-08 05:17:23,933 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 05a6d234-5ccd-4c49-9f20-ef699be14f65
2025-02-08 05:17:23,942 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c7993687-24c2-4d51-842a-2bb9360cd255
2025-02-08 05:17:23,955 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4f6efb4e-598f-4c90-b0d2-bc07c26c3eca
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,993 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 92ebf53b-f28b-496f-9c0c-5782f1873d50
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:23,998 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c2228548-c848-49a6-820f-8ff8d955d252
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,033 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 553d1686-fe00-4ebe-a2b9-ee6a4e6b9a59
2025-02-08 05:17:24,047 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5b2f55d1-48e3-4d2f-b367-02d9e3434de8
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,061 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e36b6922-200b-410b-8fe5-5b78fd5f3faa
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,111 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 474d77c0-0078-4643-9a9e-b8c1657d4268
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,126 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 19049516-b9ff-4585-ba0f-1a6045d4aee3
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,137 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 11cc3a9e-1456-4eb2-8d4a-6fc73253b23d
2025-02-08 05:17:24,191 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b5090cc4-a7fb-4eb3-8ade-be73c7115892
2025-02-08 05:17:24,229 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f7fd9541-4cab-4ada-9d60-91b0cfad28dc
2025-02-08 05:17:24,230 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bdc7ffd6-336c-417d-9d29-cb3f29016f72
2025-02-08 05:17:24,244 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 679df522-f4ec-43fc-a60f-61650934adfe
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,259 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 51a05249-d5df-4abb-b870-52ceb57cd794
2025-02-08 05:17:24,289 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3b07f60a-7b88-4d74-b2d2-74339c04f31e
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,304 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d966937c-8336-4496-a92c-8abc19679f77
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,305 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3e168ab7-e7fe-413e-a821-5192f05ff919
2025-02-08 05:17:24,310 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 23f56c29-6abd-4119-b9b0-2ada3414cb27
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,315 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fc54c90f-7706-4423-9893-81ef2d012ce3
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,319 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f10d08b2-b49c-4704-912b-3c488a1a07f1
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,343 - LoudVA - WARNING - [LoudServer] - Timeout reached for request afa9d34f-a5c2-4062-992b-08293e710f8d
2025-02-08 05:17:24,390 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 073b93d3-0782-43e3-b8ae-7669325063bc
127.0.0.1 - - [08/Feb/2025 05:17:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,400 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 860d559a-edf0-4576-9393-72064abdfba6
2025-02-08 05:17:24,422 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8d126fec-ab30-4cd2-b2dd-32ae146bd1e2
2025-02-08 05:17:24,446 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b3ab42be-c490-4269-9603-b733fc037dd8
2025-02-08 05:17:24,452 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 37933949-f456-4680-bd4a-f958381b9854
2025-02-08 05:17:24,465 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6d7cd568-a4d5-4911-9d01-12f0d5d5fc0d
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,507 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9cf0085d-015d-481c-9ab9-24112c8acab1
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,555 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 69e8c18b-0e37-4a0c-b3c2-86b1c9ebfb2c
2025-02-08 05:17:24,568 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 756d0b05-e670-4c62-a739-27b3a95daec2
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,632 - LoudVA - WARNING - [LoudServer] - Timeout reached for request dd9d2644-0a7f-419d-957b-dfdc43634aff
2025-02-08 05:17:24,644 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: af0653ad-b201-4e4b-b4c1-055617da4c5c
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,652 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d13bf853-b938-4d0c-989f-65614c6dceef
2025-02-08 05:17:24,689 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d66ea17f-9a5c-4299-8c61-4a0496672a64
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,705 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fffaaffb-44fa-4af1-8a11-65b9ec5113c6
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,707 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b6d03fdc-1dc7-4945-b42f-009e619bb203
2025-02-08 05:17:24,731 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5b2f55d1-48e3-4d2f-b367-02d9e3434de8
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,736 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c7993687-24c2-4d51-842a-2bb9360cd255
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,771 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 05a6d234-5ccd-4c49-9f20-ef699be14f65
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,797 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f01e5a92-ddac-41ff-b472-bc61bd947166
2025-02-08 05:17:24,800 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 693adf6b-fa85-4580-a56f-9065ea721a5f
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,806 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 11cc3a9e-1456-4eb2-8d4a-6fc73253b23d
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,841 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6daad80a-a990-48f9-8b73-1095eb32dea6
2025-02-08 05:17:24,890 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bdc7ffd6-336c-417d-9d29-cb3f29016f72
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,921 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 51a05249-d5df-4abb-b870-52ceb57cd794
2025-02-08 05:17:24,943 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b5090cc4-a7fb-4eb3-8ade-be73c7115892
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,961 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 860d559a-edf0-4576-9393-72064abdfba6
2025-02-08 05:17:24,967 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f7fd9541-4cab-4ada-9d60-91b0cfad28dc
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,977 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 59d3ed16-f777-4003-bfaa-713006e9b8f8
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:24,988 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 913f1f52-ac66-43b3-9350-008ca7b78d62
2025-02-08 05:17:25,010 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 97f70419-a5ce-43b0-8958-00e9306eb070
2025-02-08 05:17:25,018 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: afa9d34f-a5c2-4062-992b-08293e710f8d
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,053 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aa3d90ec-4e3c-4783-8acf-af325c7fa372
2025-02-08 05:17:25,061 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9cf0085d-015d-481c-9ab9-24112c8acab1
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,072 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 37933949-f456-4680-bd4a-f958381b9854
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,089 - LoudVA - WARNING - [LoudServer] - Timeout reached for request be06643d-4448-4a81-b3a5-68ca1f5ae355
2025-02-08 05:17:25,112 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 394e2898-629e-455f-bb49-ade9b35b8b56
2025-02-08 05:17:25,122 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3e168ab7-e7fe-413e-a821-5192f05ff919
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,173 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9c49e641-deb7-475c-8f1e-7d15c89ecd94
2025-02-08 05:17:25,196 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8d126fec-ab30-4cd2-b2dd-32ae146bd1e2
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,210 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 69e8c18b-0e37-4a0c-b3c2-86b1c9ebfb2c
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,210 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cd94470b-a9f7-42ca-a497-790a9a75ff6b
2025-02-08 05:17:25,212 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 65ebd16b-639e-4c98-9b16-a570a72f8029
2025-02-08 05:17:25,219 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d13bf853-b938-4d0c-989f-65614c6dceef
2025-02-08 05:17:25,229 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 927abca9-2942-4f2c-bff0-de2184e30c1f
2025-02-08 05:17:25,233 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 19f470fe-7320-4e9c-a2d1-c059964ec741
2025-02-08 05:17:25,238 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c4fa97c4-7539-4849-b686-3aa179954dff
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,242 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: dd9d2644-0a7f-419d-957b-dfdc43634aff
2025-02-08 05:17:25,351 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b6d03fdc-1dc7-4945-b42f-009e619bb203
2025-02-08 05:17:25,357 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b36f7927-6889-4793-8ae5-038641c9c28b
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,469 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c0ccaef2-434f-462b-9ca6-56d3fff8818d
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,471 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6daad80a-a990-48f9-8b73-1095eb32dea6
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,522 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f01e5a92-ddac-41ff-b472-bc61bd947166
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,583 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 59d3ed16-f777-4003-bfaa-713006e9b8f8
2025-02-08 05:17:25,615 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 913f1f52-ac66-43b3-9350-008ca7b78d62
127.0.0.1 - - [08/Feb/2025 05:17:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,615 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 97f70419-a5ce-43b0-8958-00e9306eb070
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,616 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 33984c30-97e7-4884-b305-1a17b7eb040a
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,642 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 64cacd1d-5394-4ce4-860b-55bd819071f7
2025-02-08 05:17:25,652 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: aa3d90ec-4e3c-4783-8acf-af325c7fa372
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,706 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 394e2898-629e-455f-bb49-ade9b35b8b56
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,719 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 81c98da1-e42b-4308-b654-73f21c6ebe01
2025-02-08 05:17:25,767 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6b3fed74-993d-4388-bd79-5f9fbab8a060
2025-02-08 05:17:25,771 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: be06643d-4448-4a81-b3a5-68ca1f5ae355
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,789 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9c49e641-deb7-475c-8f1e-7d15c89ecd94
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,810 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cd78cf8f-c868-423a-8081-552270488a18
2025-02-08 05:17:25,859 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 19f470fe-7320-4e9c-a2d1-c059964ec741
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,860 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cd94470b-a9f7-42ca-a497-790a9a75ff6b
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,896 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 20975fa5-63e2-45f3-a512-db2e3c861ada
2025-02-08 05:17:25,903 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 927abca9-2942-4f2c-bff0-de2184e30c1f
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,927 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 00196807-e4b5-4669-b04a-74e160caa852
2025-02-08 05:17:25,940 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ea5fe7c7-a454-4412-b8f4-ba61d723bda0
2025-02-08 05:17:25,949 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 65ebd16b-639e-4c98-9b16-a570a72f8029
2025-02-08 05:17:25,953 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c0ccaef2-434f-462b-9ca6-56d3fff8818d
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,966 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b36f7927-6889-4793-8ae5-038641c9c28b
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:25,990 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c4fa97c4-7539-4849-b686-3aa179954dff
2025-02-08 05:17:26,008 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9686c31e-3baa-4275-9bd9-41270188a73b
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,050 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2bdd81e2-5e0c-404c-a934-12fb62c54a81
2025-02-08 05:17:26,060 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3faf055b-a224-4d86-bb4f-9eea9d601770
2025-02-08 05:17:26,066 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0f5feedd-c6b1-4868-81bf-ceca58919e3e
2025-02-08 05:17:26,116 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 92e8459d-2a55-440c-a56f-d056c62f5ed4
2025-02-08 05:17:26,164 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fd7fdb3f-aa24-4ad5-9241-8b681d8b5d41
2025-02-08 05:17:26,214 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e46c6f74-51d7-41e3-84c0-080f46d666bb
2025-02-08 05:17:26,245 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 64cacd1d-5394-4ce4-860b-55bd819071f7
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,283 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 176e1a89-4f41-470a-b4d0-3c907023c46f
2025-02-08 05:17:26,298 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 33984c30-97e7-4884-b305-1a17b7eb040a
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,337 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1c251475-71b5-4da8-9774-8a89170952c9
2025-02-08 05:17:26,341 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 43efdad9-ebc9-43bd-91f7-2763dae594e8
2025-02-08 05:17:26,415 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6b3fed74-993d-4388-bd79-5f9fbab8a060
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,428 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 91d729ef-90e8-4915-bc91-97545044041b
2025-02-08 05:17:26,446 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cd78cf8f-c868-423a-8081-552270488a18
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,476 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 20975fa5-63e2-45f3-a512-db2e3c861ada
2025-02-08 05:17:26,494 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 00263d81-49e0-4aeb-9e69-d5111675f773
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,524 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 81c98da1-e42b-4308-b654-73f21c6ebe01
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,528 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9fdf04b6-3051-43e4-866e-b49526087b74
2025-02-08 05:17:26,534 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ea5fe7c7-a454-4412-b8f4-ba61d723bda0
127.0.0.1 - - [08/Feb/2025 05:17:26] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,540 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 00196807-e4b5-4669-b04a-74e160caa852
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,553 - LoudVA - WARNING - [LoudServer] - Timeout reached for request debe6dfc-e254-42fe-ae31-a9542f83e432
2025-02-08 05:17:26,590 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a2bae2be-708c-417b-9908-42168ab1a3f9
2025-02-08 05:17:26,648 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 553cdea5-9cd3-4284-8500-22bb32ad94a2
2025-02-08 05:17:26,685 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9686c31e-3baa-4275-9bd9-41270188a73b
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,693 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4b33f80f-54bc-4529-9ae5-70fd843eeda2
2025-02-08 05:17:26,747 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 92e8459d-2a55-440c-a56f-d056c62f5ed4
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,764 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4c99901a-1f3f-4820-88f0-d73793097f1e
2025-02-08 05:17:26,772 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 056e21a5-94ce-42e2-b2b4-3406ffc8e0f8
2025-02-08 05:17:26,777 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0f5feedd-c6b1-4868-81bf-ceca58919e3e
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,783 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aa7897f5-eb23-4875-be8b-1d5dc949c2da
2025-02-08 05:17:26,792 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e46c6f74-51d7-41e3-84c0-080f46d666bb
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,797 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fd7fdb3f-aa24-4ad5-9241-8b681d8b5d41
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,806 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2bdd81e2-5e0c-404c-a934-12fb62c54a81
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,810 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3faf055b-a224-4d86-bb4f-9eea9d601770
2025-02-08 05:17:26,868 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1c251475-71b5-4da8-9774-8a89170952c9
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,880 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 43efdad9-ebc9-43bd-91f7-2763dae594e8
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,903 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 176e1a89-4f41-470a-b4d0-3c907023c46f
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,947 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 91d729ef-90e8-4915-bc91-97545044041b
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:26,968 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eade7090-693e-4989-a86e-d9cc2d2836a5
2025-02-08 05:17:27,025 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9fdf04b6-3051-43e4-866e-b49526087b74
2025-02-08 05:17:27,059 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 00263d81-49e0-4aeb-9e69-d5111675f773
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:27,111 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 553cdea5-9cd3-4284-8500-22bb32ad94a2
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:27,132 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: debe6dfc-e254-42fe-ae31-a9542f83e432
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:27,184 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bd597790-3bb2-49a2-a477-930340cf6610
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:27,208 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 056e21a5-94ce-42e2-b2b4-3406ffc8e0f8
2025-02-08 05:17:27,223 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a2bae2be-708c-417b-9908-42168ab1a3f9
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:27,282 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 74f537e7-e02b-40c5-9333-008441d66206
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:27,282 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: aa7897f5-eb23-4875-be8b-1d5dc949c2da
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:27,293 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4c99901a-1f3f-4820-88f0-d73793097f1e
2025-02-08 05:17:27,315 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 13159a6b-63df-40ca-9006-cd7088bbe938
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:27,331 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4b33f80f-54bc-4529-9ae5-70fd843eeda2
2025-02-08 05:17:27,333 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 281943a1-145f-460b-965f-3b652789ed61
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:27,537 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f58b2342-1cd9-4df3-ae3b-b9a2b486f4a6
2025-02-08 05:17:27,578 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bd597790-3bb2-49a2-a477-930340cf6610
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:27,633 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eade7090-693e-4989-a86e-d9cc2d2836a5
127.0.0.1 - - [08/Feb/2025 05:17:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:27,760 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 587a1f1a-50cd-4d18-87b4-05dc2b6239cd
2025-02-08 05:17:27,767 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c387bc03-fa07-4aa0-88d5-71c6c58fbfa3
2025-02-08 05:17:27,776 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d21046f4-615a-4576-9fa0-6ab405550ca6
2025-02-08 05:17:27,792 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f92f8626-a98e-47d2-84c7-94680e9b257d
2025-02-08 05:17:27,812 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8d41b6d0-8c29-4eea-ad79-3e7f03d2cd30
2025-02-08 05:17:27,819 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 74f537e7-e02b-40c5-9333-008441d66206
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:27,837 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a72c3392-5b8f-4c56-bca6-63da74fe0d55
2025-02-08 05:17:27,864 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 23e95645-63ba-4c43-aa88-a2f3896b526b
2025-02-08 05:17:27,917 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 281943a1-145f-460b-965f-3b652789ed61
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:27,922 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 13159a6b-63df-40ca-9006-cd7088bbe938
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,006 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c387bc03-fa07-4aa0-88d5-71c6c58fbfa3
2025-02-08 05:17:28,025 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 587a1f1a-50cd-4d18-87b4-05dc2b6239cd
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,040 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d21046f4-615a-4576-9fa0-6ab405550ca6
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,040 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8d41b6d0-8c29-4eea-ad79-3e7f03d2cd30
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,050 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d2b9383b-2c71-4a39-a3db-3b162eb80ca7
2025-02-08 05:17:28,066 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 94f7ea11-98f3-4cd9-b964-6d971ee07e3f
2025-02-08 05:17:28,095 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a72c3392-5b8f-4c56-bca6-63da74fe0d55
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,113 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f58b2342-1cd9-4df3-ae3b-b9a2b486f4a6
2025-02-08 05:17:28,120 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c234565d-9a7f-4725-a7a6-3f3c70f23500
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,133 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f92f8626-a98e-47d2-84c7-94680e9b257d
2025-02-08 05:17:28,133 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 23e95645-63ba-4c43-aa88-a2f3896b526b
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,167 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6291f283-4c24-44ed-a1d8-896e718b2b8c
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,183 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f9a26a4c-2793-447e-8f5f-a33a7e72b257
2025-02-08 05:17:28,198 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d2b9383b-2c71-4a39-a3db-3b162eb80ca7
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,282 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6291f283-4c24-44ed-a1d8-896e718b2b8c
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,284 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 94f7ea11-98f3-4cd9-b964-6d971ee07e3f
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,310 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c234565d-9a7f-4725-a7a6-3f3c70f23500
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,372 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f9a26a4c-2793-447e-8f5f-a33a7e72b257
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,622 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b68fd57c-f6c6-468f-b840-e5f3f0e21b59
2025-02-08 05:17:28,634 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b68fd57c-f6c6-468f-b840-e5f3f0e21b59
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,650 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 12d52be0-5557-4938-8f3a-c9346f754620
2025-02-08 05:17:28,675 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4f1c42a8-f634-4568-b9d2-4217ce9b7bbd
2025-02-08 05:17:28,703 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4f1c42a8-f634-4568-b9d2-4217ce9b7bbd
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,720 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 12d52be0-5557-4938-8f3a-c9346f754620
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:28,937 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 11c0355e-f712-4113-af90-6f75ce0f4915
2025-02-08 05:17:28,952 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 11c0355e-f712-4113-af90-6f75ce0f4915
127.0.0.1 - - [08/Feb/2025 05:17:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:29,004 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 24d649db-f7ac-4257-874f-796a60754932
2025-02-08 05:17:29,048 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 24d649db-f7ac-4257-874f-796a60754932
127.0.0.1 - - [08/Feb/2025 05:17:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:29,447 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4d9855b0-aef5-4f7e-8643-4873431d5d5c
2025-02-08 05:17:29,464 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4d9855b0-aef5-4f7e-8643-4873431d5d5c
127.0.0.1 - - [08/Feb/2025 05:17:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:29,497 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f044532d-4d74-4a87-ad41-39d4e97a05d7
2025-02-08 05:17:29,517 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f044532d-4d74-4a87-ad41-39d4e97a05d7
127.0.0.1 - - [08/Feb/2025 05:17:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:29,576 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ce7839ff-a7a7-4955-a0ef-cf2f1bdba6cf
2025-02-08 05:17:29,611 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ce7839ff-a7a7-4955-a0ef-cf2f1bdba6cf
127.0.0.1 - - [08/Feb/2025 05:17:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:29,707 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a2f711d6-8a5d-485a-92e6-41fb6f7b9926
2025-02-08 05:17:29,710 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a2f711d6-8a5d-485a-92e6-41fb6f7b9926
127.0.0.1 - - [08/Feb/2025 05:17:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:30,251 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6774bf1e-41d6-4825-9519-9067df64f3d1
2025-02-08 05:17:30,309 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6774bf1e-41d6-4825-9519-9067df64f3d1
127.0.0.1 - - [08/Feb/2025 05:17:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:30,439 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 53865b0a-2e0f-474d-9b9d-d480cd95a19e
2025-02-08 05:17:30,492 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 53865b0a-2e0f-474d-9b9d-d480cd95a19e
127.0.0.1 - - [08/Feb/2025 05:17:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:30,520 - LoudVA - WARNING - [LoudServer] - Timeout reached for request be3831a3-9784-43b1-a3d4-808dd4679b55
2025-02-08 05:17:30,533 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: be3831a3-9784-43b1-a3d4-808dd4679b55
127.0.0.1 - - [08/Feb/2025 05:17:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:30,760 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6b9ff229-0456-464a-b800-896780bcb5ab
2025-02-08 05:17:30,867 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6b9ff229-0456-464a-b800-896780bcb5ab
127.0.0.1 - - [08/Feb/2025 05:17:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:31,039 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c4a170cf-cb97-4ef9-b831-ea144bd2981b
2025-02-08 05:17:31,156 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 20ab6df1-10b6-4f03-ae78-1822be38d010
2025-02-08 05:17:31,184 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c4a170cf-cb97-4ef9-b831-ea144bd2981b
2025-02-08 05:17:31,200 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 20ab6df1-10b6-4f03-ae78-1822be38d010
127.0.0.1 - - [08/Feb/2025 05:17:31] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:17:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:31,232 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7e3945a6-2bd7-42a4-878f-f00a69d9e28d
2025-02-08 05:17:31,253 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7e3945a6-2bd7-42a4-878f-f00a69d9e28d
127.0.0.1 - - [08/Feb/2025 05:17:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:31,555 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 22239e60-78e0-4490-acaf-1432dd1388e9
2025-02-08 05:17:31,560 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 22239e60-78e0-4490-acaf-1432dd1388e9
127.0.0.1 - - [08/Feb/2025 05:17:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:31,708 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 46463c93-dabb-40ea-af64-2eb629a82b73
2025-02-08 05:17:31,751 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 46463c93-dabb-40ea-af64-2eb629a82b73
127.0.0.1 - - [08/Feb/2025 05:17:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:31,805 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e4d08274-21ab-4190-8c19-62e1dacfa7c7
2025-02-08 05:17:31,820 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e4d08274-21ab-4190-8c19-62e1dacfa7c7
127.0.0.1 - - [08/Feb/2025 05:17:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:31,959 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 886b897e-8cae-4708-95c6-590621e5ece6
2025-02-08 05:17:32,017 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 886b897e-8cae-4708-95c6-590621e5ece6
127.0.0.1 - - [08/Feb/2025 05:17:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:32,095 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 33a73aa1-bab2-40b8-8aa2-e5fa60c0c666
2025-02-08 05:17:32,105 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cc504c6e-5952-47d8-8195-7e1690872dec
2025-02-08 05:17:32,112 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8708344a-decf-4fab-9002-fa4d27c501ae
2025-02-08 05:17:32,118 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 33a73aa1-bab2-40b8-8aa2-e5fa60c0c666
127.0.0.1 - - [08/Feb/2025 05:17:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:32,133 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cc504c6e-5952-47d8-8195-7e1690872dec
127.0.0.1 - - [08/Feb/2025 05:17:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:32,141 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6b453c6e-9b2c-47cd-bb66-17d7d060f52e
2025-02-08 05:17:32,155 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6b453c6e-9b2c-47cd-bb66-17d7d060f52e
127.0.0.1 - - [08/Feb/2025 05:17:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:32,158 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8708344a-decf-4fab-9002-fa4d27c501ae
127.0.0.1 - - [08/Feb/2025 05:17:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:32,546 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b6cf4d14-1038-4ae4-9b84-da527c95077e
2025-02-08 05:17:32,584 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b6cf4d14-1038-4ae4-9b84-da527c95077e
127.0.0.1 - - [08/Feb/2025 05:17:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:32,612 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3173d47a-4d04-4381-bbca-77060a04aabc
2025-02-08 05:17:32,624 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3173d47a-4d04-4381-bbca-77060a04aabc
127.0.0.1 - - [08/Feb/2025 05:17:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:32,692 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ed30e255-1b1b-4554-81c8-1aee68b7986d
2025-02-08 05:17:32,699 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ed30e255-1b1b-4554-81c8-1aee68b7986d
127.0.0.1 - - [08/Feb/2025 05:17:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:33,061 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 16ca308d-151b-4125-83b5-4b21fd9b13c2
2025-02-08 05:17:33,086 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 16ca308d-151b-4125-83b5-4b21fd9b13c2
127.0.0.1 - - [08/Feb/2025 05:17:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:33,135 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ae8b4ee3-08e3-48a6-8809-97fa931ab4af
2025-02-08 05:17:33,144 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ae8b4ee3-08e3-48a6-8809-97fa931ab4af
127.0.0.1 - - [08/Feb/2025 05:17:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:33,190 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e143a01a-e320-487b-aac4-19d7898497c1
2025-02-08 05:17:33,199 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e143a01a-e320-487b-aac4-19d7898497c1
127.0.0.1 - - [08/Feb/2025 05:17:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:33,434 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5d8993a3-2a22-4a5b-bb21-870e4c54137b
2025-02-08 05:17:33,440 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5d8993a3-2a22-4a5b-bb21-870e4c54137b
127.0.0.1 - - [08/Feb/2025 05:17:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:33,854 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 21c5aca4-762f-42b7-95b8-7117928cb3a9
2025-02-08 05:17:33,855 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 21c5aca4-762f-42b7-95b8-7117928cb3a9
127.0.0.1 - - [08/Feb/2025 05:17:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:33,918 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 50d67502-5234-413e-8305-8673759c9b4b
2025-02-08 05:17:33,924 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 50d67502-5234-413e-8305-8673759c9b4b
127.0.0.1 - - [08/Feb/2025 05:17:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:33,999 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2496e170-73a0-4970-aa19-8b2bdfaa6654
2025-02-08 05:17:34,029 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2496e170-73a0-4970-aa19-8b2bdfaa6654
127.0.0.1 - - [08/Feb/2025 05:17:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:34,199 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 04f16614-ea13-4242-85b7-8650c42206c5
2025-02-08 05:17:34,202 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 04f16614-ea13-4242-85b7-8650c42206c5
127.0.0.1 - - [08/Feb/2025 05:17:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:34,378 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ef6cc274-1b37-4255-b09c-159e59cf8504
2025-02-08 05:17:34,391 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ef6cc274-1b37-4255-b09c-159e59cf8504
127.0.0.1 - - [08/Feb/2025 05:17:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:34,451 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cab6f25b-ec4a-4abe-86ea-33f90890f569
2025-02-08 05:17:34,456 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 84b36ccd-69c1-49d9-8714-f71f3373fb17
2025-02-08 05:17:34,458 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cab6f25b-ec4a-4abe-86ea-33f90890f569
127.0.0.1 - - [08/Feb/2025 05:17:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:34,460 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 84b36ccd-69c1-49d9-8714-f71f3373fb17
127.0.0.1 - - [08/Feb/2025 05:17:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:34,861 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9069b410-8b01-4d25-9c7d-b228dd1e49f7
2025-02-08 05:17:34,881 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9069b410-8b01-4d25-9c7d-b228dd1e49f7
127.0.0.1 - - [08/Feb/2025 05:17:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:34,927 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ed7ab881-abd6-406c-98af-4279d513da1f
2025-02-08 05:17:34,930 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ed7ab881-abd6-406c-98af-4279d513da1f
127.0.0.1 - - [08/Feb/2025 05:17:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:35,586 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 17391de6-1c4e-46be-866a-a1dbd1b288e1
2025-02-08 05:17:35,603 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 17391de6-1c4e-46be-866a-a1dbd1b288e1
127.0.0.1 - - [08/Feb/2025 05:17:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:35,859 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bf5b011c-4ff3-4f39-bee0-9c6f5ad2f977
2025-02-08 05:17:35,872 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bf5b011c-4ff3-4f39-bee0-9c6f5ad2f977
127.0.0.1 - - [08/Feb/2025 05:17:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:35,882 - LoudVA - WARNING - [LoudServer] - Timeout reached for request aca6f0b1-f24c-4f3d-94e3-a46b405f558d
2025-02-08 05:17:35,900 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: aca6f0b1-f24c-4f3d-94e3-a46b405f558d
127.0.0.1 - - [08/Feb/2025 05:17:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:36,077 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 26e2c520-f7cd-4a4e-a41c-a8c650bf6ab0
2025-02-08 05:17:36,085 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 26e2c520-f7cd-4a4e-a41c-a8c650bf6ab0
127.0.0.1 - - [08/Feb/2025 05:17:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:36,293 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c0875d83-457c-4779-9709-14e9933801af
2025-02-08 05:17:36,313 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c0875d83-457c-4779-9709-14e9933801af
127.0.0.1 - - [08/Feb/2025 05:17:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:36,324 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1e67f483-888f-4b9e-8531-02366c9f7452
2025-02-08 05:17:36,337 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1e67f483-888f-4b9e-8531-02366c9f7452
127.0.0.1 - - [08/Feb/2025 05:17:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:36,368 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 61e34f7d-0085-4c30-b0b3-7fbfbe27080c
2025-02-08 05:17:36,402 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 61e34f7d-0085-4c30-b0b3-7fbfbe27080c
127.0.0.1 - - [08/Feb/2025 05:17:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:36,435 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 24d7f607-3ee9-4ace-ba7f-39ffc7302342
2025-02-08 05:17:36,468 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 24d7f607-3ee9-4ace-ba7f-39ffc7302342
127.0.0.1 - - [08/Feb/2025 05:17:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:36,686 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9064ee56-e80e-46f2-9825-adf67df5554d
2025-02-08 05:17:36,717 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9064ee56-e80e-46f2-9825-adf67df5554d
127.0.0.1 - - [08/Feb/2025 05:17:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:37,067 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a02082a2-3ce8-41b0-a0a4-7c7bb426ec02
2025-02-08 05:17:37,094 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a02082a2-3ce8-41b0-a0a4-7c7bb426ec02
127.0.0.1 - - [08/Feb/2025 05:17:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:37,257 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9b3b3d0e-0bce-4352-bbc0-63e761e6dca7
2025-02-08 05:17:37,273 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9b3b3d0e-0bce-4352-bbc0-63e761e6dca7
127.0.0.1 - - [08/Feb/2025 05:17:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:37,535 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8a17fea0-01b5-4480-8a3b-f573ddf2b2d6
2025-02-08 05:17:37,563 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8a17fea0-01b5-4480-8a3b-f573ddf2b2d6
127.0.0.1 - - [08/Feb/2025 05:17:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:37,584 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a7cec072-0d5c-4252-a280-17c4af62d8ed
2025-02-08 05:17:37,607 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a7cec072-0d5c-4252-a280-17c4af62d8ed
127.0.0.1 - - [08/Feb/2025 05:17:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:37,626 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9a05201f-cbef-409f-95e1-6b01d3db99ee
2025-02-08 05:17:37,641 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9a05201f-cbef-409f-95e1-6b01d3db99ee
127.0.0.1 - - [08/Feb/2025 05:17:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:37,777 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 066fd1b1-925d-4fd9-9a62-8f1b048ae688
2025-02-08 05:17:37,791 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 066fd1b1-925d-4fd9-9a62-8f1b048ae688
127.0.0.1 - - [08/Feb/2025 05:17:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:38,003 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 202b4d68-f51b-4467-9601-40b6111a211b
2025-02-08 05:17:38,008 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 202b4d68-f51b-4467-9601-40b6111a211b
127.0.0.1 - - [08/Feb/2025 05:17:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:38,181 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b80600a9-c009-4fde-885d-1b14f2901857
2025-02-08 05:17:38,192 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b80600a9-c009-4fde-885d-1b14f2901857
127.0.0.1 - - [08/Feb/2025 05:17:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:38,271 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f549cb38-bd3c-43ca-88f7-35387a24d4cb
2025-02-08 05:17:38,282 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f549cb38-bd3c-43ca-88f7-35387a24d4cb
127.0.0.1 - - [08/Feb/2025 05:17:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:38,432 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1f5fcfbc-6ec0-4560-b226-f2db6bc0e871
2025-02-08 05:17:38,468 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1f5fcfbc-6ec0-4560-b226-f2db6bc0e871
127.0.0.1 - - [08/Feb/2025 05:17:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:38,783 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 230e82aa-ca8a-4183-9895-a4274413c487
2025-02-08 05:17:38,793 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6c14c3b7-b979-4708-832c-e5f842a01475
2025-02-08 05:17:38,813 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 230e82aa-ca8a-4183-9895-a4274413c487
127.0.0.1 - - [08/Feb/2025 05:17:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:38,830 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6c14c3b7-b979-4708-832c-e5f842a01475
127.0.0.1 - - [08/Feb/2025 05:17:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:39,129 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 610bff46-ca38-41ff-b5d5-d462fffbe211
2025-02-08 05:17:39,189 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9187d4d0-c186-45df-872c-12af82455380
2025-02-08 05:17:39,196 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 610bff46-ca38-41ff-b5d5-d462fffbe211
127.0.0.1 - - [08/Feb/2025 05:17:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:39,202 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9187d4d0-c186-45df-872c-12af82455380
127.0.0.1 - - [08/Feb/2025 05:17:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:39,293 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1b395946-06b7-4bc4-8cd6-a1a9a5128a49
2025-02-08 05:17:39,308 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1b395946-06b7-4bc4-8cd6-a1a9a5128a49
127.0.0.1 - - [08/Feb/2025 05:17:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:39,656 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 81ad9784-2196-4241-94e4-e65a9241bc71
2025-02-08 05:17:39,664 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 81ad9784-2196-4241-94e4-e65a9241bc71
127.0.0.1 - - [08/Feb/2025 05:17:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:39,916 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5700ffad-76af-43bf-8406-05d70ed5c40d
2025-02-08 05:17:39,952 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5700ffad-76af-43bf-8406-05d70ed5c40d
127.0.0.1 - - [08/Feb/2025 05:17:39] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:40,159 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3d652c1c-fafe-4a9a-a00c-9bd264d33657
2025-02-08 05:17:40,190 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3d652c1c-fafe-4a9a-a00c-9bd264d33657
127.0.0.1 - - [08/Feb/2025 05:17:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:40,343 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9f203a69-e93b-4c4b-82c8-be4bec707d1f
2025-02-08 05:17:40,402 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 59803dce-c232-4787-9919-44def8e3e6d7
2025-02-08 05:17:40,414 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9f203a69-e93b-4c4b-82c8-be4bec707d1f
127.0.0.1 - - [08/Feb/2025 05:17:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:40,427 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f633eb13-31df-407e-b4a8-43ddd7441f20
2025-02-08 05:17:40,428 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 59803dce-c232-4787-9919-44def8e3e6d7
127.0.0.1 - - [08/Feb/2025 05:17:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:40,447 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f633eb13-31df-407e-b4a8-43ddd7441f20
127.0.0.1 - - [08/Feb/2025 05:17:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:40,603 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f190355a-4308-4c8d-8001-b18c4c441a7f
2025-02-08 05:17:40,621 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f190355a-4308-4c8d-8001-b18c4c441a7f
127.0.0.1 - - [08/Feb/2025 05:17:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:40,891 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c6d51216-4d48-4327-b3bb-bef8e18d4c22
2025-02-08 05:17:40,900 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c6d51216-4d48-4327-b3bb-bef8e18d4c22
127.0.0.1 - - [08/Feb/2025 05:17:40] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:40,995 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5af0fe70-164a-4a4c-95f7-2e050087b7c9
2025-02-08 05:17:41,001 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5af0fe70-164a-4a4c-95f7-2e050087b7c9
127.0.0.1 - - [08/Feb/2025 05:17:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:41,250 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3482c24c-f757-49ac-ae0c-3a163e8cf855
2025-02-08 05:17:41,271 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3482c24c-f757-49ac-ae0c-3a163e8cf855
127.0.0.1 - - [08/Feb/2025 05:17:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:41,491 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6609001e-ed9a-4781-9b1f-6532f1d11ea1
2025-02-08 05:17:41,492 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 438a3b21-3246-4717-ad8c-b53b89cb25cb
2025-02-08 05:17:41,498 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 438a3b21-3246-4717-ad8c-b53b89cb25cb
127.0.0.1 - - [08/Feb/2025 05:17:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:41,537 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6609001e-ed9a-4781-9b1f-6532f1d11ea1
127.0.0.1 - - [08/Feb/2025 05:17:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:41,560 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0d8efc5e-7daa-49db-a8c7-e3a6e23aa5ec
2025-02-08 05:17:41,566 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0d8efc5e-7daa-49db-a8c7-e3a6e23aa5ec
127.0.0.1 - - [08/Feb/2025 05:17:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:41,567 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 769cfae3-86b4-4b42-86b2-f58b911253ef
2025-02-08 05:17:41,575 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 769cfae3-86b4-4b42-86b2-f58b911253ef
127.0.0.1 - - [08/Feb/2025 05:17:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:41,871 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ee474beb-6a43-4bd6-997c-418098823761
2025-02-08 05:17:41,880 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ee474beb-6a43-4bd6-997c-418098823761
127.0.0.1 - - [08/Feb/2025 05:17:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:41,915 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 913c4436-2123-4edd-a5c2-ba5ac14db664
2025-02-08 05:17:41,917 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 913c4436-2123-4edd-a5c2-ba5ac14db664
127.0.0.1 - - [08/Feb/2025 05:17:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:42,084 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e01c00a8-f30c-4c6c-92f8-c8e53e1e86b3
2025-02-08 05:17:42,093 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e01c00a8-f30c-4c6c-92f8-c8e53e1e86b3
127.0.0.1 - - [08/Feb/2025 05:17:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:42,265 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8dd28339-aa24-44c0-9a66-f4f9a81e2994
2025-02-08 05:17:42,277 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8dd28339-aa24-44c0-9a66-f4f9a81e2994
127.0.0.1 - - [08/Feb/2025 05:17:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:42,336 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9b659d74-6156-4d19-8bea-e4362f413049
2025-02-08 05:17:42,384 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9b659d74-6156-4d19-8bea-e4362f413049
127.0.0.1 - - [08/Feb/2025 05:17:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:42,504 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5eb0b32e-a2d1-4640-bf4c-270675dcaee3
2025-02-08 05:17:42,530 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5eb0b32e-a2d1-4640-bf4c-270675dcaee3
127.0.0.1 - - [08/Feb/2025 05:17:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:42,788 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eaef6f40-2eef-4047-ae9c-17fa8147f17d
2025-02-08 05:17:42,792 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a3731b9c-222d-49b8-9d8f-c54e6bc139e6
2025-02-08 05:17:42,793 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eaef6f40-2eef-4047-ae9c-17fa8147f17d
127.0.0.1 - - [08/Feb/2025 05:17:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:42,811 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a3731b9c-222d-49b8-9d8f-c54e6bc139e6
127.0.0.1 - - [08/Feb/2025 05:17:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:43,031 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3446702e-8633-48ba-be4c-b29b68f5112d
2025-02-08 05:17:43,048 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3446702e-8633-48ba-be4c-b29b68f5112d
127.0.0.1 - - [08/Feb/2025 05:17:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:43,145 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 531adf7f-647e-4988-897d-a466431fab83
2025-02-08 05:17:43,146 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 531adf7f-647e-4988-897d-a466431fab83
127.0.0.1 - - [08/Feb/2025 05:17:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:43,348 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2568b81e-7e47-43ed-9fc2-62e8aa1bcf90
2025-02-08 05:17:43,358 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2568b81e-7e47-43ed-9fc2-62e8aa1bcf90
127.0.0.1 - - [08/Feb/2025 05:17:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:43,438 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eec817c2-ce6b-4336-a960-7be404a12546
2025-02-08 05:17:43,442 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eec817c2-ce6b-4336-a960-7be404a12546
127.0.0.1 - - [08/Feb/2025 05:17:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:43,646 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 67517959-3205-48a5-80a6-35030667c612
2025-02-08 05:17:43,656 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 67517959-3205-48a5-80a6-35030667c612
127.0.0.1 - - [08/Feb/2025 05:17:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:43,684 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e47b3940-c099-4baf-9413-285e8c5aad43
2025-02-08 05:17:43,696 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e47b3940-c099-4baf-9413-285e8c5aad43
127.0.0.1 - - [08/Feb/2025 05:17:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:43,710 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 344a39bf-7c1d-4948-96bb-9ccbdb6150c0
2025-02-08 05:17:43,720 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 344a39bf-7c1d-4948-96bb-9ccbdb6150c0
127.0.0.1 - - [08/Feb/2025 05:17:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:43,973 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c54cdb9c-59b2-4bb5-9a0c-ac17cbbc99a7
2025-02-08 05:17:43,977 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c54cdb9c-59b2-4bb5-9a0c-ac17cbbc99a7
127.0.0.1 - - [08/Feb/2025 05:17:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:44,221 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d450f377-57e7-4241-a884-7f733d04fda7
2025-02-08 05:17:44,265 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d450f377-57e7-4241-a884-7f733d04fda7
127.0.0.1 - - [08/Feb/2025 05:17:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:44,320 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 47ea9c8f-861d-41e0-a571-bb1917925c35
2025-02-08 05:17:44,338 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 47ea9c8f-861d-41e0-a571-bb1917925c35
127.0.0.1 - - [08/Feb/2025 05:17:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:44,529 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a686541e-6670-461c-8555-d2b6f14d1fa6
2025-02-08 05:17:44,542 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a686541e-6670-461c-8555-d2b6f14d1fa6
127.0.0.1 - - [08/Feb/2025 05:17:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:44,841 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cbba13ad-d4d6-4117-bc73-7a4972bb16ad
2025-02-08 05:17:44,865 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 66efd0ad-84b2-4e65-a5ce-f77592ba4979
2025-02-08 05:17:44,873 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cbba13ad-d4d6-4117-bc73-7a4972bb16ad
127.0.0.1 - - [08/Feb/2025 05:17:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:44,886 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 66efd0ad-84b2-4e65-a5ce-f77592ba4979
127.0.0.1 - - [08/Feb/2025 05:17:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:45,256 - LoudVA - WARNING - [LoudServer] - Timeout reached for request cead4dcb-f4c8-4adb-9602-e4f6cc587ba1
2025-02-08 05:17:45,260 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: cead4dcb-f4c8-4adb-9602-e4f6cc587ba1
127.0.0.1 - - [08/Feb/2025 05:17:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:45,420 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a2136b45-79c2-4a0a-b201-afe590ff5178
2025-02-08 05:17:45,426 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a2136b45-79c2-4a0a-b201-afe590ff5178
127.0.0.1 - - [08/Feb/2025 05:17:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:45,572 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c836c7e7-c797-4045-8b9d-1820cf5cc572
2025-02-08 05:17:45,586 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c836c7e7-c797-4045-8b9d-1820cf5cc572
127.0.0.1 - - [08/Feb/2025 05:17:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:45,652 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ea5a3083-9395-4121-b304-592def5c7cb7
2025-02-08 05:17:45,656 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ea5a3083-9395-4121-b304-592def5c7cb7
127.0.0.1 - - [08/Feb/2025 05:17:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:45,822 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c58d94d2-0101-4994-a430-52b3361843e6
2025-02-08 05:17:45,824 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c58d94d2-0101-4994-a430-52b3361843e6
127.0.0.1 - - [08/Feb/2025 05:17:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:46,131 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e0b8d921-c531-4e44-b08b-5ad0468bb75b
2025-02-08 05:17:46,137 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6fd4a943-6c8a-47fb-8d3b-190dca4cda24
2025-02-08 05:17:46,139 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e0b8d921-c531-4e44-b08b-5ad0468bb75b
2025-02-08 05:17:46,141 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6fd4a943-6c8a-47fb-8d3b-190dca4cda24
127.0.0.1 - - [08/Feb/2025 05:17:46] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 05:17:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:46,263 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 539ff4b3-fb01-4c00-8f13-c858567dd166
2025-02-08 05:17:46,284 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 539ff4b3-fb01-4c00-8f13-c858567dd166
127.0.0.1 - - [08/Feb/2025 05:17:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:46,580 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 328e5888-7180-44b3-98c0-9e727fe6cfea
2025-02-08 05:17:46,582 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 328e5888-7180-44b3-98c0-9e727fe6cfea
127.0.0.1 - - [08/Feb/2025 05:17:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:46,816 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8c9b111a-c51a-4c5e-8243-357bd4457f38
2025-02-08 05:17:46,831 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8c9b111a-c51a-4c5e-8243-357bd4457f38
127.0.0.1 - - [08/Feb/2025 05:17:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:46,955 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1b16bfa4-12ac-4b14-b486-7c93ba56c494
2025-02-08 05:17:46,957 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1b16bfa4-12ac-4b14-b486-7c93ba56c494
127.0.0.1 - - [08/Feb/2025 05:17:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:47,080 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c5040de0-7a1f-4bd7-ba4a-cbaf89d63d11
2025-02-08 05:17:47,085 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c5040de0-7a1f-4bd7-ba4a-cbaf89d63d11
127.0.0.1 - - [08/Feb/2025 05:17:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:47,213 - LoudVA - WARNING - [LoudServer] - Timeout reached for request fd23ad42-44ba-4b83-a04a-48d6518f7daa
2025-02-08 05:17:47,217 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fd23ad42-44ba-4b83-a04a-48d6518f7daa
127.0.0.1 - - [08/Feb/2025 05:17:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:47,586 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f509926e-eab7-4fbd-ae40-a7810845233b
2025-02-08 05:17:47,589 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f509926e-eab7-4fbd-ae40-a7810845233b
127.0.0.1 - - [08/Feb/2025 05:17:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:47,631 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 6ea1f6d9-4f02-4129-a311-3565d6ed5e30
2025-02-08 05:17:47,638 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6ea1f6d9-4f02-4129-a311-3565d6ed5e30
127.0.0.1 - - [08/Feb/2025 05:17:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:47,921 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1c817616-9a4f-4a82-a4aa-b42d38a27f00
2025-02-08 05:17:47,944 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1c817616-9a4f-4a82-a4aa-b42d38a27f00
127.0.0.1 - - [08/Feb/2025 05:17:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:48,151 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c62f1bd3-cc5e-44b3-843a-b9e99b1190a2
2025-02-08 05:17:48,157 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c62f1bd3-cc5e-44b3-843a-b9e99b1190a2
127.0.0.1 - - [08/Feb/2025 05:17:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:48,347 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a7930308-2c9d-473e-90d8-5b51e082087f
2025-02-08 05:17:48,350 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a7930308-2c9d-473e-90d8-5b51e082087f
127.0.0.1 - - [08/Feb/2025 05:17:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:48,378 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c2d0f128-4b0a-4250-9631-7da65f717485
2025-02-08 05:17:48,390 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c2d0f128-4b0a-4250-9631-7da65f717485
127.0.0.1 - - [08/Feb/2025 05:17:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:48,524 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c004ff0b-838d-421d-8f93-ce42a1c41dc6
2025-02-08 05:17:48,526 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c004ff0b-838d-421d-8f93-ce42a1c41dc6
127.0.0.1 - - [08/Feb/2025 05:17:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:48,712 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3306bd7e-636b-43dc-9d5b-a9ec0ed23e3f
2025-02-08 05:17:48,712 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3306bd7e-636b-43dc-9d5b-a9ec0ed23e3f
127.0.0.1 - - [08/Feb/2025 05:17:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:48,764 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f4eb6ed7-3514-48f6-9906-1496d275d3d1
2025-02-08 05:17:48,766 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f4eb6ed7-3514-48f6-9906-1496d275d3d1
127.0.0.1 - - [08/Feb/2025 05:17:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:48,807 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eab98f54-e6ec-4b92-927a-4bfad4c4e367
2025-02-08 05:17:48,811 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eab98f54-e6ec-4b92-927a-4bfad4c4e367
127.0.0.1 - - [08/Feb/2025 05:17:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:49,028 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bb793441-0883-4311-8f69-306a25d174a3
2025-02-08 05:17:49,028 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bb793441-0883-4311-8f69-306a25d174a3
127.0.0.1 - - [08/Feb/2025 05:17:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:49,401 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 34cccfad-04c1-4d59-b621-7d6189526538
2025-02-08 05:17:49,402 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 34cccfad-04c1-4d59-b621-7d6189526538
127.0.0.1 - - [08/Feb/2025 05:17:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:49,450 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 133c59a9-c973-45a1-a885-4415fce5e677
2025-02-08 05:17:49,452 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 133c59a9-c973-45a1-a885-4415fce5e677
127.0.0.1 - - [08/Feb/2025 05:17:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:49,552 - LoudVA - WARNING - [LoudServer] - Timeout reached for request df2c58a3-be5c-4397-ae79-211cd0957f59
2025-02-08 05:17:49,556 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: df2c58a3-be5c-4397-ae79-211cd0957f59
127.0.0.1 - - [08/Feb/2025 05:17:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:49,556 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c7a31601-1cc9-42b2-824b-a4d5bfb676cd
2025-02-08 05:17:49,562 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c7a31601-1cc9-42b2-824b-a4d5bfb676cd
127.0.0.1 - - [08/Feb/2025 05:17:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:49,584 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 29edafb3-c8dd-49dd-b3f4-cb9b2959a8c4
2025-02-08 05:17:49,592 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 29edafb3-c8dd-49dd-b3f4-cb9b2959a8c4
127.0.0.1 - - [08/Feb/2025 05:17:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:49,663 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 53e3d8c9-6451-428b-b7f2-88bd13146110
2025-02-08 05:17:49,667 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 53e3d8c9-6451-428b-b7f2-88bd13146110
127.0.0.1 - - [08/Feb/2025 05:17:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:49,903 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0d83d1e0-8a9c-4587-95f0-3d42711af7c9
2025-02-08 05:17:49,904 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0d83d1e0-8a9c-4587-95f0-3d42711af7c9
127.0.0.1 - - [08/Feb/2025 05:17:49] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:50,093 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 505f79b1-57b0-454c-b3a5-755b104a6dae
2025-02-08 05:17:50,094 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 505f79b1-57b0-454c-b3a5-755b104a6dae
127.0.0.1 - - [08/Feb/2025 05:17:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:50,223 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 94f28078-7597-4cef-816d-68d829985673
2025-02-08 05:17:50,224 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 94f28078-7597-4cef-816d-68d829985673
127.0.0.1 - - [08/Feb/2025 05:17:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:50,648 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 38250b43-ea0b-44a9-a72f-09c78aba7eb5
2025-02-08 05:17:50,651 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 38250b43-ea0b-44a9-a72f-09c78aba7eb5
127.0.0.1 - - [08/Feb/2025 05:17:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:50,830 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 78d0ac7a-7862-4782-add4-20c8343b7d8b
2025-02-08 05:17:50,831 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 78d0ac7a-7862-4782-add4-20c8343b7d8b
127.0.0.1 - - [08/Feb/2025 05:17:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:50,972 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 17bf5221-a842-4b2a-baab-2b46d9462d3c
2025-02-08 05:17:50,974 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 17bf5221-a842-4b2a-baab-2b46d9462d3c
127.0.0.1 - - [08/Feb/2025 05:17:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:51,108 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eb5ebab0-55cf-4007-b337-181b3bfc24f5
2025-02-08 05:17:51,109 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eb5ebab0-55cf-4007-b337-181b3bfc24f5
127.0.0.1 - - [08/Feb/2025 05:17:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:51,133 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e4009cf3-a8ba-43d0-94db-cd82299f3e80
2025-02-08 05:17:51,135 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e4009cf3-a8ba-43d0-94db-cd82299f3e80
127.0.0.1 - - [08/Feb/2025 05:17:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:51,523 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 80e50b59-d423-4bcb-ad46-09bfa6e2a428
2025-02-08 05:17:51,523 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 80e50b59-d423-4bcb-ad46-09bfa6e2a428
127.0.0.1 - - [08/Feb/2025 05:17:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:51,669 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 7a59f4a7-f1d2-417d-9b6a-3f25d79e86d5
2025-02-08 05:17:51,672 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7a59f4a7-f1d2-417d-9b6a-3f25d79e86d5
127.0.0.1 - - [08/Feb/2025 05:17:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:51,907 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0e7c5a0c-08b0-4f8c-80de-eec59ec1b2a1
2025-02-08 05:17:51,913 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0e7c5a0c-08b0-4f8c-80de-eec59ec1b2a1
127.0.0.1 - - [08/Feb/2025 05:17:51] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:52,257 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 722c3ed6-4b28-44c8-98c0-449ff73b04e0
2025-02-08 05:17:52,260 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 722c3ed6-4b28-44c8-98c0-449ff73b04e0
127.0.0.1 - - [08/Feb/2025 05:17:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:52,426 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 9b8c7fdf-1035-4439-8c1a-c34cb73f9569
2025-02-08 05:17:52,427 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9b8c7fdf-1035-4439-8c1a-c34cb73f9569
127.0.0.1 - - [08/Feb/2025 05:17:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:52,474 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 48b0aeda-0c55-48b3-ab82-11d0f9040669
2025-02-08 05:17:52,476 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 48b0aeda-0c55-48b3-ab82-11d0f9040669
127.0.0.1 - - [08/Feb/2025 05:17:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:52,535 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5a2a5cc9-8df0-4d97-9acb-41ed5ab57bb8
2025-02-08 05:17:52,536 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5a2a5cc9-8df0-4d97-9acb-41ed5ab57bb8
127.0.0.1 - - [08/Feb/2025 05:17:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:53,311 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 38848cd5-194d-4c2c-8329-d37355823d48
2025-02-08 05:17:53,318 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 38848cd5-194d-4c2c-8329-d37355823d48
127.0.0.1 - - [08/Feb/2025 05:17:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:53,401 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 90f6267b-7f39-449e-9532-23fd33b49621
2025-02-08 05:17:53,401 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 90f6267b-7f39-449e-9532-23fd33b49621
127.0.0.1 - - [08/Feb/2025 05:17:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:53,560 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 540b33bd-3996-41d1-8cd2-3c48e9156692
2025-02-08 05:17:53,562 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 540b33bd-3996-41d1-8cd2-3c48e9156692
127.0.0.1 - - [08/Feb/2025 05:17:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:53,664 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 58d3818e-8669-495f-a4d3-ab6740d666d5
2025-02-08 05:17:53,670 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 58d3818e-8669-495f-a4d3-ab6740d666d5
127.0.0.1 - - [08/Feb/2025 05:17:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:54,226 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3306df15-8aae-4571-88f1-516db55d4130
2025-02-08 05:17:54,228 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3306df15-8aae-4571-88f1-516db55d4130
127.0.0.1 - - [08/Feb/2025 05:17:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:54,260 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f21526d7-00fc-49e4-9d80-a2e038900547
2025-02-08 05:17:54,262 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f21526d7-00fc-49e4-9d80-a2e038900547
127.0.0.1 - - [08/Feb/2025 05:17:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:54,276 - LoudVA - WARNING - [LoudServer] - Timeout reached for request f09c8f58-f2b8-4a58-8892-b2b4f5034fbd
2025-02-08 05:17:54,278 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f09c8f58-f2b8-4a58-8892-b2b4f5034fbd
127.0.0.1 - - [08/Feb/2025 05:17:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:54,316 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2432ee39-9e84-4c0f-adea-7739d0226ef9
2025-02-08 05:17:54,317 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2432ee39-9e84-4c0f-adea-7739d0226ef9
127.0.0.1 - - [08/Feb/2025 05:17:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:54,385 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3c23a675-ffea-4592-b65c-5be3a455e178
2025-02-08 05:17:54,385 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3c23a675-ffea-4592-b65c-5be3a455e178
127.0.0.1 - - [08/Feb/2025 05:17:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:54,676 - LoudVA - WARNING - [LoudServer] - Timeout reached for request e953058b-3f04-4ac0-be48-a62de38ede86
2025-02-08 05:17:54,676 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e953058b-3f04-4ac0-be48-a62de38ede86
127.0.0.1 - - [08/Feb/2025 05:17:54] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:55,150 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4fecc57a-fdfc-479a-8848-a3bc91382a0b
2025-02-08 05:17:55,151 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4fecc57a-fdfc-479a-8848-a3bc91382a0b
127.0.0.1 - - [08/Feb/2025 05:17:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:55,220 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d63fd6cf-f637-4e4f-a656-5e55b2685ca3
2025-02-08 05:17:55,221 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d63fd6cf-f637-4e4f-a656-5e55b2685ca3
127.0.0.1 - - [08/Feb/2025 05:17:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:55,686 - LoudVA - WARNING - [LoudServer] - Timeout reached for request bd97f0b7-c15c-4ca5-aae0-58a4270a3069
2025-02-08 05:17:55,687 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bd97f0b7-c15c-4ca5-aae0-58a4270a3069
127.0.0.1 - - [08/Feb/2025 05:17:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:55,716 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a396e70c-2e61-474b-a335-ced94c932f78
2025-02-08 05:17:55,718 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a396e70c-2e61-474b-a335-ced94c932f78
127.0.0.1 - - [08/Feb/2025 05:17:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:55,862 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a724454d-bd8b-49dd-8ee8-806f7e9f4b9a
2025-02-08 05:17:55,865 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a724454d-bd8b-49dd-8ee8-806f7e9f4b9a
127.0.0.1 - - [08/Feb/2025 05:17:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:56,097 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 097c2efc-b60d-46dd-b8f3-fdb357529024
2025-02-08 05:17:56,098 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 097c2efc-b60d-46dd-b8f3-fdb357529024
127.0.0.1 - - [08/Feb/2025 05:17:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:56,237 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2b4ef44f-ce40-4899-8757-8fa0853e3097
2025-02-08 05:17:56,238 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2b4ef44f-ce40-4899-8757-8fa0853e3097
127.0.0.1 - - [08/Feb/2025 05:17:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:56,343 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0c49ade8-4158-497b-a99f-6179cc7c1236
2025-02-08 05:17:56,343 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0c49ade8-4158-497b-a99f-6179cc7c1236
127.0.0.1 - - [08/Feb/2025 05:17:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:56,387 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ad10abf0-758f-4ee1-aff4-ce3f4273ba2a
2025-02-08 05:17:56,387 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ad10abf0-758f-4ee1-aff4-ce3f4273ba2a
127.0.0.1 - - [08/Feb/2025 05:17:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:56,391 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 39210e96-87f7-4888-88ad-51a4029e2999
2025-02-08 05:17:56,392 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 39210e96-87f7-4888-88ad-51a4029e2999
127.0.0.1 - - [08/Feb/2025 05:17:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:56,922 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 304bdc9a-565d-4695-9130-0f59e1d071b0
2025-02-08 05:17:56,924 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 304bdc9a-565d-4695-9130-0f59e1d071b0
127.0.0.1 - - [08/Feb/2025 05:17:56] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:56,999 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4f2c8020-002d-4538-b7a7-e643c9e3d01e
2025-02-08 05:17:57,000 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4f2c8020-002d-4538-b7a7-e643c9e3d01e
127.0.0.1 - - [08/Feb/2025 05:17:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:57,068 - LoudVA - WARNING - [LoudServer] - Timeout reached for request af7d23ca-2aec-42d2-84e9-5c290c85b0de
2025-02-08 05:17:57,069 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: af7d23ca-2aec-42d2-84e9-5c290c85b0de
127.0.0.1 - - [08/Feb/2025 05:17:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:57,575 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 465836af-fe4e-472e-8d41-ab973270bedb
2025-02-08 05:17:57,577 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 465836af-fe4e-472e-8d41-ab973270bedb
127.0.0.1 - - [08/Feb/2025 05:17:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:57,667 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 28c05b07-a4b2-4045-ae7a-99cbfe366b5a
2025-02-08 05:17:57,669 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 28c05b07-a4b2-4045-ae7a-99cbfe366b5a
127.0.0.1 - - [08/Feb/2025 05:17:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:57,813 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 79131a07-18aa-4a5e-9e56-403bd3fec4bc
2025-02-08 05:17:57,814 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 79131a07-18aa-4a5e-9e56-403bd3fec4bc
127.0.0.1 - - [08/Feb/2025 05:17:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:57,858 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 54a4157f-598a-4c2c-86ca-0f749d4ae559
2025-02-08 05:17:57,859 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 54a4157f-598a-4c2c-86ca-0f749d4ae559
127.0.0.1 - - [08/Feb/2025 05:17:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:58,015 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5f2b7f7b-bc28-4a7b-aa7b-38db7a0edaa2
2025-02-08 05:17:58,016 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5f2b7f7b-bc28-4a7b-aa7b-38db7a0edaa2
2025-02-08 05:17:58,016 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 65bd7b63-e6fc-47fb-9102-a5316f970a4c
127.0.0.1 - - [08/Feb/2025 05:17:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:58,019 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 65bd7b63-e6fc-47fb-9102-a5316f970a4c
127.0.0.1 - - [08/Feb/2025 05:17:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:58,042 - LoudVA - WARNING - [LoudServer] - Timeout reached for request efc1e1be-5d1c-469f-83fa-9c8100323a9a
2025-02-08 05:17:58,042 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: efc1e1be-5d1c-469f-83fa-9c8100323a9a
127.0.0.1 - - [08/Feb/2025 05:17:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:58,118 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 52a431dc-e1ca-438e-8f1b-ea7431df36cf
2025-02-08 05:17:58,118 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 52a431dc-e1ca-438e-8f1b-ea7431df36cf
127.0.0.1 - - [08/Feb/2025 05:17:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:58,374 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 68a066e6-f1f8-44d5-986d-f37341ba83ae
2025-02-08 05:17:58,374 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 68a066e6-f1f8-44d5-986d-f37341ba83ae
127.0.0.1 - - [08/Feb/2025 05:17:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:58,635 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3781aae0-24d0-47cf-9a31-108cdd3af67f
2025-02-08 05:17:58,636 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3781aae0-24d0-47cf-9a31-108cdd3af67f
127.0.0.1 - - [08/Feb/2025 05:17:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:58,783 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 535ed194-7d95-4c18-8391-562f1b8f115a
2025-02-08 05:17:58,783 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 535ed194-7d95-4c18-8391-562f1b8f115a
127.0.0.1 - - [08/Feb/2025 05:17:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:58,855 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 949a94f2-abb9-4afe-931c-5dc08526bfa9
2025-02-08 05:17:58,856 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 949a94f2-abb9-4afe-931c-5dc08526bfa9
127.0.0.1 - - [08/Feb/2025 05:17:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 05:17:59,052 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2cac0e11-e3c8-4e74-8620-ffc705145b98
2025-02-08 05:17:59,053 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2cac0e11-e3c8-4e74-8620-ffc705145b98
127.0.0.1 - - [08/Feb/2025 05:17:59] "POST /inference HTTP/1.1" 200 -
