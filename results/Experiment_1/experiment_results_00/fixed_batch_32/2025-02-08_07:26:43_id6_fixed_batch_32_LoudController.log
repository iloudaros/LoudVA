2025-02-08 07:25:44,235 - LoudVA - INFO - [LoudController] - Starting LoudController...
2025-02-08 07:25:44,235 - LoudVA - INFO - [LoudController] - Press CTRL+C to stop the controller.
2025-02-08 07:25:44,235 - LoudVA - INFO - [LoudController] - Debug mode: False
2025-02-08 07:25:44,257 - LoudVA - INFO - [LoudController] - Selected scheduler: fixed_batch
2025-02-08 07:25:44,260 - LoudVA - INFO - [LoudServer] - Starting LoudVA server...
 * Serving Flask app 'LoudServer'
 * Debug mode: off
WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.
 * Running on http://127.0.0.1:5000
Press CTRL+C to quit
2025-02-08 07:25:46,303 - LoudVA - INFO - [DeviceData] - Using profiling data for decision making.
2025-02-08 07:25:46,303 - LoudVA - INFO - [DeviceData] - Filling missing profile data with predictions.
2025-02-08 07:25:46,317 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/Profiling.csv
2025-02-08 07:25:46,317 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/xavier-nx-00/measurements/xavier-nx-00_filtered_freqs.csv
2025-02-08 07:25:46,318 - LoudVA - INFO - [DeviceData] - Loaded profile from /home/louduser/LoudVA/LoudController/../measurements/archive/Representative/LoudJetson0/measurements/LoudJetson0_filtered_freqs.csv
2025-02-08 07:25:46,318 - LoudVA - INFO - [DeviceData] - Loaded GPU specs from /home/louduser/LoudVA/LoudController/../data/devices/gpu_specs.csv
2025-02-08 07:25:46,349 - LoudVA - INFO - [DeviceData] - Initial frequency on agx-xavier-00: 114750000
2025-02-08 07:25:46,349 - LoudVA - INFO - [DeviceData] - agx-xavier-00 : Filling missing profile data...
2025-02-08 07:25:46,350 - LoudVA - INFO - [DeviceData] - agx-xavier-00 : Missing profile data filled with predictions.
2025-02-08 07:25:46,350 - LoudVA - INFO - [DeviceData] - Devices initialized successfully
2025-02-08 07:25:46,350 - LoudVA - INFO - [LoudController] - Using fixed batch size 32
127.0.0.1 - - [08/Feb/2025 07:26:46] "GET / HTTP/1.1" 200 -
2025-02-08 07:26:46,978 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:26:51,327 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:26:57,053 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.0
2025-02-08 07:27:01,282 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:27:07,075 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:27:08,847 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0af013df-f4ee-4f93-bd3f-3f3bf4bb55ad
127.0.0.1 - - [08/Feb/2025 07:27:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:27:09,494 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c7e0afd1-73cb-4ea3-bc7e-596f358ce141
127.0.0.1 - - [08/Feb/2025 07:27:09] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:27:11,268 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:27:12,988 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 03f36e75-612c-421f-bc73-77bb9bfd51d5
127.0.0.1 - - [08/Feb/2025 07:27:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:27:16,450 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5e2bf88f-3525-412e-b9a7-c6c9de84abec
127.0.0.1 - - [08/Feb/2025 07:27:16] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:27:16,992 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:27:20,460 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e9925ae5-3d82-4e57-b1c9-902bf29bfe10
127.0.0.1 - - [08/Feb/2025 07:27:20] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:27:21,310 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:27:24,824 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c199a202-d04e-4d84-86bc-9a2279ea30dc
127.0.0.1 - - [08/Feb/2025 07:27:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:27:27,022 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 21.0
2025-02-08 07:27:31,206 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:27:31,917 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4a2e9b8b-7a65-40a2-b3bf-89082c2093ee
127.0.0.1 - - [08/Feb/2025 07:27:31] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:27:35,585 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 651bc3ec-ee7d-4a14-af79-79ef10a3e01c
127.0.0.1 - - [08/Feb/2025 07:27:35] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:27:36,910 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:27:41,329 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:27:45,115 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b19017b3-eb42-4503-ad82-cbe1d11f75a4
127.0.0.1 - - [08/Feb/2025 07:27:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:27:45,119 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8d25101e-486c-439f-859d-c2d8a69a66c6
127.0.0.1 - - [08/Feb/2025 07:27:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:27:46,995 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:27:48,054 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9871336a-2647-4259-9d2c-ec54cead60c0
127.0.0.1 - - [08/Feb/2025 07:27:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:27:50,161 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 8.0
2025-02-08 07:27:52,521 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3b470440-290f-4332-828c-bd97711be199
127.0.0.1 - - [08/Feb/2025 07:27:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:27:55,151 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:27:57,021 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 07:28:00,135 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 11.0
2025-02-08 07:28:03,015 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 093a2bb3-3804-41cd-b395-f467498a5dea
127.0.0.1 - - [08/Feb/2025 07:28:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:03,020 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9ddead51-df61-46d1-a920-203f897dbe0d
127.0.0.1 - - [08/Feb/2025 07:28:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:05,179 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:28:06,999 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 6f0c5b9e-7ebf-4327-8ff8-64e965477d95
127.0.0.1 - - [08/Feb/2025 07:28:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:07,109 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:28:08,244 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bf4948cc-2378-4d97-9e50-6c8614d1ae53
127.0.0.1 - - [08/Feb/2025 07:28:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:10,135 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:28:13,019 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 55ce9a10-86ec-489b-a910-f9f587242a61
127.0.0.1 - - [08/Feb/2025 07:28:13] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:13,176 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bc82cc13-2700-443e-9359-f81b3acc5576
127.0.0.1 - - [08/Feb/2025 07:28:13] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:15,201 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:28:17,028 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:28:18,397 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e143fc04-343e-4e59-80da-480e1f5ad04d
127.0.0.1 - - [08/Feb/2025 07:28:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:20,125 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:28:24,214 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7eeff996-389f-4808-830a-025e965bc425
127.0.0.1 - - [08/Feb/2025 07:28:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:25,250 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:28:25,843 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fa867908-38a4-4a79-8c1d-faba6937cd24
127.0.0.1 - - [08/Feb/2025 07:28:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:27,021 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:28:30,138 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:28:33,392 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ebb965e8-4c59-4e1f-865b-e5269f384de7
127.0.0.1 - - [08/Feb/2025 07:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:33,406 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 327a04f0-31f0-4ef5-83cb-645e0358cd10
127.0.0.1 - - [08/Feb/2025 07:28:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:35,281 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:28:36,530 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d591999b-1d77-478c-89c9-353a977d16fc
127.0.0.1 - - [08/Feb/2025 07:28:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:37,050 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:28:40,245 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:28:44,334 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 68941744-c503-43ac-b588-d07f9ab80efd
2025-02-08 07:28:44,336 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 46191429-3b46-4f0f-ba19-c45c63651ba8
127.0.0.1 - - [08/Feb/2025 07:28:44] "POST /inference HTTP/1.1" 200 -
127.0.0.1 - - [08/Feb/2025 07:28:44] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:45,238 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:28:47,040 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:28:50,294 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:28:50,835 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5a6f2739-b674-4483-99ba-c44ad79b017f
127.0.0.1 - - [08/Feb/2025 07:28:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:28:55,211 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:28:57,062 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:29:00,306 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:29:00,398 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:29:02,001 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1dbc4110-d944-49bd-aac4-ef2a3bb03a77
127.0.0.1 - - [08/Feb/2025 07:29:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:29:02,019 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eb9f7403-1845-439d-81ec-badbd8f679ca
127.0.0.1 - - [08/Feb/2025 07:29:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:29:05,385 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:29:05,666 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fcfeb314-2eed-43e1-ad71-5ad2befd193f
127.0.0.1 - - [08/Feb/2025 07:29:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:29:07,131 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:29:10,390 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:29:10,476 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 07:29:11,266 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f880cf2e-81eb-4441-823e-e8f09f91406b
127.0.0.1 - - [08/Feb/2025 07:29:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:29:15,246 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 07:29:17,024 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:29:19,885 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5dc98d07-b3bb-4d97-b3a8-1a7b8870d96e
127.0.0.1 - - [08/Feb/2025 07:29:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:29:19,908 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f093fa5a-506c-42a5-8343-5cf869121168
127.0.0.1 - - [08/Feb/2025 07:29:19] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:29:20,225 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:29:20,274 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:29:25,221 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:29:25,638 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d82cf7ae-ecb9-4f7b-b9b6-b2faa532a6e9
127.0.0.1 - - [08/Feb/2025 07:29:25] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:29:26,936 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:29:29,651 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c22fbca1-9d2e-41d8-be2d-cdc3605d69db
127.0.0.1 - - [08/Feb/2025 07:29:29] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:29:30,309 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.0
2025-02-08 07:29:30,406 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:29:35,193 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:29:36,999 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:29:38,893 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d2c31152-673f-45b7-a30f-e93353446f23
127.0.0.1 - - [08/Feb/2025 07:29:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:29:38,938 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 58f03b65-4a38-4719-bc10-015afa943e96
127.0.0.1 - - [08/Feb/2025 07:29:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:29:40,202 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:29:42,244 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:29:43,270 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.0
2025-02-08 07:29:45,191 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:29:46,985 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: bddd427b-8ed5-4c53-9a00-bb5969964c38
127.0.0.1 - - [08/Feb/2025 07:29:46] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:29:47,055 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:29:47,228 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:29:48,167 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:29:50,119 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 5.0
2025-02-08 07:29:52,241 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 9.0
2025-02-08 07:29:53,119 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:29:55,255 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:29:57,336 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:29:58,307 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:29:59,079 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3686b069-ecbb-401d-8018-100a1e2a70fb
127.0.0.1 - - [08/Feb/2025 07:29:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:29:59,106 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4d5579fd-0957-454c-8af9-a8ebda30e14b
127.0.0.1 - - [08/Feb/2025 07:29:59] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:30:00,468 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:30:00,839 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 26c78490-e1d9-4083-be26-12de20e0a486
127.0.0.1 - - [08/Feb/2025 07:30:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:30:02,653 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 07:30:03,277 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:30:05,056 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9abb52b9-efef-4f68-ba7b-5fb55dfd6a99
127.0.0.1 - - [08/Feb/2025 07:30:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:30:07,324 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 07:30:08,161 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 07:30:10,513 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 99b77c86-e6e8-4939-8959-dd467d091229
127.0.0.1 - - [08/Feb/2025 07:30:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:30:10,670 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e6e65d8e-7aae-46c3-9f58-a657bdc045b4
127.0.0.1 - - [08/Feb/2025 07:30:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:30:12,346 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:30:13,479 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
2025-02-08 07:30:17,736 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 22.0
2025-02-08 07:30:18,183 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:30:21,998 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 9316e87f-d735-4869-8cca-35c1bfbb2964
127.0.0.1 - - [08/Feb/2025 07:30:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:30:22,459 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
2025-02-08 07:30:23,419 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.0
2025-02-08 07:30:24,908 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4419fdeb-c9e4-4427-9007-f0e0f7f53938
127.0.0.1 - - [08/Feb/2025 07:30:24] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:30:27,727 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:30:28,266 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
2025-02-08 07:30:30,934 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 21fcac6e-6ac6-45cd-bd11-fedb8565e657
127.0.0.1 - - [08/Feb/2025 07:30:30] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:30:32,769 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:30:33,286 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:30:34,035 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2d40b947-71cf-426c-a329-28aa0801feb4
127.0.0.1 - - [08/Feb/2025 07:30:34] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:30:36,150 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 05345f10-662b-4407-8587-590ab0524fa8
127.0.0.1 - - [08/Feb/2025 07:30:36] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:30:37,363 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
2025-02-08 07:30:38,392 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-60:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:30:42,407 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:30:42,851 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7229496c-4c01-413b-a94b-2690b7b8dba6
127.0.0.1 - - [08/Feb/2025 07:30:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:30:43,458 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-61:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-62:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-63:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:30:47,473 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 12.0
Exception in thread Thread-64:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:30:48,375 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
Exception in thread Thread-65:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-66:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:30:52,633 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:30:53,250 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 16.0
Exception in thread Thread-68:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-67:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:30:57,723 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
2025-02-08 07:30:58,295 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 14.0
Exception in thread Thread-69:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:31:02,617 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
Exception in thread Thread-70:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:31:03,364 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
Exception in thread Thread-71:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-73:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-72:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:31:07,552 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:31:08,288 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
Exception in thread Thread-74:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:31:12,312 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
2025-02-08 07:31:13,437 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 19.0
Exception in thread Thread-75:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-76:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:31:18,134 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 20.0
2025-02-08 07:31:18,275 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-77:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-78:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:31:22,463 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 15.0
2025-02-08 07:31:23,760 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 17.0
Exception in thread Thread-79:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:31:27,781 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 18.0
2025-02-08 07:31:28,297 - LoudVA - INFO - [LoudServer] - Received inference request with latency constraint: 13.0
Exception in thread Thread-80:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-81:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-82:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-83:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-84:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-85:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-86:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-87:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-88:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-89:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-90:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-91:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-92:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
Exception in thread Thread-93:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/louduser/LoudVA/LoudController/altSchedulers/FixedBatchScheduler.py", line 63, in dispatch_request
    [response] = device.inference(images, batch_size)
  File "/home/louduser/LoudVA/LoudController/DeviceData.py", line 258, in inference
    response = triton_client.inference(**args)
  File "/home/louduser/LoudVA/LoudController/triton_client.py", line 337, in inference
    triton_client.infer(model_name,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 1469, in infer
    response = self._post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/tritonclient/http/_client.py", line 284, in _post
    response = self._client_stub.post(request_uri=request_uri,
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 272, in post
    return self.request(METHOD_POST, request_uri, body=body, headers=headers)
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 250, in request
    raise e
  File "/home/louduser/.local/lib/python3.8/site-packages/geventhttpclient/client.py", line 231, in request
    sock.sendall(_request + body)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 702, in sendall
    return _sendall(self, data_memory, flags)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 391, in _sendall
    timeleft = __send_chunk(socket, chunk, flags, timeleft, end)
  File "/home/louduser/.local/lib/python3.8/site-packages/gevent/_socketcommon.py", line 328, in __send_chunk
    raise timeout('timed out')
socket.timeout: timed out
2025-02-08 07:32:05,329 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c5636837-7342-48d7-8a62-63e19b762b98
127.0.0.1 - - [08/Feb/2025 07:32:05] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:32:06,492 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5f1e2421-d4a3-40a2-8163-a5985236571b
127.0.0.1 - - [08/Feb/2025 07:32:06] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:32:07,012 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2fbe67e2-8bce-487b-9ab3-8b1bd357848f
127.0.0.1 - - [08/Feb/2025 07:32:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:32:08,199 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 7eb26820-d1e3-45a6-bff6-b62c42592005
127.0.0.1 - - [08/Feb/2025 07:32:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:32:08,203 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 233cfb1a-e21f-407d-9dcb-93831bf6c795
127.0.0.1 - - [08/Feb/2025 07:32:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:32:08,357 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: f860ad73-19ad-4206-8b55-0a06fc2a4e13
127.0.0.1 - - [08/Feb/2025 07:32:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:32:08,772 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fff7bca0-9cab-40d6-9a09-7ecb2c70cfb5
127.0.0.1 - - [08/Feb/2025 07:32:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:32:10,164 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 53ce6312-fded-488e-96b8-3ce9fce57b63
127.0.0.1 - - [08/Feb/2025 07:32:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:32:10,685 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: fec2c39e-014d-4d55-903d-3cbeaf72c17b
127.0.0.1 - - [08/Feb/2025 07:32:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:32:10,762 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1415772f-387c-497a-97f5-e5079af33956
127.0.0.1 - - [08/Feb/2025 07:32:10] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:32:11,470 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 84936028-a512-4e0e-a5ec-e9f6528eb047
127.0.0.1 - - [08/Feb/2025 07:32:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:32:11,567 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b48736ce-3302-4486-ad32-5a603c7ed72b
127.0.0.1 - - [08/Feb/2025 07:32:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:32:11,799 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: e0a5ad72-bbc3-4011-ae2a-60cabbe393f0
127.0.0.1 - - [08/Feb/2025 07:32:11] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:34:40,944 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8c57abdd-5883-4b00-ae59-e572b5c3d903
2025-02-08 07:34:41,113 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8c57abdd-5883-4b00-ae59-e572b5c3d903
127.0.0.1 - - [08/Feb/2025 07:34:41] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:34:42,405 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 63f96c6f-bba8-4e12-8243-19293a42b47b
2025-02-08 07:34:42,434 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 63f96c6f-bba8-4e12-8243-19293a42b47b
127.0.0.1 - - [08/Feb/2025 07:34:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:34:43,419 - LoudVA - WARNING - [LoudServer] - Timeout reached for request abd6f831-1dbd-4a7a-950c-5e12274c1b48
2025-02-08 07:34:43,425 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: abd6f831-1dbd-4a7a-950c-5e12274c1b48
127.0.0.1 - - [08/Feb/2025 07:34:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:34:45,605 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 94270a45-e843-4b40-b178-bfa932ccdb8e
2025-02-08 07:34:45,762 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 94270a45-e843-4b40-b178-bfa932ccdb8e
127.0.0.1 - - [08/Feb/2025 07:34:45] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:34:47,315 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 27f377a7-053f-49ce-bea4-d4f68b76c07c
2025-02-08 07:34:47,441 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 27f377a7-053f-49ce-bea4-d4f68b76c07c
127.0.0.1 - - [08/Feb/2025 07:34:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:34:47,513 - LoudVA - WARNING - [LoudServer] - Timeout reached for request a8b3e6d7-86d8-41cd-aac4-7cba3c5ab9d6
2025-02-08 07:34:47,516 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: a8b3e6d7-86d8-41cd-aac4-7cba3c5ab9d6
127.0.0.1 - - [08/Feb/2025 07:34:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:34:48,317 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 66a14188-32eb-4a3d-b47d-67f44988250a
2025-02-08 07:34:48,339 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 66a14188-32eb-4a3d-b47d-67f44988250a
127.0.0.1 - - [08/Feb/2025 07:34:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:34:50,172 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 35f6dcb3-b016-40cf-839d-20e9fa8e5dc3
2025-02-08 07:34:50,203 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 35f6dcb3-b016-40cf-839d-20e9fa8e5dc3
127.0.0.1 - - [08/Feb/2025 07:34:50] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:34:52,260 - LoudVA - WARNING - [LoudServer] - Timeout reached for request eb9fb27c-76a2-4519-a0ad-c1992f0f9ee4
2025-02-08 07:34:52,261 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: eb9fb27c-76a2-4519-a0ad-c1992f0f9ee4
127.0.0.1 - - [08/Feb/2025 07:34:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:34:53,152 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 408c4485-32b1-4458-a9a6-3b0b784d9e6c
2025-02-08 07:34:53,152 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 408c4485-32b1-4458-a9a6-3b0b784d9e6c
127.0.0.1 - - [08/Feb/2025 07:34:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:34:55,661 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 00b3973b-7265-425b-b34c-06228bb3db01
2025-02-08 07:34:55,795 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 00b3973b-7265-425b-b34c-06228bb3db01
127.0.0.1 - - [08/Feb/2025 07:34:55] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:34:57,524 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 397e9eb8-a182-4fd2-86e9-ae7e01d1d666
2025-02-08 07:34:57,526 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 397e9eb8-a182-4fd2-86e9-ae7e01d1d666
127.0.0.1 - - [08/Feb/2025 07:34:57] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:34:58,369 - LoudVA - WARNING - [LoudServer] - Timeout reached for request b4829e45-e305-484b-b1ae-de06fc486cff
2025-02-08 07:34:58,370 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: b4829e45-e305-484b-b1ae-de06fc486cff
127.0.0.1 - - [08/Feb/2025 07:34:58] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:00,542 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 86299338-c78b-4c37-ba4f-f5e9fdc39b3d
2025-02-08 07:35:00,645 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 86299338-c78b-4c37-ba4f-f5e9fdc39b3d
127.0.0.1 - - [08/Feb/2025 07:35:00] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:02,701 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c5bc3212-012b-4838-9c85-7e14f5fa06e8
2025-02-08 07:35:02,706 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c5bc3212-012b-4838-9c85-7e14f5fa06e8
127.0.0.1 - - [08/Feb/2025 07:35:02] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:03,300 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4a49973d-12cc-4bc1-9d7b-b860499cd118
2025-02-08 07:35:03,312 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4a49973d-12cc-4bc1-9d7b-b860499cd118
127.0.0.1 - - [08/Feb/2025 07:35:03] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:07,371 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 65b40425-ab5f-4010-8ae2-29ba6a91107d
2025-02-08 07:35:07,424 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 65b40425-ab5f-4010-8ae2-29ba6a91107d
127.0.0.1 - - [08/Feb/2025 07:35:07] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:08,170 - LoudVA - WARNING - [LoudServer] - Timeout reached for request ce83be68-3d12-41aa-9a9b-50a596826db7
2025-02-08 07:35:08,181 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: ce83be68-3d12-41aa-9a9b-50a596826db7
127.0.0.1 - - [08/Feb/2025 07:35:08] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:12,375 - LoudVA - WARNING - [LoudServer] - Timeout reached for request d87c113f-f501-4fd0-b12a-d660f1a5e075
2025-02-08 07:35:12,398 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: d87c113f-f501-4fd0-b12a-d660f1a5e075
127.0.0.1 - - [08/Feb/2025 07:35:12] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:13,534 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 420a42b1-bb17-455d-8b78-9ee7896ab03b
2025-02-08 07:35:13,551 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 420a42b1-bb17-455d-8b78-9ee7896ab03b
127.0.0.1 - - [08/Feb/2025 07:35:13] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:17,787 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2aa12be3-13e8-4631-a23c-6ee028761b29
2025-02-08 07:35:17,817 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2aa12be3-13e8-4631-a23c-6ee028761b29
127.0.0.1 - - [08/Feb/2025 07:35:17] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:18,197 - LoudVA - WARNING - [LoudServer] - Timeout reached for request df8d17bb-1bc6-4c7e-bc87-c7e912f002ce
2025-02-08 07:35:18,205 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: df8d17bb-1bc6-4c7e-bc87-c7e912f002ce
127.0.0.1 - - [08/Feb/2025 07:35:18] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:22,487 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 46fec310-4fda-4122-99ec-a21b9201c5ac
2025-02-08 07:35:22,501 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 46fec310-4fda-4122-99ec-a21b9201c5ac
127.0.0.1 - - [08/Feb/2025 07:35:22] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:23,459 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 20f5a05e-294e-487f-9827-701d99018e55
2025-02-08 07:35:23,488 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 20f5a05e-294e-487f-9827-701d99018e55
127.0.0.1 - - [08/Feb/2025 07:35:23] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:27,773 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 4b7ce2d8-0f76-4001-b9a2-92ce294b9409
2025-02-08 07:35:27,801 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 4b7ce2d8-0f76-4001-b9a2-92ce294b9409
127.0.0.1 - - [08/Feb/2025 07:35:27] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:28,278 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c483b003-1551-4ad9-a271-f7f8fcf75886
2025-02-08 07:35:28,292 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c483b003-1551-4ad9-a271-f7f8fcf75886
127.0.0.1 - - [08/Feb/2025 07:35:28] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:32,823 - LoudVA - WARNING - [LoudServer] - Timeout reached for request c81d89d9-cf20-4a52-a340-caccbbf7c17c
2025-02-08 07:35:32,836 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: c81d89d9-cf20-4a52-a340-caccbbf7c17c
127.0.0.1 - - [08/Feb/2025 07:35:32] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:33,342 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 0998bb17-a661-40f7-bb10-ac58ea3d7f94
2025-02-08 07:35:33,370 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 0998bb17-a661-40f7-bb10-ac58ea3d7f94
127.0.0.1 - - [08/Feb/2025 07:35:33] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:37,391 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 3f6af91c-ae2a-471c-ba19-ff54b463d7fd
2025-02-08 07:35:37,413 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 3f6af91c-ae2a-471c-ba19-ff54b463d7fd
127.0.0.1 - - [08/Feb/2025 07:35:37] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:38,426 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 5c900521-bb27-420c-8e91-9e4e74d6a15d
2025-02-08 07:35:38,448 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 5c900521-bb27-420c-8e91-9e4e74d6a15d
127.0.0.1 - - [08/Feb/2025 07:35:38] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:42,449 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 1736dc2d-dbc2-41fc-827d-21db23fc6fd9
2025-02-08 07:35:42,466 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 1736dc2d-dbc2-41fc-827d-21db23fc6fd9
127.0.0.1 - - [08/Feb/2025 07:35:42] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:43,509 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 842354ef-404f-428c-80b4-85274993fc0b
2025-02-08 07:35:43,525 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 842354ef-404f-428c-80b4-85274993fc0b
127.0.0.1 - - [08/Feb/2025 07:35:43] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:47,501 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 2f608e34-d62d-460a-b0cf-d08f343b7d93
2025-02-08 07:35:47,505 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 2f608e34-d62d-460a-b0cf-d08f343b7d93
127.0.0.1 - - [08/Feb/2025 07:35:47] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:48,386 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 90d90d0a-cdea-4b62-b9a0-13821a21b81e
2025-02-08 07:35:48,399 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 90d90d0a-cdea-4b62-b9a0-13821a21b81e
127.0.0.1 - - [08/Feb/2025 07:35:48] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:52,686 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 8b0e224e-ed4f-47dc-b795-ba2c9936ed7f
2025-02-08 07:35:52,693 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 8b0e224e-ed4f-47dc-b795-ba2c9936ed7f
127.0.0.1 - - [08/Feb/2025 07:35:52] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:53,277 - LoudVA - WARNING - [LoudServer] - Timeout reached for request acd7aa84-509a-4361-ad30-0df079aae31f
2025-02-08 07:35:53,283 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: acd7aa84-509a-4361-ad30-0df079aae31f
127.0.0.1 - - [08/Feb/2025 07:35:53] "POST /inference HTTP/1.1" 200 -
2025-02-08 07:35:57,783 - LoudVA - WARNING - [LoudServer] - Timeout reached for request 091e60bd-6f29-40e7-994f-217642f50b7d
2025-02-08 07:35:57,789 - LoudVA - INFO - [LoudServer] - Inference completed. Request ID: 091e60bd-6f29-40e7-994f-217642f50b7d
127.0.0.1 - - [08/Feb/2025 07:35:57] "POST /inference HTTP/1.1" 200 -
