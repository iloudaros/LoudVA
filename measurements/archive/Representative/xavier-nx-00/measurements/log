Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
---Setting GPU frequency to 114750000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 114750000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 156
    Throughput: 3.24836 infer/sec
    Avg latency: 306953 usec (standard deviation 1257 usec)
    p50 latency: 306807 usec
    p90 latency: 307418 usec
    p95 latency: 308282 usec
    p99 latency: 313343 usec
    Avg HTTP time: 306917 usec (send/recv 518 usec + response wait 306399 usec)
  Server: 
    Inference count: 156
    Execution count: 156
    Successful request count: 156
    Avg request latency: 296263 usec (overhead 208 usec + queue 311 usec + compute input 315 usec + compute infer 295346 usec + compute output 83 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 3.24836 infer/sec, latency 306953 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 3375.91
Median: 3342.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 153
    Throughput: 3.39829 infer/sec
    Avg latency: 588795 usec (standard deviation 1034 usec)
    p50 latency: 588579 usec
    p90 latency: 589747 usec
    p95 latency: 590078 usec
    p99 latency: 592525 usec
    Avg HTTP time: 588766 usec (send/recv 554 usec + response wait 588212 usec)
  Server: 
    Inference count: 153
    Execution count: 153
    Successful request count: 153
    Avg request latency: 577639 usec (overhead 156 usec + queue 283342 usec + compute input 262 usec + compute infer 293795 usec + compute output 83 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 3.39829 infer/sec, latency 588795 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4895.81
Median: 4899.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 152
    Throughput: 3.89615 infer/sec
    Avg latency: 761288 usec (standard deviation 65744 usec)
    p50 latency: 758503 usec
    p90 latency: 762274 usec
    p95 latency: 801634 usec
    p99 latency: 1051724 usec
    Avg HTTP time: 761259 usec (send/recv 783 usec + response wait 760476 usec)
  Server: 
    Inference count: 152
    Execution count: 103
    Successful request count: 152
    Avg request latency: 748605 usec (overhead 207 usec + queue 343966 usec + compute input 420 usec + compute infer 403916 usec + compute output 95 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 3.89615 infer/sec, latency 761288 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4735.56
Median: 4736.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 155
    Throughput: 4.3041 infer/sec
    Avg latency: 930332 usec (standard deviation 138503 usec)
    p50 latency: 925487 usec
    p90 latency: 1182755 usec
    p95 latency: 1225978 usec
    p99 latency: 1349502 usec
    Avg HTTP time: 930303 usec (send/recv 646 usec + response wait 929657 usec)
  Server: 
    Inference count: 155
    Execution count: 82
    Successful request count: 155
    Avg request latency: 915022 usec (overhead 242 usec + queue 446181 usec + compute input 514 usec + compute infer 467985 usec + compute output 99 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 4.3041 infer/sec, latency 930332 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4834.69
Median: 4818
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 155
    Throughput: 4.69548 infer/sec
    Avg latency: 1073538 usec (standard deviation 163972 usec)
    p50 latency: 1054273 usec
    p90 latency: 1387497 usec
    p95 latency: 1517123 usec
    p99 latency: 1520237 usec
    Avg HTTP time: 1073512 usec (send/recv 603 usec + response wait 1072909 usec)
  Server: 
    Inference count: 155
    Execution count: 66
    Successful request count: 155
    Avg request latency: 1059153 usec (overhead 269 usec + queue 528841 usec + compute input 560 usec + compute infer 529379 usec + compute output 102 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 4.69548 infer/sec, latency 1073538 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4931.73
Median: 4899
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 153
    Throughput: 5.09788 infer/sec
    Avg latency: 1184126 usec (standard deviation 3294 usec)
    p50 latency: 1183452 usec
    p90 latency: 1188523 usec
    p95 latency: 1191357 usec
    p99 latency: 1194542 usec
    Avg HTTP time: 1184101 usec (send/recv 624 usec + response wait 1183477 usec)
  Server: 
    Inference count: 153
    Execution count: 51
    Successful request count: 153
    Avg request latency: 1169717 usec (overhead 301 usec + queue 577776 usec + compute input 655 usec + compute infer 590871 usec + compute output 112 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 5.09788 infer/sec, latency 1184126 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4953.64
Median: 4940.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 157
    Throughput: 5.2313 infer/sec
    Avg latency: 1334189 usec (standard deviation 2767 usec)
    p50 latency: 1333816 usec
    p90 latency: 1337720 usec
    p95 latency: 1339497 usec
    p99 latency: 1341872 usec
    Avg HTTP time: 1334164 usec (send/recv 644 usec + response wait 1333520 usec)
  Server: 
    Inference count: 157
    Execution count: 45
    Successful request count: 157
    Avg request latency: 1318018 usec (overhead 325 usec + queue 642028 usec + compute input 789 usec + compute infer 674760 usec + compute output 115 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 5.2313 infer/sec, latency 1334189 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4892.78
Median: 4859.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 156
    Throughput: 5.37715 infer/sec
    Avg latency: 1458773 usec (standard deviation 132959 usec)
    p50 latency: 1463050 usec
    p90 latency: 1468116 usec
    p95 latency: 1470113 usec
    p99 latency: 1889629 usec
    Avg HTTP time: 1458746 usec (send/recv 1400 usec + response wait 1457346 usec)
  Server: 
    Inference count: 156
    Execution count: 40
    Successful request count: 156
    Avg request latency: 1432975 usec (overhead 362 usec + queue 670541 usec + compute input 1024 usec + compute infer 760920 usec + compute output 128 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 5.37715 infer/sec, latency 1458773 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4806.75
Median: 4818.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 159
    Throughput: 5.67614 infer/sec
    Avg latency: 1601559 usec (standard deviation 3637 usec)
    p50 latency: 1600762 usec
    p90 latency: 1605381 usec
    p95 latency: 1607286 usec
    p99 latency: 1613611 usec
    Avg HTTP time: 1601534 usec (send/recv 670 usec + response wait 1600864 usec)
  Server: 
    Inference count: 159
    Execution count: 35
    Successful request count: 159
    Avg request latency: 1577497 usec (overhead 392 usec + queue 702387 usec + compute input 1111 usec + compute infer 873470 usec + compute output 136 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 5.67614 infer/sec, latency 1601559 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4888.93
Median: 4899
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
Failed to obtain stable measurement within 10 measurement windows for concurrency 10. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 10---
Running performance test
ERROR: exits as an instance (pid = 309886) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
Failed to obtain stable measurement within 10 measurement windows for concurrency 10. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 154
    Throughput: 5.49588 infer/sec
    Avg latency: 1737413 usec (standard deviation 170801 usec)
    p50 latency: 1723694 usec
    p90 latency: 1789499 usec
    p95 latency: 1902749 usec
    p99 latency: 2191236 usec
    Avg HTTP time: 1737326 usec (send/recv 2005 usec + response wait 1735321 usec)
  Server: 
    Inference count: 154
    Execution count: 32
    Successful request count: 154
    Avg request latency: 1702005 usec (overhead 505 usec + queue 719420 usec + compute input 4962 usec + compute infer 976913 usec + compute output 204 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 5.49588 infer/sec, latency 1737413 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4999.08
Median: 4981.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 164
    Throughput: 5.85027 infer/sec
    Avg latency: 1904946 usec (standard deviation 142670 usec)
    p50 latency: 1893824 usec
    p90 latency: 1907754 usec
    p95 latency: 1920662 usec
    p99 latency: 2368465 usec
    Avg HTTP time: 1904917 usec (send/recv 800 usec + response wait 1904117 usec)
  Server: 
    Inference count: 164
    Execution count: 30
    Successful request count: 164
    Avg request latency: 1867511 usec (overhead 710 usec + queue 757516 usec + compute input 4171 usec + compute infer 1104906 usec + compute output 208 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 5.85027 infer/sec, latency 1904946 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5044.76
Median: 5022.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 150
    Throughput: 5.54047 infer/sec
    Avg latency: 2089942 usec (standard deviation 147810 usec)
    p50 latency: 1787382 usec
    p90 latency: 3074777 usec
    p95 latency: 3083751 usec
    p99 latency: 3107602 usec
    Avg HTTP time: 2089867 usec (send/recv 3575 usec + response wait 2086292 usec)
  Server: 
    Inference count: 150
    Execution count: 30
    Successful request count: 150
    Avg request latency: 2063651 usec (overhead 1292 usec + queue 923908 usec + compute input 7759 usec + compute infer 1130443 usec + compute output 248 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 5.54047 infer/sec, latency 2089942 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4966.77
Median: 4940
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 159
    Throughput: 5.67324 infer/sec
    Avg latency: 2228619 usec (standard deviation 229019 usec)
    p50 latency: 2045014 usec
    p90 latency: 3106667 usec
    p95 latency: 3198092 usec
    p99 latency: 3241831 usec
    Avg HTTP time: 2228553 usec (send/recv 3653 usec + response wait 2224900 usec)
  Server: 
    Inference count: 159
    Execution count: 30
    Successful request count: 159
    Avg request latency: 2198046 usec (overhead 732 usec + queue 1069849 usec + compute input 6798 usec + compute infer 1120461 usec + compute output 205 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 5.67324 infer/sec, latency 2228619 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4920.93
Median: 4859
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 165
    Throughput: 5.68454 infer/sec
    Avg latency: 2364046 usec (standard deviation 301574 usec)
    p50 latency: 2215313 usec
    p90 latency: 3186003 usec
    p95 latency: 3197700 usec
    p99 latency: 3377618 usec
    Avg HTTP time: 2364017 usec (send/recv 3460 usec + response wait 2360557 usec)
  Server: 
    Inference count: 165
    Execution count: 30
    Successful request count: 165
    Avg request latency: 2324351 usec (overhead 635 usec + queue 1204730 usec + compute input 5699 usec + compute infer 1113071 usec + compute output 215 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 5.68454 infer/sec, latency 2364046 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4842.52
Median: 4818
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 161
    Throughput: 5.74427 infer/sec
    Avg latency: 2517868 usec (standard deviation 271324 usec)
    p50 latency: 2640797 usec
    p90 latency: 3092621 usec
    p95 latency: 3476873 usec
    p99 latency: 3497415 usec
    Avg HTTP time: 2517830 usec (send/recv 3453 usec + response wait 2514377 usec)
  Server: 
    Inference count: 161
    Execution count: 28
    Successful request count: 161
    Avg request latency: 2485537 usec (overhead 764 usec + queue 1338283 usec + compute input 7838 usec + compute infer 1138404 usec + compute output 246 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 5.74427 infer/sec, latency 2517868 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4908.62
Median: 4859
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 169
    Throughput: 6.02767 infer/sec
    Avg latency: 2723468 usec (standard deviation 212226 usec)
    p50 latency: 2776426 usec
    p90 latency: 3466174 usec
    p95 latency: 3478319 usec
    p99 latency: 3519898 usec
    Avg HTTP time: 2723426 usec (send/recv 1110 usec + response wait 2722316 usec)
  Server: 
    Inference count: 169
    Execution count: 28
    Successful request count: 169
    Avg request latency: 2698720 usec (overhead 1015 usec + queue 1568495 usec + compute input 7124 usec + compute infer 1121912 usec + compute output 174 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 6.02767 infer/sec, latency 2723468 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4925.48
Median: 4899
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
Failed to obtain stable measurement within 10 measurement windows for concurrency 17. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 17---
Running performance test
ERROR: exits as an instance (pid = 312117) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 153
    Throughput: 5.64731 infer/sec
    Avg latency: 2819417 usec (standard deviation 227420 usec)
    p50 latency: 2920983 usec
    p90 latency: 3286887 usec
    p95 latency: 3621445 usec
    p99 latency: 3769381 usec
    Avg HTTP time: 2819375 usec (send/recv 4546 usec + response wait 2814829 usec)
  Server: 
    Inference count: 153
    Execution count: 25
    Successful request count: 153
    Avg request latency: 2767158 usec (overhead 1310 usec + queue 1581077 usec + compute input 12615 usec + compute infer 1171819 usec + compute output 337 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 5.64731 infer/sec, latency 2819417 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 153
    Throughput: 5.66368 infer/sec
    Avg latency: 2811892 usec (standard deviation 179219 usec)
    p50 latency: 2922758 usec
    p90 latency: 3219136 usec
    p95 latency: 3633129 usec
    p99 latency: 3772291 usec
    Avg HTTP time: 2811847 usec (send/recv 6153 usec + response wait 2805694 usec)
  Server: 
    Inference count: 153
    Execution count: 25
    Successful request count: 153
    Avg request latency: 2774564 usec (overhead 1956 usec + queue 1589401 usec + compute input 12478 usec + compute infer 1170432 usec + compute output 296 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 5.66368 infer/sec, latency 2811892 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4895.00
Median: 4859
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 159
    Throughput: 5.86961 infer/sec
    Avg latency: 2931999 usec (standard deviation 245642 usec)
    p50 latency: 3059207 usec
    p90 latency: 3262119 usec
    p95 latency: 3763001 usec
    p99 latency: 3889530 usec
    Avg HTTP time: 2931960 usec (send/recv 6156 usec + response wait 2925804 usec)
  Server: 
    Inference count: 159
    Execution count: 25
    Successful request count: 159
    Avg request latency: 2897066 usec (overhead 898 usec + queue 1706864 usec + compute input 8989 usec + compute infer 1180067 usec + compute output 246 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 5.86961 infer/sec, latency 2931999 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 4893.91
Median: 4859
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_114750000.csv
Combined CSV file created: power_measurement_stats_freq_114750000.csv
---Setting GPU frequency to 204000000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 204000000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 152
    Throughput: 5.42634 infer/sec
    Avg latency: 183586 usec (standard deviation 48341 usec)
    p50 latency: 179287 usec
    p90 latency: 181629 usec
    p95 latency: 183698 usec
    p99 latency: 184903 usec
    Avg HTTP time: 183555 usec (send/recv 563 usec + response wait 182992 usec)
  Server: 
    Inference count: 152
    Execution count: 152
    Successful request count: 152
    Avg request latency: 172563 usec (overhead 175 usec + queue 274 usec + compute input 446 usec + compute infer 171576 usec + compute output 91 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 5.42634 infer/sec, latency 183586 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5491.80
Median: 5471.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 161
    Throughput: 5.96015 infer/sec
    Avg latency: 334465 usec (standard deviation 12063 usec)
    p50 latency: 334526 usec
    p90 latency: 337307 usec
    p95 latency: 340251 usec
    p99 latency: 343410 usec
    Avg HTTP time: 334433 usec (send/recv 677 usec + response wait 333756 usec)
  Server: 
    Inference count: 161
    Execution count: 161
    Successful request count: 161
    Avg request latency: 323213 usec (overhead 159 usec + queue 155663 usec + compute input 293 usec + compute infer 167012 usec + compute output 85 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 5.96015 infer/sec, latency 334465 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5715.77
Median: 5675
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 161
    Throughput: 6.99638 infer/sec
    Avg latency: 432214 usec (standard deviation 26262 usec)
    p50 latency: 430696 usec
    p90 latency: 432677 usec
    p95 latency: 433603 usec
    p99 latency: 597756 usec
    Avg HTTP time: 432186 usec (send/recv 635 usec + response wait 431551 usec)
  Server: 
    Inference count: 161
    Execution count: 108
    Successful request count: 161
    Avg request latency: 420894 usec (overhead 265 usec + queue 190496 usec + compute input 386 usec + compute infer 229657 usec + compute output 88 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 6.99638 infer/sec, latency 432214 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5697.63
Median: 5675
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 162
    Throughput: 7.3592 infer/sec
    Avg latency: 536629 usec (standard deviation 87487 usec)
    p50 latency: 526534 usec
    p90 latency: 692577 usec
    p95 latency: 712833 usec
    p99 latency: 775964 usec
    Avg HTTP time: 536599 usec (send/recv 921 usec + response wait 535678 usec)
  Server: 
    Inference count: 162
    Execution count: 86
    Successful request count: 162
    Avg request latency: 520481 usec (overhead 276 usec + queue 253819 usec + compute input 1111 usec + compute infer 265149 usec + compute output 125 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 7.3592 infer/sec, latency 536629 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5625.04
Median: 5593.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 168
    Throughput: 7.99598 infer/sec
    Avg latency: 615161 usec (standard deviation 112198 usec)
    p50 latency: 601130 usec
    p90 latency: 844761 usec
    p95 latency: 862944 usec
    p99 latency: 881651 usec
    Avg HTTP time: 615126 usec (send/recv 1067 usec + response wait 614059 usec)
  Server: 
    Inference count: 168
    Execution count: 73
    Successful request count: 168
    Avg request latency: 595313 usec (overhead 324 usec + queue 291447 usec + compute input 2336 usec + compute infer 301039 usec + compute output 166 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 7.99598 infer/sec, latency 615161 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5733.33
Median: 5634.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 169
    Throughput: 8.43867 infer/sec
    Avg latency: 703451 usec (standard deviation 146877 usec)
    p50 latency: 683480 usec
    p90 latency: 943609 usec
    p95 latency: 947740 usec
    p99 latency: 1024077 usec
    Avg HTTP time: 703420 usec (send/recv 1212 usec + response wait 702208 usec)
  Server: 
    Inference count: 169
    Execution count: 64
    Successful request count: 169
    Avg request latency: 686401 usec (overhead 317 usec + queue 341017 usec + compute input 2688 usec + compute infer 342260 usec + compute output 118 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 8.43867 infer/sec, latency 703451 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5679.12
Median: 5613.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 157
    Throughput: 8.71707 infer/sec
    Avg latency: 788874 usec (standard deviation 178651 usec)
    p50 latency: 757634 usec
    p90 latency: 1020000 usec
    p95 latency: 1021697 usec
    p99 latency: 1103548 usec
    Avg HTTP time: 788845 usec (send/recv 1282 usec + response wait 787563 usec)
  Server: 
    Inference count: 157
    Execution count: 53
    Successful request count: 157
    Avg request latency: 765804 usec (overhead 368 usec + queue 388280 usec + compute input 2783 usec + compute infer 374245 usec + compute output 127 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 8.71707 infer/sec, latency 788874 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5659.16
Median: 5613.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 166
    Throughput: 9.21693 infer/sec
    Avg latency: 883091 usec (standard deviation 204374 usec)
    p50 latency: 843063 usec
    p90 latency: 1106700 usec
    p95 latency: 1118596 usec
    p99 latency: 1175297 usec
    Avg HTTP time: 883065 usec (send/recv 728 usec + response wait 882337 usec)
  Server: 
    Inference count: 166
    Execution count: 49
    Successful request count: 166
    Avg request latency: 852895 usec (overhead 406 usec + queue 414980 usec + compute input 2149 usec + compute infer 435208 usec + compute output 150 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 9.21693 infer/sec, latency 883091 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5597.61
Median: 5593
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 168
    Throughput: 9.32811 infer/sec
    Avg latency: 958678 usec (standard deviation 188741 usec)
    p50 latency: 931205 usec
    p90 latency: 1186107 usec
    p95 latency: 1257505 usec
    p99 latency: 1337480 usec
    Avg HTTP time: 958648 usec (send/recv 1085 usec + response wait 957563 usec)
  Server: 
    Inference count: 168
    Execution count: 43
    Successful request count: 168
    Avg request latency: 933161 usec (overhead 443 usec + queue 490544 usec + compute input 3765 usec + compute infer 438229 usec + compute output 179 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 9.32811 infer/sec, latency 958678 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5713.15
Median: 5675
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 175
    Throughput: 9.20125 infer/sec
    Avg latency: 1053292 usec (standard deviation 213563 usec)
    p50 latency: 1012009 usec
    p90 latency: 1285377 usec
    p95 latency: 1388747 usec
    p99 latency: 1430576 usec
    Avg HTTP time: 1053261 usec (send/recv 1859 usec + response wait 1051402 usec)
  Server: 
    Inference count: 175
    Execution count: 42
    Successful request count: 175
    Avg request latency: 1024021 usec (overhead 514 usec + queue 537610 usec + compute input 8462 usec + compute infer 477230 usec + compute output 204 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 9.20125 infer/sec, latency 1053292 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5710.62
Median: 5675.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 152
    Throughput: 10.1051 infer/sec
    Avg latency: 1106529 usec (standard deviation 226400 usec)
    p50 latency: 1001574 usec
    p90 latency: 1286463 usec
    p95 latency: 1730604 usec
    p99 latency: 1737167 usec
    Avg HTTP time: 1106502 usec (send/recv 720 usec + response wait 1105782 usec)
  Server: 
    Inference count: 152
    Execution count: 31
    Successful request count: 152
    Avg request latency: 1067911 usec (overhead 729 usec + queue 430066 usec + compute input 3520 usec + compute infer 633414 usec + compute output 181 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 10.1051 infer/sec, latency 1106529 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5700.37
Median: 5675
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 158
    Throughput: 9.8658 infer/sec
    Avg latency: 1185367 usec (standard deviation 278512 usec)
    p50 latency: 1021127 usec
    p90 latency: 1737412 usec
    p95 latency: 1747376 usec
    p99 latency: 1760836 usec
    Avg HTTP time: 1185306 usec (send/recv 2657 usec + response wait 1182649 usec)
  Server: 
    Inference count: 158
    Execution count: 32
    Successful request count: 158
    Avg request latency: 1155406 usec (overhead 1167 usec + queue 521811 usec + compute input 3876 usec + compute infer 628371 usec + compute output 179 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 9.8658 infer/sec, latency 1185367 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5844.66
Median: 5798
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 156
    Throughput: 10.3923 infer/sec
    Avg latency: 1282826 usec (standard deviation 296401 usec)
    p50 latency: 1077676 usec
    p90 latency: 1761966 usec
    p95 latency: 1806561 usec
    p99 latency: 1827745 usec
    Avg HTTP time: 1282795 usec (send/recv 681 usec + response wait 1282114 usec)
  Server: 
    Inference count: 156
    Execution count: 29
    Successful request count: 156
    Avg request latency: 1257847 usec (overhead 912 usec + queue 617643 usec + compute input 3257 usec + compute infer 635876 usec + compute output 158 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 10.3923 infer/sec, latency 1282826 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5774.88
Median: 5757
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 168
    Throughput: 9.87284 infer/sec
    Avg latency: 1342421 usec (standard deviation 317920 usec)
    p50 latency: 1405968 usec
    p90 latency: 1809207 usec
    p95 latency: 1824182 usec
    p99 latency: 1889925 usec
    Avg HTTP time: 1342370 usec (send/recv 3402 usec + response wait 1338968 usec)
  Server: 
    Inference count: 168
    Execution count: 31
    Successful request count: 168
    Avg request latency: 1314984 usec (overhead 513 usec + queue 685982 usec + compute input 4257 usec + compute infer 624074 usec + compute output 157 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 9.87284 infer/sec, latency 1342421 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5741.65
Median: 5716
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 164
    Throughput: 9.63596 infer/sec
    Avg latency: 1465446 usec (standard deviation 312502 usec)
    p50 latency: 1517758 usec
    p90 latency: 1858917 usec
    p95 latency: 1969933 usec
    p99 latency: 1996613 usec
    Avg HTTP time: 1465408 usec (send/recv 4629 usec + response wait 1460779 usec)
  Server: 
    Inference count: 164
    Execution count: 29
    Successful request count: 164
    Avg request latency: 1436447 usec (overhead 1204 usec + queue 788495 usec + compute input 12621 usec + compute infer 633879 usec + compute output 247 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 9.63596 infer/sec, latency 1465446 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5709.29
Median: 5716
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 166
    Throughput: 10.3659 infer/sec
    Avg latency: 1537470 usec (standard deviation 293298 usec)
    p50 latency: 1570360 usec
    p90 latency: 1964526 usec
    p95 latency: 1971569 usec
    p99 latency: 1983203 usec
    Avg HTTP time: 1539176 usec (send/recv 769 usec + response wait 1538407 usec)
  Server: 
    Inference count: 168
    Execution count: 28
    Successful request count: 168
    Avg request latency: 1511869 usec (overhead 629 usec + queue 874492 usec + compute input 3440 usec + compute infer 633156 usec + compute output 151 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 10.3659 infer/sec, latency 1537470 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5707.21
Median: 5675.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 152
    Throughput: 10.1255 infer/sec
    Avg latency: 1629034 usec (standard deviation 230375 usec)
    p50 latency: 1652702 usec
    p90 latency: 1756783 usec
    p95 latency: 2116660 usec
    p99 latency: 2141612 usec
    Avg HTTP time: 1629002 usec (send/recv 1037 usec + response wait 1627965 usec)
  Server: 
    Inference count: 152
    Execution count: 25
    Successful request count: 152
    Avg request latency: 1602554 usec (overhead 1089 usec + queue 931983 usec + compute input 5599 usec + compute infer 663691 usec + compute output 191 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 10.1255 infer/sec, latency 1629034 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5729.18
Median: 5675
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
Failed to obtain stable measurement within 10 measurement windows for concurrency 18. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 18---
Running performance test
ERROR: exits as an instance (pid = 316686) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
Failed to obtain stable measurement within 10 measurement windows for concurrency 18. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
Failed to obtain stable measurement within 10 measurement windows for concurrency 18. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 18---
Running performance test
ERROR: exits as an instance (pid = 316872) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
Failed to obtain stable measurement within 10 measurement windows for concurrency 18. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 166
    Throughput: 10.3679 infer/sec
    Avg latency: 1748787 usec (standard deviation 212586 usec)
    p50 latency: 1809295 usec
    p90 latency: 1967230 usec
    p95 latency: 2113590 usec
    p99 latency: 2121284 usec
    Avg HTTP time: 1748753 usec (send/recv 931 usec + response wait 1747822 usec)
  Server: 
    Inference count: 166
    Execution count: 28
    Successful request count: 166
    Avg request latency: 1723965 usec (overhead 952 usec + queue 1052547 usec + compute input 7416 usec + compute infer 662824 usec + compute output 224 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 10.3679 infer/sec, latency 1748787 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 5822.52
Median: 5757.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_204000000.csv
Combined CSV file created: power_measurement_stats_freq_204000000.csv
---Setting GPU frequency to 306000000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 306000000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 168
    Throughput: 7.99587 infer/sec
    Avg latency: 124917 usec (standard deviation 2097 usec)
    p50 latency: 124620 usec
    p90 latency: 125386 usec
    p95 latency: 126802 usec
    p99 latency: 130174 usec
    Avg HTTP time: 124885 usec (send/recv 578 usec + response wait 124307 usec)
  Server: 
    Inference count: 168
    Execution count: 168
    Successful request count: 168
    Avg request latency: 114277 usec (overhead 166 usec + queue 280 usec + compute input 351 usec + compute infer 113398 usec + compute output 80 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 7.99587 infer/sec, latency 124917 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6230.87
Median: 6206
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 158
    Throughput: 8.77243 infer/sec
    Avg latency: 226510 usec (standard deviation 7817 usec)
    p50 latency: 226515 usec
    p90 latency: 229070 usec
    p95 latency: 230511 usec
    p99 latency: 232302 usec
    Avg HTTP time: 226477 usec (send/recv 699 usec + response wait 225778 usec)
  Server: 
    Inference count: 158
    Execution count: 158
    Successful request count: 158
    Avg request latency: 215472 usec (overhead 164 usec + queue 102047 usec + compute input 283 usec + compute infer 112895 usec + compute output 83 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 8.77243 infer/sec, latency 226510 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6504.57
Median: 6451
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 153
    Throughput: 10.1934 infer/sec
    Avg latency: 293433 usec (standard deviation 27827 usec)
    p50 latency: 290521 usec
    p90 latency: 295099 usec
    p95 latency: 300889 usec
    p99 latency: 404460 usec
    Avg HTTP time: 293397 usec (send/recv 651 usec + response wait 292746 usec)
  Server: 
    Inference count: 153
    Execution count: 104
    Successful request count: 153
    Avg request latency: 280351 usec (overhead 218 usec + queue 126008 usec + compute input 400 usec + compute infer 153629 usec + compute output 95 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 10.1934 infer/sec, latency 293433 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6344.21
Median: 6369
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 167
    Throughput: 11.1259 infer/sec
    Avg latency: 356388 usec (standard deviation 48406 usec)
    p50 latency: 354131 usec
    p90 latency: 365122 usec
    p95 latency: 471489 usec
    p99 latency: 519381 usec
    Avg HTTP time: 356357 usec (send/recv 925 usec + response wait 355432 usec)
  Server: 
    Inference count: 167
    Execution count: 87
    Successful request count: 167
    Avg request latency: 344119 usec (overhead 261 usec + queue 163423 usec + compute input 995 usec + compute infer 179323 usec + compute output 116 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 11.1259 infer/sec, latency 356388 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6377.36
Median: 6328.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 169
    Throughput: 12.0627 infer/sec
    Avg latency: 417233 usec (standard deviation 81143 usec)
    p50 latency: 404737 usec
    p90 latency: 573599 usec
    p95 latency: 580739 usec
    p99 latency: 584847 usec
    Avg HTTP time: 417208 usec (send/recv 590 usec + response wait 416618 usec)
  Server: 
    Inference count: 169
    Execution count: 74
    Successful request count: 169
    Avg request latency: 402887 usec (overhead 323 usec + queue 194333 usec + compute input 560 usec + compute infer 207570 usec + compute output 99 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 12.0627 infer/sec, latency 417233 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6431.50
Median: 6410.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 162
    Throughput: 12.4482 infer/sec
    Avg latency: 473211 usec (standard deviation 93280 usec)
    p50 latency: 461811 usec
    p90 latency: 639361 usec
    p95 latency: 644335 usec
    p99 latency: 689281 usec
    Avg HTTP time: 473181 usec (send/recv 955 usec + response wait 472226 usec)
  Server: 
    Inference count: 162
    Execution count: 60
    Successful request count: 162
    Avg request latency: 457724 usec (overhead 315 usec + queue 226036 usec + compute input 2073 usec + compute infer 229188 usec + compute output 111 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 12.4482 infer/sec, latency 473211 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6359.73
Median: 6369.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 167
    Throughput: 12.8342 infer/sec
    Avg latency: 537120 usec (standard deviation 119255 usec)
    p50 latency: 514361 usec
    p90 latency: 689986 usec
    p95 latency: 700264 usec
    p99 latency: 738046 usec
    Avg HTTP time: 537087 usec (send/recv 1255 usec + response wait 535832 usec)
  Server: 
    Inference count: 167
    Execution count: 56
    Successful request count: 167
    Avg request latency: 518569 usec (overhead 351 usec + queue 262173 usec + compute input 3291 usec + compute infer 252603 usec + compute output 150 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 12.8342 infer/sec, latency 537120 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6452.44
Median: 6492
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 160
    Throughput: 13.3155 infer/sec
    Avg latency: 589234 usec (standard deviation 130527 usec)
    p50 latency: 569750 usec
    p90 latency: 744854 usec
    p95 latency: 780709 usec
    p99 latency: 797518 usec
    Avg HTTP time: 589206 usec (send/recv 1403 usec + response wait 587803 usec)
  Server: 
    Inference count: 160
    Execution count: 48
    Successful request count: 160
    Avg request latency: 563740 usec (overhead 397 usec + queue 290663 usec + compute input 2862 usec + compute infer 269671 usec + compute output 146 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 13.3155 infer/sec, latency 589234 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6570.16
Median: 6492.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 175
    Throughput: 13.4517 infer/sec
    Avg latency: 674314 usec (standard deviation 163781 usec)
    p50 latency: 624553 usec
    p90 latency: 855945 usec
    p95 latency: 918946 usec
    p99 latency: 1087267 usec
    Avg HTTP time: 674285 usec (send/recv 820 usec + response wait 673465 usec)
  Server: 
    Inference count: 175
    Execution count: 47
    Successful request count: 175
    Avg request latency: 650379 usec (overhead 446 usec + queue 328327 usec + compute input 2778 usec + compute infer 318669 usec + compute output 158 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 13.4517 infer/sec, latency 674314 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6550.64
Median: 6533.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 171
    Throughput: 14.2384 infer/sec
    Avg latency: 707021 usec (standard deviation 150946 usec)
    p50 latency: 675064 usec
    p90 latency: 881375 usec
    p95 latency: 947889 usec
    p99 latency: 956328 usec
    Avg HTTP time: 706991 usec (send/recv 705 usec + response wait 706286 usec)
  Server: 
    Inference count: 171
    Execution count: 42
    Successful request count: 171
    Avg request latency: 685045 usec (overhead 425 usec + queue 363104 usec + compute input 2917 usec + compute infer 318455 usec + compute output 143 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 14.2384 infer/sec, latency 707021 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6607.87
Median: 6533.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 178
    Throughput: 14.8228 infer/sec
    Avg latency: 744788 usec (standard deviation 153113 usec)
    p50 latency: 677347 usec
    p90 latency: 872332 usec
    p95 latency: 1169273 usec
    p99 latency: 1183819 usec
    Avg HTTP time: 744759 usec (send/recv 794 usec + response wait 743965 usec)
  Server: 
    Inference count: 178
    Execution count: 35
    Successful request count: 178
    Avg request latency: 720248 usec (overhead 1176 usec + queue 283903 usec + compute input 2708 usec + compute infer 432312 usec + compute output 148 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 14.8228 infer/sec, latency 744788 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6624.72
Median: 6614.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
Failed to obtain stable measurement within 10 measurement windows for concurrency 12. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 12---
Running performance test
ERROR: exits as an instance (pid = 319455) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 179
    Throughput: 14.9032 infer/sec
    Avg latency: 813464 usec (standard deviation 191509 usec)
    p50 latency: 697902 usec
    p90 latency: 1174417 usec
    p95 latency: 1192920 usec
    p99 latency: 1202220 usec
    Avg HTTP time: 813430 usec (send/recv 785 usec + response wait 812645 usec)
  Server: 
    Inference count: 179
    Execution count: 35
    Successful request count: 179
    Avg request latency: 789978 usec (overhead 984 usec + queue 351998 usec + compute input 5265 usec + compute infer 431556 usec + compute output 174 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 14.9032 infer/sec, latency 813464 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 175
    Throughput: 14.5716 infer/sec
    Avg latency: 802148 usec (standard deviation 192413 usec)
    p50 latency: 715363 usec
    p90 latency: 1176574 usec
    p95 latency: 1179732 usec
    p99 latency: 1218238 usec
    Avg HTTP time: 802121 usec (send/recv 2448 usec + response wait 799673 usec)
  Server: 
    Inference count: 177
    Execution count: 35
    Successful request count: 177
    Avg request latency: 773110 usec (overhead 690 usec + queue 343568 usec + compute input 3612 usec + compute infer 425064 usec + compute output 176 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 14.5716 infer/sec, latency 802148 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6455.76
Median: 6451
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
Failed to obtain stable measurement within 10 measurement windows for concurrency 13. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 13---
Running performance test
ERROR: exits as an instance (pid = 319702) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
Failed to obtain stable measurement within 10 measurement windows for concurrency 13. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
Failed to obtain stable measurement within 10 measurement windows for concurrency 13. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 13---
Running performance test
ERROR: exits as an instance (pid = 319830) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
Failed to obtain stable measurement within 10 measurement windows for concurrency 13. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 170
    Throughput: 14.1539 infer/sec
    Avg latency: 870196 usec (standard deviation 199227 usec)
    p50 latency: 801567 usec
    p90 latency: 1187840 usec
    p95 latency: 1223742 usec
    p99 latency: 1235313 usec
    Avg HTTP time: 870162 usec (send/recv 3243 usec + response wait 866919 usec)
  Server: 
    Inference count: 170
    Execution count: 33
    Successful request count: 170
    Avg request latency: 834318 usec (overhead 894 usec + queue 405040 usec + compute input 4295 usec + compute infer 423919 usec + compute output 169 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 14.1539 infer/sec, latency 870196 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6540.72
Median: 6573
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 180
    Throughput: 14.9862 infer/sec
    Avg latency: 930986 usec (standard deviation 203862 usec)
    p50 latency: 950279 usec
    p90 latency: 1240783 usec
    p95 latency: 1252922 usec
    p99 latency: 1283050 usec
    Avg HTTP time: 930952 usec (send/recv 921 usec + response wait 930031 usec)
  Server: 
    Inference count: 180
    Execution count: 33
    Successful request count: 180
    Avg request latency: 899893 usec (overhead 912 usec + queue 475210 usec + compute input 4533 usec + compute infer 419058 usec + compute output 179 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 14.9862 infer/sec, latency 930986 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6567.00
Median: 6512.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 176
    Throughput: 14.6539 infer/sec
    Avg latency: 994849 usec (standard deviation 204437 usec)
    p50 latency: 1014272 usec
    p90 latency: 1278214 usec
    p95 latency: 1299515 usec
    p99 latency: 1321511 usec
    Avg HTTP time: 994822 usec (send/recv 1032 usec + response wait 993790 usec)
  Server: 
    Inference count: 176
    Execution count: 31
    Successful request count: 176
    Avg request latency: 965662 usec (overhead 1054 usec + queue 538181 usec + compute input 6243 usec + compute infer 419989 usec + compute output 194 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 14.6539 infer/sec, latency 994849 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6480.47
Median: 6512.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 180
    Throughput: 14.9682 infer/sec
    Avg latency: 1023546 usec (standard deviation 215417 usec)
    p50 latency: 1068084 usec
    p90 latency: 1279115 usec
    p95 latency: 1316814 usec
    p99 latency: 1399300 usec
    Avg HTTP time: 1023494 usec (send/recv 4055 usec + response wait 1019439 usec)
  Server: 
    Inference count: 180
    Execution count: 30
    Successful request count: 180
    Avg request latency: 983894 usec (overhead 816 usec + queue 542703 usec + compute input 5852 usec + compute infer 434333 usec + compute output 189 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 14.9682 infer/sec, latency 1023546 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6550.56
Median: 6533
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 175
    Throughput: 15.8951 infer/sec
    Avg latency: 1103167 usec (standard deviation 196841 usec)
    p50 latency: 1124069 usec
    p90 latency: 1324946 usec
    p95 latency: 1335108 usec
    p99 latency: 1365178 usec
    Avg HTTP time: 1103113 usec (send/recv 857 usec + response wait 1102256 usec)
  Server: 
    Inference count: 175
    Execution count: 28
    Successful request count: 175
    Avg request latency: 1067709 usec (overhead 753 usec + queue 635685 usec + compute input 4135 usec + compute infer 426936 usec + compute output 200 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 15.8951 infer/sec, latency 1103167 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6646.21
Median: 6614.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
Failed to obtain stable measurement within 10 measurement windows for concurrency 18. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 18---
Running performance test
ERROR: exits as an instance (pid = 320833) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
Failed to obtain stable measurement within 10 measurement windows for concurrency 18. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 182
    Throughput: 15.1551 infer/sec
    Avg latency: 1154089 usec (standard deviation 163768 usec)
    p50 latency: 1167052 usec
    p90 latency: 1421148 usec
    p95 latency: 1427768 usec
    p99 latency: 1502117 usec
    Avg HTTP time: 1154060 usec (send/recv 876 usec + response wait 1153184 usec)
  Server: 
    Inference count: 182
    Execution count: 28
    Successful request count: 182
    Avg request latency: 1125710 usec (overhead 660 usec + queue 675899 usec + compute input 3632 usec + compute infer 445343 usec + compute output 175 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 15.1551 infer/sec, latency 1154089 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6662.19
Median: 6655
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_306000000.csv
Combined CSV file created: power_measurement_stats_freq_306000000.csv
---Setting GPU frequency to 408000000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 408000000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 154
    Throughput: 10.2586 infer/sec
    Avg latency: 97246 usec (standard deviation 5045 usec)
    p50 latency: 96632 usec
    p90 latency: 97617 usec
    p95 latency: 98842 usec
    p99 latency: 103494 usec
    Avg HTTP time: 97217 usec (send/recv 568 usec + response wait 96649 usec)
  Server: 
    Inference count: 154
    Execution count: 154
    Successful request count: 154
    Avg request latency: 87280 usec (overhead 165 usec + queue 271 usec + compute input 367 usec + compute infer 86399 usec + compute output 77 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 10.2586 infer/sec, latency 97246 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 6770.83
Median: 6778.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 173
    Throughput: 11.5259 infer/sec
    Avg latency: 172038 usec (standard deviation 5615 usec)
    p50 latency: 172094 usec
    p90 latency: 173287 usec
    p95 latency: 173865 usec
    p99 latency: 177439 usec
    Avg HTTP time: 172007 usec (send/recv 646 usec + response wait 171361 usec)
  Server: 
    Inference count: 173
    Execution count: 173
    Successful request count: 173
    Avg request latency: 161720 usec (overhead 152 usec + queue 75634 usec + compute input 269 usec + compute infer 85592 usec + compute output 73 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 11.5259 infer/sec, latency 172038 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7233.82
Median: 7227
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 161
    Throughput: 13.4055 infer/sec
    Avg latency: 221961 usec (standard deviation 15573 usec)
    p50 latency: 220477 usec
    p90 latency: 223287 usec
    p95 latency: 226122 usec
    p99 latency: 305703 usec
    Avg HTTP time: 221927 usec (send/recv 655 usec + response wait 221272 usec)
  Server: 
    Inference count: 161
    Execution count: 109
    Successful request count: 161
    Avg request latency: 207802 usec (overhead 214 usec + queue 90424 usec + compute input 416 usec + compute infer 116653 usec + compute output 95 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 13.4055 infer/sec, latency 221961 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7091.08
Median: 7186.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 175
    Throughput: 14.5729 infer/sec
    Avg latency: 270449 usec (standard deviation 37899 usec)
    p50 latency: 268760 usec
    p90 latency: 273566 usec
    p95 latency: 356222 usec
    p99 latency: 394394 usec
    Avg HTTP time: 270421 usec (send/recv 821 usec + response wait 269600 usec)
  Server: 
    Inference count: 175
    Execution count: 92
    Successful request count: 175
    Avg request latency: 256788 usec (overhead 258 usec + queue 120818 usec + compute input 804 usec + compute infer 134804 usec + compute output 104 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 14.5729 infer/sec, latency 270449 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7163.83
Median: 7186.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 189
    Throughput: 15.7374 infer/sec
    Avg latency: 315097 usec (standard deviation 55836 usec)
    p50 latency: 308122 usec
    p90 latency: 417455 usec
    p95 latency: 441829 usec
    p99 latency: 447658 usec
    Avg HTTP time: 315070 usec (send/recv 911 usec + response wait 314159 usec)
  Server: 
    Inference count: 189
    Execution count: 82
    Successful request count: 189
    Avg request latency: 302513 usec (overhead 284 usec + queue 144038 usec + compute input 1178 usec + compute infer 156914 usec + compute output 98 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 15.7374 infer/sec, latency 315097 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7299.87
Median: 7308.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 179
    Throughput: 16.255 infer/sec
    Avg latency: 362850 usec (standard deviation 74780 usec)
    p50 latency: 350204 usec
    p90 latency: 464410 usec
    p95 latency: 484169 usec
    p99 latency: 508188 usec
    Avg HTTP time: 362820 usec (send/recv 969 usec + response wait 361851 usec)
  Server: 
    Inference count: 179
    Execution count: 69
    Successful request count: 179
    Avg request latency: 348149 usec (overhead 328 usec + queue 165973 usec + compute input 2692 usec + compute infer 179039 usec + compute output 116 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 16.255 infer/sec, latency 362850 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7250.72
Median: 7328.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 151
    Throughput: 16.7472 infer/sec
    Avg latency: 404297 usec (standard deviation 87644 usec)
    p50 latency: 388864 usec
    p90 latency: 522621 usec
    p95 latency: 525198 usec
    p99 latency: 570292 usec
    Avg HTTP time: 404266 usec (send/recv 1233 usec + response wait 403033 usec)
  Server: 
    Inference count: 151
    Execution count: 51
    Successful request count: 151
    Avg request latency: 383873 usec (overhead 339 usec + queue 191174 usec + compute input 1674 usec + compute infer 190556 usec + compute output 129 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 16.7472 infer/sec, latency 404297 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7211.68
Median: 7308
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 162
    Throughput: 17.9794 infer/sec
    Avg latency: 446973 usec (standard deviation 95765 usec)
    p50 latency: 429860 usec
    p90 latency: 569426 usec
    p95 latency: 599623 usec
    p99 latency: 605121 usec
    Avg HTTP time: 446945 usec (send/recv 631 usec + response wait 446314 usec)
  Server: 
    Inference count: 162
    Execution count: 47
    Successful request count: 162
    Avg request latency: 426317 usec (overhead 350 usec + queue 211123 usec + compute input 1332 usec + compute infer 213395 usec + compute output 116 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 17.9794 infer/sec, latency 446973 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7273.67
Median: 7308.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 162
    Throughput: 17.967 infer/sec
    Avg latency: 488804 usec (standard deviation 111645 usec)
    p50 latency: 470187 usec
    p90 latency: 606930 usec
    p95 latency: 636008 usec
    p99 latency: 643423 usec
    Avg HTTP time: 488772 usec (send/recv 1397 usec + response wait 487375 usec)
  Server: 
    Inference count: 162
    Execution count: 45
    Successful request count: 162
    Avg request latency: 461877 usec (overhead 364 usec + queue 240484 usec + compute input 1841 usec + compute infer 219057 usec + compute output 131 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 17.967 infer/sec, latency 488804 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7216.00
Median: 7308
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 168
    Throughput: 18.648 infer/sec
    Avg latency: 538840 usec (standard deviation 116930 usec)
    p50 latency: 514467 usec
    p90 latency: 663964 usec
    p95 latency: 690448 usec
    p99 latency: 728908 usec
    Avg HTTP time: 538806 usec (send/recv 947 usec + response wait 537859 usec)
  Server: 
    Inference count: 168
    Execution count: 40
    Successful request count: 168
    Avg request latency: 519756 usec (overhead 526 usec + queue 261810 usec + compute input 2344 usec + compute infer 254933 usec + compute output 142 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 18.648 infer/sec, latency 538840 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7351.89
Median: 7308
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 178
    Throughput: 19.7077 infer/sec
    Avg latency: 569676 usec (standard deviation 117089 usec)
    p50 latency: 517154 usec
    p90 latency: 672536 usec
    p95 latency: 888864 usec
    p99 latency: 911882 usec
    Avg HTTP time: 569644 usec (send/recv 873 usec + response wait 568771 usec)
  Server: 
    Inference count: 178
    Execution count: 35
    Successful request count: 178
    Avg request latency: 541483 usec (overhead 623 usec + queue 208322 usec + compute input 5185 usec + compute infer 327188 usec + compute output 164 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 19.7077 infer/sec, latency 569676 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7061.88
Median: 7186.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 180
    Throughput: 19.9783 infer/sec
    Avg latency: 617256 usec (standard deviation 146590 usec)
    p50 latency: 520174 usec
    p90 latency: 887324 usec
    p95 latency: 894092 usec
    p99 latency: 903070 usec
    Avg HTTP time: 617230 usec (send/recv 877 usec + response wait 616353 usec)
  Server: 
    Inference count: 180
    Execution count: 36
    Successful request count: 180
    Avg request latency: 592985 usec (overhead 564 usec + queue 264702 usec + compute input 2242 usec + compute infer 325311 usec + compute output 166 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 19.9783 infer/sec, latency 617256 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7290.60
Median: 7268
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
Failed to obtain stable measurement within 10 measurement windows for concurrency 13. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 13---
Running performance test
ERROR: exits as an instance (pid = 323311) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
Failed to obtain stable measurement within 10 measurement windows for concurrency 13. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 13---
Running performance test
ERROR: exits as an instance (pid = 323311) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
Failed to obtain stable measurement within 10 measurement windows for concurrency 13. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 13---
Running performance test
ERROR: exits as an instance (pid = 323311) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
Failed to obtain stable measurement within 10 measurement windows for concurrency 13. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 13---
Running performance test
ERROR: exits as an instance (pid = 323311) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
Failed to obtain stable measurement within 10 measurement windows for concurrency 13. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 13---
Running performance test
ERROR: exits as an instance (pid = 323311) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 170
    Throughput: 18.8702 infer/sec
    Avg latency: 662993 usec (standard deviation 151416 usec)
    p50 latency: 569830 usec
    p90 latency: 924395 usec
    p95 latency: 926846 usec
    p99 latency: 932967 usec
    Avg HTTP time: 662960 usec (send/recv 867 usec + response wait 662093 usec)
  Server: 
    Inference count: 170
    Execution count: 33
    Successful request count: 170
    Avg request latency: 636365 usec (overhead 896 usec + queue 312772 usec + compute input 2932 usec + compute infer 319589 usec + compute output 175 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 18.8702 infer/sec, latency 662993 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
Failed to obtain stable measurement within 10 measurement windows for concurrency 13. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 13---
Running performance test
ERROR: exits as an instance (pid = 323665) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
Failed to obtain stable measurement within 10 measurement windows for concurrency 13. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 170
    Throughput: 18.8526 infer/sec
    Avg latency: 650491 usec (standard deviation 153307 usec)
    p50 latency: 559054 usec
    p90 latency: 898777 usec
    p95 latency: 924653 usec
    p99 latency: 943551 usec
    Avg HTTP time: 650462 usec (send/recv 2459 usec + response wait 648003 usec)
  Server: 
    Inference count: 170
    Execution count: 33
    Successful request count: 170
    Avg request latency: 621981 usec (overhead 804 usec + queue 298110 usec + compute input 2771 usec + compute infer 320149 usec + compute output 147 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 18.8526 infer/sec, latency 650491 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7230.70
Median: 7308.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 180
    Throughput: 19.9804 infer/sec
    Avg latency: 702935 usec (standard deviation 153598 usec)
    p50 latency: 721791 usec
    p90 latency: 927573 usec
    p95 latency: 932628 usec
    p99 latency: 939274 usec
    Avg HTTP time: 702900 usec (send/recv 705 usec + response wait 702195 usec)
  Server: 
    Inference count: 180
    Execution count: 33
    Successful request count: 180
    Avg request latency: 677547 usec (overhead 660 usec + queue 358354 usec + compute input 2047 usec + compute infer 316302 usec + compute output 183 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 19.9804 infer/sec, latency 702935 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7436.00
Median: 7349.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 177
    Throughput: 19.6465 infer/sec
    Avg latency: 753310 usec (standard deviation 152544 usec)
    p50 latency: 770380 usec
    p90 latency: 968633 usec
    p95 latency: 986675 usec
    p99 latency: 1005597 usec
    Avg HTTP time: 753281 usec (send/recv 887 usec + response wait 752394 usec)
  Server: 
    Inference count: 177
    Execution count: 31
    Successful request count: 177
    Avg request latency: 726906 usec (overhead 1033 usec + queue 403155 usec + compute input 3772 usec + compute infer 318779 usec + compute output 166 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 19.6465 infer/sec, latency 753310 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7411.32
Median: 7431
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 181
    Throughput: 20.0855 infer/sec
    Avg latency: 802414 usec (standard deviation 151771 usec)
    p50 latency: 816586 usec
    p90 latency: 1006705 usec
    p95 latency: 1028275 usec
    p99 latency: 1051981 usec
    Avg HTTP time: 802371 usec (send/recv 1155 usec + response wait 801216 usec)
  Server: 
    Inference count: 181
    Execution count: 30
    Successful request count: 181
    Avg request latency: 774788 usec (overhead 1467 usec + queue 443544 usec + compute input 5807 usec + compute infer 323766 usec + compute output 204 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 20.0855 infer/sec, latency 802414 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7515.84
Median: 7553
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 176
    Throughput: 19.5319 infer/sec
    Avg latency: 852525 usec (standard deviation 127398 usec)
    p50 latency: 871765 usec
    p90 latency: 956568 usec
    p95 latency: 1091746 usec
    p99 latency: 1138705 usec
    Avg HTTP time: 852492 usec (send/recv 1479 usec + response wait 851013 usec)
  Server: 
    Inference count: 176
    Execution count: 28
    Successful request count: 176
    Avg request latency: 832929 usec (overhead 1228 usec + queue 482620 usec + compute input 8041 usec + compute infer 340847 usec + compute output 191 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 19.5319 infer/sec, latency 852525 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7327.23
Median: 7513.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
Failed to obtain stable measurement within 10 measurement windows for concurrency 18. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 18---
Running performance test
ERROR: exits as an instance (pid = 324485) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 182
    Throughput: 20.2003 infer/sec
    Avg latency: 879103 usec (standard deviation 122794 usec)
    p50 latency: 887940 usec
    p90 latency: 1074287 usec
    p95 latency: 1093114 usec
    p99 latency: 1131574 usec
    Avg HTTP time: 879063 usec (send/recv 816 usec + response wait 878247 usec)
  Server: 
    Inference count: 182
    Execution count: 28
    Successful request count: 182
    Avg request latency: 847583 usec (overhead 777 usec + queue 501975 usec + compute input 4962 usec + compute infer 339701 usec + compute output 166 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 20.2003 infer/sec, latency 879103 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
Failed to obtain stable measurement within 10 measurement windows for concurrency 18. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 18---
Running performance test
ERROR: exits as an instance (pid = 324595) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
Failed to obtain stable measurement within 10 measurement windows for concurrency 18. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 164
    Throughput: 18.1955 infer/sec
    Avg latency: 956126 usec (standard deviation 49866 usec)
    p50 latency: 940904 usec
    p90 latency: 1002783 usec
    p95 latency: 1041902 usec
    p99 latency: 1131624 usec
    Avg HTTP time: 956091 usec (send/recv 1291 usec + response wait 954800 usec)
  Server: 
    Inference count: 164
    Execution count: 35
    Successful request count: 164
    Avg request latency: 937586 usec (overhead 1274 usec + queue 590482 usec + compute input 5840 usec + compute infer 339794 usec + compute output 195 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 18.1955 infer/sec, latency 956126 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7427.56
Median: 7431
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_408000000.csv
Combined CSV file created: power_measurement_stats_freq_408000000.csv
---Setting GPU frequency to 510000000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 510000000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 161
    Throughput: 12.3754 infer/sec
    Avg latency: 80810 usec (standard deviation 5286 usec)
    p50 latency: 80238 usec
    p90 latency: 80693 usec
    p95 latency: 81305 usec
    p99 latency: 88784 usec
    Avg HTTP time: 80777 usec (send/recv 565 usec + response wait 80212 usec)
  Server: 
    Inference count: 161
    Execution count: 161
    Successful request count: 161
    Avg request latency: 71241 usec (overhead 172 usec + queue 295 usec + compute input 382 usec + compute infer 70313 usec + compute output 79 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 12.3754 infer/sec, latency 80810 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7276.96
Median: 7390.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 170
    Throughput: 14.1563 infer/sec
    Avg latency: 140337 usec (standard deviation 4585 usec)
    p50 latency: 140119 usec
    p90 latency: 141123 usec
    p95 latency: 143749 usec
    p99 latency: 151153 usec
    Avg HTTP time: 140305 usec (send/recv 702 usec + response wait 139603 usec)
  Server: 
    Inference count: 170
    Execution count: 170
    Successful request count: 170
    Avg request latency: 130308 usec (overhead 160 usec + queue 60127 usec + compute input 307 usec + compute infer 69635 usec + compute output 77 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 14.1563 infer/sec, latency 140337 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7901.16
Median: 7921.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 177
    Throughput: 16.0773 infer/sec
    Avg latency: 185513 usec (standard deviation 42714 usec)
    p50 latency: 179419 usec
    p90 latency: 181173 usec
    p95 latency: 189308 usec
    p99 latency: 463369 usec
    Avg HTTP time: 185483 usec (send/recv 729 usec + response wait 184754 usec)
  Server: 
    Inference count: 177
    Execution count: 120
    Successful request count: 177
    Avg request latency: 171392 usec (overhead 218 usec + queue 72845 usec + compute input 564 usec + compute infer 97682 usec + compute output 81 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 16.0773 infer/sec, latency 185513 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7683.31
Median: 7880.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 164
    Throughput: 18.2049 infer/sec
    Avg latency: 219900 usec (standard deviation 29479 usec)
    p50 latency: 217883 usec
    p90 latency: 228689 usec
    p95 latency: 288556 usec
    p99 latency: 320504 usec
    Avg HTTP time: 219869 usec (send/recv 644 usec + response wait 219225 usec)
  Server: 
    Inference count: 164
    Execution count: 86
    Successful request count: 164
    Avg request latency: 206396 usec (overhead 248 usec + queue 95026 usec + compute input 485 usec + compute infer 110533 usec + compute output 102 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 18.2049 infer/sec, latency 219900 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7837.50
Median: 7880.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 177
    Throughput: 19.6478 infer/sec
    Avg latency: 258924 usec (standard deviation 46575 usec)
    p50 latency: 251036 usec
    p90 latency: 326475 usec
    p95 latency: 359773 usec
    p99 latency: 362524 usec
    Avg HTTP time: 258896 usec (send/recv 643 usec + response wait 258253 usec)
  Server: 
    Inference count: 177
    Execution count: 77
    Successful request count: 177
    Avg request latency: 245481 usec (overhead 274 usec + queue 118230 usec + compute input 574 usec + compute infer 126306 usec + compute output 95 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 19.6478 infer/sec, latency 258924 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7908.52
Median: 7962
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 180
    Throughput: 19.9544 infer/sec
    Avg latency: 296221 usec (standard deviation 61827 usec)
    p50 latency: 285258 usec
    p90 latency: 395066 usec
    p95 latency: 395844 usec
    p99 latency: 424969 usec
    Avg HTTP time: 296192 usec (send/recv 1050 usec + response wait 295142 usec)
  Server: 
    Inference count: 180
    Execution count: 68
    Successful request count: 180
    Avg request latency: 276032 usec (overhead 304 usec + queue 130311 usec + compute input 2616 usec + compute infer 142685 usec + compute output 115 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 19.9544 infer/sec, latency 296221 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7941.38
Median: 7962.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 183
    Throughput: 20.3056 infer/sec
    Avg latency: 333438 usec (standard deviation 75767 usec)
    p50 latency: 324104 usec
    p90 latency: 437284 usec
    p95 latency: 458088 usec
    p99 latency: 507601 usec
    Avg HTTP time: 333404 usec (send/recv 1481 usec + response wait 331923 usec)
  Server: 
    Inference count: 183
    Execution count: 61
    Successful request count: 183
    Avg request latency: 314887 usec (overhead 422 usec + queue 150504 usec + compute input 3228 usec + compute infer 160569 usec + compute output 164 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 20.3056 infer/sec, latency 333438 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8215.77
Median: 8207.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 195
    Throughput: 21.6321 infer/sec
    Avg latency: 364644 usec (standard deviation 85313 usec)
    p50 latency: 351707 usec
    p90 latency: 459734 usec
    p95 latency: 466434 usec
    p99 latency: 506609 usec
    Avg HTTP time: 364614 usec (send/recv 1391 usec + response wait 363223 usec)
  Server: 
    Inference count: 195
    Execution count: 59
    Successful request count: 195
    Avg request latency: 338438 usec (overhead 415 usec + queue 160713 usec + compute input 1959 usec + compute infer 175216 usec + compute output 133 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 21.6321 infer/sec, latency 364644 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8193.11
Median: 8125.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 201
    Throughput: 22.3132 infer/sec
    Avg latency: 397924 usec (standard deviation 88591 usec)
    p50 latency: 380163 usec
    p90 latency: 493049 usec
    p95 latency: 514942 usec
    p99 latency: 537390 usec
    Avg HTTP time: 397897 usec (send/recv 653 usec + response wait 397244 usec)
  Server: 
    Inference count: 201
    Execution count: 54
    Successful request count: 201
    Avg request latency: 376208 usec (overhead 510 usec + queue 176722 usec + compute input 1374 usec + compute infer 197477 usec + compute output 125 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 22.3132 infer/sec, latency 397924 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8042.00
Median: 8125.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 203
    Throughput: 22.5337 infer/sec
    Avg latency: 435788 usec (standard deviation 89397 usec)
    p50 latency: 417956 usec
    p90 latency: 536474 usec
    p95 latency: 557307 usec
    p99 latency: 569656 usec
    Avg HTTP time: 435761 usec (send/recv 762 usec + response wait 434999 usec)
  Server: 
    Inference count: 203
    Execution count: 50
    Successful request count: 203
    Avg request latency: 417773 usec (overhead 428 usec + queue 225962 usec + compute input 1600 usec + compute infer 189644 usec + compute output 137 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 22.5337 infer/sec, latency 435788 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8090.07
Median: 8125.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 208
    Throughput: 23.0463 infer/sec
    Avg latency: 467688 usec (standard deviation 104474 usec)
    p50 latency: 439637 usec
    p90 latency: 590940 usec
    p95 latency: 596704 usec
    p99 latency: 744355 usec
    Avg HTTP time: 467634 usec (send/recv 1732 usec + response wait 465902 usec)
  Server: 
    Inference count: 208
    Execution count: 45
    Successful request count: 208
    Avg request latency: 437482 usec (overhead 643 usec + queue 213826 usec + compute input 6354 usec + compute infer 216481 usec + compute output 177 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 23.0463 infer/sec, latency 467688 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8211.05
Median: 8248
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 212
    Throughput: 23.53 infer/sec
    Avg latency: 497113 usec (standard deviation 118686 usec)
    p50 latency: 430869 usec
    p90 latency: 723657 usec
    p95 latency: 731963 usec
    p99 latency: 754375 usec
    Avg HTTP time: 497068 usec (send/recv 2359 usec + response wait 494709 usec)
  Server: 
    Inference count: 212
    Execution count: 42
    Successful request count: 212
    Avg request latency: 471108 usec (overhead 768 usec + queue 203301 usec + compute input 3813 usec + compute infer 263031 usec + compute output 194 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 23.53 infer/sec, latency 497113 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8081.42
Median: 8166
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 211
    Throughput: 23.414 infer/sec
    Avg latency: 540472 usec (standard deviation 123187 usec)
    p50 latency: 472073 usec
    p90 latency: 747228 usec
    p95 latency: 753483 usec
    p99 latency: 797722 usec
    Avg HTTP time: 540418 usec (send/recv 1030 usec + response wait 539388 usec)
  Server: 
    Inference count: 211
    Execution count: 40
    Successful request count: 211
    Avg request latency: 517816 usec (overhead 687 usec + queue 252132 usec + compute input 4234 usec + compute infer 260590 usec + compute output 172 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 23.414 infer/sec, latency 540472 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8179.57
Median: 8207.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
Failed to obtain stable measurement within 10 measurement windows for concurrency 14. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 14---
Running performance test
ERROR: exits as an instance (pid = 326919) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
Failed to obtain stable measurement within 10 measurement windows for concurrency 14. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 213
    Throughput: 23.6445 infer/sec
    Avg latency: 578521 usec (standard deviation 122721 usec)
    p50 latency: 596085 usec
    p90 latency: 761333 usec
    p95 latency: 789670 usec
    p99 latency: 800779 usec
    Avg HTTP time: 578496 usec (send/recv 759 usec + response wait 577737 usec)
  Server: 
    Inference count: 213
    Execution count: 39
    Successful request count: 213
    Avg request latency: 559930 usec (overhead 780 usec + queue 296506 usec + compute input 2868 usec + compute infer 259602 usec + compute output 173 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 23.6445 infer/sec, latency 578521 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8059.75
Median: 8207.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
Failed to obtain stable measurement within 10 measurement windows for concurrency 15. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 15---
Running performance test
ERROR: exits as an instance (pid = 327237) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 199
    Throughput: 24.8499 infer/sec
    Avg latency: 607612 usec (standard deviation 124890 usec)
    p50 latency: 621875 usec
    p90 latency: 783435 usec
    p95 latency: 786982 usec
    p99 latency: 801194 usec
    Avg HTTP time: 607575 usec (send/recv 652 usec + response wait 606923 usec)
  Server: 
    Inference count: 199
    Execution count: 35
    Successful request count: 199
    Avg request latency: 583165 usec (overhead 563 usec + queue 323249 usec + compute input 2195 usec + compute infer 257012 usec + compute output 145 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 24.8499 infer/sec, latency 607612 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
Failed to obtain stable measurement within 10 measurement windows for concurrency 15. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 15---
Running performance test
ERROR: exits as an instance (pid = 327346) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 199
    Throughput: 24.8412 infer/sec
    Avg latency: 611852 usec (standard deviation 126381 usec)
    p50 latency: 626859 usec
    p90 latency: 785674 usec
    p95 latency: 789735 usec
    p99 latency: 801969 usec
    Avg HTTP time: 611821 usec (send/recv 815 usec + response wait 611006 usec)
  Server: 
    Inference count: 199
    Execution count: 35
    Successful request count: 199
    Avg request latency: 589560 usec (overhead 506 usec + queue 329112 usec + compute input 2645 usec + compute infer 257153 usec + compute output 143 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 24.8412 infer/sec, latency 611852 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
Failed to obtain stable measurement within 10 measurement windows for concurrency 15. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 15---
Running performance test
ERROR: exits as an instance (pid = 327442) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 222
    Throughput: 24.6402 infer/sec
    Avg latency: 612375 usec (standard deviation 125931 usec)
    p50 latency: 624719 usec
    p90 latency: 785117 usec
    p95 latency: 792489 usec
    p99 latency: 805690 usec
    Avg HTTP time: 612347 usec (send/recv 968 usec + response wait 611379 usec)
  Server: 
    Inference count: 222
    Execution count: 39
    Successful request count: 222
    Avg request latency: 580855 usec (overhead 651 usec + queue 318901 usec + compute input 3597 usec + compute infer 257519 usec + compute output 185 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 24.6402 infer/sec, latency 612375 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 215
    Throughput: 23.7422 infer/sec
    Avg latency: 601236 usec (standard deviation 131961 usec)
    p50 latency: 626066 usec
    p90 latency: 783704 usec
    p95 latency: 791175 usec
    p99 latency: 816643 usec
    Avg HTTP time: 601177 usec (send/recv 2657 usec + response wait 598520 usec)
  Server: 
    Inference count: 215
    Execution count: 38
    Successful request count: 215
    Avg request latency: 572771 usec (overhead 544 usec + queue 309493 usec + compute input 3730 usec + compute infer 258829 usec + compute output 174 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 23.7422 infer/sec, latency 601236 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8141.83
Median: 8207.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 217
    Throughput: 24.0825 infer/sec
    Avg latency: 643894 usec (standard deviation 115129 usec)
    p50 latency: 660058 usec
    p90 latency: 763012 usec
    p95 latency: 823148 usec
    p99 latency: 859742 usec
    Avg HTTP time: 643866 usec (send/recv 712 usec + response wait 643154 usec)
  Server: 
    Inference count: 217
    Execution count: 36
    Successful request count: 217
    Avg request latency: 621239 usec (overhead 826 usec + queue 351814 usec + compute input 3119 usec + compute infer 265333 usec + compute output 146 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 24.0825 infer/sec, latency 643894 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8158.86
Median: 8220
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 150
    Throughput: 24.96 infer/sec
    Avg latency: 674818 usec (standard deviation 108453 usec)
    p50 latency: 688505 usec
    p90 latency: 760215 usec
    p95 latency: 854183 usec
    p99 latency: 903543 usec
    Avg HTTP time: 674791 usec (send/recv 734 usec + response wait 674057 usec)
  Server: 
    Inference count: 150
    Execution count: 24
    Successful request count: 150
    Avg request latency: 653570 usec (overhead 724 usec + queue 380059 usec + compute input 2400 usec + compute infer 270242 usec + compute output 144 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 24.96 infer/sec, latency 674818 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8152.44
Median: 8186.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 156
    Throughput: 25.9651 infer/sec
    Avg latency: 706554 usec (standard deviation 99557 usec)
    p50 latency: 717318 usec
    p90 latency: 872164 usec
    p95 latency: 875361 usec
    p99 latency: 883219 usec
    Avg HTTP time: 706521 usec (send/recv 679 usec + response wait 705842 usec)
  Server: 
    Inference count: 156
    Execution count: 24
    Successful request count: 156
    Avg request latency: 677664 usec (overhead 854 usec + queue 401766 usec + compute input 1866 usec + compute infer 273005 usec + compute output 172 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 25.9651 infer/sec, latency 706554 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8350.86
Median: 8329
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_510000000.csv
Combined CSV file created: power_measurement_stats_freq_510000000.csv
---Setting GPU frequency to 599250000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 599250000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 170
    Throughput: 14.1557 infer/sec
    Avg latency: 70653 usec (standard deviation 686 usec)
    p50 latency: 70751 usec
    p90 latency: 71175 usec
    p95 latency: 71594 usec
    p99 latency: 72893 usec
    Avg HTTP time: 70624 usec (send/recv 526 usec + response wait 70098 usec)
  Server: 
    Inference count: 170
    Execution count: 170
    Successful request count: 170
    Avg request latency: 61557 usec (overhead 160 usec + queue 281 usec + compute input 305 usec + compute infer 60736 usec + compute output 74 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 14.1557 infer/sec, latency 70653 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 7785.19
Median: 7839
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 196
    Throughput: 16.3193 infer/sec
    Avg latency: 122218 usec (standard deviation 3632 usec)
    p50 latency: 122038 usec
    p90 latency: 123616 usec
    p95 latency: 125172 usec
    p99 latency: 127734 usec
    Avg HTTP time: 122184 usec (send/recv 659 usec + response wait 121525 usec)
  Server: 
    Inference count: 196
    Execution count: 196
    Successful request count: 196
    Avg request latency: 112485 usec (overhead 162 usec + queue 51405 usec + compute input 286 usec + compute infer 60558 usec + compute output 73 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 16.3193 infer/sec, latency 122218 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8394.04
Median: 8452.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 172
    Throughput: 19.0917 infer/sec
    Avg latency: 157301 usec (standard deviation 12143 usec)
    p50 latency: 155883 usec
    p90 latency: 158337 usec
    p95 latency: 161292 usec
    p99 latency: 217088 usec
    Avg HTTP time: 157272 usec (send/recv 628 usec + response wait 156644 usec)
  Server: 
    Inference count: 172
    Execution count: 116
    Successful request count: 172
    Avg request latency: 147569 usec (overhead 226 usec + queue 64482 usec + compute input 480 usec + compute infer 82298 usec + compute output 82 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 19.0917 infer/sec, latency 157301 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8195.76
Median: 8438.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 190
    Throughput: 21.0888 infer/sec
    Avg latency: 189934 usec (standard deviation 12739 usec)
    p50 latency: 189150 usec
    p90 latency: 190375 usec
    p95 latency: 192643 usec
    p99 latency: 257460 usec
    Avg HTTP time: 189908 usec (send/recv 585 usec + response wait 189323 usec)
  Server: 
    Inference count: 190
    Execution count: 96
    Successful request count: 190
    Avg request latency: 180045 usec (overhead 239 usec + queue 85213 usec + compute input 449 usec + compute infer 94055 usec + compute output 88 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 21.0888 infer/sec, latency 189934 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8319.16
Median: 8452.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 200
    Throughput: 22.2008 infer/sec
    Avg latency: 222840 usec (standard deviation 35810 usec)
    p50 latency: 218584 usec
    p90 latency: 282061 usec
    p95 latency: 313007 usec
    p99 latency: 316135 usec
    Avg HTTP time: 222811 usec (send/recv 850 usec + response wait 221961 usec)
  Server: 
    Inference count: 200
    Execution count: 85
    Successful request count: 200
    Avg request latency: 211778 usec (overhead 272 usec + queue 102038 usec + compute input 1120 usec + compute infer 108244 usec + compute output 102 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 22.2008 infer/sec, latency 222840 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8435.05
Median: 8601.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 209
    Throughput: 23.1972 infer/sec
    Avg latency: 257602 usec (standard deviation 50677 usec)
    p50 latency: 246732 usec
    p90 latency: 341615 usec
    p95 latency: 346436 usec
    p99 latency: 368962 usec
    Avg HTTP time: 257572 usec (send/recv 746 usec + response wait 256826 usec)
  Server: 
    Inference count: 209
    Execution count: 79
    Successful request count: 209
    Avg request latency: 236937 usec (overhead 295 usec + queue 117156 usec + compute input 1008 usec + compute infer 118353 usec + compute output 124 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 23.1972 infer/sec, latency 257602 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8685.03
Median: 8710.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 212
    Throughput: 23.5106 infer/sec
    Avg latency: 292478 usec (standard deviation 65103 usec)
    p50 latency: 276672 usec
    p90 latency: 395763 usec
    p95 latency: 403018 usec
    p99 latency: 430774 usec
    Avg HTTP time: 292429 usec (send/recv 1439 usec + response wait 290990 usec)
  Server: 
    Inference count: 212
    Execution count: 70
    Successful request count: 212
    Avg request latency: 273260 usec (overhead 374 usec + queue 129776 usec + compute input 3960 usec + compute infer 138990 usec + compute output 159 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 23.5106 infer/sec, latency 292478 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8743.94
Median: 8792.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 154
    Throughput: 25.6202 infer/sec
    Avg latency: 318798 usec (standard deviation 63744 usec)
    p50 latency: 305185 usec
    p90 latency: 403680 usec
    p95 latency: 421459 usec
    p99 latency: 453149 usec
    Avg HTTP time: 318771 usec (send/recv 830 usec + response wait 317941 usec)
  Server: 
    Inference count: 154
    Execution count: 44
    Successful request count: 154
    Avg request latency: 303197 usec (overhead 386 usec + queue 148334 usec + compute input 2233 usec + compute infer 152105 usec + compute output 138 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 25.6202 infer/sec, latency 318798 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8637.22
Median: 8792.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 179
    Throughput: 25.5375 infer/sec
    Avg latency: 349761 usec (standard deviation 79849 usec)
    p50 latency: 334361 usec
    p90 latency: 433179 usec
    p95 latency: 448423 usec
    p99 latency: 461354 usec
    Avg HTTP time: 349734 usec (send/recv 703 usec + response wait 349031 usec)
  Server: 
    Inference count: 179
    Execution count: 49
    Successful request count: 179
    Avg request latency: 331435 usec (overhead 546 usec + queue 161381 usec + compute input 1262 usec + compute infer 168097 usec + compute output 148 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 25.5375 infer/sec, latency 349761 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8631.00
Median: 8792
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 181
    Throughput: 25.8233 infer/sec
    Avg latency: 381355 usec (standard deviation 88582 usec)
    p50 latency: 407014 usec
    p90 latency: 465493 usec
    p95 latency: 480032 usec
    p99 latency: 507505 usec
    Avg HTTP time: 381328 usec (send/recv 810 usec + response wait 380518 usec)
  Server: 
    Inference count: 181
    Execution count: 45
    Successful request count: 181
    Avg request latency: 356514 usec (overhead 608 usec + queue 170341 usec + compute input 4769 usec + compute infer 180627 usec + compute output 168 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 25.8233 infer/sec, latency 381355 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8786.25
Median: 8833.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 165
    Throughput: 27.4445 infer/sec
    Avg latency: 398236 usec (standard deviation 83660 usec)
    p50 latency: 363732 usec
    p90 latency: 479723 usec
    p95 latency: 615894 usec
    p99 latency: 624925 usec
    Avg HTTP time: 398211 usec (send/recv 706 usec + response wait 397505 usec)
  Server: 
    Inference count: 165
    Execution count: 35
    Successful request count: 165
    Avg request latency: 371375 usec (overhead 561 usec + queue 152424 usec + compute input 1954 usec + compute infer 216289 usec + compute output 147 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 27.4445 infer/sec, latency 398236 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9110.12
Median: 9242.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
Failed to obtain stable measurement within 10 measurement windows for concurrency 12. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 12---
Running performance test
ERROR: exits as an instance (pid = 329854) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 171
    Throughput: 28.4445 infer/sec
    Avg latency: 427689 usec (standard deviation 97064 usec)
    p50 latency: 383978 usec
    p90 latency: 618216 usec
    p95 latency: 634148 usec
    p99 latency: 644238 usec
    Avg HTTP time: 427176 usec (send/recv 734 usec + response wait 426442 usec)
  Server: 
    Inference count: 173
    Execution count: 33
    Successful request count: 173
    Avg request latency: 398324 usec (overhead 571 usec + queue 169705 usec + compute input 2392 usec + compute infer 225516 usec + compute output 138 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 28.4445 infer/sec, latency 427689 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
Failed to obtain stable measurement within 10 measurement windows for concurrency 12. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 12---
Running performance test
ERROR: exits as an instance (pid = 329931) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 172
    Throughput: 28.6291 infer/sec
    Avg latency: 427563 usec (standard deviation 98546 usec)
    p50 latency: 382441 usec
    p90 latency: 617980 usec
    p95 latency: 621145 usec
    p99 latency: 651128 usec
    Avg HTTP time: 427538 usec (send/recv 713 usec + response wait 426825 usec)
  Server: 
    Inference count: 172
    Execution count: 33
    Successful request count: 172
    Avg request latency: 402774 usec (overhead 586 usec + queue 174417 usec + compute input 1694 usec + compute infer 225940 usec + compute output 136 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 28.6291 infer/sec, latency 427563 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 167
    Throughput: 27.7984 infer/sec
    Avg latency: 430616 usec (standard deviation 98146 usec)
    p50 latency: 384459 usec
    p90 latency: 616696 usec
    p95 latency: 619993 usec
    p99 latency: 622232 usec
    Avg HTTP time: 430589 usec (send/recv 690 usec + response wait 429899 usec)
  Server: 
    Inference count: 167
    Execution count: 33
    Successful request count: 167
    Avg request latency: 405497 usec (overhead 586 usec + queue 179071 usec + compute input 1862 usec + compute infer 223839 usec + compute output 137 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 27.7984 infer/sec, latency 430616 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8920.70
Median: 9180.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 160
    Throughput: 26.6158 infer/sec
    Avg latency: 459565 usec (standard deviation 108085 usec)
    p50 latency: 393863 usec
    p90 latency: 629721 usec
    p95 latency: 650982 usec
    p99 latency: 656128 usec
    Avg HTTP time: 459527 usec (send/recv 2743 usec + response wait 456784 usec)
  Server: 
    Inference count: 160
    Execution count: 31
    Successful request count: 160
    Avg request latency: 432828 usec (overhead 591 usec + queue 206543 usec + compute input 2644 usec + compute infer 222891 usec + compute output 159 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 26.6158 infer/sec, latency 459565 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8821.75
Median: 8771.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 165
    Throughput: 27.4324 infer/sec
    Avg latency: 490424 usec (standard deviation 114245 usec)
    p50 latency: 486067 usec
    p90 latency: 654446 usec
    p95 latency: 666530 usec
    p99 latency: 700635 usec
    Avg HTTP time: 490394 usec (send/recv 2960 usec + response wait 487434 usec)
  Server: 
    Inference count: 165
    Execution count: 30
    Successful request count: 165
    Avg request latency: 458846 usec (overhead 556 usec + queue 228477 usec + compute input 5534 usec + compute infer 224073 usec + compute output 205 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 27.4324 infer/sec, latency 490424 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9071.30
Median: 9487
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 170
    Throughput: 28.0747 infer/sec
    Avg latency: 513660 usec (standard deviation 119426 usec)
    p50 latency: 536498 usec
    p90 latency: 675618 usec
    p95 latency: 680508 usec
    p99 latency: 688875 usec
    Avg HTTP time: 513628 usec (send/recv 3068 usec + response wait 510560 usec)
  Server: 
    Inference count: 170
    Execution count: 30
    Successful request count: 170
    Avg request latency: 489292 usec (overhead 1110 usec + queue 262575 usec + compute input 2458 usec + compute infer 222995 usec + compute output 153 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 28.0747 infer/sec, latency 513660 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9133.38
Median: 9365
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 168
    Throughput: 27.9614 infer/sec
    Avg latency: 558951 usec (standard deviation 93726 usec)
    p50 latency: 573911 usec
    p90 latency: 630808 usec
    p95 latency: 735865 usec
    p99 latency: 742322 usec
    Avg HTTP time: 558925 usec (send/recv 706 usec + response wait 558219 usec)
  Server: 
    Inference count: 168
    Execution count: 28
    Successful request count: 168
    Avg request latency: 542913 usec (overhead 1512 usec + queue 306390 usec + compute input 2177 usec + compute infer 232679 usec + compute output 154 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 27.9614 infer/sec, latency 558951 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8700.21
Median: 9201
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 173
    Throughput: 28.7952 infer/sec
    Avg latency: 583827 usec (standard deviation 100699 usec)
    p50 latency: 590772 usec
    p90 latency: 701946 usec
    p95 latency: 712338 usec
    p99 latency: 749432 usec
    Avg HTTP time: 583796 usec (send/recv 613 usec + response wait 583183 usec)
  Server: 
    Inference count: 173
    Execution count: 27
    Successful request count: 173
    Avg request latency: 557040 usec (overhead 597 usec + queue 323171 usec + compute input 3732 usec + compute infer 229392 usec + compute output 147 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 28.7952 infer/sec, latency 583827 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8769.35
Median: 9119
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 178
    Throughput: 29.6306 infer/sec
    Avg latency: 609491 usec (standard deviation 97482 usec)
    p50 latency: 620382 usec
    p90 latency: 728276 usec
    p95 latency: 729600 usec
    p99 latency: 731318 usec
    Avg HTTP time: 609466 usec (send/recv 632 usec + response wait 608834 usec)
  Server: 
    Inference count: 178
    Execution count: 27
    Successful request count: 178
    Avg request latency: 583811 usec (overhead 724 usec + queue 350640 usec + compute input 1813 usec + compute infer 230489 usec + compute output 143 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 29.6306 infer/sec, latency 609491 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9239.14
Median: 9406.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_599250000.csv
Combined CSV file created: power_measurement_stats_freq_599250000.csv
---Setting GPU frequency to 701250000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 701250000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 186
    Throughput: 15.4855 infer/sec
    Avg latency: 64321 usec (standard deviation 5533 usec)
    p50 latency: 63529 usec
    p90 latency: 64717 usec
    p95 latency: 68100 usec
    p99 latency: 76063 usec
    Avg HTTP time: 64289 usec (send/recv 620 usec + response wait 63669 usec)
  Server: 
    Inference count: 186
    Execution count: 186
    Successful request count: 186
    Avg request latency: 54761 usec (overhead 166 usec + queue 270 usec + compute input 464 usec + compute infer 53784 usec + compute output 76 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 15.4855 infer/sec, latency 64321 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8005.80
Median: 8166
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 167
    Throughput: 18.5376 infer/sec
    Avg latency: 107375 usec (standard deviation 3525 usec)
    p50 latency: 107056 usec
    p90 latency: 107918 usec
    p95 latency: 108489 usec
    p99 latency: 109282 usec
    Avg HTTP time: 107337 usec (send/recv 718 usec + response wait 106619 usec)
  Server: 
    Inference count: 167
    Execution count: 167
    Successful request count: 167
    Avg request latency: 97234 usec (overhead 155 usec + queue 43633 usec + compute input 300 usec + compute infer 53076 usec + compute output 69 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 18.5376 infer/sec, latency 107375 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8665.38
Median: 8990.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 198
    Throughput: 21.9789 infer/sec
    Avg latency: 137376 usec (standard deviation 8740 usec)
    p50 latency: 136671 usec
    p90 latency: 137900 usec
    p95 latency: 139467 usec
    p99 latency: 190213 usec
    Avg HTTP time: 137348 usec (send/recv 631 usec + response wait 136717 usec)
  Server: 
    Inference count: 198
    Execution count: 133
    Successful request count: 198
    Avg request latency: 127004 usec (overhead 217 usec + queue 54145 usec + compute input 410 usec + compute infer 72147 usec + compute output 84 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 21.9789 infer/sec, latency 137376 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8871.73
Median: 9064
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 211
    Throughput: 23.418 infer/sec
    Avg latency: 168599 usec (standard deviation 20253 usec)
    p50 latency: 166166 usec
    p90 latency: 172657 usec
    p95 latency: 220954 usec
    p99 latency: 247943 usec
    Avg HTTP time: 168570 usec (send/recv 792 usec + response wait 167778 usec)
  Server: 
    Inference count: 211
    Execution count: 109
    Successful request count: 211
    Avg request latency: 154931 usec (overhead 256 usec + queue 70436 usec + compute input 914 usec + compute infer 83224 usec + compute output 100 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 23.418 infer/sec, latency 168599 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8995.11
Median: 9078.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 174
    Throughput: 24.8236 infer/sec
    Avg latency: 197716 usec (standard deviation 34901 usec)
    p50 latency: 192354 usec
    p90 latency: 271168 usec
    p95 latency: 275207 usec
    p99 latency: 288499 usec
    Avg HTTP time: 197688 usec (send/recv 892 usec + response wait 196796 usec)
  Server: 
    Inference count: 174
    Execution count: 75
    Successful request count: 174
    Avg request latency: 182111 usec (overhead 277 usec + queue 85241 usec + compute input 1410 usec + compute infer 95080 usec + compute output 102 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 24.8236 infer/sec, latency 197716 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9015.28
Median: 9180.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 206
    Throughput: 25.7102 infer/sec
    Avg latency: 229560 usec (standard deviation 46428 usec)
    p50 latency: 220205 usec
    p90 latency: 302423 usec
    p95 latency: 314117 usec
    p99 latency: 352150 usec
    Avg HTTP time: 229525 usec (send/recv 1230 usec + response wait 228295 usec)
  Server: 
    Inference count: 206
    Execution count: 77
    Successful request count: 206
    Avg request latency: 213705 usec (overhead 346 usec + queue 102275 usec + compute input 2761 usec + compute infer 108170 usec + compute output 152 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 25.7102 infer/sec, latency 229560 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9360.56
Median: 9385.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 162
    Throughput: 26.9495 infer/sec
    Avg latency: 256211 usec (standard deviation 59540 usec)
    p50 latency: 246566 usec
    p90 latency: 333871 usec
    p95 latency: 346469 usec
    p99 latency: 350864 usec
    Avg HTTP time: 256181 usec (send/recv 1708 usec + response wait 254473 usec)
  Server: 
    Inference count: 162
    Execution count: 55
    Successful request count: 162
    Avg request latency: 233660 usec (overhead 352 usec + queue 109201 usec + compute input 3423 usec + compute infer 120540 usec + compute output 143 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 26.9495 infer/sec, latency 256211 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9377.41
Median: 9344.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 176
    Throughput: 29.2929 infer/sec
    Avg latency: 278042 usec (standard deviation 60174 usec)
    p50 latency: 263602 usec
    p90 latency: 352719 usec
    p95 latency: 369252 usec
    p99 latency: 384592 usec
    Avg HTTP time: 278014 usec (send/recv 719 usec + response wait 277295 usec)
  Server: 
    Inference count: 176
    Execution count: 52
    Successful request count: 176
    Avg request latency: 258874 usec (overhead 361 usec + queue 128300 usec + compute input 1488 usec + compute infer 128592 usec + compute output 132 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 29.2929 infer/sec, latency 278042 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9321.88
Median: 9446.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 180
    Throughput: 29.963 infer/sec
    Avg latency: 305102 usec (standard deviation 67007 usec)
    p50 latency: 292478 usec
    p90 latency: 376221 usec
    p95 latency: 378535 usec
    p99 latency: 397200 usec
    Avg HTTP time: 305076 usec (send/recv 634 usec + response wait 304442 usec)
  Server: 
    Inference count: 180
    Execution count: 49
    Successful request count: 180
    Avg request latency: 284031 usec (overhead 362 usec + queue 139293 usec + compute input 1205 usec + compute infer 143049 usec + compute output 121 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 29.963 infer/sec, latency 305102 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9467.46
Median: 9487
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 183
    Throughput: 30.4593 infer/sec
    Avg latency: 324067 usec (standard deviation 73861 usec)
    p50 latency: 316843 usec
    p90 latency: 393305 usec
    p95 latency: 396898 usec
    p99 latency: 447057 usec
    Avg HTTP time: 324042 usec (send/recv 698 usec + response wait 323344 usec)
  Server: 
    Inference count: 183
    Execution count: 46
    Successful request count: 183
    Avg request latency: 300560 usec (overhead 435 usec + queue 141400 usec + compute input 1223 usec + compute infer 157361 usec + compute output 141 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 30.4593 infer/sec, latency 324067 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9740.60
Median: 9978
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 184
    Throughput: 30.4898 infer/sec
    Avg latency: 342390 usec (standard deviation 71735 usec)
    p50 latency: 313494 usec
    p90 latency: 419784 usec
    p95 latency: 536250 usec
    p99 latency: 547995 usec
    Avg HTTP time: 342363 usec (send/recv 2125 usec + response wait 340238 usec)
  Server: 
    Inference count: 184
    Execution count: 38
    Successful request count: 184
    Avg request latency: 313744 usec (overhead 639 usec + queue 116585 usec + compute input 1600 usec + compute infer 194757 usec + compute output 163 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 30.4898 infer/sec, latency 342390 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9539.15
Median: 10060
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 181
    Throughput: 30.1214 infer/sec
    Avg latency: 376436 usec (standard deviation 82960 usec)
    p50 latency: 341039 usec
    p90 latency: 500922 usec
    p95 latency: 549827 usec
    p99 latency: 564221 usec
    Avg HTTP time: 376402 usec (send/recv 2519 usec + response wait 373883 usec)
  Server: 
    Inference count: 181
    Execution count: 37
    Successful request count: 181
    Avg request latency: 350629 usec (overhead 679 usec + queue 161819 usec + compute input 4665 usec + compute infer 183309 usec + compute output 156 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 30.1214 infer/sec, latency 376436 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9913.81
Median: 10142
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 189
    Throughput: 31.365 infer/sec
    Avg latency: 402553 usec (standard deviation 96670 usec)
    p50 latency: 351745 usec
    p90 latency: 563157 usec
    p95 latency: 574922 usec
    p99 latency: 595379 usec
    Avg HTTP time: 402521 usec (send/recv 2789 usec + response wait 399732 usec)
  Server: 
    Inference count: 189
    Execution count: 36
    Successful request count: 189
    Avg request latency: 371276 usec (overhead 917 usec + queue 170195 usec + compute input 4131 usec + compute infer 195854 usec + compute output 178 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 31.365 infer/sec, latency 402553 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9762.30
Median: 10101
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 200
    Throughput: 33.2811 infer/sec
    Avg latency: 427078 usec (standard deviation 91013 usec)
    p50 latency: 438461 usec
    p90 latency: 567938 usec
    p95 latency: 585558 usec
    p99 latency: 588661 usec
    Avg HTTP time: 426842 usec (send/recv 672 usec + response wait 426170 usec)
  Server: 
    Inference count: 197
    Execution count: 35
    Successful request count: 197
    Avg request latency: 398130 usec (overhead 640 usec + queue 199791 usec + compute input 2058 usec + compute infer 195500 usec + compute output 140 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 33.2811 infer/sec, latency 427078 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9395.57
Median: 10101
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 204
    Throughput: 33.9576 infer/sec
    Avg latency: 455315 usec (standard deviation 94480 usec)
    p50 latency: 468771 usec
    p90 latency: 587468 usec
    p95 latency: 589146 usec
    p99 latency: 591111 usec
    Avg HTTP time: 455290 usec (send/recv 628 usec + response wait 454662 usec)
  Server: 
    Inference count: 204
    Execution count: 35
    Successful request count: 204
    Avg request latency: 432482 usec (overhead 654 usec + queue 235624 usec + compute input 1711 usec + compute infer 194352 usec + compute output 140 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 33.9576 infer/sec, latency 455315 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9905.19
Median: 10101.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 200
    Throughput: 33.2837 infer/sec
    Avg latency: 486000 usec (standard deviation 95619 usec)
    p50 latency: 496374 usec
    p90 latency: 594823 usec
    p95 latency: 604311 usec
    p99 latency: 618949 usec
    Avg HTTP time: 485972 usec (send/recv 780 usec + response wait 485192 usec)
  Server: 
    Inference count: 200
    Execution count: 33
    Successful request count: 200
    Avg request latency: 461227 usec (overhead 676 usec + queue 261931 usec + compute input 3097 usec + compute infer 195365 usec + compute output 158 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 33.2837 infer/sec, latency 486000 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9793.62
Median: 10121.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 192
    Throughput: 31.8246 infer/sec
    Avg latency: 522392 usec (standard deviation 95407 usec)
    p50 latency: 520408 usec
    p90 latency: 636337 usec
    p95 latency: 655386 usec
    p99 latency: 664876 usec
    Avg HTTP time: 522361 usec (send/recv 911 usec + response wait 521450 usec)
  Server: 
    Inference count: 192
    Execution count: 31
    Successful request count: 192
    Avg request latency: 500876 usec (overhead 699 usec + queue 298660 usec + compute input 6401 usec + compute infer 194971 usec + compute output 144 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 31.8246 infer/sec, latency 522392 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9974.81
Median: 10080.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 189
    Throughput: 31.4439 infer/sec
    Avg latency: 573506 usec (standard deviation 9754 usec)
    p50 latency: 570918 usec
    p90 latency: 588216 usec
    p95 latency: 592518 usec
    p99 latency: 597511 usec
    Avg HTTP time: 573464 usec (send/recv 1218 usec + response wait 572246 usec)
  Server: 
    Inference count: 189
    Execution count: 42
    Successful request count: 189
    Avg request latency: 549816 usec (overhead 598 usec + queue 340557 usec + compute input 3081 usec + compute infer 205398 usec + compute output 181 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 31.4439 infer/sec, latency 573506 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9437.05
Median: 10162.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_701250000.csv
Combined CSV file created: power_measurement_stats_freq_701250000.csv
---Setting GPU frequency to 752250000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 752250000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 197
    Throughput: 16.4027 infer/sec
    Avg latency: 60827 usec (standard deviation 4302 usec)
    p50 latency: 60517 usec
    p90 latency: 61057 usec
    p95 latency: 61462 usec
    p99 latency: 63495 usec
    Avg HTTP time: 60796 usec (send/recv 555 usec + response wait 60241 usec)
  Server: 
    Inference count: 197
    Execution count: 197
    Successful request count: 197
    Avg request latency: 51485 usec (overhead 160 usec + queue 266 usec + compute input 345 usec + compute infer 50639 usec + compute output 73 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 16.4027 infer/sec, latency 60827 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8225.41
Median: 8370.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 176
    Throughput: 19.5342 infer/sec
    Avg latency: 101737 usec (standard deviation 3188 usec)
    p50 latency: 101429 usec
    p90 latency: 103499 usec
    p95 latency: 105184 usec
    p99 latency: 106961 usec
    Avg HTTP time: 101699 usec (send/recv 670 usec + response wait 101029 usec)
  Server: 
    Inference count: 176
    Execution count: 176
    Successful request count: 176
    Avg request latency: 91922 usec (overhead 160 usec + queue 41099 usec + compute input 275 usec + compute infer 50315 usec + compute output 72 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 19.5342 infer/sec, latency 101737 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9248.22
Median: 9406.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 201
    Throughput: 22.2897 infer/sec
    Avg latency: 133465 usec (standard deviation 25176 usec)
    p50 latency: 130158 usec
    p90 latency: 134045 usec
    p95 latency: 136414 usec
    p99 latency: 317773 usec
    Avg HTTP time: 133432 usec (send/recv 768 usec + response wait 132664 usec)
  Server: 
    Inference count: 201
    Execution count: 135
    Successful request count: 201
    Avg request latency: 121197 usec (overhead 222 usec + queue 49837 usec + compute input 574 usec + compute infer 70467 usec + compute output 96 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 22.2897 infer/sec, latency 133465 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9193.16
Median: 9426.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 195
    Throughput: 24.3418 infer/sec
    Avg latency: 162061 usec (standard deviation 30542 usec)
    p50 latency: 157014 usec
    p90 latency: 204528 usec
    p95 latency: 210699 usec
    p99 latency: 321858 usec
    Avg HTTP time: 162030 usec (send/recv 961 usec + response wait 161069 usec)
  Server: 
    Inference count: 195
    Execution count: 102
    Successful request count: 195
    Avg request latency: 150582 usec (overhead 256 usec + queue 67231 usec + compute input 890 usec + compute infer 82096 usec + compute output 109 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 24.3418 infer/sec, latency 162061 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9355.56
Median: 9507.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 159
    Throughput: 26.4528 infer/sec
    Avg latency: 185295 usec (standard deviation 35596 usec)
    p50 latency: 178867 usec
    p90 latency: 251370 usec
    p95 latency: 257322 usec
    p99 latency: 261174 usec
    Avg HTTP time: 185265 usec (send/recv 908 usec + response wait 184357 usec)
  Server: 
    Inference count: 159
    Execution count: 70
    Successful request count: 159
    Avg request latency: 169589 usec (overhead 252 usec + queue 79464 usec + compute input 1229 usec + compute infer 88544 usec + compute output 98 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 26.4528 infer/sec, latency 185295 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9471.75
Median: 9507.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 172
    Throughput: 28.6152 infer/sec
    Avg latency: 213013 usec (standard deviation 44992 usec)
    p50 latency: 202065 usec
    p90 latency: 280186 usec
    p95 latency: 283945 usec
    p99 latency: 309816 usec
    Avg HTTP time: 212987 usec (send/recv 631 usec + response wait 212356 usec)
  Server: 
    Inference count: 172
    Execution count: 65
    Successful request count: 172
    Avg request latency: 200029 usec (overhead 291 usec + queue 96735 usec + compute input 1790 usec + compute infer 101112 usec + compute output 100 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 28.6152 infer/sec, latency 213013 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9843.81
Median: 10080.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 175
    Throughput: 29.1025 infer/sec
    Avg latency: 234832 usec (standard deviation 54181 usec)
    p50 latency: 226659 usec
    p90 latency: 304904 usec
    p95 latency: 309128 usec
    p99 latency: 322585 usec
    Avg HTTP time: 234805 usec (send/recv 1159 usec + response wait 233646 usec)
  Server: 
    Inference count: 175
    Execution count: 59
    Successful request count: 175
    Avg request latency: 217094 usec (overhead 311 usec + queue 103340 usec + compute input 1105 usec + compute infer 112227 usec + compute output 110 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 29.1025 infer/sec, latency 234832 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9881.75
Median: 10080.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 182
    Throughput: 30.2934 infer/sec
    Avg latency: 259193 usec (standard deviation 56354 usec)
    p50 latency: 247809 usec
    p90 latency: 326530 usec
    p95 latency: 327366 usec
    p99 latency: 330758 usec
    Avg HTTP time: 259161 usec (send/recv 1178 usec + response wait 257983 usec)
  Server: 
    Inference count: 182
    Execution count: 55
    Successful request count: 182
    Avg request latency: 241612 usec (overhead 329 usec + queue 125234 usec + compute input 892 usec + compute infer 115045 usec + compute output 111 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 30.2934 infer/sec, latency 259193 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9932.58
Median: 10284.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 193
    Throughput: 32.12 infer/sec
    Avg latency: 283489 usec (standard deviation 64570 usec)
    p50 latency: 267574 usec
    p90 latency: 347487 usec
    p95 latency: 364772 usec
    p99 latency: 369528 usec
    Avg HTTP time: 283462 usec (send/recv 657 usec + response wait 282805 usec)
  Server: 
    Inference count: 193
    Execution count: 52
    Successful request count: 193
    Avg request latency: 261756 usec (overhead 392 usec + queue 124619 usec + compute input 1387 usec + compute infer 135242 usec + compute output 115 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 32.12 infer/sec, latency 283489 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9899.55
Median: 10305.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 196
    Throughput: 32.6133 infer/sec
    Avg latency: 309217 usec (standard deviation 73108 usec)
    p50 latency: 297284 usec
    p90 latency: 390475 usec
    p95 latency: 402475 usec
    p99 latency: 476824 usec
    Avg HTTP time: 309190 usec (send/recv 667 usec + response wait 308523 usec)
  Server: 
    Inference count: 196
    Execution count: 48
    Successful request count: 196
    Avg request latency: 288009 usec (overhead 440 usec + queue 127899 usec + compute input 2430 usec + compute infer 157108 usec + compute output 130 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 32.6133 infer/sec, latency 309217 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10247.40
Median: 10366.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 209
    Throughput: 34.7892 infer/sec
    Avg latency: 325410 usec (standard deviation 67306 usec)
    p50 latency: 295861 usec
    p90 latency: 415002 usec
    p95 latency: 506621 usec
    p99 latency: 512065 usec
    Avg HTTP time: 325384 usec (send/recv 675 usec + response wait 324709 usec)
  Server: 
    Inference count: 209
    Execution count: 43
    Successful request count: 209
    Avg request latency: 295815 usec (overhead 676 usec + queue 112154 usec + compute input 1636 usec + compute infer 181218 usec + compute output 131 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 34.7892 infer/sec, latency 325410 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9969.91
Median: 10428.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 190
    Throughput: 31.5895 infer/sec
    Avg latency: 363595 usec (standard deviation 84420 usec)
    p50 latency: 324855 usec
    p90 latency: 509174 usec
    p95 latency: 528899 usec
    p99 latency: 565456 usec
    Avg HTTP time: 363536 usec (send/recv 2738 usec + response wait 360798 usec)
  Server: 
    Inference count: 190
    Execution count: 38
    Successful request count: 190
    Avg request latency: 339539 usec (overhead 535 usec + queue 150321 usec + compute input 6456 usec + compute infer 182070 usec + compute output 156 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 31.5895 infer/sec, latency 363595 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9924.00
Median: 10428
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 209
    Throughput: 34.7888 infer/sec
    Avg latency: 379176 usec (standard deviation 86852 usec)
    p50 latency: 341168 usec
    p90 latency: 527576 usec
    p95 latency: 531237 usec
    p99 latency: 553087 usec
    Avg HTTP time: 379151 usec (send/recv 636 usec + response wait 378515 usec)
  Server: 
    Inference count: 209
    Execution count: 39
    Successful request count: 209
    Avg request latency: 351822 usec (overhead 608 usec + queue 164637 usec + compute input 2454 usec + compute infer 183990 usec + compute output 132 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 34.7888 infer/sec, latency 379176 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10401.35
Median: 10510.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 201
    Throughput: 33.4568 infer/sec
    Avg latency: 411577 usec (standard deviation 90112 usec)
    p50 latency: 418371 usec
    p90 latency: 537500 usec
    p95 latency: 548604 usec
    p99 latency: 578548 usec
    Avg HTTP time: 411550 usec (send/recv 758 usec + response wait 410792 usec)
  Server: 
    Inference count: 201
    Execution count: 37
    Successful request count: 201
    Avg request latency: 387940 usec (overhead 1039 usec + queue 202144 usec + compute input 3996 usec + compute infer 180621 usec + compute output 139 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 33.4568 infer/sec, latency 411577 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10262.29
Median: 10469.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 207
    Throughput: 34.4505 infer/sec
    Avg latency: 431760 usec (standard deviation 88170 usec)
    p50 latency: 444265 usec
    p90 latency: 554645 usec
    p95 latency: 560975 usec
    p99 latency: 576448 usec
    Avg HTTP time: 431735 usec (send/recv 688 usec + response wait 431047 usec)
  Server: 
    Inference count: 207
    Execution count: 36
    Successful request count: 207
    Avg request latency: 408444 usec (overhead 615 usec + queue 222516 usec + compute input 2197 usec + compute infer 182959 usec + compute output 157 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 34.4505 infer/sec, latency 431760 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9178.55
Median: 10346.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 209
    Throughput: 34.7566 infer/sec
    Avg latency: 460223 usec (standard deviation 87382 usec)
    p50 latency: 466107 usec
    p90 latency: 577268 usec
    p95 latency: 578914 usec
    p99 latency: 626716 usec
    Avg HTTP time: 458891 usec (send/recv 688 usec + response wait 458203 usec)
  Server: 
    Inference count: 211
    Execution count: 35
    Successful request count: 211
    Avg request latency: 435862 usec (overhead 551 usec + queue 245832 usec + compute input 4377 usec + compute infer 184964 usec + compute output 137 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 34.7566 infer/sec, latency 460223 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10135.93
Median: 10510.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 209
    Throughput: 34.7806 infer/sec
    Avg latency: 483058 usec (standard deviation 86297 usec)
    p50 latency: 493765 usec
    p90 latency: 579280 usec
    p95 latency: 583441 usec
    p99 latency: 606472 usec
    Avg HTTP time: 482911 usec (send/recv 791 usec + response wait 482120 usec)
  Server: 
    Inference count: 208
    Execution count: 33
    Successful request count: 208
    Avg request latency: 459695 usec (overhead 701 usec + queue 270282 usec + compute input 2707 usec + compute infer 185857 usec + compute output 147 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 34.7806 infer/sec, latency 483058 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10400.77
Median: 10551.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 216
    Throughput: 35.9359 infer/sec
    Avg latency: 510413 usec (standard deviation 74378 usec)
    p50 latency: 524348 usec
    p90 latency: 623648 usec
    p95 latency: 637051 usec
    p99 latency: 657695 usec
    Avg HTTP time: 510386 usec (send/recv 1023 usec + response wait 509363 usec)
  Server: 
    Inference count: 216
    Execution count: 33
    Successful request count: 216
    Avg request latency: 483366 usec (overhead 1022 usec + queue 283323 usec + compute input 5596 usec + compute infer 193240 usec + compute output 184 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 35.9359 infer/sec, latency 510413 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10274.94
Median: 10673
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_752250000.csv
Combined CSV file created: power_measurement_stats_freq_752250000.csv
---Setting GPU frequency to 803250000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 803250000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 157
    Throughput: 17.4253 infer/sec
    Avg latency: 57239 usec (standard deviation 2119 usec)
    p50 latency: 56893 usec
    p90 latency: 57896 usec
    p95 latency: 59697 usec
    p99 latency: 64727 usec
    Avg HTTP time: 57208 usec (send/recv 550 usec + response wait 56658 usec)
  Server: 
    Inference count: 157
    Execution count: 157
    Successful request count: 157
    Avg request latency: 48021 usec (overhead 156 usec + queue 275 usec + compute input 314 usec + compute infer 47202 usec + compute output 73 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 17.4253 infer/sec, latency 57239 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 8859.69
Median: 9309.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 180
    Throughput: 19.8562 infer/sec
    Avg latency: 100596 usec (standard deviation 23868 usec)
    p50 latency: 94955 usec
    p90 latency: 99324 usec
    p95 latency: 120521 usec
    p99 latency: 230556 usec
    Avg HTTP time: 100557 usec (send/recv 922 usec + response wait 99635 usec)
  Server: 
    Inference count: 180
    Execution count: 180
    Successful request count: 180
    Avg request latency: 89725 usec (overhead 178 usec + queue 39550 usec + compute input 410 usec + compute infer 49498 usec + compute output 88 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 19.8562 infer/sec, latency 100596 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10318.54
Median: 10448.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 173
    Throughput: 24.6841 infer/sec
    Avg latency: 121559 usec (standard deviation 9206 usec)
    p50 latency: 120443 usec
    p90 latency: 123161 usec
    p95 latency: 127933 usec
    p99 latency: 167466 usec
    Avg HTTP time: 121530 usec (send/recv 617 usec + response wait 120913 usec)
  Server: 
    Inference count: 173
    Execution count: 117
    Successful request count: 173
    Avg request latency: 108342 usec (overhead 201 usec + queue 44251 usec + compute input 392 usec + compute infer 63416 usec + compute output 81 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 24.6841 infer/sec, latency 121559 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10089.65
Median: 10510.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 159
    Throughput: 26.4583 infer/sec
    Avg latency: 148758 usec (standard deviation 25231 usec)
    p50 latency: 145666 usec
    p90 latency: 191864 usec
    p95 latency: 214907 usec
    p99 latency: 220808 usec
    Avg HTTP time: 148728 usec (send/recv 783 usec + response wait 147945 usec)
  Server: 
    Inference count: 159
    Execution count: 85
    Successful request count: 159
    Avg request latency: 135507 usec (overhead 241 usec + queue 60260 usec + compute input 868 usec + compute infer 74038 usec + compute output 99 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 26.4583 infer/sec, latency 148758 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10350.75
Median: 10510.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 170
    Throughput: 28.2858 infer/sec
    Avg latency: 173840 usec (standard deviation 31314 usec)
    p50 latency: 169334 usec
    p90 latency: 222386 usec
    p95 latency: 241199 usec
    p99 latency: 254157 usec
    Avg HTTP time: 173811 usec (send/recv 932 usec + response wait 172879 usec)
  Server: 
    Inference count: 170
    Execution count: 74
    Successful request count: 170
    Avg request latency: 158222 usec (overhead 263 usec + queue 72563 usec + compute input 1228 usec + compute infer 84075 usec + compute output 92 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 28.2858 infer/sec, latency 173840 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10289.25
Median: 10693.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 182
    Throughput: 30.29 infer/sec
    Avg latency: 200045 usec (standard deviation 41143 usec)
    p50 latency: 191250 usec
    p90 latency: 265636 usec
    p95 latency: 271537 usec
    p99 latency: 282302 usec
    Avg HTTP time: 200014 usec (send/recv 633 usec + response wait 199381 usec)
  Server: 
    Inference count: 182
    Execution count: 69
    Successful request count: 182
    Avg request latency: 185423 usec (overhead 290 usec + queue 87961 usec + compute input 1358 usec + compute infer 95716 usec + compute output 97 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 30.29 infer/sec, latency 200045 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10671.35
Median: 10775.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 184
    Throughput: 30.6167 infer/sec
    Avg latency: 225578 usec (standard deviation 50347 usec)
    p50 latency: 213729 usec
    p90 latency: 291367 usec
    p95 latency: 309659 usec
    p99 latency: 323192 usec
    Avg HTTP time: 225540 usec (send/recv 1295 usec + response wait 224245 usec)
  Server: 
    Inference count: 184
    Execution count: 62
    Successful request count: 184
    Avg request latency: 207186 usec (overhead 367 usec + queue 100692 usec + compute input 2249 usec + compute infer 103738 usec + compute output 138 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 30.6167 infer/sec, latency 225578 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10443.69
Median: 10878
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 193
    Throughput: 32.1249 infer/sec
    Avg latency: 249067 usec (standard deviation 52847 usec)
    p50 latency: 236300 usec
    p90 latency: 310883 usec
    p95 latency: 329048 usec
    p99 latency: 343532 usec
    Avg HTTP time: 249040 usec (send/recv 678 usec + response wait 248362 usec)
  Server: 
    Inference count: 193
    Execution count: 57
    Successful request count: 193
    Avg request latency: 226635 usec (overhead 391 usec + queue 109205 usec + compute input 1999 usec + compute infer 114903 usec + compute output 136 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 32.1249 infer/sec, latency 249067 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10531.37
Median: 10898.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 198
    Throughput: 32.9367 infer/sec
    Avg latency: 268336 usec (standard deviation 56695 usec)
    p50 latency: 256963 usec
    p90 latency: 331947 usec
    p95 latency: 336218 usec
    p99 latency: 351934 usec
    Avg HTTP time: 268281 usec (send/recv 1366 usec + response wait 266915 usec)
  Server: 
    Inference count: 198
    Execution count: 54
    Successful request count: 198
    Avg request latency: 247768 usec (overhead 356 usec + queue 127598 usec + compute input 1184 usec + compute infer 118511 usec + compute output 118 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 32.9367 infer/sec, latency 268336 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10515.66
Median: 10837.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 198
    Throughput: 32.7978 infer/sec
    Avg latency: 299423 usec (standard deviation 74606 usec)
    p50 latency: 292472 usec
    p90 latency: 389071 usec
    p95 latency: 406613 usec
    p99 latency: 456262 usec
    Avg HTTP time: 299389 usec (send/recv 1631 usec + response wait 297758 usec)
  Server: 
    Inference count: 198
    Execution count: 48
    Successful request count: 198
    Avg request latency: 272142 usec (overhead 661 usec + queue 115480 usec + compute input 8554 usec + compute infer 147281 usec + compute output 165 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 32.7978 infer/sec, latency 299423 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10747.16
Median: 10796.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 215
    Throughput: 35.7846 infer/sec
    Avg latency: 313057 usec (standard deviation 65993 usec)
    p50 latency: 282062 usec
    p90 latency: 394369 usec
    p95 latency: 422708 usec
    p99 latency: 498833 usec
    Avg HTTP time: 313028 usec (send/recv 664 usec + response wait 312364 usec)
  Server: 
    Inference count: 215
    Execution count: 45
    Successful request count: 215
    Avg request latency: 290573 usec (overhead 466 usec + queue 127126 usec + compute input 2958 usec + compute infer 159890 usec + compute output 133 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 35.7846 infer/sec, latency 313057 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10843.96
Median: 10919.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 215
    Throughput: 35.7854 infer/sec
    Avg latency: 333618 usec (standard deviation 77881 usec)
    p50 latency: 281446 usec
    p90 latency: 480786 usec
    p95 latency: 481482 usec
    p99 latency: 482776 usec
    Avg HTTP time: 333592 usec (send/recv 617 usec + response wait 332975 usec)
  Server: 
    Inference count: 215
    Execution count: 43
    Successful request count: 215
    Avg request latency: 306404 usec (overhead 561 usec + queue 130555 usec + compute input 1475 usec + compute infer 173686 usec + compute output 127 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 35.7854 infer/sec, latency 333618 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10716.18
Median: 10919.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 219
    Throughput: 36.441 infer/sec
    Avg latency: 364015 usec (standard deviation 83107 usec)
    p50 latency: 314210 usec
    p90 latency: 503807 usec
    p95 latency: 506112 usec
    p99 latency: 530320 usec
    Avg HTTP time: 363984 usec (send/recv 788 usec + response wait 363196 usec)
  Server: 
    Inference count: 219
    Execution count: 41
    Successful request count: 219
    Avg request latency: 342847 usec (overhead 606 usec + queue 164016 usec + compute input 3183 usec + compute infer 174890 usec + compute output 150 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 36.441 infer/sec, latency 364015 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11053.31
Median: 10980.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
Failed to obtain stable measurement within 10 measurement windows for concurrency 14. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 14---
Running performance test
ERROR: exits as an instance (pid = 337501) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 219
    Throughput: 36.4447 infer/sec
    Avg latency: 386237 usec (standard deviation 84171 usec)
    p50 latency: 396556 usec
    p90 latency: 508056 usec
    p95 latency: 519284 usec
    p99 latency: 528223 usec
    Avg HTTP time: 386209 usec (send/recv 779 usec + response wait 385430 usec)
  Server: 
    Inference count: 219
    Execution count: 39
    Successful request count: 219
    Avg request latency: 362701 usec (overhead 733 usec + queue 185771 usec + compute input 2025 usec + compute infer 174012 usec + compute output 159 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 36.4447 infer/sec, latency 386237 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 218
    Throughput: 36.2838 infer/sec
    Avg latency: 383144 usec (standard deviation 83470 usec)
    p50 latency: 394341 usec
    p90 latency: 505006 usec
    p95 latency: 510950 usec
    p99 latency: 527372 usec
    Avg HTTP time: 383117 usec (send/recv 622 usec + response wait 382495 usec)
  Server: 
    Inference count: 218
    Execution count: 39
    Successful request count: 218
    Avg request latency: 358169 usec (overhead 587 usec + queue 181963 usec + compute input 1736 usec + compute infer 173743 usec + compute output 139 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 36.2838 infer/sec, latency 383144 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10426.62
Median: 11001.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
Failed to obtain stable measurement within 10 measurement windows for concurrency 15. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 15---
Running performance test
ERROR: exits as an instance (pid = 337706) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 210
    Throughput: 34.9263 infer/sec
    Avg latency: 418640 usec (standard deviation 86495 usec)
    p50 latency: 421322 usec
    p90 latency: 531153 usec
    p95 latency: 553089 usec
    p99 latency: 564812 usec
    Avg HTTP time: 418613 usec (send/recv 944 usec + response wait 417669 usec)
  Server: 
    Inference count: 210
    Execution count: 37
    Successful request count: 210
    Avg request latency: 394279 usec (overhead 563 usec + queue 216511 usec + compute input 4839 usec + compute infer 172194 usec + compute output 171 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 34.9263 infer/sec, latency 418640 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 214
    Throughput: 35.5321 infer/sec
    Avg latency: 407304 usec (standard deviation 85057 usec)
    p50 latency: 419971 usec
    p90 latency: 496061 usec
    p95 latency: 547528 usec
    p99 latency: 570691 usec
    Avg HTTP time: 407261 usec (send/recv 2308 usec + response wait 404953 usec)
  Server: 
    Inference count: 214
    Execution count: 38
    Successful request count: 214
    Avg request latency: 381343 usec (overhead 802 usec + queue 201440 usec + compute input 3810 usec + compute infer 175127 usec + compute output 163 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 35.5321 infer/sec, latency 407304 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10602.30
Median: 11082
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 217
    Throughput: 35.762 infer/sec
    Avg latency: 426436 usec (standard deviation 85697 usec)
    p50 latency: 442722 usec
    p90 latency: 517800 usec
    p95 latency: 550858 usec
    p99 latency: 568261 usec
    Avg HTTP time: 426409 usec (send/recv 2721 usec + response wait 423688 usec)
  Server: 
    Inference count: 217
    Execution count: 37
    Successful request count: 217
    Avg request latency: 401506 usec (overhead 612 usec + queue 221940 usec + compute input 2728 usec + compute infer 176074 usec + compute output 151 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 35.762 infer/sec, latency 426436 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10678.76
Median: 11041
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 226
    Throughput: 37.6091 infer/sec
    Avg latency: 453340 usec (standard deviation 69610 usec)
    p50 latency: 464027 usec
    p90 latency: 515142 usec
    p95 latency: 570887 usec
    p99 latency: 590075 usec
    Avg HTTP time: 453312 usec (send/recv 690 usec + response wait 452622 usec)
  Server: 
    Inference count: 226
    Execution count: 36
    Successful request count: 226
    Avg request latency: 428706 usec (overhead 640 usec + queue 244426 usec + compute input 2188 usec + compute infer 181305 usec + compute output 145 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 37.6091 infer/sec, latency 453340 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11049.37
Median: 11041.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 227
    Throughput: 37.7807 infer/sec
    Avg latency: 481301 usec (standard deviation 68907 usec)
    p50 latency: 489126 usec
    p90 latency: 588082 usec
    p95 latency: 591070 usec
    p99 latency: 617250 usec
    Avg HTTP time: 481268 usec (send/recv 979 usec + response wait 480289 usec)
  Server: 
    Inference count: 227
    Execution count: 35
    Successful request count: 227
    Avg request latency: 455452 usec (overhead 590 usec + queue 267796 usec + compute input 3413 usec + compute infer 183471 usec + compute output 181 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 37.7807 infer/sec, latency 481301 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10696.44
Median: 11082
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_803250000.csv
Combined CSV file created: power_measurement_stats_freq_803250000.csv
---Setting GPU frequency to 854250000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 854250000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 164
    Throughput: 18.202 infer/sec
    Avg latency: 54870 usec (standard deviation 519 usec)
    p50 latency: 54903 usec
    p90 latency: 55472 usec
    p95 latency: 55603 usec
    p99 latency: 55982 usec
    Avg HTTP time: 54837 usec (send/recv 491 usec + response wait 54346 usec)
  Server: 
    Inference count: 164
    Execution count: 164
    Successful request count: 164
    Avg request latency: 45670 usec (overhead 152 usec + queue 264 usec + compute input 371 usec + compute infer 44816 usec + compute output 66 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 18.202 infer/sec, latency 54870 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9295.00
Median: 9554.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 198
    Throughput: 21.9782 infer/sec
    Avg latency: 90668 usec (standard deviation 2775 usec)
    p50 latency: 90199 usec
    p90 latency: 91986 usec
    p95 latency: 92807 usec
    p99 latency: 99193 usec
    Avg HTTP time: 90636 usec (send/recv 632 usec + response wait 90004 usec)
  Server: 
    Inference count: 198
    Execution count: 198
    Successful request count: 198
    Avg request latency: 81030 usec (overhead 150 usec + queue 35753 usec + compute input 305 usec + compute infer 44753 usec + compute output 67 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 21.9782 infer/sec, latency 90668 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10290.10
Median: 10837
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 156
    Throughput: 25.9671 infer/sec
    Avg latency: 115642 usec (standard deviation 7162 usec)
    p50 latency: 115128 usec
    p90 latency: 116383 usec
    p95 latency: 116939 usec
    p99 latency: 159602 usec
    Avg HTTP time: 115614 usec (send/recv 583 usec + response wait 115031 usec)
  Server: 
    Inference count: 156
    Execution count: 105
    Successful request count: 156
    Avg request latency: 104541 usec (overhead 202 usec + queue 43303 usec + compute input 367 usec + compute infer 60593 usec + compute output 74 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 25.9671 infer/sec, latency 115642 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10228.76
Median: 10837
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 168
    Throughput: 27.9601 infer/sec
    Avg latency: 142130 usec (standard deviation 21840 usec)
    p50 latency: 139555 usec
    p90 latency: 143002 usec
    p95 latency: 184736 usec
    p99 latency: 207836 usec
    Avg HTTP time: 142103 usec (send/recv 759 usec + response wait 141344 usec)
  Server: 
    Inference count: 168
    Execution count: 88
    Successful request count: 168
    Avg request latency: 128272 usec (overhead 240 usec + queue 57034 usec + compute input 850 usec + compute infer 70048 usec + compute output 100 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 27.9601 infer/sec, latency 142130 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10577.08
Median: 10878.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 176
    Throughput: 29.2771 infer/sec
    Avg latency: 168431 usec (standard deviation 30608 usec)
    p50 latency: 162460 usec
    p90 latency: 223690 usec
    p95 latency: 232815 usec
    p99 latency: 250492 usec
    Avg HTTP time: 168400 usec (send/recv 945 usec + response wait 167455 usec)
  Server: 
    Inference count: 176
    Execution count: 77
    Successful request count: 176
    Avg request latency: 155593 usec (overhead 278 usec + queue 73221 usec + compute input 1258 usec + compute infer 80723 usec + compute output 113 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 29.2771 infer/sec, latency 168431 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10891.25
Median: 11061.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 184
    Throughput: 30.6179 infer/sec
    Avg latency: 190239 usec (standard deviation 39797 usec)
    p50 latency: 183344 usec
    p90 latency: 253231 usec
    p95 latency: 254119 usec
    p99 latency: 273482 usec
    Avg HTTP time: 190209 usec (send/recv 931 usec + response wait 189278 usec)
  Server: 
    Inference count: 184
    Execution count: 70
    Successful request count: 184
    Avg request latency: 177746 usec (overhead 298 usec + queue 85843 usec + compute input 1557 usec + compute infer 89940 usec + compute output 107 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 30.6179 infer/sec, latency 190239 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10803.83
Median: 11143.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 199
    Throughput: 33.1232 infer/sec
    Avg latency: 213483 usec (standard deviation 47171 usec)
    p50 latency: 203240 usec
    p90 latency: 275568 usec
    p95 latency: 277448 usec
    p99 latency: 293104 usec
    Avg HTTP time: 213455 usec (send/recv 640 usec + response wait 212815 usec)
  Server: 
    Inference count: 199
    Execution count: 67
    Successful request count: 199
    Avg request latency: 197937 usec (overhead 306 usec + queue 97637 usec + compute input 734 usec + compute infer 99155 usec + compute output 104 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 33.1232 infer/sec, latency 213483 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10993.62
Median: 11205.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 204
    Throughput: 33.9514 infer/sec
    Avg latency: 236552 usec (standard deviation 48480 usec)
    p50 latency: 225706 usec
    p90 latency: 299413 usec
    p95 latency: 311960 usec
    p99 latency: 334158 usec
    Avg HTTP time: 236526 usec (send/recv 623 usec + response wait 235903 usec)
  Server: 
    Inference count: 204
    Execution count: 60
    Successful request count: 204
    Avg request latency: 222980 usec (overhead 343 usec + queue 114990 usec + compute input 1295 usec + compute infer 106241 usec + compute output 110 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 33.9514 infer/sec, latency 236552 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11186.68
Median: 11307.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 205
    Throughput: 34.1147 infer/sec
    Avg latency: 261915 usec (standard deviation 56306 usec)
    p50 latency: 250030 usec
    p90 latency: 332697 usec
    p95 latency: 341068 usec
    p99 latency: 382329 usec
    Avg HTTP time: 261886 usec (send/recv 793 usec + response wait 261093 usec)
  Server: 
    Inference count: 205
    Execution count: 55
    Successful request count: 205
    Avg request latency: 239518 usec (overhead 413 usec + queue 117590 usec + compute input 4003 usec + compute infer 117375 usec + compute output 136 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 34.1147 infer/sec, latency 261915 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10925.56
Median: 11369.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 213
    Throughput: 35.4395 infer/sec
    Avg latency: 282784 usec (standard deviation 54997 usec)
    p50 latency: 271130 usec
    p90 latency: 344466 usec
    p95 latency: 358032 usec
    p99 latency: 363997 usec
    Avg HTTP time: 282753 usec (send/recv 689 usec + response wait 282064 usec)
  Server: 
    Inference count: 213
    Execution count: 52
    Successful request count: 213
    Avg request latency: 261205 usec (overhead 387 usec + queue 139502 usec + compute input 1511 usec + compute infer 119674 usec + compute output 131 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 35.4395 infer/sec, latency 282784 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11222.37
Median: 11409.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 223
    Throughput: 36.9788 infer/sec
    Avg latency: 297517 usec (standard deviation 60124 usec)
    p50 latency: 270972 usec
    p90 latency: 366803 usec
    p95 latency: 462847 usec
    p99 latency: 474259 usec
    Avg HTTP time: 297489 usec (send/recv 772 usec + response wait 296717 usec)
  Server: 
    Inference count: 223
    Execution count: 45
    Successful request count: 223
    Avg request latency: 279743 usec (overhead 909 usec + queue 109212 usec + compute input 2302 usec + compute infer 167168 usec + compute output 151 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 36.9788 infer/sec, latency 297517 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11131.68
Median: 11369.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 217
    Throughput: 36.1084 infer/sec
    Avg latency: 316843 usec (standard deviation 75473 usec)
    p50 latency: 286509 usec
    p90 latency: 461437 usec
    p95 latency: 463998 usec
    p99 latency: 479660 usec
    Avg HTTP time: 316814 usec (send/recv 1912 usec + response wait 314902 usec)
  Server: 
    Inference count: 217
    Execution count: 44
    Successful request count: 217
    Avg request latency: 287245 usec (overhead 647 usec + queue 119041 usec + compute input 1698 usec + compute infer 165713 usec + compute output 145 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 36.1084 infer/sec, latency 316843 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11238.00
Median: 11369.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 231
    Throughput: 38.4354 infer/sec
    Avg latency: 344142 usec (standard deviation 77366 usec)
    p50 latency: 297188 usec
    p90 latency: 482189 usec
    p95 latency: 484244 usec
    p99 latency: 487237 usec
    Avg HTTP time: 344116 usec (send/recv 607 usec + response wait 343509 usec)
  Server: 
    Inference count: 231
    Execution count: 43
    Successful request count: 231
    Avg request latency: 320607 usec (overhead 622 usec + queue 150982 usec + compute input 1663 usec + compute infer 167181 usec + compute output 159 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 38.4354 infer/sec, latency 344142 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11112.06
Median: 11409.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 232
    Throughput: 38.6038 infer/sec
    Avg latency: 370586 usec (standard deviation 80247 usec)
    p50 latency: 380079 usec
    p90 latency: 485814 usec
    p95 latency: 490670 usec
    p99 latency: 514001 usec
    Avg HTTP time: 370560 usec (send/recv 728 usec + response wait 369832 usec)
  Server: 
    Inference count: 232
    Execution count: 42
    Successful request count: 232
    Avg request latency: 346754 usec (overhead 639 usec + queue 177345 usec + compute input 2831 usec + compute infer 165790 usec + compute output 148 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 38.6038 infer/sec, latency 370586 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11174.47
Median: 11532
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 222
    Throughput: 36.9342 infer/sec
    Avg latency: 403677 usec (standard deviation 83787 usec)
    p50 latency: 407715 usec
    p90 latency: 513518 usec
    p95 latency: 532461 usec
    p99 latency: 553874 usec
    Avg HTTP time: 403640 usec (send/recv 1066 usec + response wait 402574 usec)
  Server: 
    Inference count: 222
    Execution count: 39
    Successful request count: 222
    Avg request latency: 380516 usec (overhead 825 usec + queue 207734 usec + compute input 6237 usec + compute infer 165545 usec + compute output 175 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 36.9342 infer/sec, latency 403677 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11301.88
Median: 11573
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 237
    Throughput: 39.4524 infer/sec
    Avg latency: 412637 usec (standard deviation 77871 usec)
    p50 latency: 423173 usec
    p90 latency: 523563 usec
    p95 latency: 525448 usec
    p99 latency: 527291 usec
    Avg HTTP time: 412608 usec (send/recv 686 usec + response wait 411922 usec)
  Server: 
    Inference count: 237
    Execution count: 39
    Successful request count: 237
    Avg request latency: 388369 usec (overhead 473 usec + queue 217808 usec + compute input 1611 usec + compute infer 168337 usec + compute output 138 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 39.4524 infer/sec, latency 412637 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11146.93
Median: 11532
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 229
    Throughput: 38.0633 infer/sec
    Avg latency: 429205 usec (standard deviation 76854 usec)
    p50 latency: 444693 usec
    p90 latency: 526013 usec
    p95 latency: 549754 usec
    p99 latency: 566149 usec
    Avg HTTP time: 429152 usec (send/recv 3364 usec + response wait 425788 usec)
  Server: 
    Inference count: 229
    Execution count: 38
    Successful request count: 229
    Avg request latency: 402715 usec (overhead 569 usec + queue 226023 usec + compute input 2358 usec + compute infer 173619 usec + compute output 145 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 38.0633 infer/sec, latency 429205 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11026.61
Median: 11532
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 234
    Throughput: 38.9272 infer/sec
    Avg latency: 465478 usec (standard deviation 60499 usec)
    p50 latency: 479147 usec
    p90 latency: 500427 usec
    p95 latency: 569361 usec
    p99 latency: 602550 usec
    Avg HTTP time: 465449 usec (send/recv 951 usec + response wait 464498 usec)
  Server: 
    Inference count: 234
    Execution count: 36
    Successful request count: 234
    Avg request latency: 438216 usec (overhead 746 usec + queue 252983 usec + compute input 5009 usec + compute infer 179300 usec + compute output 178 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 38.9272 infer/sec, latency 465478 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11354.94
Median: 11655
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_854250000.csv
Combined CSV file created: power_measurement_stats_freq_854250000.csv
---Setting GPU frequency to 905250000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 905250000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 170
    Throughput: 18.8648 infer/sec
    Avg latency: 52942 usec (standard deviation 1632 usec)
    p50 latency: 52759 usec
    p90 latency: 53716 usec
    p95 latency: 55666 usec
    p99 latency: 60120 usec
    Avg HTTP time: 52912 usec (send/recv 544 usec + response wait 52368 usec)
  Server: 
    Inference count: 170
    Execution count: 170
    Successful request count: 170
    Avg request latency: 43764 usec (overhead 156 usec + queue 288 usec + compute input 333 usec + compute infer 42912 usec + compute output 74 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 18.8648 infer/sec, latency 52942 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 9253.78
Median: 10126.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 208
    Throughput: 23.0912 infer/sec
    Avg latency: 86197 usec (standard deviation 2441 usec)
    p50 latency: 85978 usec
    p90 latency: 87563 usec
    p95 latency: 89250 usec
    p99 latency: 90700 usec
    Avg HTTP time: 86167 usec (send/recv 641 usec + response wait 85526 usec)
  Server: 
    Inference count: 208
    Execution count: 208
    Successful request count: 208
    Avg request latency: 76673 usec (overhead 145 usec + queue 33628 usec + compute input 249 usec + compute infer 42583 usec + compute output 67 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 23.0912 infer/sec, latency 86197 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11319.58
Median: 11514
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 164
    Throughput: 27.2929 infer/sec
    Avg latency: 110528 usec (standard deviation 9429 usec)
    p50 latency: 109570 usec
    p90 latency: 111562 usec
    p95 latency: 113205 usec
    p99 latency: 152981 usec
    Avg HTTP time: 110499 usec (send/recv 631 usec + response wait 109868 usec)
  Server: 
    Inference count: 164
    Execution count: 111
    Successful request count: 164
    Avg request latency: 98952 usec (overhead 192 usec + queue 40808 usec + compute input 384 usec + compute infer 57492 usec + compute output 75 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 27.2929 infer/sec, latency 110528 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11051.55
Median: 11552.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 174
    Throughput: 28.9664 infer/sec
    Avg latency: 136217 usec (standard deviation 20220 usec)
    p50 latency: 133116 usec
    p90 latency: 174236 usec
    p95 latency: 176892 usec
    p99 latency: 206838 usec
    Avg HTTP time: 136186 usec (send/recv 821 usec + response wait 135365 usec)
  Server: 
    Inference count: 174
    Execution count: 91
    Successful request count: 174
    Avg request latency: 124537 usec (overhead 241 usec + queue 55968 usec + compute input 797 usec + compute infer 67440 usec + compute output 90 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 28.9664 infer/sec, latency 136217 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11037.69
Median: 11596
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 190
    Throughput: 31.625 infer/sec
    Avg latency: 158192 usec (standard deviation 27021 usec)
    p50 latency: 154046 usec
    p90 latency: 216914 usec
    p95 latency: 220935 usec
    p99 latency: 222937 usec
    Avg HTTP time: 158036 usec (send/recv 597 usec + response wait 157439 usec)
  Server: 
    Inference count: 191
    Execution count: 83
    Successful request count: 191
    Avg request latency: 145868 usec (overhead 254 usec + queue 68693 usec + compute input 554 usec + compute infer 76269 usec + compute output 97 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 31.625 infer/sec, latency 158192 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11364.18
Median: 11727.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 192
    Throughput: 31.8943 infer/sec
    Avg latency: 185244 usec (standard deviation 37167 usec)
    p50 latency: 176534 usec
    p90 latency: 243028 usec
    p95 latency: 252839 usec
    p99 latency: 286019 usec
    Avg HTTP time: 185213 usec (send/recv 1200 usec + response wait 184013 usec)
  Server: 
    Inference count: 192
    Execution count: 72
    Successful request count: 192
    Avg request latency: 172154 usec (overhead 331 usec + queue 82470 usec + compute input 2364 usec + compute infer 86849 usec + compute output 140 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 31.8943 infer/sec, latency 185244 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11411.53
Median: 11841
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 199
    Throughput: 33.0854 infer/sec
    Avg latency: 204319 usec (standard deviation 43544 usec)
    p50 latency: 195372 usec
    p90 latency: 264845 usec
    p95 latency: 280717 usec
    p99 latency: 305709 usec
    Avg HTTP time: 205107 usec (send/recv 1233 usec + response wait 203874 usec)
  Server: 
    Inference count: 204
    Execution count: 67
    Successful request count: 204
    Avg request latency: 187339 usec (overhead 315 usec + queue 89045 usec + compute input 2026 usec + compute infer 95837 usec + compute output 115 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 33.0854 infer/sec, latency 204319 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11330.23
Median: 11941
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 214
    Throughput: 35.6184 infer/sec
    Avg latency: 224813 usec (standard deviation 49604 usec)
    p50 latency: 215944 usec
    p90 latency: 283313 usec
    p95 latency: 300532 usec
    p99 latency: 320112 usec
    Avg HTTP time: 224785 usec (send/recv 629 usec + response wait 224156 usec)
  Server: 
    Inference count: 214
    Execution count: 64
    Successful request count: 214
    Avg request latency: 205103 usec (overhead 350 usec + queue 97136 usec + compute input 1550 usec + compute infer 105952 usec + compute output 115 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 35.6184 infer/sec, latency 224813 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11387.06
Median: 11870.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 215
    Throughput: 35.5913 infer/sec
    Avg latency: 247292 usec (standard deviation 53003 usec)
    p50 latency: 238180 usec
    p90 latency: 304040 usec
    p95 latency: 308879 usec
    p99 latency: 323137 usec
    Avg HTTP time: 247212 usec (send/recv 1585 usec + response wait 245627 usec)
  Server: 
    Inference count: 215
    Execution count: 60
    Successful request count: 215
    Avg request latency: 224876 usec (overhead 368 usec + queue 115601 usec + compute input 1362 usec + compute infer 107412 usec + compute output 133 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 35.5913 infer/sec, latency 247292 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11944.25
Median: 12075.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 224
    Throughput: 37.2767 infer/sec
    Avg latency: 273753 usec (standard deviation 63573 usec)
    p50 latency: 258601 usec
    p90 latency: 340915 usec
    p95 latency: 365157 usec
    p99 latency: 413891 usec
    Avg HTTP time: 273528 usec (send/recv 762 usec + response wait 272766 usec)
  Server: 
    Inference count: 225
    Execution count: 54
    Successful request count: 225
    Avg request latency: 249913 usec (overhead 426 usec + queue 113423 usec + compute input 5370 usec + compute infer 130561 usec + compute output 131 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 37.2767 infer/sec, latency 273753 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11862.00
Median: 12002.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 237
    Throughput: 39.3023 infer/sec
    Avg latency: 284997 usec (standard deviation 60772 usec)
    p50 latency: 260809 usec
    p90 latency: 364767 usec
    p95 latency: 440552 usec
    p99 latency: 448110 usec
    Avg HTTP time: 284968 usec (send/recv 823 usec + response wait 284145 usec)
  Server: 
    Inference count: 237
    Execution count: 49
    Successful request count: 237
    Avg request latency: 267311 usec (overhead 864 usec + queue 110659 usec + compute input 2407 usec + compute infer 153229 usec + compute output 150 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 39.3023 infer/sec, latency 284997 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11910.00
Median: 12002.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 231
    Throughput: 38.4465 infer/sec
    Avg latency: 315968 usec (standard deviation 72123 usec)
    p50 latency: 280416 usec
    p90 latency: 439945 usec
    p95 latency: 457882 usec
    p99 latency: 470121 usec
    Avg HTTP time: 315930 usec (send/recv 855 usec + response wait 315075 usec)
  Server: 
    Inference count: 231
    Execution count: 47
    Successful request count: 231
    Avg request latency: 295022 usec (overhead 671 usec + queue 137343 usec + compute input 4973 usec + compute infer 151859 usec + compute output 175 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 38.4465 infer/sec, latency 315968 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11983.66
Median: 12105.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 235
    Throughput: 38.9071 infer/sec
    Avg latency: 324188 usec (standard deviation 75901 usec)
    p50 latency: 279725 usec
    p90 latency: 456264 usec
    p95 latency: 460148 usec
    p99 latency: 462616 usec
    Avg HTTP time: 324159 usec (send/recv 2219 usec + response wait 321940 usec)
  Server: 
    Inference count: 235
    Execution count: 45
    Successful request count: 235
    Avg request latency: 299985 usec (overhead 494 usec + queue 140609 usec + compute input 1467 usec + compute infer 157287 usec + compute output 127 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 38.9071 infer/sec, latency 324188 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11836.58
Median: 12207.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 234
    Throughput: 38.9458 infer/sec
    Avg latency: 351973 usec (standard deviation 76379 usec)
    p50 latency: 362431 usec
    p90 latency: 462617 usec
    p95 latency: 468139 usec
    p99 latency: 477859 usec
    Avg HTTP time: 351945 usec (send/recv 664 usec + response wait 351281 usec)
  Server: 
    Inference count: 234
    Execution count: 43
    Successful request count: 234
    Avg request latency: 329616 usec (overhead 480 usec + queue 170598 usec + compute input 1673 usec + compute infer 156724 usec + compute output 139 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 38.9458 infer/sec, latency 351973 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12042.37
Median: 12187.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 242
    Throughput: 40.2808 infer/sec
    Avg latency: 373812 usec (standard deviation 76878 usec)
    p50 latency: 384744 usec
    p90 latency: 479868 usec
    p95 latency: 481672 usec
    p99 latency: 486084 usec
    Avg HTTP time: 373783 usec (send/recv 649 usec + response wait 373134 usec)
  Server: 
    Inference count: 242
    Execution count: 42
    Successful request count: 242
    Avg request latency: 351314 usec (overhead 550 usec + queue 190903 usec + compute input 1855 usec + compute infer 157865 usec + compute output 140 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 40.2808 infer/sec, latency 373812 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11875.50
Median: 12187.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 248
    Throughput: 41.2784 infer/sec
    Avg latency: 395294 usec (standard deviation 77210 usec)
    p50 latency: 405851 usec
    p90 latency: 483903 usec
    p95 latency: 486532 usec
    p99 latency: 492457 usec
    Avg HTTP time: 395263 usec (send/recv 643 usec + response wait 394620 usec)
  Server: 
    Inference count: 248
    Execution count: 41
    Successful request count: 248
    Avg request latency: 370439 usec (overhead 594 usec + queue 208948 usec + compute input 1733 usec + compute infer 159016 usec + compute output 148 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 41.2784 infer/sec, latency 395294 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12125.81
Median: 12288.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
Failed to obtain stable measurement within 10 measurement windows for concurrency 17. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 17---
Running performance test
ERROR: exits as an instance (pid = 342607) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 247
    Throughput: 41.0996 infer/sec
    Avg latency: 420983 usec (standard deviation 72540 usec)
    p50 latency: 424400 usec
    p90 latency: 519516 usec
    p95 latency: 524656 usec
    p99 latency: 580525 usec
    Avg HTTP time: 420957 usec (send/recv 790 usec + response wait 420167 usec)
  Server: 
    Inference count: 247
    Execution count: 39
    Successful request count: 247
    Avg request latency: 397142 usec (overhead 548 usec + queue 228390 usec + compute input 4540 usec + compute infer 163514 usec + compute output 148 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 41.0996 infer/sec, latency 420983 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 228
    Throughput: 37.8164 infer/sec
    Avg latency: 424434 usec (standard deviation 69517 usec)
    p50 latency: 431032 usec
    p90 latency: 519988 usec
    p95 latency: 546763 usec
    p99 latency: 576407 usec
    Avg HTTP time: 424402 usec (send/recv 2505 usec + response wait 421897 usec)
  Server: 
    Inference count: 228
    Execution count: 37
    Successful request count: 228
    Avg request latency: 398220 usec (overhead 848 usec + queue 224790 usec + compute input 5096 usec + compute infer 167310 usec + compute output 175 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 37.8164 infer/sec, latency 424434 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11624.69
Median: 12187
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 234
    Throughput: 38.9463 infer/sec
    Avg latency: 464699 usec (standard deviation 91155 usec)
    p50 latency: 464900 usec
    p90 latency: 568100 usec
    p95 latency: 672599 usec
    p99 latency: 775749 usec
    Avg HTTP time: 464658 usec (send/recv 934 usec + response wait 463724 usec)
  Server: 
    Inference count: 234
    Execution count: 36
    Successful request count: 234
    Avg request latency: 438272 usec (overhead 1065 usec + queue 256146 usec + compute input 5516 usec + compute infer 175345 usec + compute output 199 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 38.9463 infer/sec, latency 464699 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11757.14
Median: 12268
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_905250000.csv
Combined CSV file created: power_measurement_stats_freq_905250000.csv
---Setting GPU frequency to 956250000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 956250000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 178
    Throughput: 19.7586 infer/sec
    Avg latency: 50801 usec (standard deviation 1455 usec)
    p50 latency: 50740 usec
    p90 latency: 51156 usec
    p95 latency: 51421 usec
    p99 latency: 60605 usec
    Avg HTTP time: 50774 usec (send/recv 511 usec + response wait 50263 usec)
  Server: 
    Inference count: 178
    Execution count: 178
    Successful request count: 178
    Avg request latency: 41786 usec (overhead 156 usec + queue 266 usec + compute input 309 usec + compute infer 40987 usec + compute output 66 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 19.7586 infer/sec, latency 50801 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10056.65
Median: 10616.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 219
    Throughput: 24.3105 infer/sec
    Avg latency: 82497 usec (standard deviation 721 usec)
    p50 latency: 82370 usec
    p90 latency: 83328 usec
    p95 latency: 83893 usec
    p99 latency: 84624 usec
    Avg HTTP time: 82470 usec (send/recv 577 usec + response wait 81893 usec)
  Server: 
    Inference count: 219
    Execution count: 219
    Successful request count: 219
    Avg request latency: 73172 usec (overhead 145 usec + queue 32013 usec + compute input 255 usec + compute infer 40690 usec + compute output 68 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 24.3105 infer/sec, latency 82497 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11792.82
Median: 12208
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 168
    Throughput: 27.9654 infer/sec
    Avg latency: 106069 usec (standard deviation 12413 usec)
    p50 latency: 104820 usec
    p90 latency: 107839 usec
    p95 latency: 145255 usec
    p99 latency: 148031 usec
    Avg HTTP time: 106040 usec (send/recv 714 usec + response wait 105326 usec)
  Server: 
    Inference count: 168
    Execution count: 116
    Successful request count: 168
    Avg request latency: 94830 usec (overhead 204 usec + queue 39744 usec + compute input 367 usec + compute infer 54439 usec + compute output 74 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 27.9654 infer/sec, latency 106069 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11981.90
Median: 12290
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 186
    Throughput: 30.9645 infer/sec
    Avg latency: 128461 usec (standard deviation 15449 usec)
    p50 latency: 127272 usec
    p90 latency: 130583 usec
    p95 latency: 167955 usec
    p99 latency: 188849 usec
    Avg HTTP time: 128430 usec (send/recv 734 usec + response wait 127696 usec)
  Server: 
    Inference count: 186
    Execution count: 96
    Successful request count: 186
    Avg request latency: 117711 usec (overhead 248 usec + queue 51628 usec + compute input 687 usec + compute infer 65059 usec + compute output 89 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 30.9645 infer/sec, latency 128461 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11854.41
Median: 12228.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 200
    Throughput: 33.2768 infer/sec
    Avg latency: 151111 usec (standard deviation 25986 usec)
    p50 latency: 147477 usec
    p90 latency: 192328 usec
    p95 latency: 210005 usec
    p99 latency: 212768 usec
    Avg HTTP time: 151085 usec (send/recv 586 usec + response wait 150499 usec)
  Server: 
    Inference count: 200
    Execution count: 87
    Successful request count: 200
    Avg request latency: 138956 usec (overhead 248 usec + queue 64026 usec + compute input 533 usec + compute infer 74054 usec + compute output 94 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 33.2768 infer/sec, latency 151111 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12434.26
Median: 12535
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 203
    Throughput: 33.7154 infer/sec
    Avg latency: 175678 usec (standard deviation 35619 usec)
    p50 latency: 168514 usec
    p90 latency: 232364 usec
    p95 latency: 234992 usec
    p99 latency: 261932 usec
    Avg HTTP time: 175649 usec (send/recv 1039 usec + response wait 174610 usec)
  Server: 
    Inference count: 203
    Execution count: 76
    Successful request count: 203
    Avg request latency: 161684 usec (overhead 345 usec + queue 75189 usec + compute input 2103 usec + compute infer 83909 usec + compute output 137 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 33.7154 infer/sec, latency 175678 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12368.08
Median: 12596.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 214
    Throughput: 35.6066 infer/sec
    Avg latency: 195093 usec (standard deviation 44703 usec)
    p50 latency: 186854 usec
    p90 latency: 250390 usec
    p95 latency: 252544 usec
    p99 latency: 270361 usec
    Avg HTTP time: 195065 usec (send/recv 1008 usec + response wait 194057 usec)
  Server: 
    Inference count: 214
    Execution count: 73
    Successful request count: 214
    Avg request latency: 176286 usec (overhead 345 usec + queue 80828 usec + compute input 996 usec + compute infer 94003 usec + compute output 113 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 35.6066 infer/sec, latency 195093 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11957.00
Median: 12576
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 215
    Throughput: 35.7771 infer/sec
    Avg latency: 224860 usec (standard deviation 53167 usec)
    p50 latency: 208181 usec
    p90 latency: 287492 usec
    p95 latency: 296611 usec
    p99 latency: 396183 usec
    Avg HTTP time: 224829 usec (send/recv 771 usec + response wait 224058 usec)
  Server: 
    Inference count: 215
    Execution count: 63
    Successful request count: 215
    Avg request latency: 208330 usec (overhead 366 usec + queue 106746 usec + compute input 1889 usec + compute infer 99189 usec + compute output 138 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 35.7771 infer/sec, latency 224860 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11041.00
Median: 12780
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 226
    Throughput: 37.6172 infer/sec
    Avg latency: 237841 usec (standard deviation 54595 usec)
    p50 latency: 227500 usec
    p90 latency: 305288 usec
    p95 latency: 310685 usec
    p99 latency: 334163 usec
    Avg HTTP time: 237811 usec (send/recv 656 usec + response wait 237155 usec)
  Server: 
    Inference count: 226
    Execution count: 61
    Successful request count: 226
    Avg request latency: 217798 usec (overhead 492 usec + queue 94572 usec + compute input 3180 usec + compute infer 119431 usec + compute output 122 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 37.6172 infer/sec, latency 237841 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12116.50
Median: 12677.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 224
    Throughput: 37.2743 infer/sec
    Avg latency: 260798 usec (standard deviation 59056 usec)
    p50 latency: 289233 usec
    p90 latency: 318856 usec
    p95 latency: 327885 usec
    p99 latency: 358716 usec
    Avg HTTP time: 260770 usec (send/recv 1575 usec + response wait 259195 usec)
  Server: 
    Inference count: 224
    Execution count: 57
    Successful request count: 224
    Avg request latency: 230790 usec (overhead 381 usec + queue 110712 usec + compute input 3949 usec + compute infer 115626 usec + compute output 121 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 37.2743 infer/sec, latency 260798 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12293.08
Median: 12718.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 238
    Throughput: 39.3988 infer/sec
    Avg latency: 275239 usec (standard deviation 57435 usec)
    p50 latency: 251429 usec
    p90 latency: 328540 usec
    p95 latency: 424121 usec
    p99 latency: 450031 usec
    Avg HTTP time: 275206 usec (send/recv 1890 usec + response wait 273316 usec)
  Server: 
    Inference count: 238
    Execution count: 50
    Successful request count: 238
    Avg request latency: 249276 usec (overhead 803 usec + queue 92582 usec + compute input 4465 usec + compute infer 151234 usec + compute output 191 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 39.3988 infer/sec, latency 275239 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12421.84
Median: 13066
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 241
    Throughput: 40.116 infer/sec
    Avg latency: 293378 usec (standard deviation 67739 usec)
    p50 latency: 264111 usec
    p90 latency: 422086 usec
    p95 latency: 425751 usec
    p99 latency: 442770 usec
    Avg HTTP time: 293345 usec (send/recv 2161 usec + response wait 291184 usec)
  Server: 
    Inference count: 241
    Execution count: 49
    Successful request count: 241
    Avg request latency: 262626 usec (overhead 667 usec + queue 109136 usec + compute input 1886 usec + compute infer 150804 usec + compute output 132 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 40.116 infer/sec, latency 293378 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12548.58
Median: 12943.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 251
    Throughput: 41.7672 infer/sec
    Avg latency: 318938 usec (standard deviation 72336 usec)
    p50 latency: 271653 usec
    p90 latency: 444800 usec
    p95 latency: 448445 usec
    p99 latency: 452108 usec
    Avg HTTP time: 318906 usec (send/recv 640 usec + response wait 318266 usec)
  Server: 
    Inference count: 251
    Execution count: 47
    Successful request count: 251
    Avg request latency: 296442 usec (overhead 666 usec + queue 139942 usec + compute input 1806 usec + compute infer 153880 usec + compute output 147 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 41.7672 infer/sec, latency 318938 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12683.70
Median: 12759.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
Failed to obtain stable measurement within 10 measurement windows for concurrency 14. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 14---
Running performance test
ERROR: exits as an instance (pid = 344596) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 243
    Throughput: 40.4369 infer/sec
    Avg latency: 337751 usec (standard deviation 76354 usec)
    p50 latency: 347567 usec
    p90 latency: 446197 usec
    p95 latency: 467844 usec
    p99 latency: 475660 usec
    Avg HTTP time: 337723 usec (send/recv 2066 usec + response wait 335657 usec)
  Server: 
    Inference count: 243
    Execution count: 45
    Successful request count: 243
    Avg request latency: 313958 usec (overhead 713 usec + queue 157291 usec + compute input 2346 usec + compute infer 153449 usec + compute output 158 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 40.4369 infer/sec, latency 337751 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 245
    Throughput: 40.7825 infer/sec
    Avg latency: 340325 usec (standard deviation 73828 usec)
    p50 latency: 350445 usec
    p90 latency: 447785 usec
    p95 latency: 448924 usec
    p99 latency: 450839 usec
    Avg HTTP time: 340299 usec (send/recv 622 usec + response wait 339677 usec)
  Server: 
    Inference count: 245
    Execution count: 45
    Successful request count: 245
    Avg request latency: 316304 usec (overhead 506 usec + queue 162501 usec + compute input 1811 usec + compute infer 151348 usec + compute output 136 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 40.7825 infer/sec, latency 340325 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12553.75
Median: 12708.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 243
    Throughput: 40.4314 infer/sec
    Avg latency: 377522 usec (standard deviation 77275 usec)
    p50 latency: 379057 usec
    p90 latency: 474481 usec
    p95 latency: 486370 usec
    p99 latency: 534668 usec
    Avg HTTP time: 377484 usec (send/recv 1044 usec + response wait 376440 usec)
  Server: 
    Inference count: 243
    Execution count: 42
    Successful request count: 243
    Avg request latency: 353234 usec (overhead 578 usec + queue 190562 usec + compute input 7335 usec + compute infer 154558 usec + compute output 201 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 40.4314 infer/sec, latency 377522 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12408.82
Median: 12821
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 251
    Throughput: 41.7474 infer/sec
    Avg latency: 385800 usec (standard deviation 72300 usec)
    p50 latency: 395961 usec
    p90 latency: 485794 usec
    p95 latency: 490064 usec
    p99 latency: 501517 usec
    Avg HTTP time: 385772 usec (send/recv 673 usec + response wait 385099 usec)
  Server: 
    Inference count: 251
    Execution count: 42
    Successful request count: 251
    Avg request latency: 366878 usec (overhead 543 usec + queue 208912 usec + compute input 2216 usec + compute infer 155071 usec + compute output 135 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 41.7474 infer/sec, latency 385800 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12388.24
Median: 12759
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 259
    Throughput: 43.0896 infer/sec
    Avg latency: 402241 usec (standard deviation 66525 usec)
    p50 latency: 410757 usec
    p90 latency: 501212 usec
    p95 latency: 504182 usec
    p99 latency: 511011 usec
    Avg HTTP time: 402210 usec (send/recv 648 usec + response wait 401562 usec)
  Server: 
    Inference count: 259
    Execution count: 41
    Successful request count: 259
    Avg request latency: 379798 usec (overhead 587 usec + queue 218501 usec + compute input 2009 usec + compute infer 158563 usec + compute output 137 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 43.0896 infer/sec, latency 402241 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12294.40
Median: 12718
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 248
    Throughput: 41.2574 infer/sec
    Avg latency: 417076 usec (standard deviation 74986 usec)
    p50 latency: 426343 usec
    p90 latency: 499736 usec
    p95 latency: 518600 usec
    p99 latency: 559986 usec
    Avg HTTP time: 417047 usec (send/recv 2818 usec + response wait 414229 usec)
  Server: 
    Inference count: 248
    Execution count: 39
    Successful request count: 248
    Avg request latency: 387496 usec (overhead 665 usec + queue 223660 usec + compute input 4219 usec + compute infer 158800 usec + compute output 151 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 41.2574 infer/sec, latency 417076 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12330.84
Median: 12902
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_956250000.csv
Combined CSV file created: power_measurement_stats_freq_956250000.csv
---Setting GPU frequency to 1007250000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 1007250000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 182
    Throughput: 20.1983 infer/sec
    Avg latency: 49548 usec (standard deviation 1357 usec)
    p50 latency: 49353 usec
    p90 latency: 50588 usec
    p95 latency: 52663 usec
    p99 latency: 54650 usec
    Avg HTTP time: 49520 usec (send/recv 525 usec + response wait 48995 usec)
  Server: 
    Inference count: 181
    Execution count: 181
    Successful request count: 181
    Avg request latency: 40534 usec (overhead 156 usec + queue 276 usec + compute input 321 usec + compute infer 39709 usec + compute output 71 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 20.1983 infer/sec, latency 49548 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10720.32
Median: 11065
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 200
    Throughput: 24.9754 infer/sec
    Avg latency: 79857 usec (standard deviation 2264 usec)
    p50 latency: 79651 usec
    p90 latency: 80893 usec
    p95 latency: 82088 usec
    p99 latency: 83592 usec
    Avg HTTP time: 79821 usec (send/recv 624 usec + response wait 79197 usec)
  Server: 
    Inference count: 200
    Execution count: 200
    Successful request count: 200
    Avg request latency: 70579 usec (overhead 140 usec + queue 30721 usec + compute input 258 usec + compute infer 39394 usec + compute output 65 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 24.9754 infer/sec, latency 79857 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12392.00
Median: 12657.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 175
    Throughput: 29.1246 infer/sec
    Avg latency: 102512 usec (standard deviation 9232 usec)
    p50 latency: 101308 usec
    p90 latency: 103478 usec
    p95 latency: 104635 usec
    p99 latency: 142022 usec
    Avg HTTP time: 102478 usec (send/recv 558 usec + response wait 101920 usec)
  Server: 
    Inference count: 175
    Execution count: 119
    Successful request count: 175
    Avg request latency: 91408 usec (overhead 194 usec + queue 37691 usec + compute input 378 usec + compute infer 53073 usec + compute output 72 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 29.1246 infer/sec, latency 102512 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11840.66
Median: 12657.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 188
    Throughput: 31.2967 infer/sec
    Avg latency: 125066 usec (standard deviation 18688 usec)
    p50 latency: 123082 usec
    p90 latency: 162188 usec
    p95 latency: 164536 usec
    p99 latency: 184077 usec
    Avg HTTP time: 125016 usec (send/recv 750 usec + response wait 124266 usec)
  Server: 
    Inference count: 188
    Execution count: 100
    Successful request count: 188
    Avg request latency: 114653 usec (overhead 239 usec + queue 52455 usec + compute input 616 usec + compute infer 61258 usec + compute output 84 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 31.2967 infer/sec, latency 125066 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12364.75
Median: 12718.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 200
    Throughput: 33.2874 infer/sec
    Avg latency: 146912 usec (standard deviation 27526 usec)
    p50 latency: 143282 usec
    p90 latency: 188770 usec
    p95 latency: 204673 usec
    p99 latency: 220747 usec
    Avg HTTP time: 146885 usec (send/recv 805 usec + response wait 146080 usec)
  Server: 
    Inference count: 200
    Execution count: 88
    Successful request count: 200
    Avg request latency: 136098 usec (overhead 255 usec + queue 63802 usec + compute input 1078 usec + compute infer 70875 usec + compute output 88 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 33.2874 infer/sec, latency 146912 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12555.25
Median: 12922.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 209
    Throughput: 34.7697 infer/sec
    Avg latency: 170745 usec (standard deviation 35245 usec)
    p50 latency: 163024 usec
    p90 latency: 225051 usec
    p95 latency: 230887 usec
    p99 latency: 251681 usec
    Avg HTTP time: 170713 usec (send/recv 1010 usec + response wait 169703 usec)
  Server: 
    Inference count: 209
    Execution count: 79
    Successful request count: 209
    Avg request latency: 156965 usec (overhead 298 usec + queue 74993 usec + compute input 1623 usec + compute infer 79936 usec + compute output 114 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 34.7697 infer/sec, latency 170745 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12902.33
Median: 12902.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 217
    Throughput: 36.0178 infer/sec
    Avg latency: 189658 usec (standard deviation 41377 usec)
    p50 latency: 181163 usec
    p90 latency: 244388 usec
    p95 latency: 254259 usec
    p99 latency: 272412 usec
    Avg HTTP time: 189629 usec (send/recv 1013 usec + response wait 188616 usec)
  Server: 
    Inference count: 217
    Execution count: 73
    Successful request count: 217
    Avg request latency: 171893 usec (overhead 302 usec + queue 83336 usec + compute input 1602 usec + compute infer 86549 usec + compute output 103 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 36.0178 infer/sec, latency 189658 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12711.83
Median: 13106.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 226
    Throughput: 37.6076 infer/sec
    Avg latency: 208094 usec (standard deviation 45629 usec)
    p50 latency: 199938 usec
    p90 latency: 263631 usec
    p95 latency: 276135 usec
    p99 latency: 281649 usec
    Avg HTTP time: 208066 usec (send/recv 604 usec + response wait 207462 usec)
  Server: 
    Inference count: 226
    Execution count: 68
    Successful request count: 226
    Avg request latency: 188668 usec (overhead 379 usec + queue 88424 usec + compute input 915 usec + compute infer 98834 usec + compute output 115 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 37.6076 infer/sec, latency 208094 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 10600.54
Median: 13208.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 233
    Throughput: 38.7809 infer/sec
    Avg latency: 227869 usec (standard deviation 49758 usec)
    p50 latency: 217932 usec
    p90 latency: 280922 usec
    p95 latency: 297741 usec
    p99 latency: 316681 usec
    Avg HTTP time: 227841 usec (send/recv 673 usec + response wait 227168 usec)
  Server: 
    Inference count: 233
    Execution count: 63
    Successful request count: 233
    Avg request latency: 212441 usec (overhead 415 usec + queue 102702 usec + compute input 1135 usec + compute infer 108074 usec + compute output 114 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 38.7809 infer/sec, latency 227869 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12479.82
Median: 13311
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 241
    Throughput: 40.106 infer/sec
    Avg latency: 248774 usec (standard deviation 56845 usec)
    p50 latency: 237198 usec
    p90 latency: 317911 usec
    p95 latency: 321079 usec
    p99 latency: 362963 usec
    Avg HTTP time: 248722 usec (send/recv 705 usec + response wait 248017 usec)
  Server: 
    Inference count: 241
    Execution count: 58
    Successful request count: 241
    Avg request latency: 232499 usec (overhead 540 usec + queue 109762 usec + compute input 3130 usec + compute infer 118945 usec + compute output 120 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 40.106 infer/sec, latency 248774 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13030.06
Median: 13311.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 242
    Throughput: 40.0576 infer/sec
    Avg latency: 264244 usec (standard deviation 56773 usec)
    p50 latency: 240444 usec
    p90 latency: 322432 usec
    p95 latency: 408882 usec
    p99 latency: 421711 usec
    Avg HTTP time: 264199 usec (send/recv 1531 usec + response wait 262668 usec)
  Server: 
    Inference count: 242
    Execution count: 51
    Successful request count: 242
    Avg request latency: 233240 usec (overhead 488 usec + queue 85465 usec + compute input 3056 usec + compute infer 144083 usec + compute output 147 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 40.0576 infer/sec, latency 264244 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12952.76
Median: 13556
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 251
    Throughput: 41.7298 infer/sec
    Avg latency: 282681 usec (standard deviation 67055 usec)
    p50 latency: 256760 usec
    p90 latency: 408784 usec
    p95 latency: 415646 usec
    p99 latency: 430160 usec
    Avg HTTP time: 282640 usec (send/recv 1970 usec + response wait 280670 usec)
  Server: 
    Inference count: 251
    Execution count: 50
    Successful request count: 251
    Avg request latency: 259188 usec (overhead 756 usec + queue 110156 usec + compute input 2902 usec + compute infer 145241 usec + compute output 132 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 41.7298 infer/sec, latency 282681 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12915.91
Median: 13331.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 257
    Throughput: 42.7729 infer/sec
    Avg latency: 306007 usec (standard deviation 68635 usec)
    p50 latency: 274395 usec
    p90 latency: 426459 usec
    p95 latency: 429069 usec
    p99 latency: 446663 usec
    Avg HTTP time: 305979 usec (send/recv 656 usec + response wait 305323 usec)
  Server: 
    Inference count: 257
    Execution count: 48
    Successful request count: 257
    Avg request latency: 279628 usec (overhead 536 usec + queue 129644 usec + compute input 2600 usec + compute infer 146709 usec + compute output 138 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 42.7729 infer/sec, latency 306007 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13320.93
Median: 13474.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 253
    Throughput: 42.1062 infer/sec
    Avg latency: 330630 usec (standard deviation 71084 usec)
    p50 latency: 337907 usec
    p90 latency: 431940 usec
    p95 latency: 438386 usec
    p99 latency: 454403 usec
    Avg HTTP time: 330603 usec (send/recv 738 usec + response wait 329865 usec)
  Server: 
    Inference count: 253
    Execution count: 46
    Successful request count: 253
    Avg request latency: 313731 usec (overhead 1430 usec + queue 162896 usec + compute input 2316 usec + compute infer 146951 usec + compute output 137 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 42.1062 infer/sec, latency 330630 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13453.60
Median: 13474.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 245
    Throughput: 40.7242 infer/sec
    Avg latency: 351816 usec (standard deviation 76633 usec)
    p50 latency: 362347 usec
    p90 latency: 452540 usec
    p95 latency: 461062 usec
    p99 latency: 476968 usec
    Avg HTTP time: 351734 usec (send/recv 2967 usec + response wait 348767 usec)
  Server: 
    Inference count: 245
    Execution count: 43
    Successful request count: 245
    Avg request latency: 329764 usec (overhead 888 usec + queue 178404 usec + compute input 3290 usec + compute infer 147008 usec + compute output 172 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 40.7242 infer/sec, latency 351816 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13006.07
Median: 13515
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 262
    Throughput: 43.6104 infer/sec
    Avg latency: 369318 usec (standard deviation 68933 usec)
    p50 latency: 378243 usec
    p90 latency: 464711 usec
    p95 latency: 467849 usec
    p99 latency: 481673 usec
    Avg HTTP time: 369284 usec (send/recv 763 usec + response wait 368521 usec)
  Server: 
    Inference count: 262
    Execution count: 43
    Successful request count: 262
    Avg request latency: 345044 usec (overhead 663 usec + queue 192284 usec + compute input 2585 usec + compute infer 149367 usec + compute output 144 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 43.6104 infer/sec, latency 369318 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13280.12
Median: 13474.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 261
    Throughput: 43.4142 infer/sec
    Avg latency: 387281 usec (standard deviation 64035 usec)
    p50 latency: 394846 usec
    p90 latency: 481886 usec
    p95 latency: 485288 usec
    p99 latency: 499287 usec
    Avg HTTP time: 387239 usec (send/recv 720 usec + response wait 386519 usec)
  Server: 
    Inference count: 261
    Execution count: 42
    Successful request count: 261
    Avg request latency: 363842 usec (overhead 843 usec + queue 209095 usec + compute input 2349 usec + compute infer 151391 usec + compute output 164 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 43.4142 infer/sec, latency 387281 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12611.76
Median: 13515
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 268
    Throughput: 44.6079 infer/sec
    Avg latency: 406513 usec (standard deviation 66376 usec)
    p50 latency: 415682 usec
    p90 latency: 468404 usec
    p95 latency: 469967 usec
    p99 latency: 472643 usec
    Avg HTTP time: 406480 usec (send/recv 716 usec + response wait 405764 usec)
  Server: 
    Inference count: 268
    Execution count: 41
    Successful request count: 268
    Avg request latency: 383371 usec (overhead 492 usec + queue 230189 usec + compute input 1720 usec + compute infer 150837 usec + compute output 131 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 44.6079 infer/sec, latency 406513 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12945.58
Median: 13556
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_1007250000.csv
Combined CSV file created: power_measurement_stats_freq_1007250000.csv
---Setting GPU frequency to 1058250000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 1058250000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 188
    Throughput: 20.8644 infer/sec
    Avg latency: 47991 usec (standard deviation 962 usec)
    p50 latency: 47943 usec
    p90 latency: 48356 usec
    p95 latency: 48636 usec
    p99 latency: 51954 usec
    Avg HTTP time: 47960 usec (send/recv 506 usec + response wait 47454 usec)
  Server: 
    Inference count: 188
    Execution count: 188
    Successful request count: 188
    Avg request latency: 39024 usec (overhead 153 usec + queue 261 usec + compute input 301 usec + compute infer 38241 usec + compute output 67 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 20.8644 infer/sec, latency 47991 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11025.65
Median: 11637.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 155
    Throughput: 25.7923 infer/sec
    Avg latency: 77278 usec (standard deviation 2930 usec)
    p50 latency: 76769 usec
    p90 latency: 78083 usec
    p95 latency: 78951 usec
    p99 latency: 86002 usec
    Avg HTTP time: 77247 usec (send/recv 684 usec + response wait 76563 usec)
  Server: 
    Inference count: 155
    Execution count: 155
    Successful request count: 155
    Avg request latency: 67854 usec (overhead 140 usec + queue 29297 usec + compute input 269 usec + compute infer 38082 usec + compute output 65 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 25.7923 infer/sec, latency 77278 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12679.30
Median: 13433
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 182
    Throughput: 30.2826 infer/sec
    Avg latency: 99484 usec (standard deviation 9364 usec)
    p50 latency: 98124 usec
    p90 latency: 102090 usec
    p95 latency: 104482 usec
    p99 latency: 138316 usec
    Avg HTTP time: 99453 usec (send/recv 655 usec + response wait 98798 usec)
  Server: 
    Inference count: 182
    Execution count: 124
    Successful request count: 182
    Avg request latency: 90029 usec (overhead 202 usec + queue 38053 usec + compute input 424 usec + compute infer 51262 usec + compute output 86 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 30.2826 infer/sec, latency 99484 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 12909.16
Median: 13474.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 197
    Throughput: 32.7867 infer/sec
    Avg latency: 120320 usec (standard deviation 16339 usec)
    p50 latency: 118563 usec
    p90 latency: 123193 usec
    p95 latency: 157948 usec
    p99 latency: 176457 usec
    Avg HTTP time: 120290 usec (send/recv 745 usec + response wait 119545 usec)
  Server: 
    Inference count: 197
    Execution count: 103
    Successful request count: 197
    Avg request latency: 109997 usec (overhead 225 usec + queue 49095 usec + compute input 707 usec + compute infer 59882 usec + compute output 86 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 32.7867 infer/sec, latency 120320 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13133.83
Median: 13576.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 208
    Throughput: 34.5865 infer/sec
    Avg latency: 142532 usec (standard deviation 28127 usec)
    p50 latency: 137950 usec
    p90 latency: 194008 usec
    p95 latency: 197470 usec
    p99 latency: 214922 usec
    Avg HTTP time: 142505 usec (send/recv 709 usec + response wait 141796 usec)
  Server: 
    Inference count: 208
    Execution count: 92
    Successful request count: 208
    Avg request latency: 131005 usec (overhead 253 usec + queue 60730 usec + compute input 1042 usec + compute infer 68891 usec + compute output 87 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 34.5865 infer/sec, latency 142532 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13280.33
Median: 13760.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 215
    Throughput: 35.7793 infer/sec
    Avg latency: 164690 usec (standard deviation 33493 usec)
    p50 latency: 158060 usec
    p90 latency: 215966 usec
    p95 latency: 218990 usec
    p99 latency: 258120 usec
    Avg HTTP time: 164658 usec (send/recv 1033 usec + response wait 163625 usec)
  Server: 
    Inference count: 215
    Execution count: 81
    Successful request count: 215
    Avg request latency: 149545 usec (overhead 325 usec + queue 68099 usec + compute input 2384 usec + compute infer 78610 usec + compute output 126 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 35.7793 infer/sec, latency 164690 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13879.00
Median: 14087.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 230
    Throughput: 38.2679 infer/sec
    Avg latency: 181461 usec (standard deviation 38955 usec)
    p50 latency: 174646 usec
    p90 latency: 234825 usec
    p95 latency: 246677 usec
    p99 latency: 254957 usec
    Avg HTTP time: 181435 usec (send/recv 1015 usec + response wait 180420 usec)
  Server: 
    Inference count: 230
    Execution count: 76
    Successful request count: 230
    Avg request latency: 163864 usec (overhead 302 usec + queue 76756 usec + compute input 1150 usec + compute infer 85548 usec + compute output 107 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 38.2679 infer/sec, latency 181461 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13511.58
Median: 14046.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 230
    Throughput: 38.2773 infer/sec
    Avg latency: 202508 usec (standard deviation 45212 usec)
    p50 latency: 192971 usec
    p90 latency: 261178 usec
    p95 latency: 272119 usec
    p99 latency: 287564 usec
    Avg HTTP time: 202479 usec (send/recv 1148 usec + response wait 201331 usec)
  Server: 
    Inference count: 230
    Execution count: 69
    Successful request count: 230
    Avg request latency: 185363 usec (overhead 378 usec + queue 89455 usec + compute input 1716 usec + compute infer 93696 usec + compute output 116 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 38.2773 infer/sec, latency 202508 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13831.41
Median: 14046.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 242
    Throughput: 40.2435 infer/sec
    Avg latency: 219802 usec (standard deviation 48321 usec)
    p50 latency: 210479 usec
    p90 latency: 284967 usec
    p95 latency: 292083 usec
    p99 latency: 318688 usec
    Avg HTTP time: 219774 usec (send/recv 1073 usec + response wait 218701 usec)
  Server: 
    Inference count: 242
    Execution count: 65
    Successful request count: 242
    Avg request latency: 198117 usec (overhead 365 usec + queue 97870 usec + compute input 1272 usec + compute infer 98488 usec + compute output 122 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 40.2435 infer/sec, latency 219802 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13824.50
Median: 14168.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 249
    Throughput: 41.4436 infer/sec
    Avg latency: 241251 usec (standard deviation 51734 usec)
    p50 latency: 229121 usec
    p90 latency: 297014 usec
    p95 latency: 306516 usec
    p99 latency: 315993 usec
    Avg HTTP time: 241222 usec (send/recv 688 usec + response wait 240534 usec)
  Server: 
    Inference count: 249
    Execution count: 60
    Successful request count: 249
    Avg request latency: 217957 usec (overhead 505 usec + queue 101728 usec + compute input 3075 usec + compute infer 112523 usec + compute output 125 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 41.4436 infer/sec, latency 241251 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13471.43
Median: 14127.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 256
    Throughput: 42.3984 infer/sec
    Avg latency: 254620 usec (standard deviation 54989 usec)
    p50 latency: 231500 usec
    p90 latency: 324146 usec
    p95 latency: 337102 usec
    p99 latency: 395455 usec
    Avg HTTP time: 254593 usec (send/recv 1587 usec + response wait 253006 usec)
  Server: 
    Inference count: 256
    Execution count: 55
    Successful request count: 256
    Avg request latency: 235361 usec (overhead 618 usec + queue 100437 usec + compute input 1878 usec + compute infer 132300 usec + compute output 127 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 42.3984 infer/sec, latency 254620 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13739.50
Median: 14188.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 257
    Throughput: 42.7562 infer/sec
    Avg latency: 274954 usec (standard deviation 63550 usec)
    p50 latency: 249207 usec
    p90 latency: 395537 usec
    p95 latency: 401078 usec
    p99 latency: 418624 usec
    Avg HTTP time: 274907 usec (send/recv 1922 usec + response wait 272985 usec)
  Server: 
    Inference count: 257
    Execution count: 51
    Successful request count: 257
    Avg request latency: 250040 usec (overhead 814 usec + queue 103831 usec + compute input 2473 usec + compute infer 142764 usec + compute output 157 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 42.7562 infer/sec, latency 274954 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13906.33
Median: 14311.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 257
    Throughput: 42.6794 infer/sec
    Avg latency: 295965 usec (standard deviation 70345 usec)
    p50 latency: 275008 usec
    p90 latency: 412357 usec
    p95 latency: 415584 usec
    p99 latency: 437275 usec
    Avg HTTP time: 295932 usec (send/recv 1899 usec + response wait 294033 usec)
  Server: 
    Inference count: 257
    Execution count: 50
    Successful request count: 257
    Avg request latency: 271843 usec (overhead 678 usec + queue 127281 usec + compute input 2448 usec + compute infer 141272 usec + compute output 163 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 42.6794 infer/sec, latency 295965 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13458.46
Median: 14250
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 258
    Throughput: 42.8443 infer/sec
    Avg latency: 316861 usec (standard deviation 72742 usec)
    p50 latency: 324822 usec
    p90 latency: 416212 usec
    p95 latency: 417981 usec
    p99 latency: 442995 usec
    Avg HTTP time: 316833 usec (send/recv 2110 usec + response wait 314723 usec)
  Server: 
    Inference count: 258
    Execution count: 48
    Successful request count: 258
    Avg request latency: 288944 usec (overhead 587 usec + queue 144785 usec + compute input 3469 usec + compute infer 139953 usec + compute output 148 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 42.8443 infer/sec, latency 316861 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13991.33
Median: 14392.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 265
    Throughput: 44.0969 infer/sec
    Avg latency: 342601 usec (standard deviation 71829 usec)
    p50 latency: 345757 usec
    p90 latency: 433930 usec
    p95 latency: 442361 usec
    p99 latency: 467876 usec
    Avg HTTP time: 342570 usec (send/recv 929 usec + response wait 341641 usec)
  Server: 
    Inference count: 265
    Execution count: 46
    Successful request count: 265
    Avg request latency: 316237 usec (overhead 524 usec + queue 170236 usec + compute input 3468 usec + compute infer 141847 usec + compute output 160 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 44.0969 infer/sec, latency 342601 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14132.50
Median: 14474.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 264
    Throughput: 43.925 infer/sec
    Avg latency: 363760 usec (standard deviation 69086 usec)
    p50 latency: 368785 usec
    p90 latency: 452268 usec
    p95 latency: 460375 usec
    p99 latency: 482492 usec
    Avg HTTP time: 363730 usec (send/recv 893 usec + response wait 362837 usec)
  Server: 
    Inference count: 264
    Execution count: 44
    Successful request count: 264
    Avg request latency: 338779 usec (overhead 742 usec + queue 189518 usec + compute input 4898 usec + compute infer 143458 usec + compute output 163 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 43.925 infer/sec, latency 363760 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13315.64
Median: 14536
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 262
    Throughput: 43.585 infer/sec
    Avg latency: 373367 usec (standard deviation 68988 usec)
    p50 latency: 381323 usec
    p90 latency: 466345 usec
    p95 latency: 473715 usec
    p99 latency: 519890 usec
    Avg HTTP time: 373333 usec (send/recv 3126 usec + response wait 370207 usec)
  Server: 
    Inference count: 262
    Execution count: 43
    Successful request count: 262
    Avg request latency: 343775 usec (overhead 613 usec + queue 194383 usec + compute input 3365 usec + compute infer 145254 usec + compute output 159 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 43.585 infer/sec, latency 373367 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13967.41
Median: 14352.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 271
    Throughput: 45.0926 infer/sec
    Avg latency: 397749 usec (standard deviation 56577 usec)
    p50 latency: 406396 usec
    p90 latency: 486006 usec
    p95 latency: 492306 usec
    p99 latency: 495646 usec
    Avg HTTP time: 397717 usec (send/recv 745 usec + response wait 396972 usec)
  Server: 
    Inference count: 271
    Execution count: 42
    Successful request count: 271
    Avg request latency: 378052 usec (overhead 998 usec + queue 223920 usec + compute input 3107 usec + compute infer 149883 usec + compute output 142 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 45.0926 infer/sec, latency 397749 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14050.58
Median: 14454
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_1058250000.csv
Combined CSV file created: power_measurement_stats_freq_1058250000.csv
---Setting GPU frequency to 1109250000---
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
Model: NVIDIA Jetson Xavier NX Developer Kit
GPU frequency set to 1109250000Hz.
---Setting concurrency to 1---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 1
  Client: 
    Request count: 192
    Throughput: 21.3092 infer/sec
    Avg latency: 46956 usec (standard deviation 1972 usec)
    p50 latency: 46755 usec
    p90 latency: 47347 usec
    p95 latency: 47814 usec
    p99 latency: 53920 usec
    Avg HTTP time: 46925 usec (send/recv 516 usec + response wait 46409 usec)
  Server: 
    Inference count: 192
    Execution count: 192
    Successful request count: 192
    Avg request latency: 37925 usec (overhead 155 usec + queue 268 usec + compute input 320 usec + compute infer 37114 usec + compute output 68 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 1, throughput: 21.3092 infer/sec, latency 46956 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 11805.04
Median: 12208.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 2---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 2 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 2
  Client: 
    Request count: 160
    Throughput: 26.6284 infer/sec
    Avg latency: 75174 usec (standard deviation 1520 usec)
    p50 latency: 74704 usec
    p90 latency: 76732 usec
    p95 latency: 77716 usec
    p99 latency: 81526 usec
    Avg HTTP time: 75144 usec (send/recv 599 usec + response wait 74545 usec)
  Server: 
    Inference count: 160
    Execution count: 160
    Successful request count: 160
    Avg request latency: 65740 usec (overhead 149 usec + queue 28270 usec + compute input 282 usec + compute infer 36970 usec + compute output 68 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 2, throughput: 26.6284 infer/sec, latency 75174 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13578.38
Median: 14229.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 3---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 3 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 3
  Client: 
    Request count: 186
    Throughput: 30.9544 infer/sec
    Avg latency: 95723 usec (standard deviation 8314 usec)
    p50 latency: 94694 usec
    p90 latency: 97087 usec
    p95 latency: 98952 usec
    p99 latency: 132037 usec
    Avg HTTP time: 95693 usec (send/recv 726 usec + response wait 94967 usec)
  Server: 
    Inference count: 186
    Execution count: 126
    Successful request count: 186
    Avg request latency: 82213 usec (overhead 197 usec + queue 31950 usec + compute input 378 usec + compute infer 49612 usec + compute output 75 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 3, throughput: 30.9544 infer/sec, latency 95723 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13746.41
Median: 14209.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 4---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 4 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 4
  Client: 
    Request count: 207
    Throughput: 34.4573 infer/sec
    Avg latency: 116478 usec (standard deviation 14845 usec)
    p50 latency: 114861 usec
    p90 latency: 117938 usec
    p95 latency: 152834 usec
    p99 latency: 169878 usec
    Avg HTTP time: 116450 usec (send/recv 577 usec + response wait 115873 usec)
  Server: 
    Inference count: 207
    Execution count: 108
    Successful request count: 207
    Avg request latency: 103741 usec (overhead 218 usec + queue 45771 usec + compute input 427 usec + compute infer 57249 usec + compute output 75 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 4, throughput: 34.4573 infer/sec, latency 116478 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13884.93
Median: 14352.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 5---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 5 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 5
  Client: 
    Request count: 216
    Throughput: 35.9399 infer/sec
    Avg latency: 137373 usec (standard deviation 25590 usec)
    p50 latency: 133569 usec
    p90 latency: 180189 usec
    p95 latency: 190815 usec
    p99 latency: 192270 usec
    Avg HTTP time: 137345 usec (send/recv 788 usec + response wait 136557 usec)
  Server: 
    Inference count: 216
    Execution count: 95
    Successful request count: 216
    Avg request latency: 123770 usec (overhead 260 usec + queue 54811 usec + compute input 1002 usec + compute infer 67609 usec + compute output 86 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 5, throughput: 35.9399 infer/sec, latency 137373 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14076.41
Median: 14495.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 6---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 6 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 6
  Client: 
    Request count: 227
    Throughput: 37.774 infer/sec
    Avg latency: 157713 usec (standard deviation 30515 usec)
    p50 latency: 152360 usec
    p90 latency: 210770 usec
    p95 latency: 215153 usec
    p99 latency: 248905 usec
    Avg HTTP time: 157686 usec (send/recv 874 usec + response wait 156812 usec)
  Server: 
    Inference count: 227
    Execution count: 83
    Successful request count: 227
    Avg request latency: 144871 usec (overhead 297 usec + queue 68142 usec + compute input 1390 usec + compute infer 74942 usec + compute output 99 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 6, throughput: 37.774 infer/sec, latency 157713 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14324.91
Median: 14781.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 7---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 7 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 7
  Client: 
    Request count: 235
    Throughput: 39.0955 infer/sec
    Avg latency: 176317 usec (standard deviation 36059 usec)
    p50 latency: 169681 usec
    p90 latency: 230114 usec
    p95 latency: 244355 usec
    p99 latency: 259788 usec
    Avg HTTP time: 176319 usec (send/recv 889 usec + response wait 175430 usec)
  Server: 
    Inference count: 237
    Execution count: 77
    Successful request count: 237
    Avg request latency: 161690 usec (overhead 313 usec + queue 78222 usec + compute input 1485 usec + compute infer 81566 usec + compute output 103 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 7, throughput: 39.0955 infer/sec, latency 176317 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14341.75
Median: 14801.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 8---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 8 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 8
  Client: 
    Request count: 247
    Throughput: 41.1012 infer/sec
    Avg latency: 195639 usec (standard deviation 42438 usec)
    p50 latency: 187161 usec
    p90 latency: 246069 usec
    p95 latency: 249284 usec
    p99 latency: 262258 usec
    Avg HTTP time: 195548 usec (send/recv 613 usec + response wait 194935 usec)
  Server: 
    Inference count: 242
    Execution count: 72
    Successful request count: 242
    Avg request latency: 178520 usec (overhead 339 usec + queue 85282 usec + compute input 1058 usec + compute infer 91735 usec + compute output 105 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 8, throughput: 41.1012 infer/sec, latency 195639 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 13841.62
Median: 14801.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 9---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 9 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 9
  Client: 
    Request count: 241
    Throughput: 40.1067 infer/sec
    Avg latency: 218982 usec (standard deviation 48220 usec)
    p50 latency: 209049 usec
    p90 latency: 269124 usec
    p95 latency: 286681 usec
    p99 latency: 313283 usec
    Avg HTTP time: 218949 usec (send/recv 1303 usec + response wait 217646 usec)
  Server: 
    Inference count: 241
    Execution count: 64
    Successful request count: 241
    Avg request latency: 199846 usec (overhead 405 usec + queue 97121 usec + compute input 3905 usec + compute infer 98262 usec + compute output 152 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 9, throughput: 40.1067 infer/sec, latency 218982 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14889.66
Median: 15148.50
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 10---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 10 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 10
  Client: 
    Request count: 250
    Throughput: 41.5984 infer/sec
    Avg latency: 236841 usec (standard deviation 57404 usec)
    p50 latency: 242293 usec
    p90 latency: 302416 usec
    p95 latency: 312960 usec
    p99 latency: 324361 usec
    Avg HTTP time: 236811 usec (send/recv 806 usec + response wait 236005 usec)
  Server: 
    Inference count: 250
    Execution count: 63
    Successful request count: 250
    Avg request latency: 212691 usec (overhead 546 usec + queue 92201 usec + compute input 3160 usec + compute infer 116635 usec + compute output 148 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 10, throughput: 41.5984 infer/sec, latency 236841 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14281.11
Median: 14985
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 11---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 11 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 11
  Client: 
    Request count: 270
    Throughput: 44.6499 infer/sec
    Avg latency: 242756 usec (standard deviation 52315 usec)
    p50 latency: 221838 usec
    p90 latency: 298932 usec
    p95 latency: 380100 usec
    p99 latency: 382181 usec
    Avg HTTP time: 242730 usec (send/recv 1387 usec + response wait 241343 usec)
  Server: 
    Inference count: 270
    Execution count: 56
    Successful request count: 270
    Avg request latency: 215817 usec (overhead 599 usec + queue 77601 usec + compute input 1395 usec + compute infer 136096 usec + compute output 125 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 11, throughput: 44.6499 infer/sec, latency 242756 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14613.91
Median: 15107.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
Failed to obtain stable measurement within 10 measurement windows for concurrency 12. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 12---
Running performance test
ERROR: exits as an instance (pid = 351033) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 273
    Throughput: 45.4347 infer/sec
    Avg latency: 265870 usec (standard deviation 60713 usec)
    p50 latency: 235327 usec
    p90 latency: 382837 usec
    p95 latency: 384439 usec
    p99 latency: 400554 usec
    Avg HTTP time: 265840 usec (send/recv 686 usec + response wait 265154 usec)
  Server: 
    Inference count: 273
    Execution count: 53
    Successful request count: 273
    Avg request latency: 240973 usec (overhead 547 usec + queue 99470 usec + compute input 1760 usec + compute infer 139050 usec + compute output 145 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 45.4347 infer/sec, latency 265870 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 12---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 12 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 12
  Client: 
    Request count: 275
    Throughput: 45.771 infer/sec
    Avg latency: 265489 usec (standard deviation 60754 usec)
    p50 latency: 227190 usec
    p90 latency: 382796 usec
    p95 latency: 384076 usec
    p99 latency: 399150 usec
    Avg HTTP time: 265452 usec (send/recv 638 usec + response wait 264814 usec)
  Server: 
    Inference count: 275
    Execution count: 54
    Successful request count: 275
    Avg request latency: 243271 usec (overhead 602 usec + queue 102815 usec + compute input 1399 usec + compute infer 138322 usec + compute output 132 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 12, throughput: 45.771 infer/sec, latency 265489 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14724.56
Median: 15107.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 13---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 13 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 13
  Client: 
    Request count: 265
    Throughput: 44.0382 infer/sec
    Avg latency: 288888 usec (standard deviation 67953 usec)
    p50 latency: 255056 usec
    p90 latency: 400916 usec
    p95 latency: 405115 usec
    p99 latency: 414431 usec
    Avg HTTP time: 288858 usec (send/recv 2633 usec + response wait 286225 usec)
  Server: 
    Inference count: 265
    Execution count: 51
    Successful request count: 265
    Avg request latency: 266929 usec (overhead 618 usec + queue 126074 usec + compute input 2110 usec + compute infer 137977 usec + compute output 149 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 13, throughput: 44.0382 infer/sec, latency 288888 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14630.00
Median: 15107
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 14---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 14 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 14
  Client: 
    Request count: 277
    Throughput: 46.0894 infer/sec
    Avg latency: 310887 usec (standard deviation 67517 usec)
    p50 latency: 314272 usec
    p90 latency: 409311 usec
    p95 latency: 417550 usec
    p99 latency: 433366 usec
    Avg HTTP time: 311257 usec (send/recv 788 usec + response wait 310469 usec)
  Server: 
    Inference count: 269
    Execution count: 49
    Successful request count: 270
    Avg request latency: 289935 usec (overhead 815 usec + queue 149495 usec + compute input 2224 usec + compute infer 137232 usec + compute output 168 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 14, throughput: 46.0894 infer/sec, latency 310887 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14836.87
Median: 15148.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 15---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 15 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 15
  Client: 
    Request count: 269
    Throughput: 44.7548 infer/sec
    Avg latency: 323921 usec (standard deviation 71086 usec)
    p50 latency: 335267 usec
    p90 latency: 418667 usec
    p95 latency: 423092 usec
    p99 latency: 428426 usec
    Avg HTTP time: 323888 usec (send/recv 2466 usec + response wait 321422 usec)
  Server: 
    Inference count: 269
    Execution count: 48
    Successful request count: 269
    Avg request latency: 299528 usec (overhead 602 usec + queue 160039 usec + compute input 2070 usec + compute infer 136661 usec + compute output 156 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 15, throughput: 44.7548 infer/sec, latency 323921 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14494.92
Median: 15148
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 16---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 16 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 16
  Client: 
    Request count: 280
    Throughput: 46.6052 infer/sec
    Avg latency: 348712 usec (standard deviation 64137 usec)
    p50 latency: 358307 usec
    p90 latency: 438612 usec
    p95 latency: 441242 usec
    p99 latency: 446575 usec
    Avg HTTP time: 348650 usec (send/recv 642 usec + response wait 348008 usec)
  Server: 
    Inference count: 280
    Execution count: 47
    Successful request count: 280
    Avg request latency: 329889 usec (overhead 1563 usec + queue 187503 usec + compute input 1909 usec + compute infer 138771 usec + compute output 143 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 16, throughput: 46.6052 infer/sec, latency 348712 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14701.62
Median: 15148.00
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
Failed to obtain stable measurement within 10 measurement windows for concurrency 17. Please try to increase the --measurement-request-count.
Failed to obtain stable measurement.
make: *** [makefile:163: measure_performance_and_power] Error 2
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
---Setting concurrency to 17---
Running performance test
ERROR: exits as an instance (pid = 351650) exists
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 194
    Throughput: 48.4127 infer/sec
    Avg latency: 361262 usec (standard deviation 60332 usec)
    p50 latency: 369842 usec
    p90 latency: 450504 usec
    p95 latency: 451192 usec
    p99 latency: 453136 usec
    Avg HTTP time: 361230 usec (send/recv 642 usec + response wait 360588 usec)
  Server: 
    Inference count: 194
    Execution count: 31
    Successful request count: 194
    Avg request latency: 334780 usec (overhead 791 usec + queue 190469 usec + compute input 1701 usec + compute infer 141689 usec + compute output 129 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 48.4127 infer/sec, latency 361262 usec
Error: Input file '/home/iloudaros/LoudVA/measurements/power/tegra_log' does not exist.
make: *** [makefile:164: measure_performance_and_power] Error 1
Error in the log file, exception raised
ðŸ”„ An error occured:Error in the log file Retrying...
rm: cannot remove '/home/iloudaros/LoudVA/measurements/power/tegra_log': No such file or directory
---Setting concurrency to 17---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 17 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 17
  Client: 
    Request count: 236
    Throughput: 47.0885 infer/sec
    Avg latency: 360742 usec (standard deviation 60117 usec)
    p50 latency: 368453 usec
    p90 latency: 449670 usec
    p95 latency: 451994 usec
    p99 latency: 454675 usec
    Avg HTTP time: 360716 usec (send/recv 665 usec + response wait 360051 usec)
  Server: 
    Inference count: 236
    Execution count: 38
    Successful request count: 236
    Avg request latency: 337306 usec (overhead 620 usec + queue 193928 usec + compute input 1615 usec + compute infer 141008 usec + compute output 135 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 17, throughput: 47.0885 infer/sec, latency 360742 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14354.52
Median: 15312
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
---Setting concurrency to 18---
Running performance test
*** Measurement Settings ***
  Batch size: 1
  Service Kind: Triton
  Using "count_windows" mode for stabilization
  Minimum number of samples in each window: 50
  Latency limit: 0 msec
  Concurrency limit: 18 concurrent requests
  Using synchronous calls for inference
  Stabilizing using average latency

Request concurrency: 18
  Client: 
    Request count: 272
    Throughput: 45.1762 infer/sec
    Avg latency: 379248 usec (standard deviation 63374 usec)
    p50 latency: 392800 usec
    p90 latency: 464836 usec
    p95 latency: 480057 usec
    p99 latency: 505565 usec
    Avg HTTP time: 379214 usec (send/recv 2401 usec + response wait 376813 usec)
  Server: 
    Inference count: 272
    Execution count: 43
    Successful request count: 272
    Avg request latency: 350787 usec (overhead 662 usec + queue 200456 usec + compute input 3927 usec + compute infer 145581 usec + compute output 160 usec)

Inferences/Second vs. Client Average Batch Latency
Concurrency: 18, throughput: 45.1762 infer/sec, latency 379248 usec
Extracted numbers from '/home/iloudaros/LoudVA/measurements/power/tegra_log' and saved them to '/home/iloudaros/LoudVA/measurements/power/power_measurement'
Mean: 14444.46
Median: 15556
Check /home/iloudaros/LoudVA/measurements/power/power_measurement_stats for the power measurements
Renaming the results
Combining the results
Combined CSV file created: performance_measurements_freq_1109250000.csv
Combined CSV file created: power_measurement_stats_freq_1109250000.csv
Returning to the default values
Restoring system configuration from /home/iloudaros/LoudVA/power_management/NX/jetsonclocks_conf.txt
